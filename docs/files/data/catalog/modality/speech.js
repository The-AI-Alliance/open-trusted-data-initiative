const data_for_modality_speech = 
[
	{"name":"speech-mendeley-pa","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tCredit - https://data.mendeley.com/datasets/sdbc8f5b77/2\n\t\n\n","url":"https://huggingface.co/datasets/aipanjab/speech-mendeley-pa","creator_name":"AI Panjab","creator_url":"https://huggingface.co/aipanjab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Panjabi","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"sample-id","keyword":"text-to-speech","description":"grandhigh/sample-id dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/grandhigh/sample-id","creator_name":"Reyhan Al","creator_url":"https://huggingface.co/grandhigh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Indonesian","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"TikTok_Hottest_Video_Transcript_Example","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tüì≤ Example Dataset: TikTok Scraper Tool\n\t\n\nüëâ Start Scraping TikTok: TikTok Scraper Tool\n\n\n\t\n\t\t\n\t\t‚ú® Key Features\n\t\n\n\n‚ö° Instant Transcription ‚Äì Turn any TikTok video into an AI-ready transcript  \nüéØ Metadata ‚Äì Get the title, language description, and video hashtags  \nüîó URL-Based Access ‚Äì Just drop in a TikTok video URL to start scraping  \nüß© LLM-Ready Output ‚Äì Receive clean JSON ready for agents, RAG, or AI tools  \nüí∏ Free Tier ‚Äì Use up to 100 queries during the beta period  \nüí´ Easy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/TikTok_Hottest_Video_Transcript_Example.","url":"https://huggingface.co/datasets/Gopher-Lab/TikTok_Hottest_Video_Transcript_Example","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"INDspeech","keyword":"text-to-speech","description":"dzakybd/INDspeech dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/dzakybd/INDspeech","creator_name":"Dzaky Zakiyal Fawwaz","creator_url":"https://huggingface.co/dzakybd","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Indonesian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"speech-brain-noise-evaluation-dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tSpeech Brain Noise Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 2,000 samples organized across multiple splits and 20 subsets.\nThe dataset includes audio data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tSubsets\n\t\n\nThis dataset includes the following subsets:\n\nnoisy-bg-snr-10: 100 samples\ntest: 100 samples\n\n\nnoisy-bg-snr-30: 100 samples\ntest: 100 samples\n\n\nnoisy-bg-snr-50: 100 samples\ntest: 100 samples\n\n\ndenoised-bg-snr-10: 100 samples\ntest: 100 samples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sujalappa/speech-brain-noise-evaluation-dataset.","url":"https://huggingface.co/datasets/sujalappa/speech-brain-noise-evaluation-dataset","creator_name":"sujal rajeev chondhekar","creator_url":"https://huggingface.co/sujalappa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"speech-brain-noise-evaluation-dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSpeech Brain Noise Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 2,000 samples organized across multiple splits and 20 subsets.\nThe dataset includes audio data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tSubsets\n\t\n\nThis dataset includes the following subsets:\n\nnoisy-bg-snr-10: 100 samples\ntest: 100 samples\n\n\nnoisy-bg-snr-30: 100 samples\ntest: 100 samples\n\n\nnoisy-bg-snr-50: 100 samples\ntest: 100 samples\n\n\ndenoised-bg-snr-10: 100 samples\ntest: 100 samples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sujalappa/speech-brain-noise-evaluation-dataset.","url":"https://huggingface.co/datasets/sujalappa/speech-brain-noise-evaluation-dataset","creator_name":"sujal rajeev chondhekar","creator_url":"https://huggingface.co/sujalappa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"sixuxar_yijiri_mak7","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Info\n\t\n\nThis dataset consists of paired audio and text data sourced from the following book:\n\nTitle: –ö—ä—ç—Ä–º–æ–∫—ä—É—ç –ú. –©–∏—Ö—É—Ö—ç—Ä –∏–¥–∂—ã—Ä–∏ –º—ç–∫I. –Ø–ø—ç —Ç—Ö—ã–ª—ä.\nPublication: –ù–∞–ª—å—á–∏–∫: –≠–ª—å–±—Ä—É—Å, 1999\n\n\n\t\n\t\t\n\t\tAudio Specifications\n\t\n\n\nSample Rate: 16,000 Hz\nTotal Length: 10:36:40\nSource: adigabook.ru\n\n\n\t\n\t\t\n\t\tProcessing Information\n\t\n\nAudio-text pairs for this dataset were extracted and aligned using META AI's forced alignment algorithm.\n","url":"https://huggingface.co/datasets/anzorq/sixuxar_yijiri_mak7","creator_name":"AQ","creator_url":"https://huggingface.co/anzorq","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Kabardian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"speech-brain-noise-evaluation-dataset","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tSpeech Brain Noise Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 2,000 samples organized across multiple splits and 20 subsets.\nThe dataset includes audio data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tSubsets\n\t\n\nThis dataset includes the following subsets:\n\nnoisy-bg-snr-10: 100 samples\ntest: 100 samples\n\n\nnoisy-bg-snr-30: 100 samples\ntest: 100 samples\n\n\nnoisy-bg-snr-50: 100 samples\ntest: 100 samples\n\n\ndenoised-bg-snr-10: 100 samples\ntest: 100 samples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sujalappa/speech-brain-noise-evaluation-dataset.","url":"https://huggingface.co/datasets/sujalappa/speech-brain-noise-evaluation-dataset","creator_name":"sujal rajeev chondhekar","creator_url":"https://huggingface.co/sujalappa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"sixuxar_yijiri_mak7","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Info\n\t\n\nThis dataset consists of paired audio and text data sourced from the following book:\n\nTitle: –ö—ä—ç—Ä–º–æ–∫—ä—É—ç –ú. –©–∏—Ö—É—Ö—ç—Ä –∏–¥–∂—ã—Ä–∏ –º—ç–∫I. –Ø–ø—ç —Ç—Ö—ã–ª—ä.\nPublication: –ù–∞–ª—å—á–∏–∫: –≠–ª—å–±—Ä—É—Å, 1999\n\n\n\t\n\t\t\n\t\tAudio Specifications\n\t\n\n\nSample Rate: 16,000 Hz\nTotal Length: 10:36:40\nSource: adigabook.ru\n\n\n\t\n\t\t\n\t\tProcessing Information\n\t\n\nAudio-text pairs for this dataset were extracted and aligned using META AI's forced alignment algorithm.\n","url":"https://huggingface.co/datasets/anzorq/sixuxar_yijiri_mak7","creator_name":"AQ","creator_url":"https://huggingface.co/anzorq","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Kabardian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"samromur_children_test","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for samromur_children\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Samr√≥mur Children Corpus consists of audio recordings and metadata files containing prompts read by the participants. It contains more than 137000 validated speech-recordings uttered by Icelandic children.\nThe corpus is a result of the crowd-sourcing effort run by the Language and Voice Lab (LVL) at the Reykjavik University, in cooperation with Almannar√≥mur, Center for Language Technology. The recording process has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ericwang/samromur_children_test.","url":"https://huggingface.co/datasets/Ericwang/samromur_children_test","creator_name":"Zhiyong Wang","creator_url":"https://huggingface.co/Ericwang","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ViHOS","keyword":"hate-speech-detection","description":"This is a dataset of Vietnamese Hate and Offensive Spans dataset from social media texts.","url":"https://huggingface.co/datasets/phusroyal/ViHOS","creator_name":"Phu Gia Hoang","creator_url":"https://huggingface.co/phusroyal","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","hate-speech-detection","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"messaih","keyword":"speech","description":"DATASET DESCRIPTION\nThe messAIh dataset is a fork of CMU MOSEI.\nUnlike its parent, MESSAIH is indended for unimodal model development and focusses exclusively on audio classification, more specifically, Speech Emotion Recognition (SER).\nOf course, it can be used for bimodal classification by transcribing each audio track.\nMESSAIH currently contains 13,234 speech samples annotated according to the CMU MOSEI scheme:\n\nEach sentence is annotated for sentiment on a [-3,3] Likert scale of:\n[‚àí3:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mirix/messaih.","url":"https://huggingface.co/datasets/mirix/messaih","creator_name":"Ed Moman","creator_url":"https://huggingface.co/mirix","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"libritts","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for LibriTTS\n\t\n\n\n\nLibriTTS is a multi-speaker English corpus of approximately 585 hours of read English speech at 24kHz sampling rate, \nprepared by Heiga Zen with the assistance of Google Speech and Google Brain team members. The LibriTTS corpus is \ndesigned for TTS research. It is derived from the original materials (mp3 audio files from LibriVox and text files \nfrom Project Gutenberg) of the LibriSpeech corpus.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the LibriTTS dataset, adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mythicinfinity/libritts.","url":"https://huggingface.co/datasets/mythicinfinity/libritts","creator_name":"Mythic Infinity","creator_url":"https://huggingface.co/mythicinfinity","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"common_voice_11_0","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 11.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Common Voice dataset consists of a unique MP3 and corresponding text file. \nMany of the 24210 recorded hours in the dataset also include demographic metadata like age, sex, and accent \nthat can help improve the accuracy of speech recognition engines.\nThe dataset currently consists of 16413 validated hours in 100 languages, but more voices and languages are always added. \nTake a look at the Languages page to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mozilla-foundation/common_voice_11_0.","url":"https://huggingface.co/datasets/mozilla-foundation/common_voice_11_0","creator_name":"Mozilla Foundation","creator_url":"https://huggingface.co/mozilla-foundation","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"ESLTTS","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tESLTTS\n\t\n\nThe full paper can be accessed here: arXiv, IEEE Xplore.\n\n\t\n\t\t\n\t\tDataset Access\n\t\n\nYou can access this dataset through Huggingface or Google Driver or IEEE Dataport.\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nWith the progress made in speaker-adaptive TTS approaches, advanced approaches have shown a remarkable capacity to reproduce the speaker‚Äôs voice in the commonly used TTS datasets. However, mimicking voices characterized by substantial accents, such as non-native English speakers, is still‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/ESLTTS.","url":"https://huggingface.co/datasets/MushanW/ESLTTS","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","English"],"keywords_longer_than_N":true},
	{"name":"jeli-asr","keyword":"automatic-speech-recognition","description":"The **Jeli-ASR Audio Dataset** is a multilingual dataset converted into the optimized Arrow format, \nensuring fast access and compatibility with modern data workflows. It contains audio samples in Bambara \nwith semi-expert transcriptions and French translations. Each subset of the dataset is organized by \nconfiguration (`jeli-asr-rmai`, `bam-asr-oza`, and `jeli-asr`) and further split into training and testing sets. \nThe dataset is designed for tasks like automatic speech recognition (ASR), text-to-speech synthesis (TTS), \nand translation. Data was recorded in Mali with griots, then transcribed and translated into French.\n","url":"https://huggingface.co/datasets/RobotsMali/jeli-asr","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","audio-language-identification","keyword-spotting"],"keywords_longer_than_N":true},
	{"name":"wiki_toxic","keyword":"hate-speech-detection","description":"Jigsaw Toxic Comment Challenge dataset. This dataset was the basis of a Kaggle competition run by Jigsaw","url":"https://huggingface.co/datasets/OxAISH-AL-LLM/wiki_toxic","creator_name":"OxAI Safety Hub Active Learning with Large Language Models Labs Team","creator_url":"https://huggingface.co/OxAISH-AL-LLM","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"jeli-asr","keyword":"text-to-speech","description":"The **Jeli-ASR Audio Dataset** is a multilingual dataset converted into the optimized Arrow format, \nensuring fast access and compatibility with modern data workflows. It contains audio samples in Bambara \nwith semi-expert transcriptions and French translations. Each subset of the dataset is organized by \nconfiguration (`jeli-asr-rmai`, `bam-asr-oza`, and `jeli-asr`) and further split into training and testing sets. \nThe dataset is designed for tasks like automatic speech recognition (ASR), text-to-speech synthesis (TTS), \nand translation. Data was recorded in Mali with griots, then transcribed and translated into French.\n","url":"https://huggingface.co/datasets/RobotsMali/jeli-asr","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","audio-language-identification","keyword-spotting"],"keywords_longer_than_N":true},
	{"name":"ha-tts-csv","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tHausa TTS Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Hausa language text-to-speech (TTS) recordings from multiple speakers. It includes audio files paired with their corresponding Hausa text transcriptions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized as follows:\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îú‚îÄ‚îÄ metadata.csv                    # Metadata (source, audio paths, text)\n‚îÇ   ‚îî‚îÄ‚îÄ audio_files/\n‚îÇ       ‚îú‚îÄ‚îÄ 97f373e8-f6e6-.../          # Speaker 1 audio files\n‚îÇ       ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aybee5/ha-tts-csv.","url":"https://huggingface.co/datasets/Aybee5/ha-tts-csv","creator_name":"Ibrahim Abdullahi","creator_url":"https://huggingface.co/Aybee5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","Hausa","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"hausa-tts-small","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tMimic Studio Hausa TTS Dataset\n\t\n\nThis dataset was created using Mimic Studio for training text-to-speech models.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nTotal Samples: 62\nLanguage: Hausa\nSpeakers: 2 speakers (Surajo Nuhu Umar, Umar Musa Halliru)\nFormat: Compatible with Unsloth TTS models\nAudio Format: WAV files, 24kHz sampling rate\n\n\n\t\n\t\t\n\t\tSpeaker Distribution\n\t\n\nSurajo Nuhu Umar     32\nUmar Musa Halliru    30\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nAybee5/hausa-tts-small/\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îú‚îÄ‚îÄ train.parquet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aybee5/hausa-tts-small.","url":"https://huggingface.co/datasets/Aybee5/hausa-tts-small","creator_name":"Ibrahim Abdullahi","creator_url":"https://huggingface.co/Aybee5","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Hausa","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"fleurs-hs","keyword":"speech","description":"\n\t\n\t\t\n\t\tFLEURS-HS\n\t\n\nAn extension of the FLEURS dataset for synthetic speech detection using text-to-speech, featured in the paper Synthetic speech detection with Wav2Vec 2.0 in various language settings.\nThis dataset is 1 of 3 used in the paper, the others being:\n\nFLEURS-HS VITS\ntest set containing (generally) more difficult synthetic samples\nseparated due to different licensing\n\n\nARCTIC-HS\nextension of the CMU_ARCTIC and L2-ARCTIC sets in a similar manner\n\n\n\n\t\n\t\t\n\t\tDataset Details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs.","url":"https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs","creator_name":"KONTXT by RealNetworks","creator_url":"https://huggingface.co/realnetworks-kontxt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","German","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"audio-testing","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\taudio-testing\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is a small, open dataset designed for quick validation of audio-related pipelines and applications, especially for Text-to-Speech (TTS) and Speech-to-Text (STT) systems.\nIt provides a few short, diverse audio clips and corresponding text transcripts, allowing developers to verify input/output handling, audio processing, and transcription logic without downloading large datasets.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\n3 short audio samples (.mp3, .wav)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JacobLinCool/audio-testing.","url":"https://huggingface.co/datasets/JacobLinCool/audio-testing","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"audio-testing","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\taudio-testing\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is a small, open dataset designed for quick validation of audio-related pipelines and applications, especially for Text-to-Speech (TTS) and Speech-to-Text (STT) systems.\nIt provides a few short, diverse audio clips and corresponding text transcripts, allowing developers to verify input/output handling, audio processing, and transcription logic without downloading large datasets.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\n3 short audio samples (.mp3, .wav)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JacobLinCool/audio-testing.","url":"https://huggingface.co/datasets/JacobLinCool/audio-testing","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"fleurs-hs","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tFLEURS-HS\n\t\n\nAn extension of the FLEURS dataset for synthetic speech detection using text-to-speech, featured in the paper Synthetic speech detection with Wav2Vec 2.0 in various language settings.\nThis dataset is 1 of 3 used in the paper, the others being:\n\nFLEURS-HS VITS\ntest set containing (generally) more difficult synthetic samples\nseparated due to different licensing\n\n\nARCTIC-HS\nextension of the CMU_ARCTIC and L2-ARCTIC sets in a similar manner\n\n\n\n\t\n\t\t\n\t\tDataset Details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs.","url":"https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs","creator_name":"KONTXT by RealNetworks","creator_url":"https://huggingface.co/realnetworks-kontxt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","German","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"libritts-phones-and-mel","keyword":"text-to-speech","description":"Dataset containing Mel Spectrograms, Prosody and Phone Alignments for the LibriTTS dataset.","url":"https://huggingface.co/datasets/cdminix/libritts-phones-and-mel","creator_name":"Christoph Minixhofer","creator_url":"https://huggingface.co/cdminix","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K<n<1M","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"speech-rj-hi","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tRajasthani Hindi Speech Dataset\n\t\n\n\nThis dataset consists of audio recordings of participants reading out stories in Rajasthani Hindi, one sentence at a time. We had 98 participants from Soda, Rajasthan. Each participant read 30 stories. In total, we have 426873 recordings in this dataset. We had roughly 58 male participants and 40 female participants.\n\nPoint to Note:\nWhile random sampling suggests that most users have to their best effort tried to accurately read out the sentences, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/severo/speech-rj-hi.","url":"https://huggingface.co/datasets/severo/speech-rj-hi","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Hindi","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"speech-rj-hi","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tRajasthani Hindi Speech Dataset\n\t\n\n\nThis dataset consists of audio recordings of participants reading out stories in Rajasthani Hindi, one sentence at a time. We had 98 participants from Soda, Rajasthan. Each participant read 30 stories. In total, we have 426873 recordings in this dataset. We had roughly 58 male participants and 40 female participants.\n\nPoint to Note:\nWhile random sampling suggests that most users have to their best effort tried to accurately read out the sentences, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/severo/speech-rj-hi.","url":"https://huggingface.co/datasets/severo/speech-rj-hi","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Hindi","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"peoples_speech","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for People's Speech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe People's Speech Dataset is among the world's largest English speech recognition corpus today that is licensed for academic and commercial usage under CC-BY-SA and CC-BY 4.0. It includes 30,000+ hours of transcribed speech in English languages with a diverse set of speakers. This open dataset is large enough to train speech-to-text systems and crucially is available with a permissive license.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MLCommons/peoples_speech.","url":"https://huggingface.co/datasets/MLCommons/peoples_speech","creator_name":"MLCommons","creator_url":"https://huggingface.co/MLCommons","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","machine-generated","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"everyayah","keyword":"automatic-speech-recognition","description":"Ô∑Ω\n\n\t\n\t\t\n\t\tDataset Card for Tarteel AI's EveryAyah Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of Quranic verses and their transcriptions, with diacritization, by different reciters.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is in Arabic.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nA typical data point comprises the audio file audio, and its transcription called text.\nThe duration is in seconds, and the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tarteel-ai/everyayah.","url":"https://huggingface.co/datasets/tarteel-ai/everyayah","creator_name":"Tarteel AI","creator_url":"https://huggingface.co/tarteel-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"peoples_speech","keyword":"speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for People's Speech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe People's Speech Dataset is among the world's largest English speech recognition corpus today that is licensed for academic and commercial usage under CC-BY-SA and CC-BY 4.0. It includes 30,000+ hours of transcribed speech in English languages with a diverse set of speakers. This open dataset is large enough to train speech-to-text systems and crucially is available with a permissive license.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MLCommons/peoples_speech.","url":"https://huggingface.co/datasets/MLCommons/peoples_speech","creator_name":"MLCommons","creator_url":"https://huggingface.co/MLCommons","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","machine-generated","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"Ergonomics_Chiar_Customer_Viewdata_E-commerse","keyword":"text-to-speech","description":"liaHa/Ergonomics_Chiar_Customer_Viewdata_E-commerse dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/liaHa/Ergonomics_Chiar_Customer_Viewdata_E-commerse","creator_name":"lia","creator_url":"https://huggingface.co/liaHa","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","zero-shot-classification","text-to-speech","English"],"keywords_longer_than_N":true},
	{"name":"telugu_asr_corpus","keyword":"automatic-speech-recognition","description":"The corpus contains roughly 360 hours of audio and transcripts in Telugu language. The transcripts have beed de-duplicated using exact match deduplication.","url":"https://huggingface.co/datasets/parambharat/telugu_asr_corpus","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","extended|openslr"],"keywords_longer_than_N":true},
	{"name":"quran-data","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Quran audio\n\t\n\nContent \n\n7 Imam Full Quran Recitation: 7*6236 wav file\ncsv contains the Text info for 11k subset short wav file\n\n\nTarteel.io user dataset ~25k wav\ncsv contains the Text info for 18k subset of the accepted user quality\n\n\n\n","url":"https://huggingface.co/datasets/ashraf-ali/quran-data","creator_name":"Ashraf Ali","creator_url":"https://huggingface.co/ashraf-ali","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Tarteel.io","cc0-1.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"nst-da","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for NST-da\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is an upload of the NST Danish ASR Database (16 kHz) ‚Äì reorganized.\nThe training and test splits are the original ones.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTraining automatic speech recognition is the intended task for this dataset. No leaderboard is active at this point.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is available in Danish (da).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\nSize of downloaded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/nst-da.","url":"https://huggingface.co/datasets/alexandrainst/nst-da","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Danish","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"nst-da","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for NST-da\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is an upload of the NST Danish ASR Database (16 kHz) ‚Äì reorganized.\nThe training and test splits are the original ones.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTraining automatic speech recognition is the intended task for this dataset. No leaderboard is active at this point.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is available in Danish (da).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\nSize of downloaded‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/nst-da.","url":"https://huggingface.co/datasets/alexandrainst/nst-da","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Danish","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"voxpopuli","keyword":"automatic-speech-recognition","description":"A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation.","url":"https://huggingface.co/datasets/distil-whisper/voxpopuli","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc0-1.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"dataset-mmb-v1","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tmabama-v6-audio Dataset\n\t\n\nEste dataset, mabama-v6-audio, est√° dise√±ado para tareas de text-to-speech (TTS) y contiene grabaciones de audio junto con sus correspondientes transcripciones en espa√±ol. Est√° dividido en tres partes: entrenamiento, prueba y validaci√≥n, permitiendo un desarrollo y evaluaci√≥n efectivos de modelos TTS.\n\n\t\n\t\t\n\t\tEstructura del Dataset\n\t\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nfile_name: Nombre del archivo de audio.\ntext: Transcripci√≥n del audio.\nspeaker_id: Identificador del‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gitgato/dataset-mmb-v1.","url":"https://huggingface.co/datasets/gitgato/dataset-mmb-v1","creator_name":"Git Porter","creator_url":"https://huggingface.co/gitgato","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Spanish","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"AniSpeech","keyword":"speech","description":"\n\t\n\t\t\n\t\tAniSpeech Dataset\n\t\n\nWelcome to the AniSpeech dataset, a continually expanding collection of captioned anime voices brought to you by ShoukanLabs.\n\nAs we label more and more audio, they'll automagically be uploaded here for use, seperated by language\n\n\n\n\t\n\t\t\n\t\tANNOUNCMENTS:\n\t\n\n\nAn upcoming update will add an immense ammount of data to the dataset... however... because we cannot manually go through this dataset we have had to rely on manual quality estimation, as such, speaker splits‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ShoukanLabs/AniSpeech.","url":"https://huggingface.co/datasets/ShoukanLabs/AniSpeech","creator_name":"ShoukanLabs","creator_url":"https://huggingface.co/ShoukanLabs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"AniSpeech","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tAniSpeech Dataset\n\t\n\nWelcome to the AniSpeech dataset, a continually expanding collection of captioned anime voices brought to you by ShoukanLabs.\n\nAs we label more and more audio, they'll automagically be uploaded here for use, seperated by language\n\n\n\n\t\n\t\t\n\t\tANNOUNCMENTS:\n\t\n\n\nAn upcoming update will add an immense ammount of data to the dataset... however... because we cannot manually go through this dataset we have had to rely on manual quality estimation, as such, speaker splits‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ShoukanLabs/AniSpeech.","url":"https://huggingface.co/datasets/ShoukanLabs/AniSpeech","creator_name":"ShoukanLabs","creator_url":"https://huggingface.co/ShoukanLabs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"AniSpeech","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tAniSpeech Dataset\n\t\n\nWelcome to the AniSpeech dataset, a continually expanding collection of captioned anime voices brought to you by ShoukanLabs.\n\nAs we label more and more audio, they'll automagically be uploaded here for use, seperated by language\n\n\n\n\t\n\t\t\n\t\tANNOUNCMENTS:\n\t\n\n\nAn upcoming update will add an immense ammount of data to the dataset... however... because we cannot manually go through this dataset we have had to rely on manual quality estimation, as such, speaker splits‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ShoukanLabs/AniSpeech.","url":"https://huggingface.co/datasets/ShoukanLabs/AniSpeech","creator_name":"ShoukanLabs","creator_url":"https://huggingface.co/ShoukanLabs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"pale","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset card for pale\n\t\n\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nThis dataset contains league of legends champions' quotes parsed from fandom.\nSee dataset viewer at the derivative repo.\nSee dataset usage example at google colab.\nThe dataset is available in the following configurations:\n\nvanilla - all data pulled from the website without significant modifications apart from the web page structure parsing;\nquotes - truncated version of the corpus, which does't contain sound effects;\nannotated - an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zeio/pale.","url":"https://huggingface.co/datasets/zeio/pale","creator_name":"zeionara","creator_url":"https://huggingface.co/zeio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","text-classification","automatic-speech-recognition","crowdsourced","English"],"keywords_longer_than_N":true},
	{"name":"voxceleb","keyword":"automatic-speech-recognition","description":"This dataset includes both VoxCeleb and VoxCeleb2\n\n\t\n\t\t\n\t\tMultipart Zips\n\t\n\nAlready joined zips for convenience but these specified files are NOT part of the original datasets\nvox2_mp4_1.zip - vox2_mp4_6.zip \nvox2_aac_1.zip - vox2_aac_2.zip \n\n\t\n\t\t\n\t\tJoining Zip\n\t\n\ncat vox1_dev* > vox1_dev_wav.zip\n\ncat vox2_dev_aac* > vox2_aac.zip\n\ncat vox2_dev_mp4* > vox2_mp4.zip\n\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@article{Nagrani19,\n    author = \"Arsha Nagrani and Joon~Son Chung and Weidi Xie and Andrew‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ProgramComputer/voxceleb.","url":"https://huggingface.co/datasets/ProgramComputer/voxceleb","creator_name":"Paul C","creator_url":"https://huggingface.co/ProgramComputer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","image-classification","video-classification","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"bengali_asr_corpus","keyword":"automatic-speech-recognition","description":"The corpus contains roughly 500 hours of audio and transcripts in Bangla language. \nThe transcripts have beed de-duplicated using exact match deduplication and audio has be converted to 16000 samples","url":"https://huggingface.co/datasets/parambharat/bengali_asr_corpus","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","extended|openslr"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_self_contained","keyword":"automatic-speech-recognition","description":"LibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\nprepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\naudiobooks from the LibriVox project, and has been carefully segmented and aligned.87","url":"https://huggingface.co/datasets/patrickvonplaten/librispeech_asr_self_contained","creator_name":"Patrick von Platen","creator_url":"https://huggingface.co/patrickvonplaten","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/fleurs.","url":"https://huggingface.co/datasets/google/fleurs","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"speech-recognition","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/fleurs.","url":"https://huggingface.co/datasets/google/fleurs","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"TikTok_Most_Shared_Video_Transcription_Example","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tüì≤ Example Dataset: TikTok Scraper Tool\n\t\n\nüëâ Start Scraping TikTok: TikTok Scraper Tool\n\n\n\t\n\t\t\n\t\t‚ú® Key Features\n\t\n\n\n‚ö° Instant Transcription ‚Äì Turn any TikTok video into an AI-ready transcript  \nüéØ Metadata ‚Äì Get the title, language description, and video hashtags  \nüîó URL-Based Access ‚Äì Just drop in a TikTok video URL to start scraping  \nüß© LLM-Ready Output ‚Äì Receive clean JSON ready for agents, RAG, or AI tools  \nüí∏ Free Tier ‚Äì Use up to 100 queries during the beta period  \nüí´ Easy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/TikTok_Most_Shared_Video_Transcription_Example.","url":"https://huggingface.co/datasets/Gopher-Lab/TikTok_Most_Shared_Video_Transcription_Example","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"fttrtest","keyword":"speech","description":"\n\t\n\t\t\n\t\tFTTRTEST\n\t\n\nThis is a merged speech dataset containing 1293 audio segments from 5 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 1293\nSpeakers: 7\nLanguages: tr\nEmotions: happy, angry, neutral\nOriginal Datasets: 5\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nlanguage: Language code (en‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/fttrtest.","url":"https://huggingface.co/datasets/Codyfederer/fttrtest","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"fttrtest","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tFTTRTEST\n\t\n\nThis is a merged speech dataset containing 1293 audio segments from 5 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 1293\nSpeakers: 7\nLanguages: tr\nEmotions: happy, angry, neutral\nOriginal Datasets: 5\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nlanguage: Language code (en‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/fttrtest.","url":"https://huggingface.co/datasets/Codyfederer/fttrtest","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"fttrtest","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tFTTRTEST\n\t\n\nThis is a merged speech dataset containing 1293 audio segments from 5 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 1293\nSpeakers: 7\nLanguages: tr\nEmotions: happy, angry, neutral\nOriginal Datasets: 5\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nlanguage: Language code (en‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/fttrtest.","url":"https://huggingface.co/datasets/Codyfederer/fttrtest","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"sayoko-tts-corpus","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\t„Çµ„É®Â≠ê Èü≥Â£∞„Ç≥„Éº„Éë„Çπ\n\t\n\n\n\t\n\t\t\n\t\t„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÊñπÊ≥ï\n\t\n\n„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÇíÂúßÁ∏Æ„Åó„Åüzip„Éï„Ç°„Ç§„É´„Çí„ÄÅgdrive„Å´ÁΩÆ„ÅÑ„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n„Åæ„Åü„ÄÅ‰ª•‰∏ã„ÅÆ„Çπ„ÇØ„É™„Éó„Éà„Åß„ÄÅhuggingface hub„Åã„Çâ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„ÇÇÂèØËÉΩ„Åß„Åô„ÄÇ\n# pip install --upgrade huggingface_hub\nfrom huggingface_hub import snapshot_download\n\nsnapshot_download(repo_id=\"bandad/sayoko-tts-corpus\", repo_type=\"dataset\", revision=\"main\", local_dir=\"./sayoko-tts-corpus\")\n\n\n\t\n\t\t\n\t\tÊ¶ÇË¶Å\n\t\n\n81Ê≠≥„ÅÆÂ•≥ÊÄß„ÅÆÈü≥Â£∞„Ç≥„Éº„Éë„Çπ„Åß„Åô„ÄÇ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bandad/sayoko-tts-corpus.","url":"https://huggingface.co/datasets/bandad/sayoko-tts-corpus","creator_name":"kai washizaki","creator_url":"https://huggingface.co/bandad","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Japanese","cc-by-4.0","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"VoxDIY-RusNews","keyword":"automatic-speech-recognition","description":"VoxDIY:  Benchmark Dataset for Russian Crowdsourced Audio Transcription.","url":"https://huggingface.co/datasets/toloka/VoxDIY-RusNews","creator_name":"Toloka","creator_url":"https://huggingface.co/toloka","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","automatic-speech-recognition","found","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"ami-ihm","keyword":"automatic-speech-recognition","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\nnon-native speakers. \\n","url":"https://huggingface.co/datasets/distil-whisper/ami-ihm","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"snips_slu_v1.0","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for SNIPS SLU v1.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains SNIPS SLU Speech Recognition Dataset, available here.\nIt contains recordings of commands for smart home appliances in English, with info about demographics of the speaker.\n","url":"https://huggingface.co/datasets/MWilinski/snips_slu_v1.0","creator_name":"Micha≈Ç Wili≈Ñski","creator_url":"https://huggingface.co/MWilinski","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"peoples_speech_v1.0","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for People's Speech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe People's Speech Dataset is among the world's largest English speech recognition corpus today that is licensed for academic and commercial usage under CC-BY-SA and CC-BY 4.0. It includes 30,000+ hours of transcribed speech in English languages with a diverse set of speakers. This open dataset is large enough to train speech-to-text systems and crucially is available with a permissive license.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MLCommons/peoples_speech_v1.0.","url":"https://huggingface.co/datasets/MLCommons/peoples_speech_v1.0","creator_name":"MLCommons","creator_url":"https://huggingface.co/MLCommons","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","machine-generated","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"VoxDIY-RusNews","keyword":"speech-recognition","description":"VoxDIY:  Benchmark Dataset for Russian Crowdsourced Audio Transcription.","url":"https://huggingface.co/datasets/toloka/VoxDIY-RusNews","creator_name":"Toloka","creator_url":"https://huggingface.co/toloka","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","automatic-speech-recognition","found","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"tts-quantized-dataset","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tüó£Ô∏è tts-quantized-dataset\n\t\n\nThis dataset contains quantized Hindi Text-to-Speech (TTS) samples generated using NVIDIA‚Äôs nemo-nano-codec-22khz-0.6kbps-12.5fps neural audio codec.It is designed for training lightweight speech synthesis models, such as token-based TTS models, audio language models, or text-to-codec models.\n\n\t\n\t\t\n\t\n\t\n\t\tüìö Dataset Summary\n\t\n\n\n\t\n\t\t\nField\nDescription\n\n\n\t\t\ntext\nThe transcription (Hindi text) corresponding to each audio sample.\n\n\nspeaker\nSpeaker identity‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArunKr/tts-quantized-dataset.","url":"https://huggingface.co/datasets/ArunKr/tts-quantized-dataset","creator_name":"Arun Kumar Tiwary","creator_url":"https://huggingface.co/ArunKr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Hindi","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"CrowdSpeech","keyword":"automatic-speech-recognition","description":"CrowdSpeech is a publicly available large-scale dataset of crowdsourced audio transcriptions. It contains annotations for more than 50 hours of English speech transcriptions from more than 1,000 crowd workers.","url":"https://huggingface.co/datasets/toloka/CrowdSpeech","creator_name":"Toloka","creator_url":"https://huggingface.co/toloka","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","automatic-speech-recognition","found","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"common_voice_13_0-timestamped","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDistil Whisper: Common Voice 13 With Timestamps\n\t\n\nThis is a variant of the Common Voice 13 dataset, augmented to return the pseudo-labelled Whisper \nTranscriptions alongside the original dataset elements. The pseudo-labelled transcriptions were generated by \nlabelling the input audio data with the Whisper large-v2\nmodel with greedy sampling and timestamp prediction. For information on how the original dataset was curated, refer to the original \ndataset card.\n\n\t\n\t\n\t\n\t\tStandalone Usage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/distil-whisper/common_voice_13_0-timestamped.","url":"https://huggingface.co/datasets/distil-whisper/common_voice_13_0-timestamped","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc0-1.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"CrowdSpeech","keyword":"speech-recognition","description":"CrowdSpeech is a publicly available large-scale dataset of crowdsourced audio transcriptions. It contains annotations for more than 50 hours of English speech transcriptions from more than 1,000 crowd workers.","url":"https://huggingface.co/datasets/toloka/CrowdSpeech","creator_name":"Toloka","creator_url":"https://huggingface.co/toloka","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["summarization","automatic-speech-recognition","found","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"hungarian-single-speaker-tts","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for CSS10 Hungarian: Single Speaker Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe corpus consists of a single speaker, with 4515 segments extracted\nfrom a single LibriVox audiobook.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is in Hungarian.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tData Splits‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KTH/hungarian-single-speaker-tts.","url":"https://huggingface.co/datasets/KTH/hungarian-single-speaker-tts","creator_name":"KTH","creator_url":"https://huggingface.co/KTH","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","other","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ParsiGoo","keyword":"text-to-speech","description":"A Persian multispeaker dataset for text-to-speech purposes.","url":"https://huggingface.co/datasets/Kamtera/ParsiGoo","creator_name":"Flincer","creator_url":"https://huggingface.co/Kamtera","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","other","monolingual","original","Persian"],"keywords_longer_than_N":true},
	{"name":"4catac","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for 4catac\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n4catac: examples of phonetic transcription in 4  Catalan accents is a dataset of phonetic transcriptions in four Catalan accents: Balearic, Central, North-Western and Valencian. \nIt consists of 160 sentences transcribed using IPA, following the recommendations of the Institut d'Estudis Catalans.\nThese sentences are the same for the four accents but may have small morphological adaptations to make them more natural for the accent.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/4catac.","url":"https://huggingface.co/datasets/projecte-aina/4catac","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","expert-generated","expert-generated","monolingual","Catalan"],"keywords_longer_than_N":true},
	{"name":"speechocean762","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tspeechocean762: A non-native English corpus for pronunciation scoring task\n\t\n\n\n\t\n\t\t\n\t\tHow to use?\n\t\n\nyou can load data using\nspeechocean762_dataset = load_dataset('seba3y/speechocean762')\n\n>> speechocean762_dataset\nDatasetDict({\n    train: Dataset({\n        features: ['spk', 'age', 'gender', 'utt_name', 'audio', 'utt_text', 'utt_accuracy', 'utt_completeness', 'utt_fluency', 'utt_prosodic', 'utt_total', 'words', 'words_accuracy', 'words_stress', 'words_total', 'phones'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/seba3y/speechocean762.","url":"https://huggingface.co/datasets/seba3y/speechocean762","creator_name":"Elsebaiy mohamed","creator_url":"https://huggingface.co/seba3y","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"PolishCyberbullyingDataset","keyword":"hate-speech","description":"\n\t\n\t\t\n\t\tExpert-annotated dataset to study cyberbullying in Polish language\n\t\n\nThis the first publically available expert-annotated dataset containing annotations of cyberbullying and hate-speech in Polish language.\nPlease, read the paper about the dataset for all necessary details.\n\n\t\n\t\t\n\t\tModel\n\t\n\nThe classification model which achieved the highest classification results for the dataset is also released under the following URL.\nPolbert-CB - Polish BERT trained for Automatic Cyberbullying‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ptaszynski/PolishCyberbullyingDataset.","url":"https://huggingface.co/datasets/ptaszynski/PolishCyberbullyingDataset","creator_name":"Michal Ptaszynski","creator_url":"https://huggingface.co/ptaszynski","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Polish","cc-by-4.0","10K - 100K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"gahd","keyword":"hate-speech","description":"\n\t\n\t\t\n\t\tDataset Card for GAHD\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nGAHD is a German Adversarial Hate speech Dataset containing 10,996 examples. We collected the dataset via four rounds of Dynamic Adversarial Data Collection and explored various methods of supporting annotators in finding adversarial examples.\n\nPaper: https://aclanthology.org/2024.naacl-long.248/\nRepository: https://github.com/jagol/gahd\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\ngahd.csv contains the following columns:\n\ngahd_id: unique‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jagoldz/gahd.","url":"https://huggingface.co/datasets/jagoldz/gahd","creator_name":"Janis Goldzycher","creator_url":"https://huggingface.co/jagoldz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","cc-by-4.0","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"gahd","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for GAHD\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nGAHD is a German Adversarial Hate speech Dataset containing 10,996 examples. We collected the dataset via four rounds of Dynamic Adversarial Data Collection and explored various methods of supporting annotators in finding adversarial examples.\n\nPaper: https://aclanthology.org/2024.naacl-long.248/\nRepository: https://github.com/jagol/gahd\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\ngahd.csv contains the following columns:\n\ngahd_id: unique‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jagoldz/gahd.","url":"https://huggingface.co/datasets/jagoldz/gahd","creator_name":"Janis Goldzycher","creator_url":"https://huggingface.co/jagoldz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","cc-by-4.0","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"NewsLensSync","keyword":"text-to-speech","description":"sparklessszzz/NewsLensSync dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sparklessszzz/NewsLensSync","creator_name":"Anonymous","creator_url":"https://huggingface.co/sparklessszzz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","question-answering","summarization","sentence-similarity"],"keywords_longer_than_N":true},
	{"name":"BanglaEnglishMixedAsrDataset","keyword":"automatic-speech-recognition","description":"akhikhan123/BanglaEnglishMixedAsrDataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/akhikhan123/BanglaEnglishMixedAsrDataset","creator_name":"Fatema Tuz Zohra Akhi","creator_url":"https://huggingface.co/akhikhan123","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","Bengali","mit","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"arabic_speech_corpus","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Arabic Speech Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis Speech corpus has been developed as part of PhD work carried out by Nawar Halabi at the University of Southampton. The corpus was recorded in south Levantine Arabic (Damascian accent) using a professional studio. Synthesized speech as an output using this corpus has produced a high quality, natural voice.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunis-ai/arabic_speech_corpus.","url":"https://huggingface.co/datasets/tunis-ai/arabic_speech_corpus","creator_name":"Tunisia.AI","creator_url":"https://huggingface.co/tunis-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"rulibrispeech","keyword":"speech","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nwav 16kHz\n\n\t\n\t\t\n\t\tüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n\t\n\n\n\t\n\t\t\n\t\t–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Å–ø–ª–∏—Ç–∞–º\n\t\n\n\n\t\n\t\t\n\t\tüîπ –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –Ω–∞–±–æ—Ä (train)\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–º–ø–ª–æ–≤\n54,472\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n92.79 —á–∞—Å–æ–≤ (334028.33 —Å–µ–∫—É–Ω–¥)\n\n\n–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–º–ø–ª–∞\n6.13 —Å–µ–∫—É–Ω–¥\n\n\n\t\n\n\n\t\n\t\t\n\t\tüîπ –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä (validate)\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–º–ø–ª–æ–≤\n1,400\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n2.81 —á–∞—Å–æ–≤ (10105.46 —Å–µ–∫—É–Ω–¥)\n\n\n–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–º–ø–ª–∞\n7.22‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sh1man/rulibrispeech.","url":"https://huggingface.co/datasets/Sh1man/rulibrispeech","creator_name":"dd","creator_url":"https://huggingface.co/Sh1man","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Russian","cc-by-4.0","10K - 100K","webdataset","Audio"],"keywords_longer_than_N":true},
	{"name":"telegu_audio_dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tTelegu Language Audio Dataset\n\t\n\nText spoken by all participants:\n\"‡∞ï‡±É‡∞§‡±ç‡∞∞‡∞ø‡∞Æ ‡∞Æ‡±á‡∞ß‡∞∏‡±ç‡∞∏‡±Å (AI) ‡∞µ‡±á‡∞ó‡∞Ç‡∞ó‡∞æ ‡∞Ö‡∞≠‡∞ø‡∞µ‡±É‡∞¶‡±ç‡∞ß‡∞ø ‡∞ö‡±Ü‡∞Ç‡∞¶‡±Å‡∞§‡±ã‡∞Ç‡∞¶‡∞ø, ‡∞∞‡±ã‡∞ú‡±Å‡∞µ‡∞æ‡∞∞‡±Ä ‡∞ú‡±Ä‡∞µ‡∞ø‡∞§‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡±á‡∞∏‡±ç‡∞§‡±ã‡∞Ç‡∞¶‡∞ø. ‡∞¶‡±Ä‡∞®‡∞ø ‡∞Ü‡∞µ‡∞ø‡∞∑‡±ç‡∞ï‡∞∞‡∞£‡∞≤‡±Å ‡∞µ‡∞ø‡∞¶‡±ç‡∞Ø, ‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø ‡∞∏‡∞Ç‡∞∞‡∞ï‡±ç‡∞∑‡∞£ ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞™‡∞®‡∞ø‡∞®‡∞ø ‡∞Æ‡±Ü‡∞∞‡±Å‡∞ó‡±Å‡∞™‡∞∞‡±Å‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø, ‡∞ï‡±ä‡∞§‡±ç‡∞§ ‡∞Ö‡∞µ‡∞ï‡∞æ‡∞∂‡∞æ‡∞≤‡∞®‡±Å ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø‡•§\"\nThe dataset supports training and evaluation of models in:\n\nAutomatic Speech Recognition (ASR)\nEmotional tone classification\nVoice synthesis and generation\nEmotion-aware conversational agents\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntended Uses‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/telegu_audio_dataset.","url":"https://huggingface.co/datasets/Kratos-AI/telegu_audio_dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Telugu","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"common_voice_13_0_dv_preprocessed","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 13.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Common Voice dataset consists of a unique MP3 and corresponding text file. \nMany of the 27141 recorded hours in the dataset also include demographic metadata like age, sex, and accent \nthat can help improve the accuracy of speech recognition engines.\nThe dataset currently consists of 17689 validated hours in 108 languages, but more voices and languages are always added. \nTake a look at the Languages page to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fmagot01/common_voice_13_0_dv_preprocessed.","url":"https://huggingface.co/datasets/fmagot01/common_voice_13_0_dv_preprocessed","creator_name":"Francisco Magot","creator_url":"https://huggingface.co/fmagot01","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"jsonl-mls-speechtokenizer","keyword":"automatic-speech-recognition","description":"anilkeshwani/jsonl-mls-speechtokenizer dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/anilkeshwani/jsonl-mls-speechtokenizer","creator_name":"Anil Keshwani","creator_url":"https://huggingface.co/anilkeshwani","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"jsonl-mls-speechtokenizer","keyword":"text-to-speech","description":"anilkeshwani/jsonl-mls-speechtokenizer dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/anilkeshwani/jsonl-mls-speechtokenizer","creator_name":"Anil Keshwani","creator_url":"https://huggingface.co/anilkeshwani","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"CanaryAura","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for \"Canary Aura\"\n\t\n\nThis is a dataset for...\n","url":"https://huggingface.co/datasets/nkazi/CanaryAura","creator_name":"Nazmul Kazi","creator_url":"https://huggingface.co/nkazi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"LoquaciousSet","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tLargeScaleASR: 25,000 hours of transcribed and heterogeneous English speech recognition data for research and commercial use.\n\t\n\nThe full details are available in the paper.\nMade of 6 subsets:\n\nlarge contains 25,000 hours of read / spontaneous and clean / noisy transcribed speech.\nmedium contains 2,500 hours of read / spontaneous and clean / noisy transcribed speech.\nsmall contains 250 hours of read / spontaneous and clean / noisy transcribed speech.\nclean contains 13,000 hours of read‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speechbrain/LoquaciousSet.","url":"https://huggingface.co/datasets/speechbrain/LoquaciousSet","creator_name":"SpeechBrain","creator_url":"https://huggingface.co/speechbrain","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","machine-generated","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"mabama-v6-audio","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tmabama-v6-audio Dataset\n\t\n\nEste dataset, mabama-v6-audio, est√° dise√±ado para tareas de text-to-speech (TTS) y contiene grabaciones de audio junto con sus correspondientes transcripciones en espa√±ol. Est√° dividido en tres partes: entrenamiento, prueba y validaci√≥n, permitiendo un desarrollo y evaluaci√≥n efectivos de modelos TTS.\n\n\t\n\t\t\n\t\tEstructura del Dataset\n\t\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nfile_name: Nombre del archivo de audio.\ntext: Transcripci√≥n del audio.\nspeaker_id: Identificador del‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ovieyra21/mabama-v6-audio.","url":"https://huggingface.co/datasets/ovieyra21/mabama-v6-audio","creator_name":"Oma Vieyra","creator_url":"https://huggingface.co/ovieyra21","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Spanish","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"LoquaciousSet","keyword":"speech-recognition","description":"\n\t\n\t\t\n\t\tLargeScaleASR: 25,000 hours of transcribed and heterogeneous English speech recognition data for research and commercial use.\n\t\n\nThe full details are available in the paper.\nMade of 6 subsets:\n\nlarge contains 25,000 hours of read / spontaneous and clean / noisy transcribed speech.\nmedium contains 2,500 hours of read / spontaneous and clean / noisy transcribed speech.\nsmall contains 250 hours of read / spontaneous and clean / noisy transcribed speech.\nclean contains 13,000 hours of read‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speechbrain/LoquaciousSet.","url":"https://huggingface.co/datasets/speechbrain/LoquaciousSet","creator_name":"SpeechBrain","creator_url":"https://huggingface.co/speechbrain","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","machine-generated","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-3lang-raw","keyword":"speech","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (3 Languages, Raw)\n\t\n\nThis dataset is a curated subset of previously published speech command datasets in Kazakh, Tatar, and Russian. It is intended for use in multilingual speech command recognition and keyword spotting tasks. No data augmentation has been applied.\nAll files are included in their original form as released in the cited works below. This repository simply reorganizes them for convenience and accessibility.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-3lang-raw.","url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-3lang-raw","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Kazakh","Tatar","Russian","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_parquet_10k","keyword":"speech","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (10k)\n\t\n\nThis dataset contains 20000 synthetic speech recordings in the Pashto language,\nwith 10000 male voice recordings and 10000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 10000 sentences\nTotal Recordings: 20000 audio files (10000 male + 10000 female)\nAudio Format: WAV, 44.1kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 44.1kHz‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_parquet_10k.","url":"https://huggingface.co/datasets/ihanif/pashto_speech_parquet_10k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_parquet_10k","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (10k)\n\t\n\nThis dataset contains 20000 synthetic speech recordings in the Pashto language,\nwith 10000 male voice recordings and 10000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 10000 sentences\nTotal Recordings: 20000 audio files (10000 male + 10000 female)\nAudio Format: WAV, 44.1kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 44.1kHz‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_parquet_10k.","url":"https://huggingface.co/datasets/ihanif/pashto_speech_parquet_10k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"0.1_augmented_hate_speech_dataset","keyword":"hate-speech","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is a public release of the dataset described in Kennedy et al. (2020) and Sachdeva et al. (2022) and augmented by Adar and Wiberg (2025).\nThis dataset card is a work in progress and will be improved over time.\n\n\t\n\t\t\n\t\tContributions\n\t\n\nDataset curated by @ck37, @pssachdeva and augmented by @emradar and @Wiberacci.\n\n\t\n\t\t\n\t\tReferences\n\t\n\nKennedy, C. J., Bacon, G., Sahn, A., & von Vacano, C. (2020). Constructing interval variables via faceted Rasch measurement and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/emradar/0.1_augmented_hate_speech_dataset.","url":"https://huggingface.co/datasets/emradar/0.1_augmented_hate_speech_dataset","creator_name":"Emir Adar","creator_url":"https://huggingface.co/emradar","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","arxiv:2009.10277","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"tts-crh-abibullah","keyword":"text-to-speech","description":" \n\n\n\t\n\t\t\n\t\tOpen Source Crimean Tatar Text-to-Speech datasets\n\t\n\nThis is subset of Abibullah voice with train/test splits.\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\nQuality: high\nDuration: 2h50m\nFrequency: 48 kHz\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { qirimtatar-tts (Revision c2ceec6)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/tts-crh-abibullah.","url":"https://huggingface.co/datasets/speech-uk/tts-crh-abibullah","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Crimean Tatar","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Granary","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tGranary: Speech Recognition and Translation Dataset in 25 European Languages\n\t\n\nGranary is a large-scale, open-source multilingual speech dataset covering 25 European languages for Automatic Speech Recognition (ASR) and Automatic Speech Translation (AST) tasks. \n\n\n\n\t\n\t\t\n\n\n\n\n\t\t\n\n\n\n\n\t\n\n\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nGranary addresses the scarcity of high-quality speech data for low-resource languages by consolidating multiple datasets under a unified framework:\nüó£Ô∏è ~1M hours of high-quality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/Granary.","url":"https://huggingface.co/datasets/nvidia/Granary","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","Bulgarian","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"bigbench","keyword":"hate-speech-detection","description":"BIG-Bench but it doesn't require the hellish dependencies (tensorflow, pypi-bigbench, protobuf) of the official version.\ndataset = load_dataset(\"tasksource/bigbench\",'movie_recommendation')\n\nCode to reproduce:\nhttps://colab.research.google.com/drive/1MKdLdF7oqrSQCeavAcsEnPdI85kD0LzU?usp=sharing\nDatasets are capped to 50k examples to keep things light.\nI also removed the default split when train was available also to save space, as default=train+val.\n@article{srivastava2022beyond‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tasksource/bigbench.","url":"https://huggingface.co/datasets/tasksource/bigbench","creator_name":"tasksource","creator_url":"https://huggingface.co/tasksource","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","text-generation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"opentts-uk-aesthetics","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tAesthetics of Open Text-to-Speech for üá∫üá¶ Ukrainian dataset\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis dataset contains metrics for https://huggingface.co/datasets/Yehor/opentts-uk dataset retrieved by https://github.com/facebookresearch/audiobox-aesthetics \n\n\t\n\t\t\n\t\tHow metrics calculated?\n\t\n\nYou can find a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Yehor/opentts-uk-aesthetics.","url":"https://huggingface.co/datasets/Yehor/opentts-uk-aesthetics","creator_name":"Smoliakov","creator_url":"https://huggingface.co/Yehor","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"mls_sidon","keyword":"speech","description":"\n\t\n\t\t\n\t\tMLS-Sidon\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is a cleansed version of Multilingual LibriSpeech (MLS) with Sidon speech restoration mode for Speech Synthesis and Spoken Language Modeling.  \nThe dataset is provided in WebDataset format for efficient large-scale training.  \n\nSource: Multilingual LibriSpeech\nLanguages: English, German, French, Spanish, Italian, Portuguese, Polish, Dutch  \nFormat: WebDataset (.tar shards)  \nLicense: CC-BY-4.0\n\n\n\n\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nEach sample in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sarulab-speech/mls_sidon.","url":"https://huggingface.co/datasets/sarulab-speech/mls_sidon","creator_name":"SaruLab Speech group","creator_url":"https://huggingface.co/sarulab-speech","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","English","French","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"mixed_shona_dataset","keyword":"automatic-speech-recognition","description":"Kittech/mixed_shona_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Kittech/mixed_shona_dataset","creator_name":"Bright Chirindo","creator_url":"https://huggingface.co/Kittech","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","automatic-speech-recognition","Shona","English"],"keywords_longer_than_N":true},
	{"name":"mls_sidon","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tMLS-Sidon\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is a cleansed version of Multilingual LibriSpeech (MLS) with Sidon speech restoration mode for Speech Synthesis and Spoken Language Modeling.  \nThe dataset is provided in WebDataset format for efficient large-scale training.  \n\nSource: Multilingual LibriSpeech\nLanguages: English, German, French, Spanish, Italian, Portuguese, Polish, Dutch  \nFormat: WebDataset (.tar shards)  \nLicense: CC-BY-4.0\n\n\n\n\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nEach sample in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sarulab-speech/mls_sidon.","url":"https://huggingface.co/datasets/sarulab-speech/mls_sidon","creator_name":"SaruLab Speech group","creator_url":"https://huggingface.co/sarulab-speech","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","English","French","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"CSEMOTIONS","keyword":"speech","description":"\n\t\n\t\t\n\t\tCSEMOTIONS: High-Quality Mandarin Emotional Speech Dataset\n\t\n\nPaper | Code\n\nCSEMOTIONS is a high-quality Mandarin emotional speech dataset designed for expressive speech synthesis, emotion recognition, and voice cloning research. The dataset contains studio-quality recordings from six professional voice actors across seven carefully curated emotional categories, supporting research in controllable and natural language speech generation.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\n\nName: CSEMOTIONS‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AIDC-AI/CSEMOTIONS.","url":"https://huggingface.co/datasets/AIDC-AI/CSEMOTIONS","creator_name":"AIDC-AI","creator_url":"https://huggingface.co/AIDC-AI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Chinese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"CSEMOTIONS","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tCSEMOTIONS: High-Quality Mandarin Emotional Speech Dataset\n\t\n\nPaper | Code\n\nCSEMOTIONS is a high-quality Mandarin emotional speech dataset designed for expressive speech synthesis, emotion recognition, and voice cloning research. The dataset contains studio-quality recordings from six professional voice actors across seven carefully curated emotional categories, supporting research in controllable and natural language speech generation.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\n\nName: CSEMOTIONS‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AIDC-AI/CSEMOTIONS.","url":"https://huggingface.co/datasets/AIDC-AI/CSEMOTIONS","creator_name":"AIDC-AI","creator_url":"https://huggingface.co/AIDC-AI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Chinese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"bashkort_tts_dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tBashkort TTS Dataset\n\t\n\nThe largest open dataset for speech synthesis in the Bashkir language ‚Äî featuring multi-speaker recordings and speaking styles.\n\n\t\n\t\t\n\t\tüìä Dataset Overview\n\t\n\n\nTotal audio files: 62,852\nSpeakers: 7 female, 1 male\nSpeaking styles: friendly, question, neutral\nLanguages: Bashkir\nFormat: MP3 audio + transcription text\n\n\n\t\n\t\t\n\t\tüéô How It Was Collected\n\t\n\n\nInitial recording: A female voice actor recorded ~15 hours of speech in Bashkir.\nVoice cloning: Using ElevenLabs‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AigizK/bashkort_tts_dataset.","url":"https://huggingface.co/datasets/AigizK/bashkort_tts_dataset","creator_name":"Aigiz Kunafin","creator_url":"https://huggingface.co/AigizK","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-classification","Bashkir","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Fleurs-Kn","keyword":"automatic-speech-recognition","description":"This is a filtered version of the Fleurs dataset only containing samples of Kannada language.\nThe dataset contains total of 2283 training, 368 validation and 838 test samples.\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'id': 1053,\n 'num_samples': 226560,\n 'path': '/home/ravi.naik/.cache/huggingface/datasets/downloads/extracted/e7c8b501d4e6892673b6dc291d42de48e7987b0d2aa6471066a671f686224ed1/10000267636955490843.wav',\n 'audio': {'path': 'train/10000267636955490843.wav',\n  'array': array([ 0.        ,  0.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RaviNaik/Fleurs-Kn.","url":"https://huggingface.co/datasets/RaviNaik/Fleurs-Kn","creator_name":"Ravi Naik","creator_url":"https://huggingface.co/RaviNaik","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"IndicSentiment","keyword":"hate-speech-detection","description":"\n  IndicSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA new, multilingual, and n-way parallel dataset for sentiment analysis in 13 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReferencehttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicSentimentClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicSentiment.","url":"https://huggingface.co/datasets/mteb/IndicSentiment","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"vox-communis-parallel-g2p","keyword":"linguistics","description":"\n\t\n\t\t\n\t\tVoxCommunis Parallel G2P dataset\n\t\n\nThis dataset was derived from the VoxCommunis Corpus to provide pairs of utterances along with their\ncorresponding phonemes, side by side, as to ease the training of grapheme-to-phoneme (G2P) models.\nThe original VoxCommunis Corpus features force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus.\nThe lexicons were developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p.","url":"https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p","creator_name":"Fl√°vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"bashkort_tts_dataset","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tBashkort TTS Dataset\n\t\n\nThe largest open dataset for speech synthesis in the Bashkir language ‚Äî featuring multi-speaker recordings and speaking styles.\n\n\t\n\t\t\n\t\tüìä Dataset Overview\n\t\n\n\nTotal audio files: 62,852\nSpeakers: 7 female, 1 male\nSpeaking styles: friendly, question, neutral\nLanguages: Bashkir\nFormat: MP3 audio + transcription text\n\n\n\t\n\t\t\n\t\tüéô How It Was Collected\n\t\n\n\nInitial recording: A female voice actor recorded ~15 hours of speech in Bashkir.\nVoice cloning: Using ElevenLabs‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AigizK/bashkort_tts_dataset.","url":"https://huggingface.co/datasets/AigizK/bashkort_tts_dataset","creator_name":"Aigiz Kunafin","creator_url":"https://huggingface.co/AigizK","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-classification","Bashkir","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"speech-recognition","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ar-quran-hadith14books-MSA","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for quran and hadith dataset\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nArabic specialized dataset to make sure that AI is not changing our sacred scriptures in speech recognition by training and evaluating upon quran and hadith.\n\nCombining quran + magma'a el zawa'ed book of sidi Nour eldin elhaithamy author including 14 book of hadith of approximately 10,000 hadith without repititions + other existing datasets like common voice, fleurs, media speech\n\nFirst dataset to have full‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/siddiqiya/ar-quran-hadith14books-MSA.","url":"https://huggingface.co/datasets/siddiqiya/ar-quran-hadith14books-MSA","creator_name":"Siddiqiya Shazoulia","creator_url":"https://huggingface.co/siddiqiya","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"VieStudentFeedbackClassification","keyword":"hate-speech-detection","description":"\n  VieStudentFeedbackClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Vietnamese dataset for classification of student feedback\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://ieeexplore.ieee.org/document/8573337\n\n\n\t\n\nSource datasets:\n\nuitnlp/vietnamese_students_feedback\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/VieStudentFeedbackClassification.","url":"https://huggingface.co/datasets/mteb/VieStudentFeedbackClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"NgocHuyenViVoice","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thangnzt/NgocHuyenViVoice.","url":"https://huggingface.co/datasets/thangnzt/NgocHuyenViVoice","creator_name":"Thang Nguyen Duc","creator_url":"https://huggingface.co/thangnzt","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Vietnamese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"sdf_dataset_en","keyword":"speech","description":"\n\t\n\t\t\n\t\tSpeechDialogueFactory Dataset\n\t\n\n\n\t\n\t\t\n\t\tBackground\n\t\n\nThis dataset is part of the SpeechDialogueFactory project, a comprehensive framework for generating high-quality speech dialogues at scale. Speech dialogue datasets are essential for developing and evaluating Speech-LLMs, but existing datasets face limitations including high collection costs, privacy concerns, and lack of conversational authenticity. This dataset addresses these challenges by providing synthetically generated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/minghanw/sdf_dataset_en.","url":"https://huggingface.co/datasets/minghanw/sdf_dataset_en","creator_name":"Minghan Wang","creator_url":"https://huggingface.co/minghanw","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-to-speech","audio-to-audio","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"sdf_dataset_en","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tSpeechDialogueFactory Dataset\n\t\n\n\n\t\n\t\t\n\t\tBackground\n\t\n\nThis dataset is part of the SpeechDialogueFactory project, a comprehensive framework for generating high-quality speech dialogues at scale. Speech dialogue datasets are essential for developing and evaluating Speech-LLMs, but existing datasets face limitations including high collection costs, privacy concerns, and lack of conversational authenticity. This dataset addresses these challenges by providing synthetically generated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/minghanw/sdf_dataset_en.","url":"https://huggingface.co/datasets/minghanw/sdf_dataset_en","creator_name":"Minghan Wang","creator_url":"https://huggingface.co/minghanw","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-to-speech","audio-to-audio","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"RSL_Maran","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ae5115242430e13/RSL_Maran.","url":"https://huggingface.co/datasets/ae5115242430e13/RSL_Maran","creator_name":"R.s.L Maran","creator_url":"https://huggingface.co/ae5115242430e13","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","table-question-answering","question-answering","text-classification","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"wpp_pav_transcrito_deepgram","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tüé§ Transcri√ß√µes WhatsApp - Deepgram Nova 2\n\t\n\nEste dataset cont√©m transcri√ß√µes de mensagens de √°udio do WhatsApp geradas usando Deepgram Nova 2.\n\n\t\n\t\t\n\t\tüìã Descri√ß√£o\n\t\n\n\nOrigem: Mensagens de √°udio do WhatsApp em portugu√™s brasileiro\nModelo: Deepgram Nova 2\nPre√ßo: $0.0043/minuto\nTotal de amostras: 198\nFormato de √°udio: WAV (16kHz)\nIdioma: Portugu√™s brasileiro\n\nModelo de transcri√ß√£o em tempo real da Deepgram com baixa lat√™ncia.\n\n\t\n\t\t\n\t\n\t\n\t\tüìä Estat√≠sticas\n\t\n\n\nTotal de amostras: 198‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_deepgram.","url":"https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_deepgram","creator_name":"Bernardo Aires","creator_url":"https://huggingface.co/BernardoAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"RSL_Maran","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ae5115242430e13/RSL_Maran.","url":"https://huggingface.co/datasets/ae5115242430e13/RSL_Maran","creator_name":"R.s.L Maran","creator_url":"https://huggingface.co/ae5115242430e13","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","table-question-answering","question-answering","text-classification","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"indicvoices_bn_tagged_transcripts","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_bn_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_bn_tagged_transcripts.","url":"https://huggingface.co/datasets/WhissleAI/indicvoices_bn_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ewe_bible_v1","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tEwe bible for Text-to-Speech\n\t\n\n","url":"https://huggingface.co/datasets/worldboss/ewe_bible_v1","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Ewe","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"japanese-text-difficulty","keyword":"linguistics","description":"\n\t\n\t\t\n\t\tAozora Text Difficulty Dataset\n\t\n\nThis dataset contains Japanese literary texts from the Aozora Bunko digital library, enhanced with jReadability-based difficulty analysis for Japanese language learning and curriculum development.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nSource: Aozora Bunko (ÈùíÁ©∫ÊñáÂ∫´) - Japan's premier digital library of public domain literature\nEnhancement: jReadability-based difficulty scoring using research-backed Japanese readability models\nPrimary Methodology: jReadability - A‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ronantakizawa/japanese-text-difficulty.","url":"https://huggingface.co/datasets/ronantakizawa/japanese-text-difficulty","creator_name":"Ronan Takizawa","creator_url":"https://huggingface.co/ronantakizawa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Japanese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"fake_voices","keyword":"text-to-speech","description":"\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Fake Voices\n\t\n\nThis dataset contains deepfakes in Brazilian Portuguese created with XTTS model.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nThe dataset was created using the XTTS model, which is a Text-to-Speech model pre-trained in several languages including Portuguese. \nIn order to generate the mentioned deepfakes, the model was fed with recordings from the CETUC Corpus, \nmade available by Fala Brasil Group. It contains speeches from 101 speakers, totaling 140 hours of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unfake/fake_voices.","url":"https://huggingface.co/datasets/unfake/fake_voices","creator_name":"Unfake","creator_url":"https://huggingface.co/unfake","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Portuguese","mit","1B<n<10B"],"keywords_longer_than_N":true},
	{"name":"ewe_bible_v1","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tEwe bible for Text-to-Speech\n\t\n\n","url":"https://huggingface.co/datasets/worldboss/ewe_bible_v1","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Ewe","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"bot_stt","keyword":"automatic-speech-recognition","description":"Beehzod/bot_stt dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Beehzod/bot_stt","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"limmits-2024","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\n\t\n\t\tIndic TTS dataset\n\t\n\n7 languages from IISC's LIMMITS Challenge 2024\n\n\t\n\t\t\n\t\n\t\n\t\tRoadmap\n\t\n\nTo use this for training VALLE-X & VoiceBox based TTS models\n\n\t\n\t\t\n\t\n\t\n\t\tFetch the tars directly\n\t\n\nwget -O 'Bengali_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Bengali_F.tar.gz'\nwget -O 'Chhattisgarhi_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Chhattisgarhi_F.tar.gz'\nwget -O 'English_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/English_F.tar.gz'\nwget -O‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iAkashPaul/limmits-2024.","url":"https://huggingface.co/datasets/iAkashPaul/limmits-2024","creator_name":"Akash","creator_url":"https://huggingface.co/iAkashPaul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","Bengali","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"limmits-2024","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\n\t\n\t\tIndic TTS dataset\n\t\n\n7 languages from IISC's LIMMITS Challenge 2024\n\n\t\n\t\t\n\t\n\t\n\t\tRoadmap\n\t\n\nTo use this for training VALLE-X & VoiceBox based TTS models\n\n\t\n\t\t\n\t\n\t\n\t\tFetch the tars directly\n\t\n\nwget -O 'Bengali_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Bengali_F.tar.gz'\nwget -O 'Chhattisgarhi_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Chhattisgarhi_F.tar.gz'\nwget -O 'English_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/English_F.tar.gz'\nwget -O‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iAkashPaul/limmits-2024.","url":"https://huggingface.co/datasets/iAkashPaul/limmits-2024","creator_name":"Akash","creator_url":"https://huggingface.co/iAkashPaul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","Bengali","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"tat_youtube","keyword":"speech","description":"yasalma/tat_youtube dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/yasalma/tat_youtube","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"test44444","keyword":"speech","description":"\n\t\n\t\t\n\t\ttest44444\n\t\n\nThis is a merged speech dataset containing 551 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 551\nSpeakers: 2\nLanguages: tr\nEmotions: neutral, happy, angry\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test44444.","url":"https://huggingface.co/datasets/Codyfederer/test44444","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"tat_youtube","keyword":"automatic-speech-recognition","description":"yasalma/tat_youtube dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/yasalma/tat_youtube","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"test44444","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\ttest44444\n\t\n\nThis is a merged speech dataset containing 551 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 551\nSpeakers: 2\nLanguages: tr\nEmotions: neutral, happy, angry\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test44444.","url":"https://huggingface.co/datasets/Codyfederer/test44444","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"tat_youtube","keyword":"text-to-speech","description":"yasalma/tat_youtube dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/yasalma/tat_youtube","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"test44444","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\ttest44444\n\t\n\nThis is a merged speech dataset containing 551 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 551\nSpeakers: 2\nLanguages: tr\nEmotions: neutral, happy, angry\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test44444.","url":"https://huggingface.co/datasets/Codyfederer/test44444","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"glaswegian_audio","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tWARNING! Some derogatory slang is included in the dataset\n\t\n\nLatest total length: 120 minutes\nSource:\nScottish phrases 1-10, privately recorded audio, Limmy, and 1 episode of Glasga Da\nMetadata:\n\n\t\n\t\t\nColumn Name\nData Type\nInformation\n\n\n\t\t\nindex\nint\nUnique identifier for each row\n\n\nfile_name\nstring\nPath to the audio file\n\n\ntranscription\nstring\nText transcription of the audio\n\n\nlength_seconds\nfloat\nLength of the audio file in seconds\n\n\nsampling_rate\nint\nSampling rate of the audio file‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/divakaivan/glaswegian_audio.","url":"https://huggingface.co/datasets/divakaivan/glaswegian_audio","creator_name":"Ivan Ivanov","creator_url":"https://huggingface.co/divakaivan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","mit","n<1K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"airline-customersupport-englishaudio","keyword":"speech","description":"\n\t\n\t\t\n\t\tAirline Customer Support English Audio Dataset\n\t\n\nText spoken by all participants:\nI missed my connecting flight due to a delay; can you book me on the next available flight? I‚Äôm stranded at the airport and need to reach my destination soon.\nThe dataset supports training and evaluation of models in:\n\nAutomatic Speech Recognition (ASR)\nEmotional tone classification\nVoice synthesis and generation\nEmotion-aware conversational agents\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntended Uses\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t‚úÖ Direct Use‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/airline-customersupport-englishaudio.","url":"https://huggingface.co/datasets/Kratos-AI/airline-customersupport-englishaudio","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Uzbek_Speech_Corpus","keyword":"speech","description":"\n\t\n\t\t\n\t\tUzbek Speech Corpus (USC)\n\t\n\nPaper: USC: An Open-Source Uzbek Speech Corpus and Initial Speech Recognition Experiments\nSummary: This repository contains dataset for reproducing the results presented in the paper \"USC: An Open-Source Uzbek Speech Corpus\". USC is a freely available, manually checked speech corpus comprising 958 speakers and 105 hours of transcribed audio recordings. \nDataset Summary:\n\n\t\n\t\t\nFeature\nDescription\n\n\n\t\t\nLanguage\nUzbek\n\n\nSize\n105 hours of audio\n\n\nNumber of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/Uzbek_Speech_Corpus.","url":"https://huggingface.co/datasets/issai/Uzbek_Speech_Corpus","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"enwaucymraeg","keyword":"automatic-speech-recognition","description":"The training and development set sentences are taken from CoVoST and have been compared to all validated sentences in the Welsh Common Voice data to ensure none of the already recorded sentences will be used here. Then all sentences containing personal names have been extracted and replaced with a randomly generated name using the Faker library and a custom Welsh names list. The sentences were then recorded by 26 volunteers from North-West Wales, 15 women, 10 men and one non-binary person.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wanasash/enwaucymraeg.","url":"https://huggingface.co/datasets/wanasash/enwaucymraeg","creator_name":"Sasha Wanasky","creator_url":"https://huggingface.co/wanasash","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Welsh","cc0-1.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"nchlt","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis is the Zulu language split of the NCHLT speech corpus (nchlt-clean split). It containes 56 hours and 14 minutes hours of isiZulu speech from 210 (98 Male; 112 Female) native speakers of the language. Each recording consists of a speaker reading three words. These words were sourced from South African government websites. The full corpus can be downloaded from the SADILAR website.\nFor a full description of the corpus, see Barnard et al. 2014.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aconeil/nchlt.","url":"https://huggingface.co/datasets/aconeil/nchlt","creator_name":"Alexandra","creator_url":"https://huggingface.co/aconeil","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Zulu","cc-by-3.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Uzbek_Speech_Corpus","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tUzbek Speech Corpus (USC)\n\t\n\nPaper: USC: An Open-Source Uzbek Speech Corpus and Initial Speech Recognition Experiments\nSummary: This repository contains dataset for reproducing the results presented in the paper \"USC: An Open-Source Uzbek Speech Corpus\". USC is a freely available, manually checked speech corpus comprising 958 speakers and 105 hours of transcribed audio recordings. \nDataset Summary:\n\n\t\n\t\t\nFeature\nDescription\n\n\n\t\t\nLanguage\nUzbek\n\n\nSize\n105 hours of audio\n\n\nNumber of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/Uzbek_Speech_Corpus.","url":"https://huggingface.co/datasets/issai/Uzbek_Speech_Corpus","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"Lux-Japanese-Speech-Corpus","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tLux Japanese Speech Corpus\n\t\n\n\n\t\n\t\t\n\t\tÊ¶ÇË¶Å\n\t\n\nLux Japanese Speech Corpus „ÅØ„ÄÅ„Ç™„É™„Ç∏„Éä„É´„Ç≠„É£„É©„ÇØ„Çø„Éº„ÄåLux („É´„ÇØ„Çπ)„Äç„Å´„Çà„ÇãÊó•Êú¨Ë™û„ÅÆ„ÉÜ„Ç≠„Çπ„ÉàË™≠„Åø‰∏ä„ÅíÈü≥Â£∞„ÇíÂèéÈå≤„Åó„Åü„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ„Åì„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØ„ÄÅ‰ª•‰∏ã„ÅÆ2Á®ÆÈ°û„ÅÆÈü≥Â£∞„Éï„Ç°„Ç§„É´„ÅßÊßãÊàê„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n\nraw: Âä†Â∑•Ââç„ÅÆ 96kHz/16bit „ÅÆ WAV „Éï„Ç°„Ç§„É´\ncleaned: „Éé„Ç§„Ç∫Èô§Âéª„Å™„Å©„ÅÆÂá¶ÁêÜ„ÇíÊñΩ„Åó„Åü 96kHz/16bit „ÅÆ WAV „Éï„Ç°„Ç§„É´\n\nÂêÑÈü≥Â£∞„Éï„Ç°„Ç§„É´„Å´ÂØæÂøú„Åô„Çã„Éà„É©„É≥„Çπ„ÇØ„É™„Éó„Ç∑„Éß„É≥ÔºàË™≠„Åø‰∏ä„Åí„ÅüÊñáÁ´†Ôºâ„ÅØ„ÄÅmetadata.csv „Å´Ë®òÈå≤„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Éá„Éº„Çø„Çª„ÉÉ„ÉàÂÖ®‰Ωì„ÅÆ„É°„ÇøÊÉÖÂ†±„ÅØ dataset_infos.json „ÅßÁÆ°ÁêÜ„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n\n\t\n\t\t\n\t\t„Éá„Ç£„É¨„ÇØ„Éà„É™ÊßãÈÄ†\n\t\n\n‰ª•‰∏ã„ÅØ„ÄÅ„Åì„ÅÆ„É™„Éù„Ç∏„Éà„É™„ÅÆÊé®Â•®„Éá„Ç£„É¨„ÇØ„Éà„É™ÊßãÈÄ†„ÅÆ‰æã„Åß„Åô„ÄÇ\nLux-Japanese-Speech-Corpus/\n‚îú‚îÄ‚îÄ .gitattributes           # Git„ÅÆ„Ç´„Çπ„Çø„Éû„Ç§„Ç∫„Éï„Ç°„Ç§„É´\n‚îú‚îÄ‚îÄ README.md‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Lami/Lux-Japanese-Speech-Corpus.","url":"https://huggingface.co/datasets/Lami/Lux-Japanese-Speech-Corpus","creator_name":"KohnoseLami","creator_url":"https://huggingface.co/Lami","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","cc-by-4.0","1B<n<10B"],"keywords_longer_than_N":true},
	{"name":"toxic_dataset_classification_azerbaijani","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tAzerbaijani Toxicity Classification Dataset\n\t\n\nCONTENT WARNING\nThis dataset contains highly offensive and toxic content in Azerbaijani language, including:\n\nExplicit sexual content\nProfanity and vulgar language\nHate speech and personal attacks\nThreats and harassment\nOther harmful and disturbing material\n\nThis dataset is intended for mature audiences (18+) and research purposes only.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThis dataset contains Azerbaijani text comments labeled with toxicity‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LocalDoc/toxic_dataset_classification_azerbaijani.","url":"https://huggingface.co/datasets/LocalDoc/toxic_dataset_classification_azerbaijani","creator_name":"LocalDoc","creator_url":"https://huggingface.co/LocalDoc","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","Azerbaijani","cc-by-4.0","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"Lux-Japanese-Speech-Corpus","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tLux Japanese Speech Corpus\n\t\n\n\n\t\n\t\t\n\t\tÊ¶ÇË¶Å\n\t\n\nLux Japanese Speech Corpus „ÅØ„ÄÅ„Ç™„É™„Ç∏„Éä„É´„Ç≠„É£„É©„ÇØ„Çø„Éº„ÄåLux („É´„ÇØ„Çπ)„Äç„Å´„Çà„ÇãÊó•Êú¨Ë™û„ÅÆ„ÉÜ„Ç≠„Çπ„ÉàË™≠„Åø‰∏ä„ÅíÈü≥Â£∞„ÇíÂèéÈå≤„Åó„Åü„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ„Åì„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØ„ÄÅ‰ª•‰∏ã„ÅÆ2Á®ÆÈ°û„ÅÆÈü≥Â£∞„Éï„Ç°„Ç§„É´„ÅßÊßãÊàê„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n\nraw: Âä†Â∑•Ââç„ÅÆ 96kHz/16bit „ÅÆ WAV „Éï„Ç°„Ç§„É´\ncleaned: „Éé„Ç§„Ç∫Èô§Âéª„Å™„Å©„ÅÆÂá¶ÁêÜ„ÇíÊñΩ„Åó„Åü 96kHz/16bit „ÅÆ WAV „Éï„Ç°„Ç§„É´\n\nÂêÑÈü≥Â£∞„Éï„Ç°„Ç§„É´„Å´ÂØæÂøú„Åô„Çã„Éà„É©„É≥„Çπ„ÇØ„É™„Éó„Ç∑„Éß„É≥ÔºàË™≠„Åø‰∏ä„Åí„ÅüÊñáÁ´†Ôºâ„ÅØ„ÄÅmetadata.csv „Å´Ë®òÈå≤„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Éá„Éº„Çø„Çª„ÉÉ„ÉàÂÖ®‰Ωì„ÅÆ„É°„ÇøÊÉÖÂ†±„ÅØ dataset_infos.json „ÅßÁÆ°ÁêÜ„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n\n\t\n\t\t\n\t\t„Éá„Ç£„É¨„ÇØ„Éà„É™ÊßãÈÄ†\n\t\n\n‰ª•‰∏ã„ÅØ„ÄÅ„Åì„ÅÆ„É™„Éù„Ç∏„Éà„É™„ÅÆÊé®Â•®„Éá„Ç£„É¨„ÇØ„Éà„É™ÊßãÈÄ†„ÅÆ‰æã„Åß„Åô„ÄÇ\nLux-Japanese-Speech-Corpus/\n‚îú‚îÄ‚îÄ .gitattributes           # Git„ÅÆ„Ç´„Çπ„Çø„Éû„Ç§„Ç∫„Éï„Ç°„Ç§„É´\n‚îú‚îÄ‚îÄ README.md‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Lami/Lux-Japanese-Speech-Corpus.","url":"https://huggingface.co/datasets/Lami/Lux-Japanese-Speech-Corpus","creator_name":"KohnoseLami","creator_url":"https://huggingface.co/Lami","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","cc-by-4.0","1B<n<10B"],"keywords_longer_than_N":true},
	{"name":"cmu-arctic-xvectors","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tSpeaker embeddings extracted from CMU ARCTIC\n\t\n\nThere is one .npy file for each utterance in the dataset, 7931 files in total. The speaker embeddings are 512-element X-vectors.\nThe CMU ARCTIC dataset divides the utterances among the following speakers:\n\nbdl (US male)\nslt (US female)\njmk (Canadian male)\nawb (Scottish male)\nrms (US male)\nclb (US female)\nksp (Indian male)\n\nThe X-vectors were extracted using this script, which uses the speechbrain/spkrec-xvect-voxceleb model.\nUsage:\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/w4ffl35/cmu-arctic-xvectors.","url":"https://huggingface.co/datasets/w4ffl35/cmu-arctic-xvectors","creator_name":"Joe Curlee","creator_url":"https://huggingface.co/w4ffl35","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"semi-Voxpopuli","keyword":"speech-recognition","description":"\n\t\n\t\t\n\t\tVoxPopuli Multilingual Audio Dataset\n\t\n\nThis dataset contains audio recordings in English (EN), Polish (PL), and Swedish (SV) languages. It is derived from the VoxPopuli dataset and tailored for multilingual language processing tasks.\nThe dataset includes audio clips and corresponding metadata to support research and development in multilingual audio processing.\n\n\t\n\t\t\n\t\tDataset Files\n\t\n\nThe dataset includes the following files:\n\ndata.csv: Contains metadata about the audio files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jagadeesh9580/semi-Voxpopuli.","url":"https://huggingface.co/datasets/Jagadeesh9580/semi-Voxpopuli","creator_name":"Jagadeesh Rachapudi","creator_url":"https://huggingface.co/Jagadeesh9580","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","soundfolder","Audio","Datasets"],"keywords_longer_than_N":true},
	{"name":"SASRBench-v1","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSASRBench-v1: Singlish ASR Benchmark V1\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSASRBench-v1 is a benchmark dataset for evaluating Automatic Speech Recognition (ASR) performance on Singlish. It is derived exclusively from the Part 3 Same Room Environment Close-talk Mic recordings of IMDA's NSC Corpus.\n\n\t\n\t\t\n\t\tDataset Derivation\n\t\n\nFrom the Part 3 Same Room Environment Close-talk Mic recordings, audio segments were extracted with the following criteria:\n\nMinimum Word Count: 10 words  \nMaximum‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mjwong/SASRBench-v1.","url":"https://huggingface.co/datasets/mjwong/SASRBench-v1","creator_name":"Ming Jie Wong","creator_url":"https://huggingface.co/mjwong","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"SIWIS_French_Speech_Synthesis_Database","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSIWIS French Speech Synthesis Database\n\t\n\nThis README provides a concise description of the dataset, including its structure, file naming conventions, and known labeling issues. Additionally, suggestions for potential improvements are outlined in the TODO section.  \nThe dataset is distributed under the Creative Commons Attribution 4.0 International (CC BY 4.0) license, permitting its use for any purpose.  \nFor more details about the database design and recording process, please refer‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aviv-anthonnyolime/SIWIS_French_Speech_Synthesis_Database.","url":"https://huggingface.co/datasets/Aviv-anthonnyolime/SIWIS_French_Speech_Synthesis_Database","creator_name":"Anthonny Olime","creator_url":"https://huggingface.co/Aviv-anthonnyolime","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","French","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Ranjan-Hindi33min","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tRanjan-Hindi33min\n\t\n\nOwner: @BBSRguyCreated: 2025-06-03Year: 2025Language: Hindi üáÆüá≥Region Focus: Odisha, IndiaSample Rate Variants: 16 kHz, 24 kHz, 32 kHzTotal Files: 29 pairs (speech + text)Duration: Approximately 33 minutes of speech  \n\n\n\t\n\t\t\n\t\n\t\n\t\tüìú Description\n\t\n\nRanjan-Hindi33min is a meticulously curated dataset comprising high-quality Hindi speech samples and their corresponding textual transcriptions. This dataset is designed to support various speech processing tasks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BBSRguy/Ranjan-Hindi33min.","url":"https://huggingface.co/datasets/BBSRguy/Ranjan-Hindi33min","creator_name":"Rashmi Ranjan Dash","creator_url":"https://huggingface.co/BBSRguy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Hindi","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"SIWIS_French_Speech_Synthesis_Database","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tSIWIS French Speech Synthesis Database\n\t\n\nThis README provides a concise description of the dataset, including its structure, file naming conventions, and known labeling issues. Additionally, suggestions for potential improvements are outlined in the TODO section.  \nThe dataset is distributed under the Creative Commons Attribution 4.0 International (CC BY 4.0) license, permitting its use for any purpose.  \nFor more details about the database design and recording process, please refer‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aviv-anthonnyolime/SIWIS_French_Speech_Synthesis_Database.","url":"https://huggingface.co/datasets/Aviv-anthonnyolime/SIWIS_French_Speech_Synthesis_Database","creator_name":"Anthonny Olime","creator_url":"https://huggingface.co/Aviv-anthonnyolime","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","French","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Test","keyword":"text-to-speech","description":"Test Dataset\n","url":"https://huggingface.co/datasets/imenLa/Test","creator_name":"imen laouirine","creator_url":"https://huggingface.co/imenLa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Arabic","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"emotion-prompts","keyword":"speech","description":"\n\t\n\t\t\n\t\tEmotion Prompts Dataset\n\t\n\nThis dataset contains simple textual prompts designed for eliciting or detecting emotional tones in generated speech or text. It is useful for training or evaluating emotion-conditioned models such as TTS (text-to-speech) or dialogue systems.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\nDifficulty: Describes prompt complexity (Simple, Moderate, Complex).\nPrompt: A text prompt with an {emotion} placeholder.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nTo use this dataset with the Hugging Face Datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caster97/emotion-prompts.","url":"https://huggingface.co/datasets/caster97/emotion-prompts","creator_name":"caster97","creator_url":"https://huggingface.co/caster97","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"gujarati-language-audiodataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tGujarati Language Audio Dataset\n\t\n\nText spoken by all participants:\n\"‡™ï‡´É‡™§‡´ç‡™∞‡™ø‡™Æ ‡™¨‡´Å‡™¶‡´ç‡™ß‡™ø‡™Æ‡™§‡´ç‡™§‡™æ (AI) ‡™ù‡™°‡™™‡™•‡´Ä ‡™µ‡™ø‡™ï‡™∏‡´Ä ‡™∞‡™π‡´Ä ‡™õ‡´á, ‡™ú‡´á ‡™∞‡´ã‡™ú‡™ø‡™Ç‡™¶‡™æ ‡™ú‡´Ä‡™µ‡™®‡™®‡´á ‡™¨‡™¶‡™≤‡´Ä ‡™∞‡™π‡´Ä ‡™õ‡´á. ‡™§‡´á‡™®‡´Ä ‡™®‡™µ‡´Ä‡™®‡™§‡™æ‡™ì ‡™∂‡™ø‡™ï‡´ç‡™∑‡™£, ‡™Ü‡™∞‡´ã‡™ó‡´ç‡™Ø‡™∏‡™Ç‡™≠‡™æ‡™≥ ‡™Ö‡™®‡´á ‡™ï‡™æ‡™Æ‡™®‡´á ‡™∏‡´Å‡™ß‡™æ‡™∞‡´á ‡™õ‡´á, ‡™®‡™µ‡´Ä ‡™§‡™ï‡´ã ‡™ä‡™≠‡´Ä ‡™ï‡™∞‡´á ‡™õ‡´á‡•§\"\nThe dataset supports training and evaluation of models in:\n\nAutomatic Speech Recognition (ASR)\nEmotional tone classification\nVoice synthesis and generation\nEmotion-aware conversational agents\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntended Uses\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t‚úÖ Direct Use\n\t\n\n\nTraining and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/gujarati-language-audiodataset.","url":"https://huggingface.co/datasets/Kratos-AI/gujarati-language-audiodataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Gujarati","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_2k","keyword":"speech","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset (2k)\n\t\n\nThis dataset contains 4000 synthetic speech recordings in the Pashto language,\nwith 2000 male voice recordings and 2000 female voice recordings.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 2000 sentences\nTotal Recordings: 4000 audio files (2000 male + 2000 female)\nAudio Format: WAV, 44.1kHz, 16-bit PCM\nSampling Rate: 44.1kHz (44100 Hz)\nVoices: \nMale: ps-AF-GulNawazNeural\nFemale: ps-AF-LatifaNeural\n\n\nTotal Audio Duration: \nMale: 0.00 seconds‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_2k.","url":"https://huggingface.co/datasets/ihanif/pashto_speech_2k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_2k","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset (2k)\n\t\n\nThis dataset contains 4000 synthetic speech recordings in the Pashto language,\nwith 2000 male voice recordings and 2000 female voice recordings.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 2000 sentences\nTotal Recordings: 4000 audio files (2000 male + 2000 female)\nAudio Format: WAV, 44.1kHz, 16-bit PCM\nSampling Rate: 44.1kHz (44100 Hz)\nVoices: \nMale: ps-AF-GulNawazNeural\nFemale: ps-AF-LatifaNeural\n\n\nTotal Audio Duration: \nMale: 0.00 seconds‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_2k.","url":"https://huggingface.co/datasets/ihanif/pashto_speech_2k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"movieAudio","keyword":"automatic-speech-recognition","description":"shaggysus/movieAudio dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/shaggysus/movieAudio","creator_name":"Sandun de silva","creator_url":"https://huggingface.co/shaggysus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"emotion-prompts","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tEmotion Prompts Dataset\n\t\n\nThis dataset contains simple textual prompts designed for eliciting or detecting emotional tones in generated speech or text. It is useful for training or evaluating emotion-conditioned models such as TTS (text-to-speech) or dialogue systems.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\nDifficulty: Describes prompt complexity (Simple, Moderate, Complex).\nPrompt: A text prompt with an {emotion} placeholder.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nTo use this dataset with the Hugging Face Datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caster97/emotion-prompts.","url":"https://huggingface.co/datasets/caster97/emotion-prompts","creator_name":"caster97","creator_url":"https://huggingface.co/caster97","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"audio_data_russian","keyword":"speech","description":"\n\t\n\t\t\n\t\tDataset Audio Russian\n\t\n\nThis is a dataset with Russian audio data, split into train for tasks like text-to-speech, speech recognition, and speaker identification.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\ntext: Audio transcription (string).\nspeaker_name: Speaker identifier (string).\naudio: Audio file.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nLoad the dataset like this:\nfrom datasets import load_dataset\ndataset = load_dataset(\"kijjjj/audio_data_russian\", split=\"train\")\nprint(dataset[0])\n\n","url":"https://huggingface.co/datasets/kijjjj/audio_data_russian","creator_name":"fgfd","creator_url":"https://huggingface.co/kijjjj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"vibravox_enhanced_by_EBEN","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset features a speech-enhanced version of the test split from the speech_clean subset of the Vibravox Dataset.\nIt is not intended for training.\n\n\t\n\t\t\n\t\tEnhancement procedure\n\t\n\nThe Bandwidth extension task has been individually achieved for each sensor using configurable EBEN (arXiv link) models available at https://huggingface.co/Cnam-LMSSC/vibravox_EBEN_models.\n\n\t\n\t\t\n\t\tRessources\n\t\n\nResults for speech-to-phoneme and speaker‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN.","url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"vibravox_enhanced_by_EBEN","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset features a speech-enhanced version of the test split from the speech_clean subset of the Vibravox Dataset.\nIt is not intended for training.\n\n\t\n\t\t\n\t\tEnhancement procedure\n\t\n\nThe Bandwidth extension task has been individually achieved for each sensor using configurable EBEN (arXiv link) models available at https://huggingface.co/Cnam-LMSSC/vibravox_EBEN_models.\n\n\t\n\t\t\n\t\tRessources\n\t\n\nResults for speech-to-phoneme and speaker‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN.","url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"audio_data_russian","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Audio Russian\n\t\n\nThis is a dataset with Russian audio data, split into train for tasks like text-to-speech, speech recognition, and speaker identification.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\ntext: Audio transcription (string).\nspeaker_name: Speaker identifier (string).\naudio: Audio file.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nLoad the dataset like this:\nfrom datasets import load_dataset\ndataset = load_dataset(\"kijjjj/audio_data_russian\", split=\"train\")\nprint(dataset[0])\n\n","url":"https://huggingface.co/datasets/kijjjj/audio_data_russian","creator_name":"fgfd","creator_url":"https://huggingface.co/kijjjj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"medical-symptoms-english-audio","keyword":"speech","description":"\n\t\n\t\t\n\t\tMedical Symptoms English Audio Dataset\n\t\n\n*This dataset contains intentionally low-quality (‚ÄúB-grade‚Äù) data. It has been curated to include noisy, imperfect, or otherwise suboptimal samples for the purpose of testing model robustness and performance under degraded input conditions\nText spoken by all participants:\n\"Doctor, I'm constantly tired, like a heavy fog I can't shake. Sharp headaches hit, worse at night, and sleep is tough. I get dizzy, and my stomach feels uneasy after meals.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/medical-symptoms-english-audio.","url":"https://huggingface.co/datasets/Kratos-AI/medical-symptoms-english-audio","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"STT-v1","keyword":"automatic-speech-recognition","description":"FILM6912/STT-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/FILM6912/STT-v1","creator_name":"FILM","creator_url":"https://huggingface.co/FILM6912","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Thai","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"nb-librivox","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tüìÑ NB-LibriVox\n\t\n\nA high-quality Norwegian text-to-speech (TTS) dataset derived from LibriVox public domain audiobooks. It includes audio clips with pseudo-aligned transcripts and punctuation, curated by the National Library of Norway for speech synthesis and ASR research.\n\n\n\t\n\t\t\n\t\tüìÇ Dataset Overview\n\t\n\n\n\t\n\t\t\nField\nDescription\n\n\n\t\t\nfile_name\nAudio file name in .wav format\n\n\nid\nUnique identifier for each utterance/sample\n\n\ntext\nTranscript automatically generated using NB-Whisper Large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NbAiLab/nb-librivox.","url":"https://huggingface.co/datasets/NbAiLab/nb-librivox","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Norwegian","Norwegian Bokm√•l","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"automatic-speech-recognition","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"nb-librivox","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tüìÑ NB-LibriVox\n\t\n\nA high-quality Norwegian text-to-speech (TTS) dataset derived from LibriVox public domain audiobooks. It includes audio clips with pseudo-aligned transcripts and punctuation, curated by the National Library of Norway for speech synthesis and ASR research.\n\n\n\t\n\t\t\n\t\tüìÇ Dataset Overview\n\t\n\n\n\t\n\t\t\nField\nDescription\n\n\n\t\t\nfile_name\nAudio file name in .wav format\n\n\nid\nUnique identifier for each utterance/sample\n\n\ntext\nTranscript automatically generated using NB-Whisper Large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NbAiLab/nb-librivox.","url":"https://huggingface.co/datasets/NbAiLab/nb-librivox","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Norwegian","Norwegian Bokm√•l","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"Mana-TTS","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tManaTTS-Persian-Speech-Dataset\n\t\n\nManaTTS is the largest publicly available single-speaker Persian corpus, comprising over 114 hours of high-quality audio (sampled at 44.1 kHz). Released under the permissive CC-0 license, this dataset is freely usable for both educational and commercial purposes.  \nCollected from Nasl-e-Mana magazine, the dataset covers a diverse range of topics, making it ideal for training robust text-to-speech (TTS) models. The release includes a fully transparent‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahtaFetrat/Mana-TTS.","url":"https://huggingface.co/datasets/MahtaFetrat/Mana-TTS","creator_name":"Mahta Fetrat","creator_url":"https://huggingface.co/MahtaFetrat","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Persian","cc0-1.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"text-to-speech","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"asr-farsi-youtube-chunked-30-seconds","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tHow To Use\n\t\n\nfrom datasets import load_dataset\ntrain = load_dataset('pourmand1376/asr-farsi-youtube-chunked-30-seconds', split='train+val')\ntest =load_dataset('pourmand1376/asr-farsi-youtube-chunked-30-seconds', split='test')\n\n+300 Hours ASR dataset generated from this kaggle dataset\n","url":"https://huggingface.co/datasets/pourmand1376/asr-farsi-youtube-chunked-30-seconds","creator_name":"Amir Pourmand","creator_url":"https://huggingface.co/pourmand1376","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"picovoice-wake-word-benchmark","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tPicovoice Wake Word Benchmark Dataset\n\t\n\nThis dataset contains a collection of wake word recordings used for benchmarking wake word detection systems. The dataset has been reformatted from the original Picovoice Wake Word Benchmark repository for easier use with Hugging Face's ecosystem.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset contains over 300 recordings of six different wake words from more than 50 distinct speakers. These recordings were originally used to benchmark different‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/domdomegg/picovoice-wake-word-benchmark.","url":"https://huggingface.co/datasets/domdomegg/picovoice-wake-word-benchmark","creator_name":"Adam Jones","creator_url":"https://huggingface.co/domdomegg","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"test324234","keyword":"speech","description":"\n\t\n\t\t\n\t\ttest324234\n\t\n\nThis is a merged speech dataset containing 491 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 491\nSpeakers: 2\nLanguages: tr\nEmotions: angry, neutral, happy\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test324234.","url":"https://huggingface.co/datasets/Codyfederer/test324234","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"nigerian_common_voice_dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Nigerian Common Voice Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Nigerian Common Voice Dataset is a comprehensive dataset consisting of 158 hours of audio recordings and corresponding transcription (sentence). \nThis dataset includes metadata like accent, locale that can help improve the accuracy of speech recognition engines. This dataset is specifically curated to address the gap in speech and language \ndatasets for African accents, making it a valuable resource for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjaminogbonna/nigerian_common_voice_dataset.","url":"https://huggingface.co/datasets/benjaminogbonna/nigerian_common_voice_dataset","creator_name":"Benjamin Ogbonna","creator_url":"https://huggingface.co/benjaminogbonna","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"Children_Counsel","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tÏïÑÎèô¬∑Ï≤≠ÏÜåÎÖÑ ÏÉÅÎã¥ Îç∞Ïù¥ÌÑ∞ÏÖã (Children Counseling Dataset)\n\t\n\nThis dataset contains counseling data for children and adolescents, including both audio recordings and transcriptions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized as follows:\n\naudio/: Contains the audio recordings of counseling sessions in MP3 format\ndata/: Contains JSON files with transcriptions and metadata for each session\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset can be used for:\n\nTraining speech recognition models for counseling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ironDong/Children_Counsel.","url":"https://huggingface.co/datasets/ironDong/Children_Counsel","creator_name":"sindongwoo","creator_url":"https://huggingface.co/ironDong","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Korean","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"whisper-eval-rare-languages-csv","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tWhisper 3 Large Evaluation on Mozilla Common Voice 17 Rare Languages (Enhanced Metrics)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis enhanced dataset contains comprehensive evaluation results of OpenAI's Whisper 3 Large model on rare languages from Mozilla Common Voice 17, with extensive additional metrics for thorough ASR evaluation.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\nEnhanced Error Metrics:\n\nWER (Word Error Rate): Standard word-level error measurement\nCER (Character Error Rate): Character-level error‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/norbertm/whisper-eval-rare-languages-csv.","url":"https://huggingface.co/datasets/norbertm/whisper-eval-rare-languages-csv","creator_name":"Norbert M","creator_url":"https://huggingface.co/norbertm","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","multilingual","Assamese","Breton","Welsh"],"keywords_longer_than_N":true},
	{"name":"TrainingSpeech","keyword":"automatic-speech-recognition","description":"TrainingSpeech is an initiative to provide open and freely reusable dataset of voices \n\nfor speech-to-text models training\n\non non-english languages \n\nusing already available data (such as audio-books).\n\n\nRight now, data are extracted exclusively from audio-books and in French language. Let me know if you are intersted to contribute by creating an issue.\n\n\t\n\t\t\n\t\n\t\n\t\tTooling\n\t\n\nTrainingSpeech  comes with a CLI that automate and simplify:\n\ntranscript extraction\nforced-alignment (using aeneas)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wasertech/TrainingSpeech.","url":"https://huggingface.co/datasets/wasertech/TrainingSpeech","creator_name":"Danny Waser","creator_url":"https://huggingface.co/wasertech","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","French","French","mit","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"test324234","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\ttest324234\n\t\n\nThis is a merged speech dataset containing 491 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 491\nSpeakers: 2\nLanguages: tr\nEmotions: angry, neutral, happy\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test324234.","url":"https://huggingface.co/datasets/Codyfederer/test324234","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"UrduRomanSentimentClassification","keyword":"hate-speech-detection","description":"\n  UrduRomanSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Roman Urdu dataset is a data corpus comprising of more than 20000 records tagged for sentiment (Positive, Negative, Neutral)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\nReference\nhttps://archive.ics.uci.edu/dataset/458/roman+urdu+data+set\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/UrduRomanSentimentClassification.","url":"https://huggingface.co/datasets/mteb/UrduRomanSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"nigerian_common_voice_dataset","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Nigerian Common Voice Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Nigerian Common Voice Dataset is a comprehensive dataset consisting of 158 hours of audio recordings and corresponding transcription (sentence). \nThis dataset includes metadata like accent, locale that can help improve the accuracy of speech recognition engines. This dataset is specifically curated to address the gap in speech and language \ndatasets for African accents, making it a valuable resource for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjaminogbonna/nigerian_common_voice_dataset.","url":"https://huggingface.co/datasets/benjaminogbonna/nigerian_common_voice_dataset","creator_name":"Benjamin Ogbonna","creator_url":"https://huggingface.co/benjaminogbonna","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"test324234","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\ttest324234\n\t\n\nThis is a merged speech dataset containing 491 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 491\nSpeakers: 2\nLanguages: tr\nEmotions: angry, neutral, happy\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test324234.","url":"https://huggingface.co/datasets/Codyfederer/test324234","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"animespeech-orpheus-prep-800","keyword":"automatic-speech-recognition","description":"Preprocessed dataset in Orpheus TTS FT format corresponding to voices [\"107\", \"125\", \"145\", \"16\", \"163\", \"179\", \"180\", \"183\", \"185\", \"187\"] from ShoukanLabs/AniSpeech\n","url":"https://huggingface.co/datasets/taresh18/animespeech-orpheus-prep-800","creator_name":"Taresh Rajput","creator_url":"https://huggingface.co/taresh18","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"animespeech-orpheus-prep-800","keyword":"text-to-speech","description":"Preprocessed dataset in Orpheus TTS FT format corresponding to voices [\"107\", \"125\", \"145\", \"16\", \"163\", \"179\", \"180\", \"183\", \"185\", \"187\"] from ShoukanLabs/AniSpeech\n","url":"https://huggingface.co/datasets/taresh18/animespeech-orpheus-prep-800","creator_name":"Taresh Rajput","creator_url":"https://huggingface.co/taresh18","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"nchlt_speech_ssw","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tNCHLT Speech Corpus -- siSwati\n\t\n\nThis is the siSwati language part of the NCHLT Speech Corpus of the South African languages.\nLanguage code (ISO 639): ssw\nURI: https://hdl.handle.net/20.500.12185/271\n\n\t\n\t\t\n\t\tLicence:\n\t\n\nCreative Commons Attribution 3.0 Unported License (CC BY 3.0): http://creativecommons.org/licenses/by/3.0/legalcode\n\n\t\n\t\t\n\t\tAttribution:\n\t\n\nThe Department of Arts and Culture of the government of the Republic of South Africa (DAC), Council for Scientific and Industrial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/danielshaps/nchlt_speech_ssw.","url":"https://huggingface.co/datasets/danielshaps/nchlt_speech_ssw","creator_name":"Daniel van Niekerk","creator_url":"https://huggingface.co/danielshaps","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Swati","cc-by-3.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Tatoeba-Speech-Irish","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nSynthetic audio dataset, created using Azure text-to-speech service.\nThe bilingual text is a portion of the Tatoeba dataset, consisting of 1,983 text segments.\nThe dataset consists of two sets of audio data, one with a female voice (OrlaNeural) and the other with a male voice (ColmNeural).\nThe speech data comprises approximately 2 hours and 39 minutes (02:39:31) spread across 3,966 utterances.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['audio', 'text_ga'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Tatoeba-Speech-Irish.","url":"https://huggingface.co/datasets/ymoslem/Tatoeba-Speech-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"Tatoeba-Speech-Irish","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nSynthetic audio dataset, created using Azure text-to-speech service.\nThe bilingual text is a portion of the Tatoeba dataset, consisting of 1,983 text segments.\nThe dataset consists of two sets of audio data, one with a female voice (OrlaNeural) and the other with a male voice (ColmNeural).\nThe speech data comprises approximately 2 hours and 39 minutes (02:39:31) spread across 3,966 utterances.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['audio', 'text_ga'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Tatoeba-Speech-Irish.","url":"https://huggingface.co/datasets/ymoslem/Tatoeba-Speech-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"Gemini-2.0-Flash-Puck-Voice","keyword":"text-to-speech","description":"fireblade2534/Gemini-2.0-Flash-Puck-Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/fireblade2534/Gemini-2.0-Flash-Puck-Voice","creator_name":"fireblade2534","creator_url":"https://huggingface.co/fireblade2534","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"test6","keyword":"speech","description":"\n\t\n\t\t\n\t\ttest6\n\t\n\nThis is a merged speech dataset containing 1994 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 1994\nSpeakers: 3\nLanguages: en\nEmotions: neutral, negative_surprise, positive_surprise, distress, relief, contentment, adoration, interest, confusion, happy, sadness, triumph, fear, disappointment, awe, realization, angry\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test6.","url":"https://huggingface.co/datasets/Codyfederer/test6","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"lomwe-speech-text","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tLomwe Speech-Text Parallel Dataset\n\t\n\nThis dataset is a collection of aligned audio-text pairs in Lomwe, extracted from the CMU Wilderness dataset. It is useful for tasks such as:\n\nSpeech recognition (ASR)\nText-to-speech (TTS)\nLanguage modeling for low-resource languages\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry in the dataset contains:\n\naudio: A .wav file sampled at 16kHz\ntext: A transcription of the spoken audio in Lomwe (digits removed)\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n\n\t\n\t\t\naudio\ntext‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/lomwe-speech-text.","url":"https://huggingface.co/datasets/michsethowusu/lomwe-speech-text","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","audio-intent-classification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"test6","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\ttest6\n\t\n\nThis is a merged speech dataset containing 1994 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 1994\nSpeakers: 3\nLanguages: en\nEmotions: neutral, negative_surprise, positive_surprise, distress, relief, contentment, adoration, interest, confusion, happy, sadness, triumph, fear, disappointment, awe, realization, angry\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test6.","url":"https://huggingface.co/datasets/Codyfederer/test6","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"lomwe-speech-text","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tLomwe Speech-Text Parallel Dataset\n\t\n\nThis dataset is a collection of aligned audio-text pairs in Lomwe, extracted from the CMU Wilderness dataset. It is useful for tasks such as:\n\nSpeech recognition (ASR)\nText-to-speech (TTS)\nLanguage modeling for low-resource languages\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry in the dataset contains:\n\naudio: A .wav file sampled at 16kHz\ntext: A transcription of the spoken audio in Lomwe (digits removed)\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n\n\t\n\t\t\naudio\ntext‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/lomwe-speech-text.","url":"https://huggingface.co/datasets/michsethowusu/lomwe-speech-text","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","audio-intent-classification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"test6","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\ttest6\n\t\n\nThis is a merged speech dataset containing 1994 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 1994\nSpeakers: 3\nLanguages: en\nEmotions: neutral, negative_surprise, positive_surprise, distress, relief, contentment, adoration, interest, confusion, happy, sadness, triumph, fear, disappointment, awe, realization, angry\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test6.","url":"https://huggingface.co/datasets/Codyfederer/test6","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"som_tts","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tSomali TTS Dataset\n\t\n\nThis dataset contains high-quality Somali speech recordings with corresponding transcriptions.It is designed for training Text-to-Speech (TTS) models such as Coqui XTTS v2, FastSpeech, or VITS for the Somali language.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nFormat: .wav audio + metadata.csv (tab-separated: wav_path, transcription)\nLanguage: Somali\nTotal Samples: ~20,000 clips\nSampling Rate: 22050 Hz\n\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo train with Coqui TTS:\ntts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zakihassan/som_tts.","url":"https://huggingface.co/datasets/zakihassan/som_tts","creator_name":"Zakarie Hassan Abdi","creator_url":"https://huggingface.co/zakihassan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Somali","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"tretret34543","keyword":"speech","description":"\n\t\n\t\t\n\t\ttretret34543\n\t\n\nThis is a merged speech dataset containing 822 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 822\nSpeakers: 11\nLanguages: tr\nEmotions: happy, angry, neutral\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nlanguage: Language code‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/tretret34543.","url":"https://huggingface.co/datasets/Codyfederer/tretret34543","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"tretret34543","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\ttretret34543\n\t\n\nThis is a merged speech dataset containing 822 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 822\nSpeakers: 11\nLanguages: tr\nEmotions: happy, angry, neutral\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nlanguage: Language code‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/tretret34543.","url":"https://huggingface.co/datasets/Codyfederer/tretret34543","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"common_voice_20_armenian","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tCommon Voice 20 - Armenian\n\t\n\nThis dataset is the Armenian portion of Mozilla's Common Voice 20.0 release, \na massively multilingual collection of transcribed speech intended for speech technology research and development.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Armenian (hy)\nSource: Mozilla Common Voice\nVersion: 20.0\nLicense: CC0-1.0\n\n\n","url":"https://huggingface.co/datasets/Chillarmo/common_voice_20_armenian","creator_name":"Movses Movsesyan","creator_url":"https://huggingface.co/Chillarmo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Armenian","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"tretret34543","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\ttretret34543\n\t\n\nThis is a merged speech dataset containing 822 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 822\nSpeakers: 11\nLanguages: tr\nEmotions: happy, angry, neutral\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nlanguage: Language code‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/tretret34543.","url":"https://huggingface.co/datasets/Codyfederer/tretret34543","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ga-speech-text-parallel","keyword":"speech","description":"\n\t\n\t\t\n\t\tGa Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 98343 parallel speech-text pairs for Ga, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Ga - gaa\nTask: Speech Recognition, Text-to-Speech\nSize: 98343 audio files > 1KB (small/corrupted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/ga-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/ga-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Ga"],"keywords_longer_than_N":true},
	{"name":"115hours_pvtv_myanmar_asr","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\t115 Hours PVTV Myanmar ASR\n\t\n\nThis dataset contains 156,262 audio-transcript pairs of spoken Burmese, totaling approximately 115.31 hours. The audio segments were extracted from publicly available YouTube videos published by PVTV and aligned using subtitle timestamps.\n\n\t\n\t\t\n\t\tDedication\n\t\n\nThis dataset would not exist without the persistent voices of PVTV editors, journalists, narrators, and production teams, who continue to speak to the people under difficult conditions. PVTV is the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/115hours_pvtv_myanmar_asr.","url":"https://huggingface.co/datasets/freococo/115hours_pvtv_myanmar_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","Burmese","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"115hours_pvtv_myanmar_asr","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\t115 Hours PVTV Myanmar ASR\n\t\n\nThis dataset contains 156,262 audio-transcript pairs of spoken Burmese, totaling approximately 115.31 hours. The audio segments were extracted from publicly available YouTube videos published by PVTV and aligned using subtitle timestamps.\n\n\t\n\t\t\n\t\tDedication\n\t\n\nThis dataset would not exist without the persistent voices of PVTV editors, journalists, narrators, and production teams, who continue to speak to the people under difficult conditions. PVTV is the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/115hours_pvtv_myanmar_asr.","url":"https://huggingface.co/datasets/freococo/115hours_pvtv_myanmar_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","Burmese","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"ga-speech-text-parallel","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tGa Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 98343 parallel speech-text pairs for Ga, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Ga - gaa\nTask: Speech Recognition, Text-to-Speech\nSize: 98343 audio files > 1KB (small/corrupted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/ga-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/ga-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Ga"],"keywords_longer_than_N":true},
	{"name":"RuReviewsClassification","keyword":"hate-speech-detection","description":"\n  RuReviewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nProduct review classification (3-point scale) based on RuRevies dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/sismetanin/rureviews\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"RuReviewsClassification\")\nevaluator = mteb.MTEB([task])\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RuReviewsClassification.","url":"https://huggingface.co/datasets/mteb/RuReviewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"ga-speech-text-parallel","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tGa Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 98343 parallel speech-text pairs for Ga, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Ga - gaa\nTask: Speech Recognition, Text-to-Speech\nSize: 98343 audio files > 1KB (small/corrupted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/ga-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/ga-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Ga"],"keywords_longer_than_N":true},
	{"name":"libritts_r","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for LibriTTS-R\n\t\n\n\n\nLibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus \n(http://www.openslr.org/60/) which is a multi-speaker English corpus of approximately \n585 hours of read English speech at 24kHz sampling rate, published in 2019.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the LibriTTS-R dataset, adapted for the datasets library.\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\n\t\n\t\t\n\t\tSplits\n\t\n\nThere are 7 splits (dots replace dashes from the original dataset, to comply with hf naming‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pharaouk/libritts_r.","url":"https://huggingface.co/datasets/pharaouk/libritts_r","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Kazakh_Speech_Corpus_2","keyword":"speech","description":"\n\t\n\t\t\n\t\tKazakh Speech Corpus 2 (KSC2)\n\t\n\nThis dataset card describes the KSC2, an industrial-scale, open-source speech corpus for the Kazakh language.\nPaper: KSC2: An Industrial-Scale Open-Source Kazakh Speech Corpus\nSummary: KSC2 corpus subsumes the previously introduced two corpora: Kazakh Speech Corpus and Kazakh Text-To-Speech 2, and supplements additional data from other sources like tv programs, radio, senate, and podcasts. In total, KSC2 contains around 1.2k hours of high-quality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/Kazakh_Speech_Corpus_2.","url":"https://huggingface.co/datasets/issai/Kazakh_Speech_Corpus_2","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kazakh","mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"Kazakh_Speech_Corpus_2","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tKazakh Speech Corpus 2 (KSC2)\n\t\n\nThis dataset card describes the KSC2, an industrial-scale, open-source speech corpus for the Kazakh language.\nPaper: KSC2: An Industrial-Scale Open-Source Kazakh Speech Corpus\nSummary: KSC2 corpus subsumes the previously introduced two corpora: Kazakh Speech Corpus and Kazakh Text-To-Speech 2, and supplements additional data from other sources like tv programs, radio, senate, and podcasts. In total, KSC2 contains around 1.2k hours of high-quality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/Kazakh_Speech_Corpus_2.","url":"https://huggingface.co/datasets/issai/Kazakh_Speech_Corpus_2","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kazakh","mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"task2_advanced","keyword":"linguistics","description":"\n\t\n\t\t\n\t\t–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n\t\n\n\n\t\n\t\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ\n\t\n\n–î–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞ –∫–Ω–∏–≥–∏ \"Harry Potter and the Philosopher's Stone\", –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω–æ–≥–æ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞. –í –ø—Ä–æ—Ü–µ—Å—Å–µ –∞–Ω–∞–ª–∏–∑–∞ –±—ã–ª–∏ –ø—Ä–æ–≤–µ–¥–µ–Ω—ã —Ç—Ä–∏ –∫–ª—é—á–µ–≤—ã—Ö —Ç–∏–ø–∞ –∞–Ω–∞–ª–∏–∑–∞:\n\n–ê–Ω–∞–ª–∏–∑ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö: –û—Ü–µ–Ω–∫–∞ –¥–æ–ª–∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ –≤ –∫–æ—Ä–ø—É—Å–µ —Ç–µ–∫—Å—Ç–∞ –∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –ª–µ–∫—Å–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è.\n–ê–Ω–∞–ª–∏–∑ —á–∞—Å—Ç–æ—Ç—ã POS-—Ç–µ–≥–æ–≤: –ò–∑—É—á–µ–Ω–∏–µ —á–∞—Å—Ç–æ—Ç—ã‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lamdary/task2_advanced.","url":"https://huggingface.co/datasets/lamdary/task2_advanced","creator_name":"Daria Malysheva","creator_url":"https://huggingface.co/lamdary","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"automatic-speech-recognition","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\nChanges:\n\nUsed archive.org metadata API to annotate rows with \"duration\" column\n\n","url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"openai-voices","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tOpenAI Voices\n\t\n\nA collection of TTS samples collected from the OpenAI API and app.\nCurrently the following voices are available:\n\nSky\nJuniper\n\nThese are not labeled, however they are clean lossless audio files, and may contain noise from the model.\nPlease refer to sky/statement.wav for the highest quality voice sample!\n","url":"https://huggingface.co/datasets/leafspark/openai-voices","creator_name":"leafspark","creator_url":"https://huggingface.co/leafspark","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"text-to-speech","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\nChanges:\n\nUsed archive.org metadata API to annotate rows with \"duration\" column\n\n","url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"emilia-sitio-do-pica-pau-amarelo-2012","keyword":"text-to-speech","description":"gabrielsemiceki9/emilia-sitio-do-pica-pau-amarelo-2012 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/gabrielsemiceki9/emilia-sitio-do-pica-pau-amarelo-2012","creator_name":"877","creator_url":"https://huggingface.co/gabrielsemiceki9","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Portuguese","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"composite_corpus_es_v1.0","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tComposite dataset for Spanish made from public available data\n\t\n\nThis dataset is composed of the following public available data:\n\n\t\n\t\t\n\t\tTrain split:\n\t\n\nThe train split is composed of the following datasets combined:\n\nmozilla-foundation/common_voice_18_0/es: \"validated\" split removing \"test_cv\" and \"dev_cv\" split's sentences. (validated split contains official train + dev + test splits and more unique data)\nopenslr: a train split made from the SLR(39,61,67,71,72,73,74,75,108) subsets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/composite_corpus_es_v1.0.","url":"https://huggingface.co/datasets/HiTZ/composite_corpus_es_v1.0","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"composite_corpus_eseu_v1.0","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tComposite bilingual dataset for Spanish and Basque made from public available data\n\t\n\nThis dataset is composed of the following public available data:\n\n\t\n\t\t\n\t\tTrain split:\n\t\n\nThe train split is composed of the following datasets combined:\n\nmozilla-foundation/common_voice_18_0/es: a portion of the \"validated\" split removing \"test_cv\" and \"dev_cv\" split's sentences. (validated split contains official train + dev + test splits and more unique data)\nmozilla-foundation/common_voice_18_0/eu:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/composite_corpus_eseu_v1.0.","url":"https://huggingface.co/datasets/HiTZ/composite_corpus_eseu_v1.0","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Basque","Spanish","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"bengali_regional_dataset_refine","keyword":"automatic-speech-recognition","description":"This is the dataset of  ‡¶≠‡¶æ‡¶∑‡¶æ-‡¶¨‡¶ø‡¶ö‡¶ø‡¶§‡ßç‡¶∞‡¶æ: ASR for Regional Dialects competition.\nhere i preprocessed and make train and eval split.\nthis dataset consist of 10 dialact named 'barishal', 'chittagong', 'habiganj', 'kishoreganj', 'narail',\n       'narsingdi', 'rangpur', 'sandwip', 'sylhet', 'tangail'.\nbarishal district has 796 samples\nchittagong district has 1406 samples\nhabiganj district has 940 samples\nkishoreganj district has 1638 samples\nnarail district has 1488 samples\nnarsingdi district has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sha1779/bengali_regional_dataset_refine.","url":"https://huggingface.co/datasets/sha1779/bengali_regional_dataset_refine","creator_name":"Md sazzad hossain","creator_url":"https://huggingface.co/sha1779","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Bengali","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"jacob-common-voice-19-zh-TW-curated","keyword":"automatic-speech-recognition","description":"JacobLinCool/jacob-common-voice-19-zh-TW-curated dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/JacobLinCool/jacob-common-voice-19-zh-TW-curated","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Chinese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"IWSLT2025-Test","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset details\n\t\n\nThis is the blind test set of IWSLT 2025's model compression track.\nIt consists of audio extracted from ACL presentations.\nFor training data in the same domain, the ACL 60/60 dataset can be used.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@INPROCEEDINGS{Abdulmumin2025-IWSLT,\n  title     = \"{Findings of the IWSLT 2025 Evaluation Campaign}\",\n  author    = \"Abdulmumin, Idris and Agostinelli, Victor and Alum√§e, Tanel and\n               Anastasopoulos, Antonios and {Ashwin} and Bentivogli‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/IWSLT2025-Test.","url":"https://huggingface.co/datasets/ymoslem/IWSLT2025-Test","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"jacob-common-voice-19-zh-TW-curated","keyword":"text-to-speech","description":"JacobLinCool/jacob-common-voice-19-zh-TW-curated dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/JacobLinCool/jacob-common-voice-19-zh-TW-curated","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Chinese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"EchoX-Dialogues-Plus","keyword":"automatic-speech-recognition","description":"\n\n  EchoX-Dialogues-Plus: Training Data Plus for EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs\n\n\n\n\n  üêà‚Äç‚¨õ Github¬†ÔΩú¬†üìÉ Paper¬†ÔΩú¬†üöÄ Space¬†\n\n\n  üß† EchoX-8B¬†ÔΩú¬†üß† EchoX-3B¬†ÔΩú¬†üì¶ EchoX-Dialogues (base)¬†\n\n\n\n\t\n\t\n\t\n\t\tEchoX-Dialogues-Plus\n\t\n\nEchoX-Dialogues-Plus extends KurtDu/EchoX-Dialogues with large-scale Speech-to-Speech (S2S) and Speech-to-Text (S2T) dialogues.\nAll assistant/output speech is synthetic (single, consistent timbre for S2S). Texts are from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KurtDu/EchoX-Dialogues-Plus.","url":"https://huggingface.co/datasets/KurtDu/EchoX-Dialogues-Plus","creator_name":"Yuhao Du","creator_url":"https://huggingface.co/KurtDu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","question-answering","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"parczech4speech-segmented","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tParCzech4Speech (Sentence-Segmented Variant)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nParCzech4Speech (Sentence-Segmented Variant) is a large-scale Czech speech dataset based on parliamentary recordings and official transcripts. \nThis sentence-segmented variant is designed for speech recognition and synthesis tasks, offering clean audio-text alignment and reliable segment boundaries. \nIt is derived from the ParCzech 4.0 corpus and AudioPSP 24.01 audio collection. \nUsing WhisperX and Wav2Vec 2.0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ufal/parczech4speech-segmented.","url":"https://huggingface.co/datasets/ufal/parczech4speech-segmented","creator_name":"Institute of Formal and Applied Linguistics, Charles University, Prague","creator_url":"https://huggingface.co/ufal","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Czech","cc-by-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"ami-disfluent","keyword":"automatic-speech-recognition","description":"JacobLinCool/ami-disfluent dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/JacobLinCool/ami-disfluent","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"EchoX-Dialogues-Plus","keyword":"text-to-speech","description":"\n\n  EchoX-Dialogues-Plus: Training Data Plus for EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs\n\n\n\n\n  üêà‚Äç‚¨õ Github¬†ÔΩú¬†üìÉ Paper¬†ÔΩú¬†üöÄ Space¬†\n\n\n  üß† EchoX-8B¬†ÔΩú¬†üß† EchoX-3B¬†ÔΩú¬†üì¶ EchoX-Dialogues (base)¬†\n\n\n\n\t\n\t\n\t\n\t\tEchoX-Dialogues-Plus\n\t\n\nEchoX-Dialogues-Plus extends KurtDu/EchoX-Dialogues with large-scale Speech-to-Speech (S2S) and Speech-to-Text (S2T) dialogues.\nAll assistant/output speech is synthetic (single, consistent timbre for S2S). Texts are from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KurtDu/EchoX-Dialogues-Plus.","url":"https://huggingface.co/datasets/KurtDu/EchoX-Dialogues-Plus","creator_name":"Yuhao Du","creator_url":"https://huggingface.co/KurtDu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","question-answering","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"parczech4speech-segmented","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tParCzech4Speech (Sentence-Segmented Variant)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nParCzech4Speech (Sentence-Segmented Variant) is a large-scale Czech speech dataset based on parliamentary recordings and official transcripts. \nThis sentence-segmented variant is designed for speech recognition and synthesis tasks, offering clean audio-text alignment and reliable segment boundaries. \nIt is derived from the ParCzech 4.0 corpus and AudioPSP 24.01 audio collection. \nUsing WhisperX and Wav2Vec 2.0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ufal/parczech4speech-segmented.","url":"https://huggingface.co/datasets/ufal/parczech4speech-segmented","creator_name":"Institute of Formal and Applied Linguistics, Charles University, Prague","creator_url":"https://huggingface.co/ufal","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Czech","cc-by-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"voa_myanmar_asr_audio_1","keyword":"speech","description":"\nüì¢ This is the first publicly released ASR-ready Burmese speech dataset with over 1 million audio chunks ‚Äî a milestone in the history of Myanmar language technology.\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset was created by scraping and segmenting the full archive of the VOA Burmese morning radio program. Out of a total of 3,687 full-length MP3 broadcasts, this release processes 3,267 of them, resulting in approximately 1.8 million sentence-level audio chunks, totaling ~3,267 hours of segmented audio.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/voa_myanmar_asr_audio_1.","url":"https://huggingface.co/datasets/freococo/voa_myanmar_asr_audio_1","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Public Domain Dedication & License","license_url":"https://scancode-licensedb.aboutcode.org/pddl-1.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","pddl"],"keywords_longer_than_N":true},
	{"name":"parler-tts_mls_eng_10k_snac_token_old","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/blanchon/parler-tts_mls_eng_10k_snac_token_old.","url":"https://huggingface.co/datasets/blanchon/parler-tts_mls_eng_10k_snac_token_old","creator_name":"Julien BLANCHON","creator_url":"https://huggingface.co/blanchon","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"voa_myanmar_asr_audio_1","keyword":"automatic-speech-recognition","description":"\nüì¢ This is the first publicly released ASR-ready Burmese speech dataset with over 1 million audio chunks ‚Äî a milestone in the history of Myanmar language technology.\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset was created by scraping and segmenting the full archive of the VOA Burmese morning radio program. Out of a total of 3,687 full-length MP3 broadcasts, this release processes 3,267 of them, resulting in approximately 1.8 million sentence-level audio chunks, totaling ~3,267 hours of segmented audio.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/voa_myanmar_asr_audio_1.","url":"https://huggingface.co/datasets/freococo/voa_myanmar_asr_audio_1","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Public Domain Dedication & License","license_url":"https://scancode-licensedb.aboutcode.org/pddl-1.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","pddl"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 21.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 21. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_21_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_21_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"VoxCommunis","keyword":"linguistics","description":"\n\t\n\t\t\n\t\tVoxCommunis Corpus\n\t\n\nThe VoxCommunis Corpus is a phonetic corpus derived from the Mozilla Common Voice Corpus. Corresponding audio files and corpus metadata can be downloaded from Mozilla Common Voice, or from one of several Hugging Face repositories for the differing versions. \nWithin each folder, the filenames share similar structure and contain critical information for effectively using the file. More detail regarding the specifics of the filename for each file type is provided‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.","url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"ai-gospel-music-dictionaries","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tAI Gospel Music Dictionaries\n\t\n\nA comprehensive collection of JSON dictionaries designed to support AI-powered gospel music and lyrics generation, with a focus on biblical and theological content.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository contains a curated set of dictionaries that can be used for:\n\nMusic generation tasks\nLyrics generation with biblical themes\nInstrument and genre specifications\nBiblical reference materials\n\n\n\t\n\t\t\n\t\tDictionaries\n\t\n\n\n\t\n\t\t\n\t\tBiblical Content‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cmathhug/ai-gospel-music-dictionaries.","url":"https://huggingface.co/datasets/cmathhug/ai-gospel-music-dictionaries","creator_name":"Cruz Macias","creator_url":"https://huggingface.co/cmathhug","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-audio","text-to-speech","cc0-1.0","n<1K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"common-voice-corpus-20","keyword":"automatic-speech-recognition","description":"hataphu/common-voice-corpus-20 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/hataphu/common-voice-corpus-20","creator_name":"Ha Van Tan","creator_url":"https://huggingface.co/hataphu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Vietnamese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Gemini-2.0-Flash-Aoede-Voice","keyword":"text-to-speech","description":"fireblade2534/Gemini-2.0-Flash-Aoede-Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/fireblade2534/Gemini-2.0-Flash-Aoede-Voice","creator_name":"fireblade2534","creator_url":"https://huggingface.co/fireblade2534","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"odia-language-audiodataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tOdia Language Audio Dataset\n\t\n\nText spoken by all participants:\n\"‡¨ï‡≠É‡¨§‡≠ç‡¨∞‡¨ø‡¨Æ ‡¨¨‡≠Å‡¨¶‡≠ç‡¨ß‡¨ø‡¨Æ‡¨§‡≠ç‡¨§‡¨æ (AI) ‡¨¶‡≠ç‡¨∞‡≠Å‡¨§ ‡¨ó‡¨§‡¨ø‡¨∞‡≠á ‡¨¨‡¨ø‡¨ï‡¨∂‡¨ø‡¨§ ‡¨π‡≠á‡¨â‡¨õ‡¨ø, ‡¨Ø‡¨æ‡¨π‡¨æ ‡¨¶‡≠à‡¨®‡¨¶‡¨ø‡¨® ‡¨ú‡≠Ä‡¨¨‡¨®‡¨ï‡≠Å ‡¨¨‡¨¶‡¨≥‡¨æ‡¨â‡¨õ‡¨ø‡•§ ‡¨è‡¨π‡¨æ‡¨∞ ‡¨®‡≠Ç‡¨Ü‡¨™‡¨£ ‡¨∂‡¨ø‡¨ï‡≠ç‡¨∑‡¨æ, ‡¨∏‡≠ç‡≠±‡¨æ‡¨∏‡≠ç‡¨•‡≠ç‡≠ü‡¨∏‡≠á‡¨¨‡¨æ ‡¨ì ‡¨ï‡¨æ‡¨Æ‡¨ï‡≠Å ‡¨â‡¨®‡≠ç‡¨®‡¨§ ‡¨ï‡¨∞‡≠Å‡¨õ‡¨ø, ‡¨®‡≠Ç‡¨Ü ‡¨∏‡≠Å‡¨Ø‡≠ã‡¨ó ‡¨∏‡≠É‡¨∑‡≠ç‡¨ü‡¨ø ‡¨ï‡¨∞‡≠Å‡¨õ‡¨ø‡•§\"\nThe dataset supports training and evaluation of models in:\n\nAutomatic Speech Recognition (ASR)\nEmotional tone classification\nVoice synthesis and generation\nEmotion-aware conversational agents\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntended Uses\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t‚úÖ Direct Use\n\t\n\n\nTraining and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/odia-language-audiodataset.","url":"https://huggingface.co/datasets/Kratos-AI/odia-language-audiodataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Malayalam","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"NanoFiQA2018Retrieval","keyword":"hate-speech-detection","description":"\n  NanoFiQA2018Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNanoFiQA2018 is a smaller subset of the Financial Opinion Mining and Question Answering dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Social\n\n\nReferencehttps://sites.google.com/view/fiqa/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NanoFiQA2018Retrieval\"])\nevaluator = mteb.MTEB(task)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NanoFiQA2018Retrieval.","url":"https://huggingface.co/datasets/mteb/NanoFiQA2018Retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"sauatai-ertegiler-kz-misspellings-kk-s170-len60-n6-m1-2-v1","keyword":"grammar","description":"\n\t\n\t\t\n\t\tSauatAI ‚Äî Kazakh Misspelled Sentences from Ertegiler.kz\n\t\n\nSauatAI is a grammar-focused dataset built from 170 children‚Äôs stories scraped from ertegiler.kz on July 5, 2025. The dataset was designed to support Kazakh language grammar correction, error detection, and text augmentation research.\n\n\t\n\t\t\n\t\tüìå Dataset Details\n\t\n\n\ns170 ‚Äî 170 unique stories were scraped and sentence-tokenized.\nlen60 ‚Äî Only sentences with ‚â§60 characters were retained.\nn6 ‚Äî Each correct sentence has 5‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alphazhan/sauatai-ertegiler-kz-misspellings-kk-s170-len60-n6-m1-2-v1.","url":"https://huggingface.co/datasets/alphazhan/sauatai-ertegiler-kz-misspellings-kk-s170-len60-n6-m1-2-v1","creator_name":"Alzhan Nurgaliyev","creator_url":"https://huggingface.co/alphazhan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","Kazakh","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Sarc7","keyword":"sarcasm-detection","description":"langlglang/Sarc7 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/langlglang/Sarc7","creator_name":"Lang Xiong","creator_url":"https://huggingface.co/langlglang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","üá∫üá∏ Region: US","sarcasm-detection","text-classification"],"keywords_longer_than_N":true},
	{"name":"my_dataset_2","keyword":"text-to-speech","description":"kashif314/my_dataset_2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kashif314/my_dataset_2","creator_name":"kashif","creator_url":"https://huggingface.co/kashif314","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Urdu","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"MANGO","keyword":"speech","description":"\n\t\n\t\t\n\t\tMANGO: A Corpus of Human Ratings for Speech\n\t\n\nMANGO (MUSHRA Assessment corpus using Native listeners and Guidelines to understand human Opinions at scale) is the first large-scale dataset designed for evaluating Text-to-Speech (TTS) systems in Indian languages. \n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\n255,150 human ratings of TTS-generated outputs and ground-truth human speech.\nCovers two major Indian languages: Hindi & Tamil, and English.\nBased on the MUSHRA (Multiple Stimuli with Hidden Reference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/MANGO.","url":"https://huggingface.co/datasets/ai4bharat/MANGO","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","crowd-sourced","Hindi","Tamil","English"],"keywords_longer_than_N":true},
	{"name":"MANGO","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tMANGO: A Corpus of Human Ratings for Speech\n\t\n\nMANGO (MUSHRA Assessment corpus using Native listeners and Guidelines to understand human Opinions at scale) is the first large-scale dataset designed for evaluating Text-to-Speech (TTS) systems in Indian languages. \n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\n255,150 human ratings of TTS-generated outputs and ground-truth human speech.\nCovers two major Indian languages: Hindi & Tamil, and English.\nBased on the MUSHRA (Multiple Stimuli with Hidden Reference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/MANGO.","url":"https://huggingface.co/datasets/ai4bharat/MANGO","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","crowd-sourced","Hindi","Tamil","English"],"keywords_longer_than_N":true},
	{"name":"MANGO","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tMANGO: A Corpus of Human Ratings for Speech\n\t\n\nMANGO (MUSHRA Assessment corpus using Native listeners and Guidelines to understand human Opinions at scale) is the first large-scale dataset designed for evaluating Text-to-Speech (TTS) systems in Indian languages. \n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\n255,150 human ratings of TTS-generated outputs and ground-truth human speech.\nCovers two major Indian languages: Hindi & Tamil, and English.\nBased on the MUSHRA (Multiple Stimuli with Hidden Reference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/MANGO.","url":"https://huggingface.co/datasets/ai4bharat/MANGO","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","crowd-sourced","Hindi","Tamil","English"],"keywords_longer_than_N":true},
	{"name":"deg-speech-text-parallel","keyword":"speech","description":"\n\t\n\t\t\n\t\tDeg Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 125958 parallel speech-text pairs for Deg, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Deg - mzw\nTask: Speech Recognition, Text-to-Speech\nSize: 125958 audio files > 1KB (small/corrupted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/deg-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/deg-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Deg"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_test_vad","keyword":"speech","description":"Voice Activity Detection (VAD) Test Dataset\nThis dataset is based on the test.clean and test.other splits from the\nlibrispeech_asr\ncorpus. It includes two binary labels:\n\nspeech: Indicates presence of speech ([0, 1]), computed using a dynamic threshold method with background noise estimation and smoothing.\n\nconfidence: A post-processing flag to optionally correct transient dropouts in speech. It is set to 1 by default, but switches to 0 for up to ~0.1 seconds (3 chunks of audio) following a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/guynich/librispeech_asr_test_vad.","url":"https://huggingface.co/datasets/guynich/librispeech_asr_test_vad","creator_name":"Guy Nicholson","creator_url":"https://huggingface.co/guynich","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"deg-speech-text-parallel","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDeg Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 125958 parallel speech-text pairs for Deg, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Deg - mzw\nTask: Speech Recognition, Text-to-Speech\nSize: 125958 audio files > 1KB (small/corrupted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/deg-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/deg-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Deg"],"keywords_longer_than_N":true},
	{"name":"kikongo-bible-asr","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tKikongo Bible ASR\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/kikongo-bible-asr.","url":"https://huggingface.co/datasets/Svngoku/kikongo-bible-asr","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Kongo","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"deg-speech-text-parallel","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDeg Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 125958 parallel speech-text pairs for Deg, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Deg - mzw\nTask: Speech Recognition, Text-to-Speech\nSize: 125958 audio files > 1KB (small/corrupted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/deg-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/deg-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Deg"],"keywords_longer_than_N":true},
	{"name":"kikongo-bible-asr","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tKikongo Bible ASR\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/kikongo-bible-asr.","url":"https://huggingface.co/datasets/Svngoku/kikongo-bible-asr","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Kongo","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"darija_speech_to_text","keyword":"automatic-speech-recognition","description":"adiren7/darija_speech_to_text dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/adiren7/darija_speech_to_text","creator_name":"Adil Oubaibou","creator_url":"https://huggingface.co/adiren7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"SpokenWords-GA-EN-MTed","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis is the Irish portion of the Spoken Words dataset (available at MLCommons/ml_spoken_words),\nwith merged splits ‚Äútrain‚Äù, ‚Äúvalidation‚Äù, and ‚Äútest‚Äù, augmented with machine translation.\nThe Irish sentences are automatically translated into English using Google Translation API.\nThe dataset includes approximately 3 hours and 2 minutes of audio (03:02:02), spoken by multiple narrators.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['keyword'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/SpokenWords-GA-EN-MTed.","url":"https://huggingface.co/datasets/ymoslem/SpokenWords-GA-EN-MTed","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"whisper-internal-test","keyword":"automatic-speech-recognition","description":"Original datasets can be found in shb777/gemini-flash-2.0-speech.\nFor personal testing purposes.\n","url":"https://huggingface.co/datasets/neulus/whisper-internal-test","creator_name":"Minseok Lee","creator_url":"https://huggingface.co/neulus","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"KoDetox","keyword":"hate-speech","description":"\n\t\n\t\t\n\t\tKoDetox: A Paired Dataset for Korean Hate Speech Detoxification\n\t\n\n\n\t\n\t\t\n\t\tüóÇÔ∏è Dataset Summary\n\t\n\nKoDetox is a Korean dataset consisting of 8,856 pairs of toxic comments and their detoxified counterparts. The detoxified counterparts were generated by Qwen3-14B.\nThe dataset is curated for tasks such as toxic language mitigation, instruction tuning, and alignment tuning (e.g., DPO, PPO) in Korean.\nEach sample contains:\n\noriginal: a Korean hate speech or toxic comment\npurified: a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jaime-Choi/KoDetox.","url":"https://huggingface.co/datasets/Jaime-Choi/KoDetox","creator_name":"Haemin Choi","creator_url":"https://huggingface.co/Jaime-Choi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","Korean","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"EstonianValenceClassification","keyword":"hate-speech-detection","description":"\n  EstonianValenceClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDataset containing annotated Estonian news data from the Postimees and √ïhtuleht newspapers.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReferencehttps://figshare.com/articles/dataset/Estonian_Valence_Corpus_Eesti_valentsikorpus/24517054\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/EstonianValenceClassification.","url":"https://huggingface.co/datasets/mteb/EstonianValenceClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"SpokenWords-GA-EN-MTed","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis is the Irish portion of the Spoken Words dataset (available at MLCommons/ml_spoken_words),\nwith merged splits ‚Äútrain‚Äù, ‚Äúvalidation‚Äù, and ‚Äútest‚Äù, augmented with machine translation.\nThe Irish sentences are automatically translated into English using Google Translation API.\nThe dataset includes approximately 3 hours and 2 minutes of audio (03:02:02), spoken by multiple narrators.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['keyword'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/SpokenWords-GA-EN-MTed.","url":"https://huggingface.co/datasets/ymoslem/SpokenWords-GA-EN-MTed","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"inbrowser-proctor-dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Inbrowser Proctor Dataset\n\t\n\n\n\t\n\t\t\n\t\tProject Description\n\t\n\nInbrowser Proctoring is an online browser proctoring application designed to supervise exams and prevent cheating in real-time. Utilizing a combination of video, audio, and screen recording technologies, along with advanced AI algorithms, the system closely monitors test-takers to identify suspicious behaviors and activities. By analyzing audio and visual data, it can detect anomalies that may indicate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lord-reso/inbrowser-proctor-dataset.","url":"https://huggingface.co/datasets/lord-reso/inbrowser-proctor-dataset","creator_name":"Aayush Man Shrestha","creator_url":"https://huggingface.co/lord-reso","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"inbrowser-proctor-dataset","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Inbrowser Proctor Dataset\n\t\n\n\n\t\n\t\t\n\t\tProject Description\n\t\n\nInbrowser Proctoring is an online browser proctoring application designed to supervise exams and prevent cheating in real-time. Utilizing a combination of video, audio, and screen recording technologies, along with advanced AI algorithms, the system closely monitors test-takers to identify suspicious behaviors and activities. By analyzing audio and visual data, it can detect anomalies that may indicate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lord-reso/inbrowser-proctor-dataset.","url":"https://huggingface.co/datasets/lord-reso/inbrowser-proctor-dataset","creator_name":"Aayush Man Shrestha","creator_url":"https://huggingface.co/lord-reso","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"serere-dataset-v1","keyword":"speech","description":"\n\t\n\t\t\n\t\tS√©r√®re Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nCe dataset contient des enregistrements audio en langue s√©r√®re avec leurs transcriptions. Le s√©r√®re est une langue parl√©e principalement au S√©n√©gal.\n\n\t\n\t\t\n\t\tUtilisation\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"votre-nom/serere-speech-dataset\")\n\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naudio: Fichiers audio au format WAV\ntranscription: Transcription textuelle de l'audio\nsource_directory: R√©pertoire source de l'audio\nfilename: Nom du‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Moustapha91/serere-dataset-v1.","url":"https://huggingface.co/datasets/Moustapha91/serere-dataset-v1","creator_name":"Moustapha Sarr","creator_url":"https://huggingface.co/Moustapha91","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Serer","mit","1K<n<10K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"serere-dataset-v1","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tS√©r√®re Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nCe dataset contient des enregistrements audio en langue s√©r√®re avec leurs transcriptions. Le s√©r√®re est une langue parl√©e principalement au S√©n√©gal.\n\n\t\n\t\t\n\t\tUtilisation\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"votre-nom/serere-speech-dataset\")\n\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naudio: Fichiers audio au format WAV\ntranscription: Transcription textuelle de l'audio\nsource_directory: R√©pertoire source de l'audio\nfilename: Nom du‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Moustapha91/serere-dataset-v1.","url":"https://huggingface.co/datasets/Moustapha91/serere-dataset-v1","creator_name":"Moustapha Sarr","creator_url":"https://huggingface.co/Moustapha91","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Serer","mit","1K<n<10K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"piper_italiano","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tPiper Italiano\n\t\n\nSto cercando di creare un nuovo checkpoint per PiperTTS in italiano.\nLa fonte per il traine √® il Multilingual LibriSpeech (MLS) rilasciato sotto licenza Creative Commons\nQui metter√≤ i dataset estratti dal suddetto blocco dati\nIl dataset √® nel formato che gradisce PiperTTS come indicato a questo link\n\nAurora √® lo speaker 6807\nLeonardo √® lo speaker 1595 - Probabile voce di Riccardo (modello originale di piper) ma ad una maggiore qualit√†\n\n","url":"https://huggingface.co/datasets/kirys79/piper_italiano","creator_name":"Federico Improta","creator_url":"https://huggingface.co/kirys79","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Italian","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"KAI-indian-emotional-speech-corpus","keyword":"speech","description":"\n\t\n\t\t\n\t\tIndian Emotional Speech Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset comprises high-quality audio recordings of Indian speakers reading a standardized 50-word paragraph in four distinct emotional tones ‚Äî happy, sad, surprised, and angry.\nEach recording is approximately 20‚Äì25 seconds long and includes the full paragraph with tone shifts at specific points.\nText spoken by all participants:\n\n(happy tone) Last Monday was perfect‚ÄîI got the job I‚Äôd been dreaming of! I screamed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/KAI-indian-emotional-speech-corpus.","url":"https://huggingface.co/datasets/Kratos-AI/KAI-indian-emotional-speech-corpus","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"lwazi-asr-corpus-compressed","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tLwazi ASR Corpus Collection\n\t\n\nThis repository contains a curated collection of the Lwazi Automatic Speech Recognition (ASR) Corpus for several low-resourced South African languages. These datasets are designed for use in speech recognition research and development, particularly for underrepresented languages.\n\n\t\n\t\t\n\t\tCorpus Overview\n\t\n\nEach corpus consists of scripted telephonic speech recordings collected from native speakers, along with corresponding transcriptions. The audio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dsfsi/lwazi-asr-corpus-compressed.","url":"https://huggingface.co/datasets/dsfsi/lwazi-asr-corpus-compressed","creator_name":"Data Science for Social Impact","creator_url":"https://huggingface.co/dsfsi","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Tswana","Tsonga","Venda","Zulu"],"keywords_longer_than_N":true},
	{"name":"TatSC_ASR","keyword":"speech","description":"\n\t\n\t\t\n\t\tTatar Speech Corpus ASR\n\t\n\n[Original repository] [Original site]\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTatar Speech Corpus ASR is a speech dataset sourced from this GitHub repository. TatSC contains 269.1 hours of transcribed speech with 271,914 utterances. It is the first open-source Tatar speech corpus covering both crowdsourced and audiobooks data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nParts:The dataset contains a single set of recordings, though they come from two different sources:\n\nCrowdsourced‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yasalma/TatSC_ASR.","url":"https://huggingface.co/datasets/yasalma/TatSC_ASR","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Tatar","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"TatSC_ASR","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTatar Speech Corpus ASR\n\t\n\n[Original repository] [Original site]\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTatar Speech Corpus ASR is a speech dataset sourced from this GitHub repository. TatSC contains 269.1 hours of transcribed speech with 271,914 utterances. It is the first open-source Tatar speech corpus covering both crowdsourced and audiobooks data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nParts:The dataset contains a single set of recordings, though they come from two different sources:\n\nCrowdsourced‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yasalma/TatSC_ASR.","url":"https://huggingface.co/datasets/yasalma/TatSC_ASR","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Tatar","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"killkan","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tKillkan: Speech Recognition dataset for Kichwa\n\t\n\nKillkan (Kichwa uyachkata payllatak killkak anta) is the first automatic speech recognition (ASR) dataset for the Kichwa language.\nSee also our paper (https://arxiv.org/abs/2404.15501).\n","url":"https://huggingface.co/datasets/ctaguchi/killkan","creator_name":"Chihiro Taguchi","creator_url":"https://huggingface.co/ctaguchi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Quechua","Imbabura Highland Quichua","Chimborazo Highland Quichua","Salasaca Highland Quichua"],"keywords_longer_than_N":true},
	{"name":"peaky-blinders-learning-purpose-only","keyword":"speech","description":"\n\t\n\t\t\n\t\tTTS Dataset - Peaky Blinders\n\t\n\nThis dataset contains audio segments with transcriptions from Peaky Blinders for Text-to-Speech training.\n\n\t\n\t\t\n\t\tDataset Generation\n\t\n\nThis dataset was generated using the TTS-Dataset-Maker pipeline, which provides:\n\nSilero VAD-based silence removal - Removes long silences while preserving natural speech gaps\nDeepFilterNet denoising - CPU-optimized audio denoising with gentle attenuation (15dB)\nAssemblyAI transcription - High-quality speech-to-text with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ahk-d/peaky-blinders-learning-purpose-only.","url":"https://huggingface.co/datasets/ahk-d/peaky-blinders-learning-purpose-only","creator_name":"ahk-d","creator_url":"https://huggingface.co/ahk-d","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"peaky-blinders-learning-purpose-only","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTTS Dataset - Peaky Blinders\n\t\n\nThis dataset contains audio segments with transcriptions from Peaky Blinders for Text-to-Speech training.\n\n\t\n\t\t\n\t\tDataset Generation\n\t\n\nThis dataset was generated using the TTS-Dataset-Maker pipeline, which provides:\n\nSilero VAD-based silence removal - Removes long silences while preserving natural speech gaps\nDeepFilterNet denoising - CPU-optimized audio denoising with gentle attenuation (15dB)\nAssemblyAI transcription - High-quality speech-to-text with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ahk-d/peaky-blinders-learning-purpose-only.","url":"https://huggingface.co/datasets/ahk-d/peaky-blinders-learning-purpose-only","creator_name":"ahk-d","creator_url":"https://huggingface.co/ahk-d","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"FeruzaSpeech_to_fine_tuning","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tFeruzaSpeech_to_fine_tuning\n\t\n\nA speech corpus of ‚è±Ô∏è¬†~59.1 total hours of Uzbek audio paired with Latin‚Äëscript transcripts, intended for fine‚Äëtuning ASR / speech‚Äëto‚Äëtext models.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains recordings of native Uzbek speakers reading a mix of classical literature excerpts and school‚Äëlevel writing prompts:\n\n001:‚ÄØCholiqushi (a novel by Rashod‚ÄØNuri‚ÄØGuntekin, trans. by Mirzakalon‚ÄØIsmoiliy; first pub. Sept‚ÄØ1900).  \n002:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nickoo004/FeruzaSpeech_to_fine_tuning.","url":"https://huggingface.co/datasets/nickoo004/FeruzaSpeech_to_fine_tuning","creator_name":"Nicholas","creator_url":"https://huggingface.co/nickoo004","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-audio","Uzbek","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"sauatai-ertegiler-kz-misspellings-kk-s170-len60-n6-m1-3-v1","keyword":"grammar","description":"\n\t\n\t\t\n\t\tSauatAI ‚Äî Kazakh Misspelled Sentences from Ertegiler.kz\n\t\n\nSauatAI is a grammar-focused dataset built from 170 children‚Äôs stories scraped from ertegiler.kz on July 5, 2025. The dataset was designed to support Kazakh language grammar correction, error detection, and text augmentation research.\n\n\t\n\t\t\n\t\tüìå Dataset Details\n\t\n\n\ns170 ‚Äî 170 unique stories were scraped and sentence-tokenized.\nlen60 ‚Äî Only sentences with ‚â§60 characters were retained.\nn6 ‚Äî Each correct sentence has 5‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alphazhan/sauatai-ertegiler-kz-misspellings-kk-s170-len60-n6-m1-3-v1.","url":"https://huggingface.co/datasets/alphazhan/sauatai-ertegiler-kz-misspellings-kk-s170-len60-n6-m1-3-v1","creator_name":"Alzhan Nurgaliyev","creator_url":"https://huggingface.co/alphazhan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","Kazakh","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"peaky-blinders-learning-purpose-only","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tTTS Dataset - Peaky Blinders\n\t\n\nThis dataset contains audio segments with transcriptions from Peaky Blinders for Text-to-Speech training.\n\n\t\n\t\t\n\t\tDataset Generation\n\t\n\nThis dataset was generated using the TTS-Dataset-Maker pipeline, which provides:\n\nSilero VAD-based silence removal - Removes long silences while preserving natural speech gaps\nDeepFilterNet denoising - CPU-optimized audio denoising with gentle attenuation (15dB)\nAssemblyAI transcription - High-quality speech-to-text with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ahk-d/peaky-blinders-learning-purpose-only.","url":"https://huggingface.co/datasets/ahk-d/peaky-blinders-learning-purpose-only","creator_name":"ahk-d","creator_url":"https://huggingface.co/ahk-d","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"yoruba-speech-text-parallel","keyword":"speech","description":"\n\t\n\t\t\n\t\tYoruba Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 1647022 parallel speech-text pairs for Yoruba, a language spoken primarily in Nigeria and other West African countries. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Yoruba - yo\nTask: Speech Recognition, Text-to-Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/yoruba-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/yoruba-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Yoruba"],"keywords_longer_than_N":true},
	{"name":"Telugu-NLP-AI-Dialect-Comedy-video-Dataset","keyword":"speech","description":"Telugu is one of the sweetest and oldest languages of India. A deep Dive into Telugu its spoken in 2 states and majorly 16 regional dailects.\nThis Dataset help you perform operations in NLP and Speech Recognition Models towards telugu Dialects.\n","url":"https://huggingface.co/datasets/Automation-Tribe/Telugu-NLP-AI-Dialect-Comedy-video-Dataset","creator_name":"AUTTRIBE-AI-AUTOMATION","creator_url":"https://huggingface.co/Automation-Tribe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","Telugu","Kannada","English"],"keywords_longer_than_N":true},
	{"name":"ravnursson_asr","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for ravnursson_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe corpus \"RAVNURSSON FAROESE SPEECH AND TRANSCRIPTS\" (or RAVNURSSON Corpus for short) is a collection of speech recordings with transcriptions intended for Automatic Speech Recognition (ASR) applications in the language that is spoken at the Faroe Islands (Faroese). It was curated at the Reykjav√≠k University (RU) in 2022.\nThe RAVNURSSON Corpus is an extract of the \"Basic Language Resource Kit 1.0\" (BLARK 1.0) [1] developed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlosdanielhernandezmena/ravnursson_asr.","url":"https://huggingface.co/datasets/carlosdanielhernandezmena/ravnursson_asr","creator_name":"Carlos Daniel Hern√°ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"yoruba-speech-text-parallel","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tYoruba Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 1647022 parallel speech-text pairs for Yoruba, a language spoken primarily in Nigeria and other West African countries. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Yoruba - yo\nTask: Speech Recognition, Text-to-Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/yoruba-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/yoruba-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Yoruba"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"automatic-speech-recognition","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\n","url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"zeroth-STT-Ko","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tZeroth-STT-Ko Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset combines the following publicly available Korean language datasets:\nJunhoee/STT_Korean_Dataset_80000\nand\nZeroth-Korean Dataset (from Project: Zeroth, by GoodAtlas and Gridspace)\nThis provides over 102K rows of data (sentences) in total.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nZeroth-Korean Dataset, created by [Lucas Jo(@Atlas Guide Inc.) and Wonkyum Lee(@Gridspace Inc.)], 2023.\nAvailable at https://github.com/goodatlas/zeroth under CC-BY-4.0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/o0dimplz0o/zeroth-STT-Ko.","url":"https://huggingface.co/datasets/o0dimplz0o/zeroth-STT-Ko","creator_name":"Michele Phan","creator_url":"https://huggingface.co/o0dimplz0o","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Korean","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"yoruba-speech-text-parallel","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tYoruba Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 1647022 parallel speech-text pairs for Yoruba, a language spoken primarily in Nigeria and other West African countries. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Yoruba - yo\nTask: Speech Recognition, Text-to-Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/yoruba-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/yoruba-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Yoruba"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"text-to-speech","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\n","url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"vn_tts_medium_clean","keyword":"text-to-speech","description":"\n\n\t\n\t\t\n\t\tüáªüá≥ Vietnamese Voice Dataset Clean (24kHz)\n\t\n\nB·ªô d·ªØ li·ªáu v·∫´n ƒëang ƒë∆∞·ª£c update th√™m v·ªõi gi·ªçng n√≥i c·ªßa m·ªôt ng∆∞·ªùi, m·ªói source s·∫Ω c√≥ m·ªôt gi·ªçng mi·ªÅn kh√°c nhau. \nDataset c√≥ gi·ªçng ƒë·ªß :\nNam - Mi·ªÅn Nam = \"source\" = \"2\", \nN·ªØ - Mi·ªÅn Nam = \"source\" = \"3\", \nNam - Mi·ªÅn B·∫Øc = \"source\" = \"0\",\nN·ªØ - Mi·ªÅn B·∫Øc = \"source\" = \"1\"\n\n\t\n\t\t\n\t\tüìÅ C·∫•u tr√∫c d·ªØ li·ªáu\n\t\n\n\ntext: C√¢u transcript t∆∞∆°ng ·ª©ng\nsource: Youtube\n\n\n\t\n\t\t\n\t\tüßπ Ti·ªÅn x·ª≠ l√Ω\n\t\n\n\nLo·∫°i b·ªè nhi·ªÖu n·ªÅn, c·∫Øt silence\nT·ª± ƒë·ªông t√°ch c√¢u b·∫±ng nltk v√† gh√©p l·∫°i ƒë·ªÉ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cosrigel/vn_tts_medium_clean.","url":"https://huggingface.co/datasets/cosrigel/vn_tts_medium_clean","creator_name":"Cos Rigel","creator_url":"https://huggingface.co/cosrigel","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Vietnamese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"vn_tts_medium_clean","keyword":"text-to-speech","description":"\n\n\t\n\t\t\n\t\tüáªüá≥ Vietnamese Voice Dataset Clean (24kHz)\n\t\n\nB·ªô d·ªØ li·ªáu v·∫´n ƒëang ƒë∆∞·ª£c update th√™m v·ªõi gi·ªçng n√≥i c·ªßa m·ªôt ng∆∞·ªùi, m·ªói source s·∫Ω c√≥ m·ªôt gi·ªçng mi·ªÅn kh√°c nhau. \nDataset c√≥ gi·ªçng ƒë·ªß :\nNam - Mi·ªÅn Nam = \"source\" = \"2\", \nN·ªØ - Mi·ªÅn Nam = \"source\" = \"3\", \nNam - Mi·ªÅn B·∫Øc = \"source\" = \"0\",\nN·ªØ - Mi·ªÅn B·∫Øc = \"source\" = \"1\"\n\n\t\n\t\t\n\t\tüìÅ C·∫•u tr√∫c d·ªØ li·ªáu\n\t\n\n\ntext: C√¢u transcript t∆∞∆°ng ·ª©ng\nsource: Youtube\n\n\n\t\n\t\t\n\t\tüßπ Ti·ªÅn x·ª≠ l√Ω\n\t\n\n\nLo·∫°i b·ªè nhi·ªÖu n·ªÅn, c·∫Øt silence\nT·ª± ƒë·ªông t√°ch c√¢u b·∫±ng nltk v√† gh√©p l·∫°i ƒë·ªÉ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cosrigel/vn_tts_medium_clean.","url":"https://huggingface.co/datasets/cosrigel/vn_tts_medium_clean","creator_name":"Cos Rigel","creator_url":"https://huggingface.co/cosrigel","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Vietnamese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"coddef","keyword":"automatic-speech-recognition","description":"falabrasil/coddef dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/falabrasil/coddef","creator_name":"Grupo FalaBrasil","creator_url":"https://huggingface.co/falabrasil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","webdataset"],"keywords_longer_than_N":true},
	{"name":"yodas-granary","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for YODAS-Granary\n\t\n\n\nRepository: NeMo-speech-data-processor: Granary\nPaper: Granary: Speech Recognition and Translation Dataset in 25 European Languages\nShared by: ESPnet\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nYODAS-Granary is a curated subset of the larger nvidia/Granary dataset, focusing on high-quality pseudo-labeled speech data for Automatic Speech Recognition (ASR) and Automatic Speech Translation (AST) across 23 European languages.\n\n\t\n\t\n\t\n\t\tOverview‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/espnet/yodas-granary.","url":"https://huggingface.co/datasets/espnet/yodas-granary","creator_name":"ESPnet","creator_url":"https://huggingface.co/espnet","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","Bulgarian","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Rhulk_pt-br","keyword":"text-to-speech","description":"satierf/Rhulk_pt-br dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/satierf/Rhulk_pt-br","creator_name":"thiago freitas pimenta","creator_url":"https://huggingface.co/satierf","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-generation","Portuguese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"test3","keyword":"speech","description":"\n\t\n\t\t\n\t\ttest3\n\t\n\nThis is a merged speech dataset containing 345 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 345\nSpeakers: 7\nLanguages: en\nEmotions: happy, neutral, angry, sad\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral, happy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test3.","url":"https://huggingface.co/datasets/Codyfederer/test3","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"test3","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\ttest3\n\t\n\nThis is a merged speech dataset containing 345 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 345\nSpeakers: 7\nLanguages: en\nEmotions: happy, neutral, angry, sad\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral, happy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test3.","url":"https://huggingface.co/datasets/Codyfederer/test3","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"WisesightSentimentClassification","keyword":"hate-speech-detection","description":"\n  WisesightSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nWisesight Sentiment Corpus: Social media messages in Thai language with sentiment label (positive, neutral, negative, question)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, News, Written\nReference\nhttps://github.com/PyThaiNLP/wisesight-sentiment\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/WisesightSentimentClassification.","url":"https://huggingface.co/datasets/mteb/WisesightSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"test3","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\ttest3\n\t\n\nThis is a merged speech dataset containing 345 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 345\nSpeakers: 7\nLanguages: en\nEmotions: happy, neutral, angry, sad\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral, happy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test3.","url":"https://huggingface.co/datasets/Codyfederer/test3","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"whisper_asr_traindata","keyword":"speech","description":"\n\t\n\t\t\n\t\tEnglish Accent Audio-transcript Dataset.\n\t\n\nAudio is extracted from movies, shows, speeches, talks to capture diverse accents - mainly scottish and indian\nThis dataset contains 30-second audio clips with aligned transcript text. \n\n\t\n\t\t\n\t\tStructure\n\t\n\nEach entry includes:\n\naudio: 30-second speech segment\ntext: Corresponding transcript\nstart_time / end_time: Segment timestamps\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nLicensed under CC-BY-4.0.\n","url":"https://huggingface.co/datasets/sarannair/whisper_asr_traindata","creator_name":"Saran Nair","creator_url":"https://huggingface.co/sarannair","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"common_voice_22_0","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 22.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 22. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_22_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_22_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"indicvoices_hi_tagged_transcripts","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_hi_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_hi_tagged_transcripts.","url":"https://huggingface.co/datasets/WhissleAI/indicvoices_hi_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"korean-leg","keyword":"speech","description":"\n\t\n\t\t\n\t\tMulti-Domain Korean Speech Dataset\n\t\n\nThis dataset contains 5 audio recordings with corresponding text transcriptions across multiple languages and domains.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA comprehensive collection of audio files paired with text transcriptions, featuring both synthetic and natural speech across various domains. Suitable for automatic speech recognition (ASR), text-to-speech (TTS), and domain-specific speech processing tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jsbeaudry/korean-leg.","url":"https://huggingface.co/datasets/jsbeaudry/korean-leg","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Korean","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"ToneWebinars","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tToneWebinars\n\t\n\nToneWebinars ‚Äî —ç—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è ZeroAgency/shkolkovo-bobr.video-webinars-audio.\n–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –±—ã–ª–∏ –ø–µ—Ä–µ–ø–∞–∫–æ–≤—ã–Ω—ã –≤ parquet —Ñ–æ—Ä–º–∞—Ç —Å –Ω–∞—Ä–µ–∑–∫–æ–π –ø–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–Ω—ã–º —Ç–∞–∫–º–∫–æ–¥–∞–º. –í –¥–∞—Ç–∞—Å–µ—Ç–µ 2053.55 —á–∞—Å–∞ –∞—É–¥–∏–æ –¥–ª—è train —Å–ø–ª–∏—Ç–∞ –∏ 154.34 –¥–ª—è validation.\n\n\n\t\n\t\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ\n\t\n\n–î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ –ø—Ä–¥–æ—Å—Ç–∞–≤–ª—è—é—Ç—Å—è:\n\n–°—Å—ã–ª–∫–∞ –Ω–∞ MP3-—Ñ–∞–π–ª (audio)\n–¢–µ–∫—Å—Ç–æ–≤–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ (text)\n–ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ (sample_rate)\n\n\n\n\t\n\t\t\n\t\t–§–æ—Ä–º–∞—Ç –∑–∞–ø–∏—Å–∏ (JSON)\n\t\n\n{\n  \"audio\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneWebinars.","url":"https://huggingface.co/datasets/Vikhrmodels/ToneWebinars","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Russian","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Fleurs-Kn","keyword":"automatic-speech-recognition","description":"This is a filtered version of the Fleurs dataset only containing samples of Kannada language.\nThe dataset contains total of 2283 training, 368 validation and 838 test samples.\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'id': 1053,\n 'num_samples': 226560,\n 'path': '/home/ravi.naik/.cache/huggingface/datasets/downloads/extracted/e7c8b501d4e6892673b6dc291d42de48e7987b0d2aa6471066a671f686224ed1/10000267636955490843.wav',\n 'audio': {'path': 'train/10000267636955490843.wav',\n  'array': array([ 0.        ,  0.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Indic-LLM-Labs/Fleurs-Kn.","url":"https://huggingface.co/datasets/Indic-LLM-Labs/Fleurs-Kn","creator_name":"Indic-LLM-Labs","creator_url":"https://huggingface.co/Indic-LLM-Labs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"korean-leg","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tMulti-Domain Korean Speech Dataset\n\t\n\nThis dataset contains 5 audio recordings with corresponding text transcriptions across multiple languages and domains.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA comprehensive collection of audio files paired with text transcriptions, featuring both synthetic and natural speech across various domains. Suitable for automatic speech recognition (ASR), text-to-speech (TTS), and domain-specific speech processing tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jsbeaudry/korean-leg.","url":"https://huggingface.co/datasets/jsbeaudry/korean-leg","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Korean","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"nchlt_speech_afr","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tNCHLT Speech Corpus -- Afrikaans\n\t\n\nThis is the Afrikaans language part of the NCHLT Speech Corpus of the South African languages.\nLanguage code (ISO 639): afr\nURI: https://hdl.handle.net/20.500.12185/280\n\n\t\n\t\t\n\t\tLicence:\n\t\n\nCreative Commons Attribution 3.0 Unported License (CC BY 3.0): http://creativecommons.org/licenses/by/3.0/legalcode\n\n\t\n\t\t\n\t\tAttribution:\n\t\n\nThe Department of Arts and Culture of the government of the Republic of South Africa (DAC), Council for Scientific and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/danielshaps/nchlt_speech_afr.","url":"https://huggingface.co/datasets/danielshaps/nchlt_speech_afr","creator_name":"Daniel van Niekerk","creator_url":"https://huggingface.co/danielshaps","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Afrikaans","cc-by-3.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"BengaliHateSpeechClassification","keyword":"hate-speech-detection","description":"\n  BengaliHateSpeechClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Bengali Hate Speech Dataset is a Bengali-language dataset of news articles collected from various Bengali media sources and categorized based on the type of hate in the text.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/bn_hate_speech\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BengaliHateSpeechClassification.","url":"https://huggingface.co/datasets/mteb/BengaliHateSpeechClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"Notcrowy","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tAudio Dataset Statistics\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal audio files\n556,667\n\n\nTotal duration\n1,024.71 hours (3,688,949 seconds)\n\n\nAverage duration\n6.63 seconds\n\n\nShortest clip\n0.41 seconds\n\n\nLongest clip\n44.97 seconds\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSpeaker Breakdown\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tTop 10 Speakers by Clip Count\n\t\n\n\n\t\n\t\t\nSpeaker\nClips\nDuration\n% of Total\n\n\n\t\t\nDespina\n60,150\n118.07 hours\n11.5%\n\n\nSulafat\n31,593\n58.15 hours\n5.7%\n\n\nAchernar29,889\n54.53 hours\n5.3%\n\n\nAutonoe\n27,897‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mobinx/Notcrowy.","url":"https://huggingface.co/datasets/mobinx/Notcrowy","creator_name":"Mobin Chowdhury","creator_url":"https://huggingface.co/mobinx","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"ToneWebinars","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tToneWebinars\n\t\n\nToneWebinars ‚Äî —ç—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è ZeroAgency/shkolkovo-bobr.video-webinars-audio.\n–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –±—ã–ª–∏ –ø–µ—Ä–µ–ø–∞–∫–æ–≤—ã–Ω—ã –≤ parquet —Ñ–æ—Ä–º–∞—Ç —Å –Ω–∞—Ä–µ–∑–∫–æ–π –ø–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–Ω—ã–º —Ç–∞–∫–º–∫–æ–¥–∞–º. –í –¥–∞—Ç–∞—Å–µ—Ç–µ 2053.55 —á–∞—Å–∞ –∞—É–¥–∏–æ –¥–ª—è train —Å–ø–ª–∏—Ç–∞ –∏ 154.34 –¥–ª—è validation.\n\n\n\t\n\t\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ\n\t\n\n–î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ –ø—Ä–¥–æ—Å—Ç–∞–≤–ª—è—é—Ç—Å—è:\n\n–°—Å—ã–ª–∫–∞ –Ω–∞ MP3-—Ñ–∞–π–ª (audio)\n–¢–µ–∫—Å—Ç–æ–≤–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ (text)\n–ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ (sample_rate)\n\n\n\n\t\n\t\t\n\t\t–§–æ—Ä–º–∞—Ç –∑–∞–ø–∏—Å–∏ (JSON)\n\t\n\n{\n  \"audio\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneWebinars.","url":"https://huggingface.co/datasets/Vikhrmodels/ToneWebinars","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Russian","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"korean-leg","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tMulti-Domain Korean Speech Dataset\n\t\n\nThis dataset contains 5 audio recordings with corresponding text transcriptions across multiple languages and domains.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA comprehensive collection of audio files paired with text transcriptions, featuring both synthetic and natural speech across various domains. Suitable for automatic speech recognition (ASR), text-to-speech (TTS), and domain-specific speech processing tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jsbeaudry/korean-leg.","url":"https://huggingface.co/datasets/jsbeaudry/korean-leg","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Korean","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"pony-singing","keyword":"text-to-speech","description":"synthbot/pony-singing dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/synthbot/pony-singing","creator_name":"Synthbot Anon","creator_url":"https://huggingface.co/synthbot","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"css10-ljspeech","keyword":"speech","description":"\n\t\n\t\t\n\t\tCSS10-LJSpeech\n\t\n\nCSS10-LJSpeech „ÅØ„ÄÅPark et al. „ÅåÂÖ¨Èñã„Åó„Åü CSS10 „Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí„ÄÅLJSpeech‰∫íÊèõ„Éï„Ç©„Éº„Éû„ÉÉ„Éà„Å´Â§âÊèõ„Åó„Åü10Ë®ÄË™û„ÅÆÈü≥Â£∞ÂêàÊàêÁî®„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇÂêÑË®ÄË™û„ÅÆÊñáÂ≠¶‰ΩúÂìÅ„ÇíÈü≥Â£∞Âåñ„Åó„ÅüÈ´òÂìÅË≥™„Å™Èü≥Â£∞„Éá„Éº„Çø„ÇíÊèê‰æõ„Åó„ÄÅLJSpeech„Éï„Ç©„Éº„Éû„ÉÉ„ÉàÔºàid|text & wavs/*.wavÔºâ„Å´Áµ±‰∏Ä„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n\n\t\n\t\t\n\t\t„Éá„Éº„ÇøÊ¶ÇË¶Å\n\t\n\n\n\t\n\t\t\nÈ†ÖÁõÆ\nÂÄ§\n\n\n\t\t\nË©±ËÄÖÊï∞\n10 (Ë®ÄË™ûÂà•)\n\n\nÁ∑èÈü≥Â£∞Êï∞\n64,196\n\n\nÂêàË®àÊôÇÈñì\nÁ¥Ñ 140 ÊôÇÈñì\n\n\n„Çµ„É≥„Éó„É™„É≥„Ç∞„É¨„Éº„Éà\n22,050 Hz\n\n\nÈü≥Â£∞„Éï„Ç©„Éº„Éû„ÉÉ„Éà\nIEEEÊµÆÂãïÂ∞èÊï∞ÁÇπ (32bit)\n\n\n„ÉÜ„Ç≠„Çπ„ÉàË®ÄË™û\n10Ë®ÄË™û\n\n\n„Éï„Ç©„Éº„Éû„ÉÉ„Éà\n`id\n\n\n\t\n\n\n\t\n\t\t\n\t\tË®ÄË™ûÂà•Áµ±Ë®à\n\t\n\n\n\t\n\t\t\nË®ÄË™û\nË®ÄË™û„Ç≥„Éº„Éâ\nÈü≥Â£∞Êï∞\nÂêàË®àÊôÇÈñì\n\n\n\t\t\n„Éâ„Ç§„ÉÑË™û\nde\n7,428\n16.14ÊôÇÈñì\n\n\n„ÇÆ„É™„Ç∑„É£Ë™û\nel\n1,844\n4.14ÊôÇÈñì\n\n\n„Çπ„Éö„Ç§„É≥Ë™û\nes\n11,016\n19.15ÊôÇÈñì\n\n\n„Éï„Ç£„É≥„É©„É≥„ÉâË™û\nfi\n4,842\n10.53ÊôÇÈñì‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/css10-ljspeech.","url":"https://huggingface.co/datasets/ayousanz/css10-ljspeech","creator_name":"yousan","creator_url":"https://huggingface.co/ayousanz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","Greek","Spanish","Finnish","French"],"keywords_longer_than_N":true},
	{"name":"EmoVoice-DB","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for EmoVoice-DB\n\t\n\n\n\t\n\t\t\n\t\tOverview of EmoVoice-DB\n\t\n\nEmoVoice-DB is an English emotional speech dataset featuring fine-grained emotion labels expressed through natural language descriptions. This dataset contains over 20,000 emotionally expressive speech samples, each annotated with detailed and precise emotional descriptions, totaling approximately 40 hours of audio. EmoVoice-DB is built using synthetic data generated by the powerful‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yhaha/EmoVoice-DB.","url":"https://huggingface.co/datasets/yhaha/EmoVoice-DB","creator_name":"yangguanrou","creator_url":"https://huggingface.co/yhaha","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"Portuguese-audio-dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tPortuguese Voice Emotion Dataset\n\t\n\n*This dataset contains high-quality (‚ÄúA-grade‚Äù) data. It has been carefully curated, cleaned, and verified to ensure accuracy, completeness, and consistency, making it suitable for high-stakes or production-grade model training.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset comprises high-quality Portuguese speech recordings designed for training and evaluating Speech Emotion Recognition (SER) models. The dataset contains voice samples expressing four‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Portuguese-audio-dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Portuguese-audio-dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Portuguese","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Easy-Turn-Testset","keyword":"speech","description":"\n\t\n\t\t\n\t\tEasy Turn: Integrating Acoustic and Linguistic Modalities for Robust Turn-Taking in Full-Duplex Spoken Dialogue Systems\n\t\n\n\n  Guojian Li1, Chengyou Wang1, Hongfei Xue1, \n  Shuiyuan Wang1, Dehui Gao1, Zihan Zhang2, \n  Yuke Lin2, Wenjie Li2, Longshuai Xiao2, \n  Zhonghua Fu1,‚ïÄ, Lei Xie1,‚ïÄ\n\n\n\n  1 Audio, Speech and Language Processing Group (ASLP@NPU), Northwestern Polytechnical University \n  2 Huawei Technologies, China \n\n\n\n\n\n\t\n\t\t\nüé§ Demo Page\nü§ñ Easy Turn Model\nüìë Paper\nüåê Huggingface‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ASLP-lab/Easy-Turn-Testset.","url":"https://huggingface.co/datasets/ASLP-lab/Easy-Turn-Testset","creator_name":"ASLP-lab","creator_url":"https://huggingface.co/ASLP-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"hatevolution-vocabulary-expansion","keyword":"speech","description":"\n\t\n\t\t\n\t\tDataset Info\n\t\n\nThe hatevolution-vocabulary-expansion dataset contains the data used for Experiment 2 in the paper Hatevolution: What Static Benchmarks Don't Tell Us (Di Bonaventura et al., 2025). \nIt is built using the NeoBench dataset (Zheng et al., 2024), further annotated for hate speech detection. \n","url":"https://huggingface.co/datasets/dibo/hatevolution-vocabulary-expansion","creator_name":"Chiara Di Bonaventura","creator_url":"https://huggingface.co/dibo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","n<1K","arxiv:2506.12148"],"keywords_longer_than_N":true},
	{"name":"Easy-Turn-Testset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tEasy Turn: Integrating Acoustic and Linguistic Modalities for Robust Turn-Taking in Full-Duplex Spoken Dialogue Systems\n\t\n\n\n  Guojian Li1, Chengyou Wang1, Hongfei Xue1, \n  Shuiyuan Wang1, Dehui Gao1, Zihan Zhang2, \n  Yuke Lin2, Wenjie Li2, Longshuai Xiao2, \n  Zhonghua Fu1,‚ïÄ, Lei Xie1,‚ïÄ\n\n\n\n  1 Audio, Speech and Language Processing Group (ASLP@NPU), Northwestern Polytechnical University \n  2 Huawei Technologies, China \n\n\n\n\n\n\t\n\t\t\nüé§ Demo Page\nü§ñ Easy Turn Model\nüìë Paper\nüåê Huggingface‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ASLP-lab/Easy-Turn-Testset.","url":"https://huggingface.co/datasets/ASLP-lab/Easy-Turn-Testset","creator_name":"ASLP-lab","creator_url":"https://huggingface.co/ASLP-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"hatevolution-vocabulary-expansion","keyword":"hate-speech","description":"\n\t\n\t\t\n\t\tDataset Info\n\t\n\nThe hatevolution-vocabulary-expansion dataset contains the data used for Experiment 2 in the paper Hatevolution: What Static Benchmarks Don't Tell Us (Di Bonaventura et al., 2025). \nIt is built using the NeoBench dataset (Zheng et al., 2024), further annotated for hate speech detection. \n","url":"https://huggingface.co/datasets/dibo/hatevolution-vocabulary-expansion","creator_name":"Chiara Di Bonaventura","creator_url":"https://huggingface.co/dibo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","n<1K","arxiv:2506.12148"],"keywords_longer_than_N":true},
	{"name":"HebrewSentimentAnalysis","keyword":"hate-speech-detection","description":"\n  HebrewSentimentAnalysis\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHebrewSentiment is a data set consists of 12,804 user comments to posts on the official Facebook page of Israel‚Äôs president, Mr. Reuven Rivlin. In October 2015, we used the open software application Netvizz (Rieder, 2013) to scrape all the comments to all of the president‚Äôs posts in the period of June ‚Äì August 2014, the first three months of Rivlin‚Äôs presidency.2 While the president‚Äôs posts aimed at reconciling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HebrewSentimentAnalysis.","url":"https://huggingface.co/datasets/mteb/HebrewSentimentAnalysis","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"Speech2Latex","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSpeech2Latex Dataset\n\t\n\nThe Speech2LaTeX dataset is the first fully open-source large-scale dataset for converting spoken mathematical expressions and sentences into LaTeX. It comprises over 66,000 human-annotated audio samples of mathematical equations and sentences in both English and Russian, drawn from diverse scientific domains. This work lays the groundwork for future advances in multimodal AI, with a particular focus on mathematical content recognition.\nThe dataset was presented‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marsianin500/Speech2Latex.","url":"https://huggingface.co/datasets/marsianin500/Speech2Latex","creator_name":"Anonymous Account","creator_url":"https://huggingface.co/marsianin500","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-generation","crowdsourced","machine-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"IndicTTS_Bengali","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tBengali Indic TTS Dataset\n\t\n\nThis dataset is derived from the Indic TTS Database project, specifically using the Bengali monolingual recordings from both male and female speakers. The dataset contains high-quality speech recordings with corresponding text transcriptions, making it suitable for text-to-speech (TTS) research and development.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Bengali\nTotal Duration: ~15.06 hours (Male: 10.05 hours, Female: 5.01 hours)\nAudio Format: WAV\nSampling Rate:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/IndicTTS_Bengali.","url":"https://huggingface.co/datasets/SPRINGLab/IndicTTS_Bengali","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Bengali","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Hypa_Fleurs","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tHypa_Fleurs\n\t\n\nHypa_Fleurs is an open-source multilingual, multi-modal dataset with a long term vision of advancing speech and language technology for low-resource African languages by leveraging the English split of the Google Fleurs dataset to create parallel speech and text datasets for a wide range of low-resource African languages. In this initial release, professional AfroVoices experts translated the original English texts into three under-resourced African languages: Igbo (ig)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hypaai/Hypa_Fleurs.","url":"https://huggingface.co/datasets/hypaai/Hypa_Fleurs","creator_name":"Hypa-Intelligence","creator_url":"https://huggingface.co/hypaai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","text-classification","AfroVoices"],"keywords_longer_than_N":true},
	{"name":"Hypa_Fleurs","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tHypa_Fleurs\n\t\n\nHypa_Fleurs is an open-source multilingual, multi-modal dataset with a long term vision of advancing speech and language technology for low-resource African languages by leveraging the English split of the Google Fleurs dataset to create parallel speech and text datasets for a wide range of low-resource African languages. In this initial release, professional AfroVoices experts translated the original English texts into three under-resourced African languages: Igbo (ig)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hypaai/Hypa_Fleurs.","url":"https://huggingface.co/datasets/hypaai/Hypa_Fleurs","creator_name":"Hypa-Intelligence","creator_url":"https://huggingface.co/hypaai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","text-classification","AfroVoices"],"keywords_longer_than_N":true},
	{"name":"Hypa_Fleurs","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tHypa_Fleurs\n\t\n\nHypa_Fleurs is an open-source multilingual, multi-modal dataset with a long term vision of advancing speech and language technology for low-resource African languages by leveraging the English split of the Google Fleurs dataset to create parallel speech and text datasets for a wide range of low-resource African languages. In this initial release, professional AfroVoices experts translated the original English texts into three under-resourced African languages: Igbo (ig)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hypaai/Hypa_Fleurs.","url":"https://huggingface.co/datasets/hypaai/Hypa_Fleurs","creator_name":"Hypa-Intelligence","creator_url":"https://huggingface.co/hypaai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","text-classification","AfroVoices"],"keywords_longer_than_N":true},
	{"name":"recitation-segmentation-augmented","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tAutomatic Pronunciation Error Detection and Correction of the Holy Quran's Learners Using Deep Learning\n\t\n\nPaper | Project Page | Code\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis dataset is developed as part of the research presented in the paper \"Automatic Pronunciation Error Detection and Correction of the Holy Quran's Learners Using Deep Learning\". The work introduces a 98% automated pipeline to produce high-quality Quranic datasets, comprising over 850 hours of audio (~300K annotated utterances).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/obadx/recitation-segmentation-augmented.","url":"https://huggingface.co/datasets/obadx/recitation-segmentation-augmented","creator_name":"Abdullah","creator_url":"https://huggingface.co/obadx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","mit","10K - 100K","Tabular"],"keywords_longer_than_N":true},
	{"name":"quran_recitations_phonemes","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tPhoneme-labelled Quran Datatset\n\t\n\nThis dataset contains recitations from 45 professional Quran reciters, sourced from EveryAyah and QUL.\nThe audio has been automatically phoneme-labelled using a custom phonemizer that encodes Tajweed rules.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\naudio: 16 kHz resampled mono audio\n\nduration: length of the audio in seconds\n\nverse: reference in {surah_num}_{ayah_num} format\n\nreciter: name of the Qari\n\ntext: diacritised text in Uthmani script\n\nphonemes:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hetchyy/quran_recitations_phonemes.","url":"https://huggingface.co/datasets/hetchyy/quran_recitations_phonemes","creator_name":"Ahmed Ibrahim","creator_url":"https://huggingface.co/hetchyy","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"quran_recitations_phonemes","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tPhoneme-labelled Quran Datatset\n\t\n\nThis dataset contains recitations from 45 professional Quran reciters, sourced from EveryAyah and QUL.\nThe audio has been automatically phoneme-labelled using a custom phonemizer that encodes Tajweed rules.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\naudio: 16 kHz resampled mono audio\n\nduration: length of the audio in seconds\n\nverse: reference in {surah_num}_{ayah_num} format\n\nreciter: name of the Qari\n\ntext: diacritised text in Uthmani script\n\nphonemes:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hetchyy/quran_recitations_phonemes.","url":"https://huggingface.co/datasets/hetchyy/quran_recitations_phonemes","creator_name":"Ahmed Ibrahim","creator_url":"https://huggingface.co/hetchyy","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"GPTInformal-Persian","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tGPTInformal Persian\n\t\n\n\nGPTInformal Persian is a Persian dataset of 6+ hours of audio and text pairs designed for speech synthesis and other speech-related tasks. The dataset has been collected, processed, and annotated as a part of the Mana-TTS project. For details on data processing pipeline and statistics, please refer to the paper in the Citation secition.\n\n\t\n\t\t\n\t\n\t\n\t\tData Source\n\t\n\nThe text for this dataset was generated using GPT4o, with prompts covering a wide range of subjects‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahtaFetrat/GPTInformal-Persian.","url":"https://huggingface.co/datasets/MahtaFetrat/GPTInformal-Persian","creator_name":"Mahta Fetrat","creator_url":"https://huggingface.co/MahtaFetrat","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"mls-eng-10k-tags_tagged_10k_generated","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of 10K hours of English MLS\n\t\n\nThis dataset consists in annotations of a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pharaouk/mls-eng-10k-tags_tagged_10k_generated.","url":"https://huggingface.co/datasets/pharaouk/mls-eng-10k-tags_tagged_10k_generated","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"conrad-lynk-voice-pack-test","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tConrad Lynk Voice Pack\n\t\n\nA high-quality voice dataset featuring Conrad Lynk, an AI assistant for real estate professionals.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal Files: 144 audio samples\nFormat: WAV audio with text transcripts\nLanguage: English\nDomain: Real estate conversations\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"BlandAIOrg/conrad-lynk-voice-pack\")\n\n# Access audio and text\nfor item in dataset['train']:\n    audio = item['audio']‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BlandAIOrg/conrad-lynk-voice-pack-test.","url":"https://huggingface.co/datasets/BlandAIOrg/conrad-lynk-voice-pack-test","creator_name":"Bland AI","creator_url":"https://huggingface.co/BlandAIOrg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"mls-eng-10k-tags_tagged_10k_generated","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of 10K hours of English MLS\n\t\n\nThis dataset consists in annotations of a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pharaouk/mls-eng-10k-tags_tagged_10k_generated.","url":"https://huggingface.co/datasets/pharaouk/mls-eng-10k-tags_tagged_10k_generated","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"conrad-lynk-voice-pack-test","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tConrad Lynk Voice Pack\n\t\n\nA high-quality voice dataset featuring Conrad Lynk, an AI assistant for real estate professionals.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal Files: 144 audio samples\nFormat: WAV audio with text transcripts\nLanguage: English\nDomain: Real estate conversations\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"BlandAIOrg/conrad-lynk-voice-pack\")\n\n# Access audio and text\nfor item in dataset['train']:\n    audio = item['audio']‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BlandAIOrg/conrad-lynk-voice-pack-test.","url":"https://huggingface.co/datasets/BlandAIOrg/conrad-lynk-voice-pack-test","creator_name":"Bland AI","creator_url":"https://huggingface.co/BlandAIOrg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Tamazight-ASR-Dataset-v2","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTamazight-Arabic Speech Recognition Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains speech segments in Tamazight (specifically focusing on the Tachelhit dialect) paired with their corresponding Arabic transcriptions. It is designed to support the development of automatic speech recognition (ASR) systems for the Tamazight language, particularly for translation into Modern Standard Arabic.\nThis is an actively growing dataset, with regular updates and new data points being‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SoufianeDahimi/Tamazight-ASR-Dataset-v2.","url":"https://huggingface.co/datasets/SoufianeDahimi/Tamazight-ASR-Dataset-v2","creator_name":"Soufiane Dahimi","creator_url":"https://huggingface.co/SoufianeDahimi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","Standard Moroccan Tamazight","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Japanese-Eroge-Voice","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tJapanese-Eroge-Voice\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains pairs of audio data and corresponding transcriptions extracted from Japanese eroge (adult games) that I have personally purchased. The transcriptions are generated using the litagin/anime-whisper model.\n\n\n\t\n\t\t\n\t\tPreprocessing Steps\n\t\n\nThe raw audio data has undergone the following preprocessing steps:\n\nLoudness Normalization:\nAudio loudness is normalized using ffmpeg's 2-pass loudnorm filter to target parameters of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NandemoGHS/Japanese-Eroge-Voice.","url":"https://huggingface.co/datasets/NandemoGHS/Japanese-Eroge-Voice","creator_name":"NandemoGHS","creator_url":"https://huggingface.co/NandemoGHS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Japanese-Eroge-Voice","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tJapanese-Eroge-Voice\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains pairs of audio data and corresponding transcriptions extracted from Japanese eroge (adult games) that I have personally purchased. The transcriptions are generated using the litagin/anime-whisper model.\n\n\n\t\n\t\t\n\t\tPreprocessing Steps\n\t\n\nThe raw audio data has undergone the following preprocessing steps:\n\nLoudness Normalization:\nAudio loudness is normalized using ffmpeg's 2-pass loudnorm filter to target parameters of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NandemoGHS/Japanese-Eroge-Voice.","url":"https://huggingface.co/datasets/NandemoGHS/Japanese-Eroge-Voice","creator_name":"NandemoGHS","creator_url":"https://huggingface.co/NandemoGHS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Japanese-Eroge-Voice","keyword":"speech","description":"\n\t\n\t\t\n\t\tJapanese-Eroge-Voice\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains pairs of audio data and corresponding transcriptions extracted from Japanese eroge (adult games) that I have personally purchased. The transcriptions are generated using the litagin/anime-whisper model.\n\n\n\t\n\t\t\n\t\tPreprocessing Steps\n\t\n\nThe raw audio data has undergone the following preprocessing steps:\n\nLoudness Normalization:\nAudio loudness is normalized using ffmpeg's 2-pass loudnorm filter to target parameters of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NandemoGHS/Japanese-Eroge-Voice.","url":"https://huggingface.co/datasets/NandemoGHS/Japanese-Eroge-Voice","creator_name":"NandemoGHS","creator_url":"https://huggingface.co/NandemoGHS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"xhosa_merged_audio","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tXhosa Merged Audio\n\t\n\nThis dataset was cultivated from Beijuka/xhosa_parakeet_50hr. This dataset orginally came from NCHLT isiXhosa Speech Corpus (see below).\nThe original corpus contained audio and transcription in 3-5 word segments. This meant that the majority of the dataset was ~5 seconds long. Whisper can receive an input of 30 seconds. This meant that the dataset required substantial padding. To reduce the amount of padding, the audio segments were merged together sequentially‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wjbmattingly/xhosa_merged_audio.","url":"https://huggingface.co/datasets/wjbmattingly/xhosa_merged_audio","creator_name":"William Mattingly","creator_url":"https://huggingface.co/wjbmattingly","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Xhosa","cc-by-3.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-voices","keyword":"speech","description":"\n\t\n\t\t\n\t\tHailuo AI Voices Dataset üé§\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tüìä Dataset Overview\n\t\n\nThe dataset provides a comprehensive collection of voice samples with the following features:\n\n\t\n\t\t\nFeature\nDescription\n\n\n\t\t\nAudio Files\nHigh-quality WAV format recordings\n\n\nTranscription\nAccurate transcriptions of each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices.","url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"lapsbm","keyword":"automatic-speech-recognition","description":"falabrasil/lapsbm dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/falabrasil/lapsbm","creator_name":"Grupo FalaBrasil","creator_url":"https://huggingface.co/falabrasil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","webdataset"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-voices","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tHailuo AI Voices Dataset üé§\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tüìä Dataset Overview\n\t\n\nThe dataset provides a comprehensive collection of voice samples with the following features:\n\n\t\n\t\t\nFeature\nDescription\n\n\n\t\t\nAudio Files\nHigh-quality WAV format recordings\n\n\nTranscription\nAccurate transcriptions of each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices.","url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-voices","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tHailuo AI Voices Dataset üé§\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tüìä Dataset Overview\n\t\n\nThe dataset provides a comprehensive collection of voice samples with the following features:\n\n\t\n\t\t\nFeature\nDescription\n\n\n\t\t\nAudio Files\nHigh-quality WAV format recordings\n\n\nTranscription\nAccurate transcriptions of each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices.","url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-voices","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tHailuo AI Voices Dataset üé§\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tüìä Dataset Overview\n\t\n\nThe dataset provides a comprehensive collection of voice samples with the following features:\n\n\t\n\t\t\nFeature\nDescription\n\n\n\t\t\nAudio Files\nHigh-quality WAV format recordings\n\n\nTranscription\nAccurate transcriptions of each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices.","url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-voices","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_20k","keyword":"speech","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (20k)\n\t\n\nThis dataset contains 40000 synthetic speech recordings in the Pashto language,\nwith 20000 male voice recordings and 20000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 20000 sentences\nTotal Recordings: 40000 audio files (20000 male + 20000 female)\nAudio Format: WAV, 24kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 24kHz‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_20k.","url":"https://huggingface.co/datasets/ihanif/pashto_speech_20k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"swahili-words-speech-text-parallel","keyword":"speech","description":"\n\t\n\t\t\n\t\tSwahili Words Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 411048 parallel speech-text pairs for Swahili, a widely spoken language in East Africa. The dataset consists of audio recordings paired with corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Swahili - sw\nTask: Speech Recognition, Text-to-Speech\nSize: 411048 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/swahili-words-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/swahili-words-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Swahili"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_20k","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (20k)\n\t\n\nThis dataset contains 40000 synthetic speech recordings in the Pashto language,\nwith 20000 male voice recordings and 20000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 20000 sentences\nTotal Recordings: 40000 audio files (20000 male + 20000 female)\nAudio Format: WAV, 24kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 24kHz‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_20k.","url":"https://huggingface.co/datasets/ihanif/pashto_speech_20k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"swahili-words-speech-text-parallel","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSwahili Words Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 411048 parallel speech-text pairs for Swahili, a widely spoken language in East Africa. The dataset consists of audio recordings paired with corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Swahili - sw\nTask: Speech Recognition, Text-to-Speech\nSize: 411048 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/swahili-words-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/swahili-words-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Swahili"],"keywords_longer_than_N":true},
	{"name":"STT_uz","keyword":"automatic-speech-recognition","description":"The dataset is organized into the following directories and files:\naudio/\nother/: Contains .tar archives like uz_other_0.taruz_other_1.tar\ntrain/: Contains .tar archives like uz_train_0.tar.\nvalidated/: Contains .tar archives like uz_validated_0.tar, uz_validated_1.tar, and uz_validated_2.tar.\ntest/: Contains individual .wav files.\ntranscription/: Contains .tsv files including:\nother.tsv\ntrain.tsv\nvalidated.tsv\ntest.tsv\nThe .tsv files have two columns: file_name and transcription. Each entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Beehzod/STT_uz.","url":"https://huggingface.co/datasets/Beehzod/STT_uz","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","10K - 100K","webdataset"],"keywords_longer_than_N":true},
	{"name":"swahili-words-speech-text-parallel","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tSwahili Words Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 411048 parallel speech-text pairs for Swahili, a widely spoken language in East Africa. The dataset consists of audio recordings paired with corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Swahili - sw\nTask: Speech Recognition, Text-to-Speech\nSize: 411048 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/swahili-words-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/swahili-words-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Swahili"],"keywords_longer_than_N":true},
	{"name":"tetttttt","keyword":"speech","description":"\n\t\n\t\t\n\t\ttetttttt\n\t\n\nThis is a merged speech dataset containing 491 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 491\nSpeakers: 2\nLanguages: tr\nEmotions: angry, neutral, happy\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/tetttttt.","url":"https://huggingface.co/datasets/Codyfederer/tetttttt","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"tetttttt","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\ttetttttt\n\t\n\nThis is a merged speech dataset containing 491 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 491\nSpeakers: 2\nLanguages: tr\nEmotions: angry, neutral, happy\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/tetttttt.","url":"https://huggingface.co/datasets/Codyfederer/tetttttt","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"DKHateClassification","keyword":"hate-speech-detection","description":"\n  DKHateClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDanish Tweets annotated for Hate Speech either being Offensive or not\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReference\nhttps://aclanthology.org/2020.lrec-1.430/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"DKHateClassification\")\nevaluator = mteb.MTEB([task])\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DKHateClassification.","url":"https://huggingface.co/datasets/mteb/DKHateClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"tetttttt","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\ttetttttt\n\t\n\nThis is a merged speech dataset containing 491 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 491\nSpeakers: 2\nLanguages: tr\nEmotions: angry, neutral, happy\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/tetttttt.","url":"https://huggingface.co/datasets/Codyfederer/tetttttt","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"medical-opinion-english-audio","keyword":"speech","description":"\n\t\n\t\t\n\t\tMedical Opinion English Audio Dataset\n\t\n\n*This dataset contains intentionally low-quality (‚ÄúB-grade‚Äù) data. It has been curated to include noisy, imperfect, or otherwise suboptimal samples for the purpose of testing model robustness and performance under degraded input conditions\nText spoken by all participants:\n\"\"Doctor, another physician suggested my chest pain is stress-related, but I'm anxious. It feels like a heavy weight on my heart, and I struggle to breathe deeply. I'm scared.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/medical-opinion-english-audio.","url":"https://huggingface.co/datasets/Kratos-AI/medical-opinion-english-audio","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"composite_corpus_eu_v2.1","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tComposite dataset for Basque made from public available data\n\t\n\nThis dataset is composed of the following public available data:\n\n\t\n\t\t\n\t\tTrain split:\n\t\n\nThe train split is composed of the following datasets combined:\n\nmozilla-foundation/common_voice_18_0/eu: \"validated\" split removing \"test_cv\" and \"dev_cv\" split's sentences. (validated split contains official train + dev + test splits and more unique data)\ngttsehu/basque_parliament_1/eu: \"train_clean\" split removing some of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/composite_corpus_eu_v2.1.","url":"https://huggingface.co/datasets/HiTZ/composite_corpus_eu_v2.1","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Basque","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"genaral-swahili","keyword":"speech","description":"\n\t\n\t\t\n\t\tMulti-Domain Swahili Speech Dataset\n\t\n\nThis dataset contains 5 audio recordings with corresponding text transcriptions across multiple languages and domains.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA comprehensive collection of audio files paired with text transcriptions, featuring both synthetic and natural speech across various domains. Suitable for automatic speech recognition (ASR), text-to-speech (TTS), and domain-specific speech processing tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jsbeaudry/genaral-swahili.","url":"https://huggingface.co/datasets/jsbeaudry/genaral-swahili","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Swahili","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"genaral-swahili","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tMulti-Domain Swahili Speech Dataset\n\t\n\nThis dataset contains 5 audio recordings with corresponding text transcriptions across multiple languages and domains.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA comprehensive collection of audio files paired with text transcriptions, featuring both synthetic and natural speech across various domains. Suitable for automatic speech recognition (ASR), text-to-speech (TTS), and domain-specific speech processing tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jsbeaudry/genaral-swahili.","url":"https://huggingface.co/datasets/jsbeaudry/genaral-swahili","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Swahili","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"genaral-swahili","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tMulti-Domain Swahili Speech Dataset\n\t\n\nThis dataset contains 5 audio recordings with corresponding text transcriptions across multiple languages and domains.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA comprehensive collection of audio files paired with text transcriptions, featuring both synthetic and natural speech across various domains. Suitable for automatic speech recognition (ASR), text-to-speech (TTS), and domain-specific speech processing tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jsbeaudry/genaral-swahili.","url":"https://huggingface.co/datasets/jsbeaudry/genaral-swahili","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Swahili","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"fama-data","keyword":"speech","description":"\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nThe FAMA training data is the collection of English and Italian datasets for automatic speech recognition (ASR) and speech translation (ST)\nused to train the FAMA models family.\nThe ASR section of FAMA is derived from the MOSEL data collection, including the automatic\ntranscripts obtained with Whisper and available in the HuggingFace MOSEL Dataset.\nThe ASR is further augmented with automatically transcribed speech from the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/fama-data.","url":"https://huggingface.co/datasets/FBK-MT/fama-data","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","automatic-speech-recognition","multilingual","Italian","English"],"keywords_longer_than_N":true},
	{"name":"Turkish_Speech_Corpus","keyword":"speech","description":"\n\t\n\t\t\n\t\tTurkish Speech Corpus (TSC)\n\t\n\nThis repository presents an open-source Turkish Speech Corpus, introduced in \"Multilingual Speech Recognition for Turkic Languages\". The corpus contains 218.2 hours of transcribed speech with 186,171 utterances and is the largest publicly available Turkish dataset of its kind at that time. \nPaper: Multilingual Speech Recognition for Turkic Languages.  \nGitHub Repository: https://github.com/IS2AI/TurkicASR\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\n@Article{info14020074‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/Turkish_Speech_Corpus.","url":"https://huggingface.co/datasets/issai/Turkish_Speech_Corpus","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Turkish","mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"fama-data","keyword":"automatic-speech-recognition","description":"\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nThe FAMA training data is the collection of English and Italian datasets for automatic speech recognition (ASR) and speech translation (ST)\nused to train the FAMA models family.\nThe ASR section of FAMA is derived from the MOSEL data collection, including the automatic\ntranscripts obtained with Whisper and available in the HuggingFace MOSEL Dataset.\nThe ASR is further augmented with automatically transcribed speech from the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/fama-data.","url":"https://huggingface.co/datasets/FBK-MT/fama-data","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","automatic-speech-recognition","multilingual","Italian","English"],"keywords_longer_than_N":true},
	{"name":"sagaw_karen_asr","keyword":"automatic-speech-recognition","description":"This is the first public Sagaw Karen language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tSagaw Karen ASR\n\t\n\nThis dataset contains audio recordings and aligned metadata in the Sagaw Karen language (ISO 639-3: ksw), a major Sgaw Karenic language spoken throughout southern and eastern Myanmar. The language is sometimes also referred to as Sgaw Karen or Sakaw Karen in English transliterations.\nAll audio segments in this dataset were sourced from publicly available news broadcasts published by PVTV‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/sagaw_karen_asr.","url":"https://huggingface.co/datasets/freococo/sagaw_karen_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"sagaw_karen_asr","keyword":"automatic-speech-recognition","description":"This is the first public Sagaw Karen language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tSagaw Karen ASR\n\t\n\nThis dataset contains audio recordings and aligned metadata in the Sagaw Karen language (ISO 639-3: ksw), a major Sgaw Karenic language spoken throughout southern and eastern Myanmar. The language is sometimes also referred to as Sgaw Karen or Sakaw Karen in English transliterations.\nAll audio segments in this dataset were sourced from publicly available news broadcasts published by PVTV‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/sagaw_karen_asr.","url":"https://huggingface.co/datasets/freococo/sagaw_karen_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"Turkish_Speech_Corpus","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTurkish Speech Corpus (TSC)\n\t\n\nThis repository presents an open-source Turkish Speech Corpus, introduced in \"Multilingual Speech Recognition for Turkic Languages\". The corpus contains 218.2 hours of transcribed speech with 186,171 utterances and is the largest publicly available Turkish dataset of its kind at that time. \nPaper: Multilingual Speech Recognition for Turkic Languages.  \nGitHub Repository: https://github.com/IS2AI/TurkicASR\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\n@Article{info14020074‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/Turkish_Speech_Corpus.","url":"https://huggingface.co/datasets/issai/Turkish_Speech_Corpus","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Turkish","mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"speech-to-text","keyword":"text-to-speech","description":"LeVy4/speech-to-text dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/LeVy4/speech-to-text","creator_name":"Le Thao Vy","creator_url":"https://huggingface.co/LeVy4","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Vietnamese","cc0-1.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"libritts_r_tags_tagged_10k_generated","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Annotated LibriTTS-R\n\t\n\nThis dataset is an annotated version of LibriTTS-R [1]. LibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus which is a multi-speaker English corpus of approximately 960 hours of read English speech at 24kHz sampling rate, published in 2019. \nIn the text_description column, it provides natural language annotations on the characteristics of speakers and utterances, that have been generated using the Data-Speech repository.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/libritts_r_tags_tagged_10k_generated.","url":"https://huggingface.co/datasets/parler-tts/libritts_r_tags_tagged_10k_generated","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"hatecheck-polish","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-polish.","url":"https://huggingface.co/datasets/Paul/hatecheck-polish","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hifi-tts","keyword":"text-to-speech","description":"Hi-Fi Multi-Speaker English TTS Dataset (Hi-Fi TTS) is based on LibriVox's public domain audio books and Gutenberg Project texts.","url":"https://huggingface.co/datasets/MikhailT/hifi-tts","creator_name":"Mikhail Tsimashkou","creator_url":"https://huggingface.co/MikhailT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"guturalScream_metalVocals","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for \"Gutural Speech Recognition\"\n\t\n\nThis dataset contains annotations of 57 songs.\n\n\t\n\t\t\n\t\tHow to use\n\t\n\nLoad the dataset from huggingface in your notebook:\n!pip install datasets[audio]\n\nimport datasets\n\ndataset = datasets.load_dataset(\"jpdiazpardo/guturalScream_metalVocals\")\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: the trimmed audio file from the song.\ntext: the transcribed vocals.\nsong_name: the song title.\nartist_name: the artist name.\nalbum_name: the name of the album where the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jpdiazpardo/guturalScream_metalVocals.","url":"https://huggingface.co/datasets/jpdiazpardo/guturalScream_metalVocals","creator_name":"Juan Pablo D√≠az","creator_url":"https://huggingface.co/jpdiazpardo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","1K<n<10K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"ami-sdm","keyword":"automatic-speech-recognition","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\nnon-native speakers. \\n","url":"https://huggingface.co/datasets/distil-whisper/ami-sdm","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"mls_eng","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for English MLS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the English version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls_eng.","url":"https://huggingface.co/datasets/parler-tts/mls_eng","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"samromur_synthetic","keyword":"automatic-speech-recognition","description":"Samr√≥mur Synthetic consists of 72 hours of synthetized speech in Icelandic.","url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_synthetic","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","machine-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Medical_Interview","keyword":"automatic-speech-recognition","description":"The dataset was re-organized and used in the following paper. Please cite if you adopted the corpus in your work.\n@inproceedings{liu2024post,\n  title={Post-decoder Biasing for End-to-End Speech Recognition of Multi-turn Medical Interview},\n  author={Liu, Heyang and Wang, Yanfeng and Wang, Yu},\n  booktitle={Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},\n  pages={12917--12926},\n  year={2024}\n}\n\n","url":"https://huggingface.co/datasets/SandO114/Medical_Interview","creator_name":"Heyang Liu","creator_url":"https://huggingface.co/SandO114","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"hatecheck-italian","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-italian.","url":"https://huggingface.co/datasets/Paul/hatecheck-italian","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"testnew","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tAudio Dataset Statistics\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal audio files\n556,667\n\n\nTotal duration\n1,024.71 hours (3,688,949 seconds)\n\n\nAverage duration\n6.63 seconds\n\n\nShortest clip\n0.41 seconds\n\n\nLongest clip\n44.97 seconds\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSpeaker Breakdown\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tTop 10 Speakers by Clip Count\n\t\n\n\n\t\n\t\t\nSpeaker\nClips\nDuration\n% of Total\n\n\n\t\t\nDespina\n60,150\n118.07 hours\n11.5%\n\n\nSulafat\n31,593\n58.15 hours\n5.7%\n\n\nAchernar29,889\n54.53 hours\n5.3%\n\n\nAutonoe\n27,897‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/setfunctionenvironment/testnew.","url":"https://huggingface.co/datasets/setfunctionenvironment/testnew","creator_name":"setfunctionenvironment","creator_url":"https://huggingface.co/setfunctionenvironment","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"mls_eng","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for English MLS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the English version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls_eng.","url":"https://huggingface.co/datasets/parler-tts/mls_eng","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"VoxCelebSpoof","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tVoxCelebSpoof\n\t\n\nVoxCelebSpoof is a dataset related to detecting spoofing attacks on automatic speaker verification systems. This dataset is part of a broader effort to improve the security of voice biometric systems against various types of spoofing attacks, such as replay attacks, voice synthesis, and voice conversion.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe VoxCelebSpoof dataset includes a range of audio samples from different types of synthesis spoofs. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MattyB95/VoxCelebSpoof.","url":"https://huggingface.co/datasets/MattyB95/VoxCelebSpoof","creator_name":"Matthew Boakes","creator_url":"https://huggingface.co/MattyB95","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","text-to-speech","English","mit","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"fleurs-hs-vits","keyword":"speech","description":"\n\t\n\t\t\n\t\tFLEURS-HS VITS\n\t\n\nAn extension of the FLEURS dataset for synthetic speech detection using text-to-speech, featured in the paper Synthetic speech detection with Wav2Vec 2.0 in various language settings.\nThis dataset is 1 of 3 used in the paper, the others being:\n\nFLEURS-HS\nthe default train, dev and test sets\nseparated due to different licensing\n\n\nARCTIC-HS\nextension of the CMU_ARCTIC and L2-ARCTIC sets in a similar manner\n\n\n\n\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs-vits.","url":"https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs-vits","creator_name":"KONTXT by RealNetworks","creator_url":"https://huggingface.co/realnetworks-kontxt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","German","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"KOTOX-classification","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tKOTOX\n\t\n\n\n\t\n\t\t\n\t\t: A Korean Toxic Dataset for Deobfuscation and Detoxification\n\t\n\nHate Speech Detection dataset üëâ Here!Detoxification or Sanitization dataset üëâ KOTOX  \nüìö paper | \nüêà‚Äç‚¨õ git\n\n\t\n\t\t\n\t\tüìù Dataset Summary\n\t\n\nKOTOX is the first Korean dataset designed for both toxic text detoxification and obfuscation robustness.   \nIt provides paired neutral-toxic sentences and their obfuscated counterparts, constructed with 17 linguistically grounded transformation rules reflecting the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ssgyejin/KOTOX-classification.","url":"https://huggingface.co/datasets/ssgyejin/KOTOX-classification","creator_name":"leeyejin","creator_url":"https://huggingface.co/ssgyejin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","rule-based","llm-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"libritts_r","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for LibriTTS-R\n\t\n\n\n\nLibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus \n(http://www.openslr.org/60/) which is a multi-speaker English corpus of approximately \n585 hours of read English speech at 24kHz sampling rate, published in 2019.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the LibriTTS-R dataset, adapted for the datasets library.\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\n\t\n\t\t\n\t\tSplits\n\t\n\nThere are 7 splits (dots replace dashes from the original dataset, to comply with hf naming‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mythicinfinity/libritts_r.","url":"https://huggingface.co/datasets/mythicinfinity/libritts_r","creator_name":"Mythic Infinity","creator_url":"https://huggingface.co/mythicinfinity","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"fleurs-hs-vits","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tFLEURS-HS VITS\n\t\n\nAn extension of the FLEURS dataset for synthetic speech detection using text-to-speech, featured in the paper Synthetic speech detection with Wav2Vec 2.0 in various language settings.\nThis dataset is 1 of 3 used in the paper, the others being:\n\nFLEURS-HS\nthe default train, dev and test sets\nseparated due to different licensing\n\n\nARCTIC-HS\nextension of the CMU_ARCTIC and L2-ARCTIC sets in a similar manner\n\n\n\n\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs-vits.","url":"https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs-vits","creator_name":"KONTXT by RealNetworks","creator_url":"https://huggingface.co/realnetworks-kontxt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","German","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"HAUSA-TTSCSV","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tHausa TTS Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Hausa language text-to-speech (TTS) recordings from multiple speakers. It includes audio files paired with their corresponding Hausa text transcriptions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized as follows:\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îú‚îÄ‚îÄ metadata.csv                    # Metadata (source, audio paths, text)\n‚îÇ   ‚îî‚îÄ‚îÄ audio_files/\n‚îÇ       ‚îú‚îÄ‚îÄ 97f373e8-f6e6-.../          # Speaker 1 audio files\n‚îÇ       ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aybee5/HAUSA-TTSCSV.","url":"https://huggingface.co/datasets/Aybee5/HAUSA-TTSCSV","creator_name":"Ibrahim Abdullahi","creator_url":"https://huggingface.co/Aybee5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","Hausa","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"rixvox","keyword":"automatic-speech-recognition","description":"RixVox is a speech dataset comprised of speeches from the Swedish Parliament (the Riksdag). Audio from speeches have been aligned with official transcripts, on the sentence level, using aeneas. \nSpeaker metadata is available for each observation, including the speaker's name, gender, party, birth year and electoral district. The dataset contains a total of 5493 hours of speech. \nAn observation may consist of one or several sentences (up to 30 seconds in duration).","url":"https://huggingface.co/datasets/KBLab/rixvox","creator_name":"National Library of Sweden / KBLab","creator_url":"https://huggingface.co/KBLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","Swedish","cc-by-4.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"ro-offense","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive language detection with manually \nannotated offensive labels from a local Romanian sports news website (gsp.ro):\nResulting in 12,445 annotated messages\n\n\t\n\t\n\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense.","url":"https://huggingface.co/datasets/readerbench/ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ro-offense","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive language detection with manually \nannotated offensive labels from a local Romanian sports news website (gsp.ro):\nResulting in 12,445 annotated messages\n\n\t\n\t\n\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense.","url":"https://huggingface.co/datasets/readerbench/ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"honest","keyword":"hate-speech-detection","description":"HONEST dataset comprises a set of templates for measuring hurtful sentence completions in language models. The templates are provided in six languages (English, Italian, French, Portuguese, Romanian, and Spanish) for binary gender and in English for LGBTQAI+ individuals. WARNING: This dataset contains content that are offensive and/or hateful in nature.","url":"https://huggingface.co/datasets/MilaNLProc/honest","creator_name":"MilaNLP","creator_url":"https://huggingface.co/MilaNLProc","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","no-annotation","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"rixvox","keyword":"speech-recognition","description":"RixVox is a speech dataset comprised of speeches from the Swedish Parliament (the Riksdag). Audio from speeches have been aligned with official transcripts, on the sentence level, using aeneas. \nSpeaker metadata is available for each observation, including the speaker's name, gender, party, birth year and electoral district. The dataset contains a total of 5493 hours of speech. \nAn observation may consist of one or several sentences (up to 30 seconds in duration).","url":"https://huggingface.co/datasets/KBLab/rixvox","creator_name":"National Library of Sweden / KBLab","creator_url":"https://huggingface.co/KBLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","Swedish","cc-by-4.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"vocsim","keyword":"speech","description":"\n\t\n\t\t\n\t\tVocSim: A Training-Free Benchmark for Content Identity in Single-Source Audio Embeddings\n\t\n\n\n\n\nVocSim evaluates how well neural audio embeddings generalize for zero-shot audio similarity. It tests recognizing fine-grained acoustic similarity without specific similarity training.\n\n\n\t\n\t\n\t\n\t\tKey Features\n\t\n\n\nDiverse Sources: Human speech (phones, words, utterances), birdsong, otter calls, environmental sounds.Varied Conditions: Spans clean to noisy recordings, short (<100ms) to long‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anonymous-submission000/vocsim.","url":"https://huggingface.co/datasets/anonymous-submission000/vocsim","creator_name":"Anonymous","creator_url":"https://huggingface.co/anonymous-submission000","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["cc-by-4.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"DiPCo","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDipCo - Dinner Party Corpus, Interspeech 2020\n\t\n\n\nPlease consider to use Zenodo Data Backup Link to Download Audio: https://zenodo.org/record/8122551\n\nPaper: https://www.isca-speech.org/archive/interspeech_2020/segbroeck20_interspeech.html\n\n\nAuthor(s):\n\nVan Segbroeck, Maarten; Zaid, Ahmed; Kutsenko, Ksenia; Huerta, Cirenia; Nguyen, Tinh; Luo, Xuewen; Hoffmeister, Bj√∂rn; Trmal, Jan; Omologo, Maurizio; Maas, Roland\n\n\nContact person(s):\n\nMaas, Roland; Hoffmeister, Bj√∂rn\n\n\nDistributor(s):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huckiyang/DiPCo.","url":"https://huggingface.co/datasets/huckiyang/DiPCo","creator_name":"Huck Yang","creator_url":"https://huggingface.co/huckiyang","license_name":"Community Data License Agreement Permissive 1.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-1.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","voice-activity-detection","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"simsamu","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSimsamu dataset\n\t\n\nThis repository contains recordings of simulated medical dispatch dialogs in the\nfrench language, annotated for diarization and transcription. It is published\nunder the MIT license.\nThese dialogs were recorded as part of the training of emergency medicine\ninterns, which consisted in simulating a medical dispatch call where the interns\ntook turns playing the caller and the regulating doctor. \nEach situation was decided randomly in advance, blind to who was playing the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/medkit/simsamu.","url":"https://huggingface.co/datasets/medkit/simsamu","creator_name":"medkit","creator_url":"https://huggingface.co/medkit","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","voice-activity-detection","monolingual","French","mit"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for MultiLingual LibriSpeech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/multilingual_librispeech.","url":"https://huggingface.co/datasets/facebook/multilingual_librispeech","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"tarteel-ai-everyayah-Quran","keyword":"automatic-speech-recognition","description":"Ô∑Ω\n\n\t\n\t\t\n\t\tDataset Card for Tarteel AI's EveryAyah Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of Quranic verses and their transcriptions, with diacritization, by different reciters.\n\n\t\n\t\t\n\t\tHow to download\n\t\n\n!pip install -q datasets\n\nfrom datasets import load_dataset\ndataset =load_dataset(\"Salama1429/tarteel-ai-everyayah-Quran\", verification_mode=\"no_checks\")\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Salama1429/tarteel-ai-everyayah-Quran.","url":"https://huggingface.co/datasets/Salama1429/tarteel-ai-everyayah-Quran","creator_name":"Mohamed Salama","creator_url":"https://huggingface.co/Salama1429","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"DiPCo","keyword":"speech-recognition","description":"\n\t\n\t\t\n\t\tDipCo - Dinner Party Corpus, Interspeech 2020\n\t\n\n\nPlease consider to use Zenodo Data Backup Link to Download Audio: https://zenodo.org/record/8122551\n\nPaper: https://www.isca-speech.org/archive/interspeech_2020/segbroeck20_interspeech.html\n\n\nAuthor(s):\n\nVan Segbroeck, Maarten; Zaid, Ahmed; Kutsenko, Ksenia; Huerta, Cirenia; Nguyen, Tinh; Luo, Xuewen; Hoffmeister, Bj√∂rn; Trmal, Jan; Omologo, Maurizio; Maas, Roland\n\n\nContact person(s):\n\nMaas, Roland; Hoffmeister, Bj√∂rn\n\n\nDistributor(s):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huckiyang/DiPCo.","url":"https://huggingface.co/datasets/huckiyang/DiPCo","creator_name":"Huck Yang","creator_url":"https://huggingface.co/huckiyang","license_name":"Community Data License Agreement Permissive 1.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-1.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","voice-activity-detection","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"mabama-v1","keyword":"text-to-speech","description":"ovieyra21/mabama-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ovieyra21/mabama-v1","creator_name":"Oma Vieyra","creator_url":"https://huggingface.co/ovieyra21","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","audio-classification","Spanish","mit"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for MultiLingual LibriSpeech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/multilingual_librispeech.","url":"https://huggingface.co/datasets/facebook/multilingual_librispeech","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"the-mc-speech-dataset","keyword":"automatic-speech-recognition","description":"This is public domain speech dataset consisting of 24018 short audio clips of a single speaker reading sentences in Polish. A transcription is provided for each clip. Clips have total length of more than 22 hours.\nTexts are in public domain. The audio was recorded in 2021-22 as a part of my master's thesis and is in public domain.\nIf you use this dataset, please cite:\n@masterthesis{mcspeech,\n  title={Analiza por√≥wnawcza korpus√≥w nagra≈Ñ mowy dla cel√≥w syntezy mowy w jƒôzyku polskim}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/czyzi0/the-mc-speech-dataset.","url":"https://huggingface.co/datasets/czyzi0/the-mc-speech-dataset","creator_name":"Mateusz Czy≈ºnikiewicz","creator_url":"https://huggingface.co/czyzi0","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Polish","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"nst-da-norm","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for NST-da Normalized\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): da\nLicense: cc0-1.0\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]\nDemo [optional]: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JackismyShephard/nst-da-norm.","url":"https://huggingface.co/datasets/JackismyShephard/nst-da-norm","creator_name":"Christian Troelsen","creator_url":"https://huggingface.co/JackismyShephard","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"hatecheck-hindi","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-hindi.","url":"https://huggingface.co/datasets/Paul/hatecheck-hindi","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"coral-tts","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for CoRal TTS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of two professional Danish speakers, female and male, recording roughly 17 hours of Danish speech each.\nThe dataset is part of the CoRal project which is funded by the Danish Innovation Fund.\nThe text data was selected by the Alexandra Institute (Github repo for the dataset creation) and consists of sentences from sundhed.dk, borger.dk, names of bus stops and stations, manually filtered Reddit comments, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CoRal-project/coral-tts.","url":"https://huggingface.co/datasets/CoRal-project/coral-tts","creator_name":"CoRal","creator_url":"https://huggingface.co/CoRal-project","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Danish","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"nst_swedish_tts","keyword":"text-to-speech","description":"Database for Swedish speech synthesis, originally produced by Nordic Language Technology AS (NST).","url":"https://huggingface.co/datasets/jimregan/nst_swedish_tts","creator_name":"Jim O'Regan","creator_url":"https://huggingface.co/jimregan","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","Swedish","cc0-1.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"the-mc-speech-dataset","keyword":"text-to-speech","description":"This is public domain speech dataset consisting of 24018 short audio clips of a single speaker reading sentences in Polish. A transcription is provided for each clip. Clips have total length of more than 22 hours.\nTexts are in public domain. The audio was recorded in 2021-22 as a part of my master's thesis and is in public domain.\nIf you use this dataset, please cite:\n@masterthesis{mcspeech,\n  title={Analiza por√≥wnawcza korpus√≥w nagra≈Ñ mowy dla cel√≥w syntezy mowy w jƒôzyku polskim}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/czyzi0/the-mc-speech-dataset.","url":"https://huggingface.co/datasets/czyzi0/the-mc-speech-dataset","creator_name":"Mateusz Czy≈ºnikiewicz","creator_url":"https://huggingface.co/czyzi0","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Polish","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"nst-da-norm","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for NST-da Normalized\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): da\nLicense: cc0-1.0\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]\nDemo [optional]: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JackismyShephard/nst-da-norm.","url":"https://huggingface.co/datasets/JackismyShephard/nst-da-norm","creator_name":"Christian Troelsen","creator_url":"https://huggingface.co/JackismyShephard","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"elevenlabs_dataset","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tSynthetic TTS Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset was created with the aim of exploring the concept of using synthetic datasets for training Text-to-Speech (TTS) models. It consists of 1,388 audio files with a total duration of 2 hours and 20 minutes and their corresponding textual transcripts. The dataset leverages the capabilities of advanced AI services, utilizing paid subscriptions to ChatGPT-4 for text generation and ElevenLabs.io for audio generation.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/skypro1111/elevenlabs_dataset.","url":"https://huggingface.co/datasets/skypro1111/elevenlabs_dataset","creator_name":"Serhii Kravchenko","creator_url":"https://huggingface.co/skypro1111","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","cc-by-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"PetraAI","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tPETRA\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nPETRA is a multilingual dataset for training and evaluating AI systems on a diverse range of tasks across multiple modalities. It contains data in Arabic and English for tasks including translation, summarization, question answering, and more.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nData is separated by language into /ar and /en directories\nWithin each language directory, data is separated by task into subdirectories  \nTasks include:\nTranslation\nSummarization‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PetraAI/PetraAI.","url":"https://huggingface.co/datasets/PetraAI/PetraAI","creator_name":"Shady BA","creator_url":"https://huggingface.co/PetraAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr-timestamped","keyword":"automatic-speech-recognition","description":"LibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\nprepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\naudiobooks from the LibriVox project, and has been carefully segmented and aligned.87","url":"https://huggingface.co/datasets/distil-whisper/librispeech_asr-timestamped","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"medical_asr_recording_dataset","keyword":"automatic-speech-recognition","description":"Data Source\nKaggle Medical Speech, Transcription, and Intent\nContext\n\n8.5 hours of audio utterances paired with text for common medical symptoms.\n\nContent\n\nThis data contains thousands of audio utterances for common medical symptoms like ‚Äúknee pain‚Äù or ‚Äúheadache,‚Äù totaling more than 8 hours in aggregate. Each utterance was created by individual human contributors based on a given symptom. These audio snippets can be used to train conversational agents in the medical field.\nThis Figure Eight‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Hani89/medical_asr_recording_dataset.","url":"https://huggingface.co/datasets/Hani89/medical_asr_recording_dataset","creator_name":"Hani. M","creator_url":"https://huggingface.co/Hani89","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"TuPyE-Dataset","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tPortuguese Hate Speech Expanded Dataset (TuPyE)\n\t\n\nTuPyE, an enhanced iteration of TuPy, encompasses a compilation of 43,668 meticulously annotated documents specifically \nselected for the purpose of hate speech detection within diverse social network contexts. \nThis augmented dataset integrates supplementary annotations and amalgamates with datasets sourced from \nFortuna et al. (2019), \nLeite et al. (2020), \nand Vargas et al. (2022),\ncomplemented by an infusion of 10,000 original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Silly-Machine/TuPyE-Dataset.","url":"https://huggingface.co/datasets/Silly-Machine/TuPyE-Dataset","creator_name":"Silly-Machine","creator_url":"https://huggingface.co/Silly-Machine","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","monolingual","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"PetraAI","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tPETRA\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nPETRA is a multilingual dataset for training and evaluating AI systems on a diverse range of tasks across multiple modalities. It contains data in Arabic and English for tasks including translation, summarization, question answering, and more.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nData is separated by language into /ar and /en directories\nWithin each language directory, data is separated by task into subdirectories  \nTasks include:\nTranslation\nSummarization‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PetraAI/PetraAI.","url":"https://huggingface.co/datasets/PetraAI/PetraAI","creator_name":"Shady BA","creator_url":"https://huggingface.co/PetraAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"cantone","keyword":"speech","description":"\n\t\n\t\t\n\t\tCantone\n\t\n\nA dataset of 34,489 recordings of Cantonese syllables by 10 speakers.\nThose syllables are generated through the Cantonese speech synthesis engines of Amazon, Apple, Google, and Microsoft.\nAll recordings are stored as WAV files with the following format\n\nChannel: mono\nSample rate: 16 kHz\nBits per sample: 16\n\nHere's a breakdown of the number of recordings under each speaker:\n\n\t\n\t\t\nCompany\nSpeaker\n# Syllables\n\n\n\t\t\nAmazon\nHiujin\n3,885\n\n\nApple\nAasing\n2,977\n\n\nApple\nSinji\n2,977‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlienKevin/cantone.","url":"https://huggingface.co/datasets/AlienKevin/cantone","creator_name":"Xiang (Kevin) Li","creator_url":"https://huggingface.co/AlienKevin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Yue Chinese","mit","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"social_bias_frames","keyword":"hate-speech-detection","description":"Social Bias Frames is a new way of representing the biases and offensiveness that are implied in language.\nFor example, these frames are meant to distill the implication that \"women (candidates) are less qualified\"\nbehind the statement \"we shouldn‚Äôt lower our standards to hire more women.\"","url":"https://huggingface.co/datasets/allenai/social_bias_frames","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"youtube-transcriptions","keyword":"speech","description":"The YouTube transcriptions dataset contains technical tutorials (currently from James Briggs, Daniel Bourke, and AI Coffee Break) transcribed using OpenAI's Whisper (large). Each row represents roughly a sentence-length chunk of text alongside the video URL and timestamp.\nNote that each item in the dataset contains just a short chunk of text. For most use cases you will likely need to merge multiple rows to create more substantial chunks of text, if you need to do that, this code snippet will‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jamescalam/youtube-transcriptions.","url":"https://huggingface.co/datasets/jamescalam/youtube-transcriptions","creator_name":"James Briggs","creator_url":"https://huggingface.co/jamescalam","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","visual-question-answering","open-domain-qa","extractive-qa"],"keywords_longer_than_N":true},
	{"name":"nvidia-brain-noise-evaluation-dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tNvidia Brain Noise Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 64 samples organized across multiple splits and 32 subsets.\nThe dataset includes audio data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tSubsets\n\t\n\nThis dataset includes the following subsets:\n\nnoisy-bg-snr-10: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-20: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-30: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-40: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-50: 2 samples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sujalappa/nvidia-brain-noise-evaluation-dataset.","url":"https://huggingface.co/datasets/sujalappa/nvidia-brain-noise-evaluation-dataset","creator_name":"sujal rajeev chondhekar","creator_url":"https://huggingface.co/sujalappa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","n<1K"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech","keyword":"automatic-speech-recognition","description":"Multilingual LibriSpeech (MLS) dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of 8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish.","url":"https://huggingface.co/datasets/legacy-datasets/multilingual_librispeech","creator_name":"Legacy Datasets","creator_url":"https://huggingface.co/legacy-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_dummy","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr_dummy\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a truncated version of the LibriSpeech dataset. It contains 20 samples from each of the splits. To view the full dataset, visit: https://huggingface.co/datasets/librispeech_asr\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sanchit-gandhi/librispeech_asr_dummy.","url":"https://huggingface.co/datasets/sanchit-gandhi/librispeech_asr_dummy","creator_name":"Sanchit Gandhi","creator_url":"https://huggingface.co/sanchit-gandhi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"samromur_children","keyword":"automatic-speech-recognition","description":"The Samr√≥mur Children corpus contains more than 137000 validated speech-recordings uttered by Icelandic children.","url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_children","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"sova_rudevices","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for sova_rudevices\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSOVA Dataset is free public STT/ASR dataset. It consists of several parts, one of them is SOVA RuDevices. This part is an acoustic corpus of approximately 100 hours of 16kHz Russian live speech with manual annotating, prepared by SOVA.ai team.\nAuthors do not divide the dataset into train, validation and test subsets. Therefore, I was compelled to prepare this splitting. The training subset includes more than 82 hours, the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bond005/sova_rudevices.","url":"https://huggingface.co/datasets/bond005/sova_rudevices","creator_name":"Ivan Bondarenko","creator_url":"https://huggingface.co/bond005","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","expert-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"nvidia-brain-noise-evaluation-dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tNvidia Brain Noise Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 64 samples organized across multiple splits and 32 subsets.\nThe dataset includes audio data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tSubsets\n\t\n\nThis dataset includes the following subsets:\n\nnoisy-bg-snr-10: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-20: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-30: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-40: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-50: 2 samples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sujalappa/nvidia-brain-noise-evaluation-dataset.","url":"https://huggingface.co/datasets/sujalappa/nvidia-brain-noise-evaluation-dataset","creator_name":"sujal rajeev chondhekar","creator_url":"https://huggingface.co/sujalappa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","n<1K"],"keywords_longer_than_N":true},
	{"name":"nvidia-brain-noise-evaluation-dataset","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tNvidia Brain Noise Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 64 samples organized across multiple splits and 32 subsets.\nThe dataset includes audio data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tSubsets\n\t\n\nThis dataset includes the following subsets:\n\nnoisy-bg-snr-10: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-20: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-30: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-40: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-50: 2 samples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sujalappa/nvidia-brain-noise-evaluation-dataset.","url":"https://huggingface.co/datasets/sujalappa/nvidia-brain-noise-evaluation-dataset","creator_name":"sujal rajeev chondhekar","creator_url":"https://huggingface.co/sujalappa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","n<1K"],"keywords_longer_than_N":true},
	{"name":"emova-sft-4m","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tEMOVA-SFT-4M\n\t\n\n\n\n\nü§ó EMOVA-Models | ü§ó EMOVA-Datasets | ü§ó EMOVA-Demo \nüìÑ Paper | üåê Project-Page | üíª Github | üíª EMOVA-Speech-Tokenizer-Github\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-SFT-4M is a comprehensive dataset curated for omni-modal instruction tuning, including textual, visual, and audio interactions. This dataset is created by gathering open-sourced multi-modal instruction datasets and synthesizing high-quality omni-modal conversation data to enhance user experience. This dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-4m.","url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-4m","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-generation","audio-to-audio","automatic-speech-recognition","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"MASC","keyword":"automatic-speech-recognition","description":"MASC is a dataset that contains 1,000 hours of speech sampled at 16 kHz and crawled from over 700 YouTube channels. The dataset is multi-regional, multi-genre, and multi-dialect intended to advance the research and development of Arabic speech technology with a special emphasis on Arabic speech recognition.","url":"https://huggingface.co/datasets/pain/MASC","creator_name":"Mohammad Albarham","creator_url":"https://huggingface.co/pain","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"hatexplain","keyword":"hate-speech-detection","description":"Hatexplain is the first benchmark hate speech dataset covering multiple aspects of the issue. Each post in the dataset is annotated from three different perspectives: the basic, commonly used 3-class classification (i.e., hate, offensive or normal), the target community (i.e., the community that has been the victim of hate speech/offensive speech in the post), and the rationales, i.e., the portions of the post on which their labelling decision (as hate, offensive or normal) is based.","url":"https://huggingface.co/datasets/Hate-speech-CNERG/hatexplain","creator_name":"Hate-ALERT","creator_url":"https://huggingface.co/Hate-speech-CNERG","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"emova-sft-4m","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tEMOVA-SFT-4M\n\t\n\n\n\n\nü§ó EMOVA-Models | ü§ó EMOVA-Datasets | ü§ó EMOVA-Demo \nüìÑ Paper | üåê Project-Page | üíª Github | üíª EMOVA-Speech-Tokenizer-Github\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-SFT-4M is a comprehensive dataset curated for omni-modal instruction tuning, including textual, visual, and audio interactions. This dataset is created by gathering open-sourced multi-modal instruction datasets and synthesizing high-quality omni-modal conversation data to enhance user experience. This dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-4m.","url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-4m","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-generation","audio-to-audio","automatic-speech-recognition","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"crawl_domain","keyword":"text-to-speech","description":"Corpus of domain names scraped from Common Crawl and manually annotated to add word boundaries (e.g. \"commoncrawl\" to \"common crawl\"). Breaking domain names such as \"openresearch\" into component words \"open\" and \"research\" is important for applications such as Text-to-Speech synthesis and web search. Common Crawl is an open repository of web crawl data that can be accessed and analyzed by anyone. Specifically, we scraped the plaintext (WET) extracts for domain names from URLs that contained diverse letter casing (e.g. \"OpenBSD\"). Although in the previous example, segmentation is trivial using letter casing, this was not always the case (e.g. \"NASA\"), so we had to manually annotate the data. The dataset is stored as plaintext file where each line is an example of space separated segments of a domain name. The examples are stored in their original letter casing, but harder and more interesting examples can be generated by lowercasing the input first.","url":"https://huggingface.co/datasets/google-research-datasets/crawl_domain","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"esb-datasets-test-only","keyword":"speech","description":"All eight of datasets in ESB can be downloaded and prepared in just a single line of code through the Hugging Face Datasets library:\nfrom datasets import load_dataset\n\nlibrispeech = load_dataset(\"esb/datasets\", \"librispeech\", split=\"train\")\n\n\n\"esb/datasets\": the repository namespace. This is fixed for all ESB datasets.\n\n\"librispeech\": the dataset name. This can be changed to any of any one of the eight datasets in ESB to download that dataset.\n\nsplit=\"train\": the split. Set this to one of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hf-audio/esb-datasets-test-only.","url":"https://huggingface.co/datasets/hf-audio/esb-datasets-test-only","creator_name":"Hugging Face for Audio","creator_url":"https://huggingface.co/hf-audio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"libritts-r-aligned","keyword":"speech","description":"Dataset used for loading TTS spectrograms and waveform audio with alignments and a number of configurable \"measures\", which are extracted from the raw audio.","url":"https://huggingface.co/datasets/cdminix/libritts-r-aligned","creator_name":"Christoph Minixhofer","creator_url":"https://huggingface.co/cdminix","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"common_voice_13_0_dv_preprocessed","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 13.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Common Voice dataset consists of a unique MP3 and corresponding text file. \nMany of the 27141 recorded hours in the dataset also include demographic metadata like age, sex, and accent \nthat can help improve the accuracy of speech recognition engines.\nThe dataset currently consists of 17689 validated hours in 108 languages, but more voices and languages are always added. \nTake a look at the Languages page to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ferno22/common_voice_13_0_dv_preprocessed.","url":"https://huggingface.co/datasets/ferno22/common_voice_13_0_dv_preprocessed","creator_name":"Ant","creator_url":"https://huggingface.co/ferno22","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"lj_speech","keyword":"automatic-speech-recognition","description":"This is a public domain speech dataset consisting of 13,100 short audio clips of a single speaker reading\npassages from 7 non-fiction books in English. A transcription is provided for each clip. Clips vary in length\nfrom 1 to 10 seconds and have a total length of approximately 24 hours.\n\nNote that in order to limit the required storage for preparing this dataset, the audio\nis stored in the .wav format and is not converted to a float32 array. To convert the audio\nfile to a float32 array, please make use of the `.map()` function as follows:\n\n\n```python\nimport soundfile as sf\n\ndef map_to_array(batch):\n    speech_array, _ = sf.read(batch[\"file\"])\n    batch[\"speech\"] = speech_array\n    return batch\n\ndataset = dataset.map(map_to_array, remove_columns=[\"file\"])\n```","url":"https://huggingface.co/datasets/keithito/lj_speech","creator_name":"Keith Ito","creator_url":"https://huggingface.co/keithito","license_name":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"nst","keyword":"automatic-speech-recognition","description":"Homepage: https://www.nb.no/sprakbanken/en/resource-catalogue/oai-nb-no-sbr-56\nUsed lydfiler_16_1.tar.gz and metadata_se_csv.zip\n","url":"https://huggingface.co/datasets/jzju/nst","creator_name":"Johan Ju","creator_url":"https://huggingface.co/jzju","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Swedish","cc0-1.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"esb-datasets-test-only","keyword":"automatic-speech-recognition","description":"All eight of datasets in ESB can be downloaded and prepared in just a single line of code through the Hugging Face Datasets library:\nfrom datasets import load_dataset\n\nlibrispeech = load_dataset(\"esb/datasets\", \"librispeech\", split=\"train\")\n\n\n\"esb/datasets\": the repository namespace. This is fixed for all ESB datasets.\n\n\"librispeech\": the dataset name. This can be changed to any of any one of the eight datasets in ESB to download that dataset.\n\nsplit=\"train\": the split. Set this to one of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hf-audio/esb-datasets-test-only.","url":"https://huggingface.co/datasets/hf-audio/esb-datasets-test-only","creator_name":"Hugging Face for Audio","creator_url":"https://huggingface.co/hf-audio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"libritts-r-aligned","keyword":"automatic-speech-recognition","description":"Dataset used for loading TTS spectrograms and waveform audio with alignments and a number of configurable \"measures\", which are extracted from the raw audio.","url":"https://huggingface.co/datasets/cdminix/libritts-r-aligned","creator_name":"Christoph Minixhofer","creator_url":"https://huggingface.co/cdminix","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"libritts-r-aligned","keyword":"automatic-speech-recognition","description":"Dataset used for loading TTS spectrograms and waveform audio with alignments and a number of configurable \"measures\", which are extracted from the raw audio.","url":"https://huggingface.co/datasets/cdminix/libritts-r-aligned","creator_name":"Christoph Minixhofer","creator_url":"https://huggingface.co/cdminix","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"wikitoxic","keyword":"hate-speech-detection","description":"This dataset has been created as an artefact of the paper AnchorAL: Computationally Efficient Active Learning for Large and Imbalanced Datasets (Lesci and Vlachos, 2024).\nMore info about this dataset in the appendix of the paper. \nThis is the same dataset as OxAISH-AL-LLM/wiki_toxic.\nThe only differences are:\n\nAddition of a unique identifier, uid.\n\nAddition of the indices, that is, 3 columns with the embeddings of 3 different sentence-transformers\n\nall-mpnet-base-v2\nmulti-qa-mpnet-base-dot-v1‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pietrolesci/wikitoxic.","url":"https://huggingface.co/datasets/pietrolesci/wikitoxic","creator_name":"Pietro Lesci","creator_url":"https://huggingface.co/pietrolesci","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"lj_speech","keyword":"text-to-speech","description":"This is a public domain speech dataset consisting of 13,100 short audio clips of a single speaker reading\npassages from 7 non-fiction books in English. A transcription is provided for each clip. Clips vary in length\nfrom 1 to 10 seconds and have a total length of approximately 24 hours.\n\nNote that in order to limit the required storage for preparing this dataset, the audio\nis stored in the .wav format and is not converted to a float32 array. To convert the audio\nfile to a float32 array, please make use of the `.map()` function as follows:\n\n\n```python\nimport soundfile as sf\n\ndef map_to_array(batch):\n    speech_array, _ = sf.read(batch[\"file\"])\n    batch[\"speech\"] = speech_array\n    return batch\n\ndataset = dataset.map(map_to_array, remove_columns=[\"file\"])\n```","url":"https://huggingface.co/datasets/keithito/lj_speech","creator_name":"Keith Ito","creator_url":"https://huggingface.co/keithito","license_name":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"cmu-arctic-xvectors","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tSpeaker embeddings extracted from CMU ARCTIC\n\t\n\nThere is one .npy file for each utterance in the dataset, 7931 files in total. The speaker embeddings are 512-element X-vectors.\nThe CMU ARCTIC dataset divides the utterances among the following speakers:\n\nbdl (US male)\nslt (US female)\njmk (Canadian male)\nawb (Scottish male)\nrms (US male)\nclb (US female)\nksp (Indian male)\n\nThe X-vectors were extracted using this script, which uses the speechbrain/spkrec-xvect-voxceleb model.\nUsage:\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Matthijs/cmu-arctic-xvectors.","url":"https://huggingface.co/datasets/Matthijs/cmu-arctic-xvectors","creator_name":"Matthijs Hollemans","creator_url":"https://huggingface.co/Matthijs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","mit","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"libritts-r-aligned","keyword":"text-to-speech","description":"Dataset used for loading TTS spectrograms and waveform audio with alignments and a number of configurable \"measures\", which are extracted from the raw audio.","url":"https://huggingface.co/datasets/cdminix/libritts-r-aligned","creator_name":"Christoph Minixhofer","creator_url":"https://huggingface.co/cdminix","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"libritts-r-aligned","keyword":"text-to-speech","description":"Dataset used for loading TTS spectrograms and waveform audio with alignments and a number of configurable \"measures\", which are extracted from the raw audio.","url":"https://huggingface.co/datasets/cdminix/libritts-r-aligned","creator_name":"Christoph Minixhofer","creator_url":"https://huggingface.co/cdminix","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"sebut-perkataan","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSebut Perkataan\n\t\n\n\nsebut-perkataan-man voice by Husein Zolkepli\ntolong-sebut voice by Khalil Nooh\nsebut-perkataan-woman voice by Mas Aisyah Ahmad\nRecorded using low-end tech microphones.\n\n","url":"https://huggingface.co/datasets/mesolitica/sebut-perkataan","creator_name":"Mesolitica","creator_url":"https://huggingface.co/mesolitica","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Malay","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"esc-datasets","keyword":"speech","description":"All eight of datasets in ESC can be downloaded and prepared in just a single line of code through the Hugging Face Datasets library:\nfrom datasets import load_dataset\n\nlibrispeech = load_dataset(\"esc-benchmark/esc-datasets\", \"librispeech\", split=\"train\")\n\n\n\"esc-benchmark\": the repository namespace. This is fixed for all ESC datasets.\n\n\"librispeech\": the dataset name. This can be changed to any of any one of the eight datasets in ESC to download that dataset.\n\nsplit=\"train\": the split. Set this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/esc-benchmark/esc-datasets.","url":"https://huggingface.co/datasets/esc-benchmark/esc-datasets","creator_name":"ESC","creator_url":"https://huggingface.co/esc-benchmark","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"esc-datasets","keyword":"automatic-speech-recognition","description":"All eight of datasets in ESC can be downloaded and prepared in just a single line of code through the Hugging Face Datasets library:\nfrom datasets import load_dataset\n\nlibrispeech = load_dataset(\"esc-benchmark/esc-datasets\", \"librispeech\", split=\"train\")\n\n\n\"esc-benchmark\": the repository namespace. This is fixed for all ESC datasets.\n\n\"librispeech\": the dataset name. This can be changed to any of any one of the eight datasets in ESC to download that dataset.\n\nsplit=\"train\": the split. Set this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/esc-benchmark/esc-datasets.","url":"https://huggingface.co/datasets/esc-benchmark/esc-datasets","creator_name":"ESC","creator_url":"https://huggingface.co/esc-benchmark","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"bigbench","keyword":"hate-speech-detection","description":"The Beyond the Imitation Game Benchmark (BIG-bench) is a collaborative benchmark intended to\nprobe large language models, and extrapolate their future capabilities.","url":"https://huggingface.co/datasets/google/bigbench","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","text-generation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"hate_offensive","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for HateOffensive\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish (en)\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n{\n\"count\": 3,\n \"hate_speech_annotation\": 0,\n \"offensive_language_annotation\": 0,\n \"neither_annotation\": 3,\n \"label\": 2,  # \"neither\"\n \"tweet\": \"!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/legacy-datasets/hate_offensive.","url":"https://huggingface.co/datasets/legacy-datasets/hate_offensive","creator_name":"Legacy Datasets","creator_url":"https://huggingface.co/legacy-datasets","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","multi-class-classification","crowdsourced","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"base-dados-odio-lgbtqia","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tBase de Dados de √ìdio contra Pessoas LGBTQIA+ em Portugu√™s (PT-BR)\n\t\n\nCole√ß√£o de datasets para detec√ß√£o de discurso de √≥dio contra pessoas LGBTQIA+ em portugu√™s brasileiro.\n\n\t\n\t\t\n\t\tüéØ Objetivo\n\t\n\nFornecer dados de treinamento e valida√ß√£o para sistemas de detec√ß√£o de discurso de √≥dio contra pessoas LGBTQIA+ em portugu√™s brasileiro.\n\n\t\n\t\t\n\t\tüì¢ Contexto Social\n\t\n\nEste dataset foi criado a partir de uma onda de √≥dio real sofrida pelo podcast Entre Amigues da equipe C√≥digo N√£o Bin√°rio. Os‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Veronyka/base-dados-odio-lgbtqia.","url":"https://huggingface.co/datasets/Veronyka/base-dados-odio-lgbtqia","creator_name":"Veronyka \"Travahacker\" Gimenes","creator_url":"https://huggingface.co/Veronyka","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","Portuguese","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"peoples_speech-clean-timestamped","keyword":"automatic-speech-recognition","description":"The People's Speech is a free-to-download 30,000-hour and growing supervised \nconversational English speech recognition dataset licensed for academic and \ncommercial usage under CC-BY-SA (with a CC-BY subset).","url":"https://huggingface.co/datasets/distil-whisper/peoples_speech-clean-timestamped","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Sinhala-English-Code-Mixed-Code-Switched-Dataset","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tSinhala-English-Code-Mixed-Code-Switched-Dataset\n\t\n\nThis dataset contains 10,000 comments that have been annotated at the sentence level for sentiment analysis, humor detection, hate speech detection, aspect identification, and language identification.\nThe following is the tag scheme.\n\nSentiment -  Positive, Negative, Neutral,  Conflict\nHumor - Humorous, Non humorous\nHate Speech - Hate-Inducing, Abusive, Not offensive\nAspect - Network, Billing or Price, Package, Customer Service, Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Sinhala-English-Code-Mixed-Code-Switched-Dataset.","url":"https://huggingface.co/datasets/NLPC-UOM/Sinhala-English-Code-Mixed-Code-Switched-Dataset","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","hate-speech-detection","language-identification","multilingual"],"keywords_longer_than_N":true},
	{"name":"libritts-aligned","keyword":"speech","description":"Dataset used for loading TTS spectrograms and waveform audio with alignments and a number of configurable \"measures\", which are extracted from the raw audio.","url":"https://huggingface.co/datasets/cdminix/libritts-aligned","creator_name":"Christoph Minixhofer","creator_url":"https://huggingface.co/cdminix","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"libritts-aligned","keyword":"automatic-speech-recognition","description":"Dataset used for loading TTS spectrograms and waveform audio with alignments and a number of configurable \"measures\", which are extracted from the raw audio.","url":"https://huggingface.co/datasets/cdminix/libritts-aligned","creator_name":"Christoph Minixhofer","creator_url":"https://huggingface.co/cdminix","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"libritts-aligned","keyword":"automatic-speech-recognition","description":"Dataset used for loading TTS spectrograms and waveform audio with alignments and a number of configurable \"measures\", which are extracted from the raw audio.","url":"https://huggingface.co/datasets/cdminix/libritts-aligned","creator_name":"Christoph Minixhofer","creator_url":"https://huggingface.co/cdminix","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"libritts-aligned","keyword":"text-to-speech","description":"Dataset used for loading TTS spectrograms and waveform audio with alignments and a number of configurable \"measures\", which are extracted from the raw audio.","url":"https://huggingface.co/datasets/cdminix/libritts-aligned","creator_name":"Christoph Minixhofer","creator_url":"https://huggingface.co/cdminix","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"libritts-aligned","keyword":"text-to-speech","description":"Dataset used for loading TTS spectrograms and waveform audio with alignments and a number of configurable \"measures\", which are extracted from the raw audio.","url":"https://huggingface.co/datasets/cdminix/libritts-aligned","creator_name":"Christoph Minixhofer","creator_url":"https://huggingface.co/cdminix","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"hatecheck-german","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-german.","url":"https://huggingface.co/datasets/Paul/hatecheck-german","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-dutch","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-dutch.","url":"https://huggingface.co/datasets/Paul/hatecheck-dutch","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"fstdt-quotes","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for FSTDT Quotes\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFSTDT Quotes is a snapshot of the Fundies Say the Darndest Things website taken on 2023/02/03 14:16. It is intended for hate and fringe speech detection and classification.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nFSTDT Quotes is in English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example instance looks like this:\n{\n  \"id\": \"G\",\n  \"submitter\": \"anonymous\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MtCelesteMa/fstdt-quotes.","url":"https://huggingface.co/datasets/MtCelesteMa/fstdt-quotes","creator_name":"Celeste Ma","creator_url":"https://huggingface.co/MtCelesteMa","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-spanish","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-spanish.","url":"https://huggingface.co/datasets/Paul/hatecheck-spanish","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"LibriSpeech-Synthesizer-TTS","keyword":"speech","description":"rmcpantoja/LibriSpeech-Synthesizer-TTS dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rmcpantoja/LibriSpeech-Synthesizer-TTS","creator_name":"Rene Mateo Cedillo Pantoja","creator_url":"https://huggingface.co/rmcpantoja","license_name":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Spanish","Spanish Sign Language","unlicense","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"NPSC_orto","keyword":"automatic-speech-recognition","description":"The Norwegian Parliament Speech Corpus (NPSC) is a corpus for training a Norwegian ASR (Automatic Speech Recognition) models. The corpus is created by Spr√•kbanken at the National Library in Norway.\n\nNPSC is based on sound recording from meeting in the Norwegian Parliament. These talks are orthographically transcribed to either Norwegian Bokm√•l or Norwegian Nynorsk. In addition to the data actually included in this dataset, there is a significant amount of metadata that is included in the original corpus. Through the speaker id there is additional information about the speaker, like gender, age, and place of birth (ie dialect). Through the proceedings id the corpus can be linked to the official proceedings from the meetings.\n\nThe corpus is in total sound recordings from 40 entire days of meetings. This amounts to 140 hours of speech, 65,000 sentences or 1.2 million words.\n\nThis dataset builds on this corpus. In addition it adds two columns with machine generated orthographic text.","url":"https://huggingface.co/datasets/NbAiLab/NPSC_orto","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 10.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Common Voice dataset consists of a unique MP3 and corresponding text file. \nMany of the 20817 recorded hours in the dataset also include demographic metadata like age, sex, and accent \nthat can help improve the accuracy of speech recognition engines.\nThe dataset currently consists of 15234 validated hours in 96 languages, but more voices and languages are always added. \nTake a look at the Languages page to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gogogogo-1/test.","url":"https://huggingface.co/datasets/gogogogo-1/test","creator_name":"mhj","creator_url":"https://huggingface.co/gogogogo-1","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"common_voice_11_clean_tokenized","keyword":"text-to-speech","description":"A cleaned and tokenized version of the English data from Mozilla Common Voice 11 dataset.\nCleaning steps:\n\nFiltered on samples with >2 upvotes and <1 downvotes]\nRemoved non voice audio at start and end through pytorch VAD\n\nTokenization:\n\nAudio tokenized through EnCodec by Meta\nUsing 24khz pre-trained model, and target bandwidth of 1.5\nRepresented in text as audio_token_0 - audio_token_1023\n\n\nPrompts constructed as \"text: <common voice transcript>\\naudio: <audio tokens>\"\nPrompts tokenized with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anforsm/common_voice_11_clean_tokenized.","url":"https://huggingface.co/datasets/anforsm/common_voice_11_clean_tokenized","creator_name":"Anton Forsman","creator_url":"https://huggingface.co/anforsm","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-generation","English","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"LibriSpeech-Synthesizer-TTS","keyword":"text-to-speech","description":"rmcpantoja/LibriSpeech-Synthesizer-TTS dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rmcpantoja/LibriSpeech-Synthesizer-TTS","creator_name":"Rene Mateo Cedillo Pantoja","creator_url":"https://huggingface.co/rmcpantoja","license_name":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Spanish","Spanish Sign Language","unlicense","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"LibriSpeech-Synthesizer-TTS","keyword":"text-to-speech","description":"rmcpantoja/LibriSpeech-Synthesizer-TTS dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rmcpantoja/LibriSpeech-Synthesizer-TTS","creator_name":"Rene Mateo Cedillo Pantoja","creator_url":"https://huggingface.co/rmcpantoja","license_name":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Spanish","Spanish Sign Language","unlicense","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"gos-demo","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tGronings transcribed speech\n\t\n\nDemonstration dataset with Gronings transcribed speech based on the dataset released by San et al. (2021).\nFor more information see the corresponding ASRU 2021 paper.\n","url":"https://huggingface.co/datasets/bartelds/gos-demo","creator_name":"Martijn Bartelds","creator_url":"https://huggingface.co/bartelds","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Gronings","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"km-speech-corpus","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for \"km-speech-corpus\"\n\t\n\nsampling_rate: 16000\nmean_seconds: 2.5068187111021882\nmax_seconds: 19.392\nmin_seconds: 0.448\ntotal_seconds: 37459.392\ntotal_hrs: 10.405386666666667\n\n","url":"https://huggingface.co/datasets/seanghay/km-speech-corpus","creator_name":"seanghay","creator_url":"https://huggingface.co/seanghay","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Khmer","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"km-speech-corpus","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for \"km-speech-corpus\"\n\t\n\nsampling_rate: 16000\nmean_seconds: 2.5068187111021882\nmax_seconds: 19.392\nmin_seconds: 0.448\ntotal_seconds: 37459.392\ntotal_hrs: 10.405386666666667\n\n","url":"https://huggingface.co/datasets/seanghay/km-speech-corpus","creator_name":"seanghay","creator_url":"https://huggingface.co/seanghay","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Khmer","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Hausa-loud-tts","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tHausa TTS Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Hausa language text-to-speech (TTS) recordings from multiple speakers. It includes audio files paired with their corresponding Hausa text transcriptions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized as follows:\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îú‚îÄ‚îÄ metadata.csv                    # Metadata (source, audio paths, text)\n‚îÇ   ‚îî‚îÄ‚îÄ audio_files/\n‚îÇ       ‚îú‚îÄ‚îÄ 97f373e8-f6e6-.../          # Speaker 1 audio files\n‚îÇ       ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aybee5/Hausa-loud-tts.","url":"https://huggingface.co/datasets/Aybee5/Hausa-loud-tts","creator_name":"Ibrahim Abdullahi","creator_url":"https://huggingface.co/Aybee5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","Hausa","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"datatalk","keyword":"speech","description":"\n\t\n\t\t\n\t\tpelatihpokemongo/datatalk\n\t\n\nAn Elise-style Indonesian speech dataset with two columns: audio and text, published for quick prototyping in ASR/TTS. Built from local audio and transcripts with a single train split. Viewer is auto-converted to Parquet for fast preview on the Hub.\n\nReference structure: MrDragonFox/Elise\nCreation guide: Create a dataset\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset summary\n\t\n\n\nSplit: train\nRows: 5,400\nColumns:\naudio (datasets.Audio): waveform automatically decoded by the Hub\ntext‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pelatihpokemongo/datatalk.","url":"https://huggingface.co/datasets/pelatihpokemongo/datatalk","creator_name":"pelatih pokemon","creator_url":"https://huggingface.co/pelatihpokemongo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Indonesian","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"datatalk","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tpelatihpokemongo/datatalk\n\t\n\nAn Elise-style Indonesian speech dataset with two columns: audio and text, published for quick prototyping in ASR/TTS. Built from local audio and transcripts with a single train split. Viewer is auto-converted to Parquet for fast preview on the Hub.\n\nReference structure: MrDragonFox/Elise\nCreation guide: Create a dataset\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset summary\n\t\n\n\nSplit: train\nRows: 5,400\nColumns:\naudio (datasets.Audio): waveform automatically decoded by the Hub\ntext‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pelatihpokemongo/datatalk.","url":"https://huggingface.co/datasets/pelatihpokemongo/datatalk","creator_name":"pelatih pokemon","creator_url":"https://huggingface.co/pelatihpokemongo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Indonesian","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Hokchia","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tHokchia Audio Dataset\n\t\n\nHokchia, or the Fuqing dialect, is a branch of Eastern Min Chinese spoken mainly in the Fuqing City of Fujian province, China. Unlike Hokkien, which is more widely recognized and spoken in various parts of Southeast Asia, Hokchia maintains its unique linguistic characteristics and is primarily used within the Fuqing community and its diaspora. This dialect is known for its distinct pronunciation, vocabulary, and grammatical structures compared to other Min‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yjhuang01/Hokchia.","url":"https://huggingface.co/datasets/yjhuang01/Hokchia","creator_name":"Yijun Huang","creator_url":"https://huggingface.co/yjhuang01","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","original","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"datatalk","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tpelatihpokemongo/datatalk\n\t\n\nAn Elise-style Indonesian speech dataset with two columns: audio and text, published for quick prototyping in ASR/TTS. Built from local audio and transcripts with a single train split. Viewer is auto-converted to Parquet for fast preview on the Hub.\n\nReference structure: MrDragonFox/Elise\nCreation guide: Create a dataset\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset summary\n\t\n\n\nSplit: train\nRows: 5,400\nColumns:\naudio (datasets.Audio): waveform automatically decoded by the Hub\ntext‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pelatihpokemongo/datatalk.","url":"https://huggingface.co/datasets/pelatihpokemongo/datatalk","creator_name":"pelatih pokemon","creator_url":"https://huggingface.co/pelatihpokemongo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Indonesian","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"mother_tongue_dataset","keyword":"automatic-speech-recognition","description":"MothersTongue/mother_tongue_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/MothersTongue/mother_tongue_dataset","creator_name":"Patronela  Tiwaringe ","creator_url":"https://huggingface.co/MothersTongue","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Shona","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"vctk","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tVCTK\n\t\n\nThis is a processed clone of the VCTK dataset with leading and trailing silence removed using Silero VAD. A fixed 25‚ÄØms of padding has been added to both ends of each audio clip to (hopefully) imrprove training and finetuning.\nThe original dataset is available at: https://datashare.ed.ac.uk/handle/10283/3443.\n\n\t\n\t\t\n\t\tReproducing\n\t\n\nThis repository notably lacks a requirements.txt file. There's likely a missing dependency or two, but roughly:\npydub\ntqdm\ntorch\ntorchaudio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jspaulsen/vctk.","url":"https://huggingface.co/datasets/jspaulsen/vctk","creator_name":"Jacob Paulsen","creator_url":"https://huggingface.co/jspaulsen","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","text-to-audio","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"vctk","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tVCTK\n\t\n\nThis is a processed clone of the VCTK dataset with leading and trailing silence removed using Silero VAD. A fixed 25‚ÄØms of padding has been added to both ends of each audio clip to (hopefully) imrprove training and finetuning.\nThe original dataset is available at: https://datashare.ed.ac.uk/handle/10283/3443.\n\n\t\n\t\t\n\t\tReproducing\n\t\n\nThis repository notably lacks a requirements.txt file. There's likely a missing dependency or two, but roughly:\npydub\ntqdm\ntorch\ntorchaudio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jspaulsen/vctk.","url":"https://huggingface.co/datasets/jspaulsen/vctk","creator_name":"Jacob Paulsen","creator_url":"https://huggingface.co/jspaulsen","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","text-to-audio","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"my-audio-dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tAudio Transcription Dataset\n\t\n\nThis dataset contains audio file paths and their corresponding transcriptions for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is structured for audio transcription tasks with two main columns:\n\naudio: Audio file paths (type: audio)\ntranscript: Text transcriptions (type: text)\n\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\naudio_dataset.csv: Main dataset file containing audio paths and transcriptions\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\naudio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aashish17405/my-audio-dataset.","url":"https://huggingface.co/datasets/Aashish17405/my-audio-dataset","creator_name":"Jaini Aashish","creator_url":"https://huggingface.co/Aashish17405","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"gametime","keyword":"speech","description":"\n\t\n\t\t\n\t\tGametime Benchmark\n\t\n\nThe Gametime dataset provides lightweight, streaming-friendly splits for TTS/ASR/SpokenLM prototyping.\n\n\n\t\n\t\t\n\t\tüì¶ Download Options\n\t\n\n\n\t\n\t\t\n\t\t1Ô∏è‚É£ Recommended ‚Äî Stream from Hugging Face\n\t\n\nfrom datasets import load_dataset\nimport io\nimport soundfile as sf\n\n# Load Basic train split\nds_basic = load_dataset(\"gametime-benchmark/gametime\", \"basic\", split=\"test\", streaming=True)\nex = next(iter(ds_basic))\nbuf = io.BytesIO(ex[\"audio_bytes\"])\nwav, sr = sf.read(buf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gametime-benchmark/gametime.","url":"https://huggingface.co/datasets/gametime-benchmark/gametime","creator_name":"GameTime","creator_url":"https://huggingface.co/gametime-benchmark","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","audio-to-audio","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"my-audio-dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tAudio Transcription Dataset\n\t\n\nThis dataset contains audio file paths and their corresponding transcriptions for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is structured for audio transcription tasks with two main columns:\n\naudio: Audio file paths (type: audio)\ntranscript: Text transcriptions (type: text)\n\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\naudio_dataset.csv: Main dataset file containing audio paths and transcriptions\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\naudio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aashish17405/my-audio-dataset.","url":"https://huggingface.co/datasets/Aashish17405/my-audio-dataset","creator_name":"Jaini Aashish","creator_url":"https://huggingface.co/Aashish17405","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"gametime","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tGametime Benchmark\n\t\n\nThe Gametime dataset provides lightweight, streaming-friendly splits for TTS/ASR/SpokenLM prototyping.\n\n\n\t\n\t\t\n\t\tüì¶ Download Options\n\t\n\n\n\t\n\t\t\n\t\t1Ô∏è‚É£ Recommended ‚Äî Stream from Hugging Face\n\t\n\nfrom datasets import load_dataset\nimport io\nimport soundfile as sf\n\n# Load Basic train split\nds_basic = load_dataset(\"gametime-benchmark/gametime\", \"basic\", split=\"test\", streaming=True)\nex = next(iter(ds_basic))\nbuf = io.BytesIO(ex[\"audio_bytes\"])\nwav, sr = sf.read(buf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gametime-benchmark/gametime.","url":"https://huggingface.co/datasets/gametime-benchmark/gametime","creator_name":"GameTime","creator_url":"https://huggingface.co/gametime-benchmark","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","audio-to-audio","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"gametime","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tGametime Benchmark\n\t\n\nThe Gametime dataset provides lightweight, streaming-friendly splits for TTS/ASR/SpokenLM prototyping.\n\n\n\t\n\t\t\n\t\tüì¶ Download Options\n\t\n\n\n\t\n\t\t\n\t\t1Ô∏è‚É£ Recommended ‚Äî Stream from Hugging Face\n\t\n\nfrom datasets import load_dataset\nimport io\nimport soundfile as sf\n\n# Load Basic train split\nds_basic = load_dataset(\"gametime-benchmark/gametime\", \"basic\", split=\"test\", streaming=True)\nex = next(iter(ds_basic))\nbuf = io.BytesIO(ex[\"audio_bytes\"])\nwav, sr = sf.read(buf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gametime-benchmark/gametime.","url":"https://huggingface.co/datasets/gametime-benchmark/gametime","creator_name":"GameTime","creator_url":"https://huggingface.co/gametime-benchmark","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","audio-to-audio","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"samromur_milljon","keyword":"automatic-speech-recognition","description":"Samr√≥mur Millj√≥n consists of approximately 1 million of speech recordings (967 hours) collected through the platform samromur.is; the transcripts accompanying these recordings were automatically verified using various ASR systems such as: Wav2Vec, Whisper and NeMo.","url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_milljon","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"JavaneseIMDBClassification","keyword":"hate-speech-detection","description":"\n  JavaneseIMDBClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLarge Movie Review Dataset translated to Javanese. This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/w11wo/nlp-datasets#javanese-imdb\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JavaneseIMDBClassification.","url":"https://huggingface.co/datasets/mteb/JavaneseIMDBClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-multispeaker","keyword":"speech","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 21138 parallel speech-text pairs for Twi (Akan), a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi (Akan) - tw\nTask: Speech Recognition, Text-to-Speech\nSize: 21138 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-multispeaker.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-multispeaker","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-multispeaker","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 21138 parallel speech-text pairs for Twi (Akan), a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi (Akan) - tw\nTask: Speech Recognition, Text-to-Speech\nSize: 21138 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-multispeaker.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-multispeaker","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"ClArTTS","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe present a speech corpus for Classical Arabic Text-to-Speech (ClArTTS) to support the development of end-to-end TTS systems for Arabic. The speech is extracted from a LibriVox audiobook, which is then processed, segmented, and manually transcribed and annotated. The final ClArTTS corpus contains about 12 hours of speech from a single male speaker sampled at 40100 kHz.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nA typical data point comprises the name of the audio file, called‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/ClArTTS.","url":"https://huggingface.co/datasets/MBZUAI/ClArTTS","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Arabic","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-multispeaker","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 21138 parallel speech-text pairs for Twi (Akan), a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi (Akan) - tw\nTask: Speech Recognition, Text-to-Speech\nSize: 21138 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-multispeaker.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-multispeaker","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"znanio-audios","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Znanio.ru Educational Audio\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 3,417 educational audio files from the znanio.ru platform, a resource for teachers, educators, students, and parents providing diverse educational content. Znanio.ru has been a pioneer in educational technologies and distance learning in the Russian-speaking internet since 2009.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Russian, with potential multilingual content:\n\nRussian (ru): The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/znanio-audios.","url":"https://huggingface.co/datasets/nyuuzyou/znanio-audios","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"eastern_poe_karen_asr","keyword":"automatic-speech-recognition","description":"This is the first public Eastern Poe Karen language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tEastern Poe Karen ASR\n\t\n\nThis dataset contains audio recordings and aligned metadata in the Eastern Poe Karen language (a regional variety of Eastern Pwo, ISO 639-3: pwo), a Karenic language spoken primarily in Mon State and Kayin State in southeastern Myanmar. While linguistically described as Eastern Pwo Karen, the community and this project prefer the term Poe as a community-endorsed spelling.\nAll audio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/eastern_poe_karen_asr.","url":"https://huggingface.co/datasets/freococo/eastern_poe_karen_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"eastern_poe_karen_asr","keyword":"automatic-speech-recognition","description":"This is the first public Eastern Poe Karen language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tEastern Poe Karen ASR\n\t\n\nThis dataset contains audio recordings and aligned metadata in the Eastern Poe Karen language (a regional variety of Eastern Pwo, ISO 639-3: pwo), a Karenic language spoken primarily in Mon State and Kayin State in southeastern Myanmar. While linguistically described as Eastern Pwo Karen, the community and this project prefer the term Poe as a community-endorsed spelling.\nAll audio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/eastern_poe_karen_asr.","url":"https://huggingface.co/datasets/freococo/eastern_poe_karen_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"french_homophone_asr","keyword":"automatic-speech-recognition","description":"The dataset, created and used in Mohebbi et al., (2023), includes instances of homophones in French spoken language, where an ASR model has to attend to syntactic cues in the context to disambiguate spoken words with identical pronunciations for transcription. \nThe test set (fr) of the Common Voice 11.0 (Ardila et al., 2020) is used to discover instances of three specific grammatical syntactic templates in which homophony may appear. \nFor the purpose of analysis, examples are filtered so that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hosein-m/french_homophone_asr.","url":"https://huggingface.co/datasets/hosein-m/french_homophone_asr","creator_name":"Hosein Mohebbi","creator_url":"https://huggingface.co/hosein-m","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","French","cc0-1.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"cml-tts","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for CML-TTS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG).\nCML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in Dutch, German, French, Italian, Polish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/cml-tts.","url":"https://huggingface.co/datasets/ylacombe/cml-tts","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Dutch","French","German"],"keywords_longer_than_N":true},
	{"name":"HAL-9000-Speech","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tHAL 9000 Speech Dataset\n\t\n\nThis repository contains audio recordings of dialogue from HAL 9000, the AI character from 2001: A Space Odyssey. The full dataset contains most, but not all audio recordings of HAL 9000 from the film. The dataset is not cleaned, as background noise and variations in his voice are prevalent.  \nThe dataset can be formatted into the LJSpeech structure to ensure compatibility with most text-to-speech (TTS) models and training pipelines, such as Piper.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/campwill/HAL-9000-Speech.","url":"https://huggingface.co/datasets/campwill/HAL-9000-Speech","creator_name":"William Campbell","creator_url":"https://huggingface.co/campwill","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"SpeechBrown","keyword":"text-to-speech","description":"  \nModels | Springer Link | arXiv Link | Proposed Dataset  | ACM Digital Library | Website\n\n\t\t\n\t\tDataset Summary\n\t\n\nSpeech Brown is a comprehensive, synthetic, and diverse paired speech-text dataset in 15 categories, covering a wide range of topics from fiction to religion. This dataset consists of over 55,000 sentence-level samples.  \nTo train the CLASP model, we created this dataset based on the Brown Corpus. The synthetic speech was generated using the NVIDIA Tacotron 2 text-to-speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llm-lab/SpeechBrown.","url":"https://huggingface.co/datasets/llm-lab/SpeechBrown","creator_name":"LLM-Lab-Org  @QCRI-ALT","creator_url":"https://huggingface.co/llm-lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"kiaraTTS","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tKiara TTS\n\t\n\nMasih belum ada training, hanya data mentahan saja \nberisi CSV dan file audio WAV \ndata hanya 270 Audio\nSemoga ada yang bisa melatih data ini, beritau saya jika kamu\nbisa melatih data ini.terimakasih banya atas kerja samanya\n\nDeveloped by: [Niki]\nLanguage(s) (NLP): [Indonesian]\nLicense: [Apache]\n\n","url":"https://huggingface.co/datasets/niki2one/kiaraTTS","creator_name":"niki","creator_url":"https://huggingface.co/niki2one","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Indonesian","apache-2.0","n<1K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"bbbb","keyword":"speech","description":"\n\t\n\t\t\n\t\tbbbb\n\t\n\nThis is a merged speech dataset containing 345 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 345\nSpeakers: 7\nLanguages: en\nEmotions: happy, sad, neutral, angry\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral, happy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/bbbb.","url":"https://huggingface.co/datasets/Codyfederer/bbbb","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"bbbb","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tbbbb\n\t\n\nThis is a merged speech dataset containing 345 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 345\nSpeakers: 7\nLanguages: en\nEmotions: happy, sad, neutral, angry\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral, happy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/bbbb.","url":"https://huggingface.co/datasets/Codyfederer/bbbb","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"anta_women_tts","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tAnta Women TTS\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a cleaned version of the Wolof TTS dataset by GalsenAI. \nWe extracted the female voice, denoised it and enhanced it with the Resemble Enhance library. \nWe also cleaned up the annotations by removing special characters, emojis, Arabic and Russian characters. \nWe've corrected a few annotation errors, but there are potentially many more to come. \nSome lines and audios judged not qualitative enough have been removed from the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/galsenai/anta_women_tts.","url":"https://huggingface.co/datasets/galsenai/anta_women_tts","creator_name":"GalsenAI Lab","creator_url":"https://huggingface.co/galsenai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Wolof","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"bbbb","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tbbbb\n\t\n\nThis is a merged speech dataset containing 345 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 345\nSpeakers: 7\nLanguages: en\nEmotions: happy, sad, neutral, angry\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral, happy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/bbbb.","url":"https://huggingface.co/datasets/Codyfederer/bbbb","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Libriheavy-HQ","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Libriheavy-HQ\n\t\n\n\n\nLibriheavy: a 50,000 hours ASR corpus with punctuation casing \nand context. Libriheavy is a labeled version of Libri-Light.\nLibriheavy-HQ replaces the default Libri-Light audio files with the highest quality available versions from librivox \nwithout re-encoding them. \nIn most cases, this consists an upgrade of the source audio from a 64kbps .mp3 to a 128kbps .mp3.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThis is the Libriheavy-HQ dataset, adapted for the datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mythicinfinity/Libriheavy-HQ.","url":"https://huggingface.co/datasets/mythicinfinity/Libriheavy-HQ","creator_name":"Mythic Infinity","creator_url":"https://huggingface.co/mythicinfinity","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Libriheavy-HQ","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Libriheavy-HQ\n\t\n\n\n\nLibriheavy: a 50,000 hours ASR corpus with punctuation casing \nand context. Libriheavy is a labeled version of Libri-Light.\nLibriheavy-HQ replaces the default Libri-Light audio files with the highest quality available versions from librivox \nwithout re-encoding them. \nIn most cases, this consists an upgrade of the source audio from a 64kbps .mp3 to a 128kbps .mp3.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThis is the Libriheavy-HQ dataset, adapted for the datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mythicinfinity/Libriheavy-HQ.","url":"https://huggingface.co/datasets/mythicinfinity/Libriheavy-HQ","creator_name":"Mythic Infinity","creator_url":"https://huggingface.co/mythicinfinity","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"english-tts-eval","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tEnglish Text-to-Speech Evaluation Dataset\n\t\n\nThe english-tts-eval dataset evaluates the performance of Text-to-Speech (TTS) systems. It includes a diverse collection of English text samples covering a wide range of use cases, such as news updates, navigation assistance, customer service, and storytelling.\nThere are 100 examples, each of which includes:\n\nText: The original text sample.\nNormalized Text: The spoken form of the text, with numbers and abbreviations expanded.\nCategory: The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ntt123/english-tts-eval.","url":"https://huggingface.co/datasets/ntt123/english-tts-eval","creator_name":"Th√¥ng Nguy·ªÖn","creator_url":"https://huggingface.co/ntt123","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"emova-sft-speech-231k","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tEMOVA-SFT-Speech-231K\n\t\n\n\n\n\nü§ó EMOVA-Models | ü§ó EMOVA-Datasets | ü§ó EMOVA-Demo \nüìÑ Paper | üåê Project-Page | üíª Github | üíª EMOVA-Speech-Tokenizer-Github\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-SFT-Speech-231K is a comprehensive dataset curated for omni-modal instruction tuning and emotional spoken dialogue. This dataset is created by converting existing text and visual instruction datasets via Text-to-Speech (TTS) tools. EMOVA-SFT-Speech-231K is part of EMOVA-Datasets collection and is used in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-231k.","url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-231k","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"emova-sft-speech-231k","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tEMOVA-SFT-Speech-231K\n\t\n\n\n\n\nü§ó EMOVA-Models | ü§ó EMOVA-Datasets | ü§ó EMOVA-Demo \nüìÑ Paper | üåê Project-Page | üíª Github | üíª EMOVA-Speech-Tokenizer-Github\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-SFT-Speech-231K is a comprehensive dataset curated for omni-modal instruction tuning and emotional spoken dialogue. This dataset is created by converting existing text and visual instruction datasets via Text-to-Speech (TTS) tools. EMOVA-SFT-Speech-231K is part of EMOVA-Datasets collection and is used in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-231k.","url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-231k","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"audiobooks","keyword":"speech","description":"\n\t\n\t\t\n\t\tCrimean Tatar Audiobooks\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCrimean Tatar Audiobooks is a speech dataset sourced from different sources (public radio stations/youtube channels) containing audiobooks in Crimean Tatar. The dataset comprises recordings of different native fiction books, all read by a single female speaker (for now). The dataset is intended for text-to-speech (TTS) research and development in the Crimean Tatar language. \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nParts:The dataset contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gaydmi/audiobooks.","url":"https://huggingface.co/datasets/gaydmi/audiobooks","creator_name":"Dmitry Gaynullin","creator_url":"https://huggingface.co/gaydmi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Crimean Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"singaporean_district_noise_snr_5_10","keyword":"speech","description":"\n\t\n\t\t\n\t\tSingaporean district with noise\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSingaporean district speech dataset with controlled noise augmentation for ASR training\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: EN\nTask: Automatic Speech Recognition  \nTotal Samples: 252\nAudio Sample Rate: 16kHz\nBase Dataset: Custom dataset\nProcessing: Noise-augmented\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (16kHz WAV format)\ntext: Transcription text\nnoise_type: Type of background noise‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_5_10.","url":"https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_5_10","creator_name":"DANG VAN THUC","creator_url":"https://huggingface.co/thucdangvan020999","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"audiobooks","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tCrimean Tatar Audiobooks\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCrimean Tatar Audiobooks is a speech dataset sourced from different sources (public radio stations/youtube channels) containing audiobooks in Crimean Tatar. The dataset comprises recordings of different native fiction books, all read by a single female speaker (for now). The dataset is intended for text-to-speech (TTS) research and development in the Crimean Tatar language. \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nParts:The dataset contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gaydmi/audiobooks.","url":"https://huggingface.co/datasets/gaydmi/audiobooks","creator_name":"Dmitry Gaynullin","creator_url":"https://huggingface.co/gaydmi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Crimean Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"singaporean_district_noise_snr_5_10","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSingaporean district with noise\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSingaporean district speech dataset with controlled noise augmentation for ASR training\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: EN\nTask: Automatic Speech Recognition  \nTotal Samples: 252\nAudio Sample Rate: 16kHz\nBase Dataset: Custom dataset\nProcessing: Noise-augmented\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (16kHz WAV format)\ntext: Transcription text\nnoise_type: Type of background noise‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_5_10.","url":"https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_5_10","creator_name":"DANG VAN THUC","creator_url":"https://huggingface.co/thucdangvan020999","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"audiobooks","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tCrimean Tatar Audiobooks\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCrimean Tatar Audiobooks is a speech dataset sourced from different sources (public radio stations/youtube channels) containing audiobooks in Crimean Tatar. The dataset comprises recordings of different native fiction books, all read by a single female speaker (for now). The dataset is intended for text-to-speech (TTS) research and development in the Crimean Tatar language. \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nParts:The dataset contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gaydmi/audiobooks.","url":"https://huggingface.co/datasets/gaydmi/audiobooks","creator_name":"Dmitry Gaynullin","creator_url":"https://huggingface.co/gaydmi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Crimean Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"soomali-asr-dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSomali ASR Dataset\n\t\n\nThis dataset contains audio recordings and corresponding transcriptions in Somali, designed for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Somali (so)\nSize: 10K - 100K samples\nFormat: Parquet\nModalities: Audio + Text\nLicense: CC-BY 4.0\nTask: Automatic Speech Recognition\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset can be used to train and evaluate ASR models for the Somali language. It is particularly helpful for developing speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/skydheere/soomali-asr-dataset.","url":"https://huggingface.co/datasets/skydheere/soomali-asr-dataset","creator_name":"imran adam ","creator_url":"https://huggingface.co/skydheere","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Somali","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"it_youtube_uzbek_speech_dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tIT Uzbek Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio clips and their corresponding transcriptions in the Uzbek language and with some english to better generalization. The data was collected from publicly available videos on YouTube related to the Information Technology (IT) field. It is designed for training and evaluating Automatic Speech Recognition (ASR) models.\nMost of the content comes from the Mohir Dev YouTube channel (respect to the team for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/islomov/it_youtube_uzbek_speech_dataset.","url":"https://huggingface.co/datasets/islomov/it_youtube_uzbek_speech_dataset","creator_name":"Sardor Islomov","creator_url":"https://huggingface.co/islomov","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"linguistic_sq","keyword":"linguistics","description":"\n\t\n\t\t\n\t\tPhysics and Math Problems Dataset\n\t\n\nThis repository contains a dataset of 3,200 enteries of different Albanian linguistics to improve Albanian queries further by introducing Albanian language rules and literature. The dataset is designed to support various NLP tasks and educational applications.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nProblems: 3,200\nLanguage: Albanian\nTopics:\nlet√´rsi shqiptare: 47\npoezi shqiptare: 45\nproza shqiptare: 48\ndrama shqiptare: 46\nautor√´ shqiptar√´: 48\nveprat kryesore‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LTS-VVE/linguistic_sq.","url":"https://huggingface.co/datasets/LTS-VVE/linguistic_sq","creator_name":"LTS","creator_url":"https://huggingface.co/LTS-VVE","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Albanian","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"rudevices","keyword":"speech","description":"\n\t\n\t\t\n\t\tüìä –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞—É–¥–∏–æ-–¥–∞—Ç–∞—Å–µ—Ç–æ–≤\n\t\n\n\n\t\n\t\t\n\t\tüìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Å–µ–º –¥–∞—Ç–∞—Å–µ—Ç–∞–º\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–í—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤/—Å–∞–±—Å–µ—Ç–æ–≤\n2\n\n\n–í—Å–µ–≥–æ —Å–µ–º–ø–ª–æ–≤\n296,394\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n369.14 —á–∞—Å–æ–≤ (1328901.86 —Å–µ–∫—É–Ω–¥)\n\n\n–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–º–ø–ª–∞\n4.48 —Å–µ–∫—É–Ω–¥\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –¥–∞—Ç–∞—Å–µ—Ç–∞–º\n\t\n\nru_audiobooks_devices ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 68.5%\nrudevices_audio_records ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 31.5%\n\n\n\n\t\n\t\t\n\t\n\t\n\t\t–î–∞—Ç–∞—Å–µ—Ç: rudevices_audio_records‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sh1man/rudevices.","url":"https://huggingface.co/datasets/Sh1man/rudevices","creator_name":"dd","creator_url":"https://huggingface.co/Sh1man","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Russian","cc-by-4.0","100K - 1M","webdataset","Audio"],"keywords_longer_than_N":true},
	{"name":"mbspeech_mn","keyword":"speech","description":"\n\t\n\t\t\n\t\tMBSpeech MN: Mongolian Biblical Speech Dataset\n\t\n\nMBSpeech MN is a Mongolian text-to-speech (TTS) dataset derived from biblical texts. It consists of aligned audio recordings and corresponding sentences in Mongolian. The dataset is suitable for training TTS models and other speech processing applications.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n  Language: Mongolian (mn)\n  Task: Text-to-Speech (TTS)\n  License: MIT\n  Size:\n  Download size: ~721 MB\n\n  Dataset size: ~822 MB\n\n  Examples: 3,846‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/btsee/mbspeech_mn.","url":"https://huggingface.co/datasets/btsee/mbspeech_mn","creator_name":"Battseren Badral","creator_url":"https://huggingface.co/btsee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Mongolian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mbspeech_mn","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tMBSpeech MN: Mongolian Biblical Speech Dataset\n\t\n\nMBSpeech MN is a Mongolian text-to-speech (TTS) dataset derived from biblical texts. It consists of aligned audio recordings and corresponding sentences in Mongolian. The dataset is suitable for training TTS models and other speech processing applications.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n  Language: Mongolian (mn)\n  Task: Text-to-Speech (TTS)\n  License: MIT\n  Size:\n  Download size: ~721 MB\n\n  Dataset size: ~822 MB\n\n  Examples: 3,846‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/btsee/mbspeech_mn.","url":"https://huggingface.co/datasets/btsee/mbspeech_mn","creator_name":"Battseren Badral","creator_url":"https://huggingface.co/btsee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Mongolian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mbspeech_mn","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tMBSpeech MN: Mongolian Biblical Speech Dataset\n\t\n\nMBSpeech MN is a Mongolian text-to-speech (TTS) dataset derived from biblical texts. It consists of aligned audio recordings and corresponding sentences in Mongolian. The dataset is suitable for training TTS models and other speech processing applications.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n  Language: Mongolian (mn)\n  Task: Text-to-Speech (TTS)\n  License: MIT\n  Size:\n  Download size: ~721 MB\n\n  Dataset size: ~822 MB\n\n  Examples: 3,846‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/btsee/mbspeech_mn.","url":"https://huggingface.co/datasets/btsee/mbspeech_mn","creator_name":"Battseren Badral","creator_url":"https://huggingface.co/btsee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Mongolian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"YouTube-English","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tEnglish Audio Dataset from YouTube\n\t\n\nThis dataset contains English audio segments and creator uploaded transcripts (likely higher quality) extracted from various YouTube channels, along with corresponding transcript metadata. The data is intended for training automatic speech recognition (ASR) models.\n\n\t\n\t\t\n\t\tData Source and Processing\n\t\n\nThe data was obtained through the following process:\n\nDownload: Audio (.m4a) and available English subtitles (.srt for en, en.j3PyPqV-e1s) were‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OrcinusOrca/YouTube-English.","url":"https://huggingface.co/datasets/OrcinusOrca/YouTube-English","creator_name":"Orca","creator_url":"https://huggingface.co/OrcinusOrca","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","100K - 1M","webdataset"],"keywords_longer_than_N":true},
	{"name":"kmr-tatoeba","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tkmr-tatoeba\n\t\n\nThis dataset is a Tatoeba-based speech corpus for Northern Kurdish (Kurmanji).It contains only the test split and is intended for automatic speech recognition (ASR) and speech-to-text translation (S2TT) evaluation.\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\nLanguage: Northern Kurdish (Kurmanji) ‚Äî kmr\nSource: Sentences from the Tatoeba Project\nSplit: Test only\nSpeakers: ~30 native speakers\nContent:\naudio: recorded sentence (.wav, 48 kHz mono)\nspeaker: anonymized speaker ID (SHA-256 hash)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aranemini/kmr-tatoeba.","url":"https://huggingface.co/datasets/aranemini/kmr-tatoeba","creator_name":"Aran Emini","creator_url":"https://huggingface.co/aranemini","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-text-to-text","Northern Kurdish","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Quran-Ayah-Corpus","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tQuran-Ayah-Corpus: A Multi-Reciter Arabic Quranic Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description:\n\t\n\nAyah-Corpus is a large-scale, multi-reciter Arabic speech dataset meticulously curated for Automatic Speech Recognition (ASR) tasks. It consists of high-quality audio recordings of Quranic verses (Ayahs) paired with their corresponding exact transcriptions. The audio is sourced from two primary repositories: Al-Quran.cloud and EveryAyah.com.\nThis dataset is specifically designed to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rabah2026/Quran-Ayah-Corpus.","url":"https://huggingface.co/datasets/rabah2026/Quran-Ayah-Corpus","creator_name":"M≈ô Ra√üah","creator_url":"https://huggingface.co/rabah2026","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"hate_speech_detection","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tIndonesian Hate Speech Detection Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 13,169 Indonesian tweets annotated for hate speech detection and abusive language classification. The dataset provides comprehensive multi-label annotations covering different types of hate speech, target categories, and intensity levels, making it valuable for building robust content moderation systems for Indonesian social media.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nTotal Samples: 13,169 Indonesian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nahiar/hate_speech_detection.","url":"https://huggingface.co/datasets/nahiar/hate_speech_detection","creator_name":"Raihan Hidayatullah Djunaedi","creator_url":"https://huggingface.co/nahiar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Indonesian","mit","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"SloPalSpeech","keyword":"speech","description":"\n\t\n\t\t\n\t\tSloPalSpeech\n\t\n\nThis dataset contains aligned and segmented Slovak speech‚Äìtext pairs sourced from official plenary session recordings of the Slovak National Council (N√°rodn√° rada Slovenskej republiky).It was prepared by collecting raw audio from MediaPort√°l NR SR and matching it with official full-text transcripts from the Joint Czech and Slovak Digital Parliamentary Library.A custom alignment and filtering pipeline segmented the recordings into short clips (‚â§30 seconds) with their‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/erikbozik/SloPalSpeech.","url":"https://huggingface.co/datasets/erikbozik/SloPalSpeech","creator_name":"Erik","creator_url":"https://huggingface.co/erikbozik","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Slovak","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"SloPalSpeech","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSloPalSpeech\n\t\n\nThis dataset contains aligned and segmented Slovak speech‚Äìtext pairs sourced from official plenary session recordings of the Slovak National Council (N√°rodn√° rada Slovenskej republiky).It was prepared by collecting raw audio from MediaPort√°l NR SR and matching it with official full-text transcripts from the Joint Czech and Slovak Digital Parliamentary Library.A custom alignment and filtering pipeline segmented the recordings into short clips (‚â§30 seconds) with their‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/erikbozik/SloPalSpeech.","url":"https://huggingface.co/datasets/erikbozik/SloPalSpeech","creator_name":"Erik","creator_url":"https://huggingface.co/erikbozik","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Slovak","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"zuhri","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tZuhri ‚Äî Urdu G2P Dataset\n\t\n\nZuhri is a comprehensive and manually verified Urdu Grapheme-to-Phoneme (G2P) dataset. It is designed to aid research and development in areas such as speech synthesis, pronunciation modeling, and computational linguistics, specifically for the Urdu language.\nThis dataset provides accurate phoneme transcriptions and IPA representations, making it ideal for use in building high-quality TTS (Text-to-Speech), ASR (Automatic Speech Recognition), and other‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/humair025/zuhri.","url":"https://huggingface.co/datasets/humair025/zuhri","creator_name":"Humair M","creator_url":"https://huggingface.co/humair025","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-audio","text-to-speech","Urdu","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"tts-french-dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tüá´üá∑ French TTS Dataset\n\t\n\nThis dataset contains French speech audio paired with clean transcriptions, intended for training text-to-speech models such as Spark-TTS or Coqui TTS.\n\n\t\n\t\t\n\t\tüìÅ Contents\n\t\n\n\ndataset.parquet ‚Äî metadata file with audio paths, transcriptions, speaker info\nAudio/ ‚Äî directory of all .wav files used for training\n\n\n\t\n\t\t\n\t\tüìä Dataset Structure\n\t\n\nThe dataset.parquet file includes the following columns:\n\n\t\n\t\t\nColumn\nDescription\n\n\n\t\t\naudio\nPath to .wav file\n\n\ntext‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Buck26/tts-french-dataset.","url":"https://huggingface.co/datasets/Buck26/tts-french-dataset","creator_name":"Mwila Bwalya David","creator_url":"https://huggingface.co/Buck26","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","crowdsourced","monolingual","French","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"minds14","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tMInDS-14\n\t\n\nMINDS-14 is training and evaluation resource for intent detection task with spoken data. It covers 14 \nintents extracted from a commercial system in the e-banking domain, associated with spoken examples in 14 diverse language varieties.\n\n\t\n\t\t\n\t\tExample\n\t\n\nMInDS-14 can be downloaded and used as follows:\nfrom datasets import load_dataset\n\nminds_14 = load_dataset(\"PolyAI/minds14\", \"fr-FR\") # for French\n# to download all data for multi-lingual fine-tuning uncomment following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PolyAI/minds14.","url":"https://huggingface.co/datasets/PolyAI/minds14","creator_name":"PolyAI","creator_url":"https://huggingface.co/PolyAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","keyword-spotting","expert-generated","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"TIE_shorts","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for TIE_Shorts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTIE_shorts is a derived version of the Technical Indian English (TIE) dataset, a large-scale speech dataset (~ 8K hours) originally consisting of approximately 750 GB of content \nsourced from the NPTEL platform. The original TIE dataset contains around 9.8K technical lectures in English delivered by instructors from various regions across India, \nwith each lecture averaging about 50 minutes. These lectures cover a wide range of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/raianand/TIE_shorts.","url":"https://huggingface.co/datasets/raianand/TIE_shorts","creator_name":"Anand Rai","creator_url":"https://huggingface.co/raianand","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"minds14","keyword":"speech-recognition","description":"\n\t\n\t\t\n\t\tMInDS-14\n\t\n\nMINDS-14 is training and evaluation resource for intent detection task with spoken data. It covers 14 \nintents extracted from a commercial system in the e-banking domain, associated with spoken examples in 14 diverse language varieties.\n\n\t\n\t\t\n\t\tExample\n\t\n\nMInDS-14 can be downloaded and used as follows:\nfrom datasets import load_dataset\n\nminds_14 = load_dataset(\"PolyAI/minds14\", \"fr-FR\") # for French\n# to download all data for multi-lingual fine-tuning uncomment following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PolyAI/minds14.","url":"https://huggingface.co/datasets/PolyAI/minds14","creator_name":"PolyAI","creator_url":"https://huggingface.co/PolyAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","keyword-spotting","expert-generated","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"voxtream-train-9k","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tModel Card for VoXtream training dataset\n\t\n\nThis repository contains a training dataset for VoXtream TTS model.\nThe dataset contains 9k hours:\n\n4.5k hours sampled from Emilia dataset. We applied additional diarization to remove multi-speaker utterances and discarded utterances with invalid automatic transcripts. We also used NISQA model to remove low-quality utterances.\n4.5k hours sampled from HiFiTTS2 dataset (22 kHz subset). We selected only single-speaker utterances and filtered the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/herimor/voxtream-train-9k.","url":"https://huggingface.co/datasets/herimor/voxtream-train-9k","creator_name":"Nikita Torgashov","creator_url":"https://huggingface.co/herimor","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","arxiv:2509.15969","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"voxtream-train-9k","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tModel Card for VoXtream training dataset\n\t\n\nThis repository contains a training dataset for VoXtream TTS model.\nThe dataset contains 9k hours:\n\n4.5k hours sampled from Emilia dataset. We applied additional diarization to remove multi-speaker utterances and discarded utterances with invalid automatic transcripts. We also used NISQA model to remove low-quality utterances.\n4.5k hours sampled from HiFiTTS2 dataset (22 kHz subset). We selected only single-speaker utterances and filtered the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/herimor/voxtream-train-9k.","url":"https://huggingface.co/datasets/herimor/voxtream-train-9k","creator_name":"Nikita Torgashov","creator_url":"https://huggingface.co/herimor","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","arxiv:2509.15969","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"tts-french-dataset","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tüá´üá∑ French TTS Dataset\n\t\n\nThis dataset contains French speech audio paired with clean transcriptions, intended for training text-to-speech models such as Spark-TTS or Coqui TTS.\n\n\t\n\t\t\n\t\tüìÅ Contents\n\t\n\n\ndataset.parquet ‚Äî metadata file with audio paths, transcriptions, speaker info\nAudio/ ‚Äî directory of all .wav files used for training\n\n\n\t\n\t\t\n\t\tüìä Dataset Structure\n\t\n\nThe dataset.parquet file includes the following columns:\n\n\t\n\t\t\nColumn\nDescription\n\n\n\t\t\naudio\nPath to .wav file\n\n\ntext‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Buck26/tts-french-dataset.","url":"https://huggingface.co/datasets/Buck26/tts-french-dataset","creator_name":"Mwila Bwalya David","creator_url":"https://huggingface.co/Buck26","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","crowdsourced","monolingual","French","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"TIE_shorts","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for TIE_Shorts\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTIE_shorts is a derived version of the Technical Indian English (TIE) dataset, a large-scale speech dataset (~ 8K hours) originally consisting of approximately 750 GB of content \nsourced from the NPTEL platform. The original TIE dataset contains around 9.8K technical lectures in English delivered by instructors from various regions across India, \nwith each lecture averaging about 50 minutes. These lectures cover a wide range of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/raianand/TIE_shorts.","url":"https://huggingface.co/datasets/raianand/TIE_shorts","creator_name":"Anand Rai","creator_url":"https://huggingface.co/raianand","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"tr-full-dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tTR-Full_dataset\n\t\n\nThis is a merged speech dataset containing 41427 audio segments from 88 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 41427\nSpeakers: 222\nLanguages: tr\nEmotions: neutral, angry, sad, happy\nOriginal Datasets: 88\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/tr-full-dataset.","url":"https://huggingface.co/datasets/Codyfederer/tr-full-dataset","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"escagleu-64k","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for escagleu-64K corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nescagleu-64k is a parallel corpus comprising 64091 sentences translated among Spanish, Catalan, Valencian Catalan, Galician, and Basque.\nThe original sentences are in Spanish and come from the Spanish Common Voice Corpus.\nWe prepared this corpus with the aim of creating a parallel speech dataset among these languages using the Common Voice platform between the frame of the project Ilenia.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/escagleu-64k.","url":"https://huggingface.co/datasets/projecte-aina/escagleu-64k","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","audio-to-audio","automatic-speech-recognition","found","expert-generated"],"keywords_longer_than_N":true},
	{"name":"tr-full-dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTR-Full_dataset\n\t\n\nThis is a merged speech dataset containing 41427 audio segments from 88 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 41427\nSpeakers: 222\nLanguages: tr\nEmotions: neutral, angry, sad, happy\nOriginal Datasets: 88\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/tr-full-dataset.","url":"https://huggingface.co/datasets/Codyfederer/tr-full-dataset","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"ToneRuLS","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tToneRuLS\n\t\n\nToneRuLS ‚Äî –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è Russian LibriSpeech (RuLS). –í –¥–∞—Ç–∞—Å–µ—Ç–µ 91.36 —á–∞—Å–∞ –∞—É–¥–∏–æ –¥–ª—è train —Å–ø–ª–∏—Ç–∞ –∏ 6.87 —á–∞—Å–∞ –¥–ª—è validation.\n\n\n\t\n\t\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ\n\t\n\n–î–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—É–¥–∏–æ—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã:\n\n–°—Å—ã–ª–∫–∞ –Ω–∞ Wav-—Ñ–∞–π–ª (audio)\n–¢–µ–∫—Å—Ç–æ–≤–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ (text)\n–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (text_with_preprocessing) - —Ç–µ–∫—Å—Ç —Å —É–±—Ä–∞–Ω–Ω–æ–π –ø—É–Ω–∫—Ç—É–∞—Ü–∏–µ–π –∏ –ø—Ä–∏–≤–µ–¥—ë–Ω–Ω—ã–π –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É\n\n\n\t\n\t\t\n\t\t–§–æ—Ä–º–∞—Ç –∑–∞–ø–∏—Å–∏ (JSON)\n\t\n\n{\n  \"audio\":           \"https://.../train/00001.wav\",\n  \"text\":            \"–ö–∞—Ä–ª‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneRuLS.","url":"https://huggingface.co/datasets/Vikhrmodels/ToneRuLS","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Russian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"tr-full-dataset","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tTR-Full_dataset\n\t\n\nThis is a merged speech dataset containing 41427 audio segments from 88 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 41427\nSpeakers: 222\nLanguages: tr\nEmotions: neutral, angry, sad, happy\nOriginal Datasets: 88\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/tr-full-dataset.","url":"https://huggingface.co/datasets/Codyfederer/tr-full-dataset","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"ToneRuLS","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tToneRuLS\n\t\n\nToneRuLS ‚Äî –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è Russian LibriSpeech (RuLS). –í –¥–∞—Ç–∞—Å–µ—Ç–µ 91.36 —á–∞—Å–∞ –∞—É–¥–∏–æ –¥–ª—è train —Å–ø–ª–∏—Ç–∞ –∏ 6.87 —á–∞—Å–∞ –¥–ª—è validation.\n\n\n\t\n\t\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ\n\t\n\n–î–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—É–¥–∏–æ—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã:\n\n–°—Å—ã–ª–∫–∞ –Ω–∞ Wav-—Ñ–∞–π–ª (audio)\n–¢–µ–∫—Å—Ç–æ–≤–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ (text)\n–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (text_with_preprocessing) - —Ç–µ–∫—Å—Ç —Å —É–±—Ä–∞–Ω–Ω–æ–π –ø—É–Ω–∫—Ç—É–∞—Ü–∏–µ–π –∏ –ø—Ä–∏–≤–µ–¥—ë–Ω–Ω—ã–π –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É\n\n\n\t\n\t\t\n\t\t–§–æ—Ä–º–∞—Ç –∑–∞–ø–∏—Å–∏ (JSON)\n\t\n\n{\n  \"audio\":           \"https://.../train/00001.wav\",\n  \"text\":            \"–ö–∞—Ä–ª‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneRuLS.","url":"https://huggingface.co/datasets/Vikhrmodels/ToneRuLS","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Russian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"opentts-oleksa","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tOpen Text-to-Speech voices for üá∫üá¶ Ukrainian\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { opentts-uk (Revision 32abc9c) },\n    year         = 2025,\n    url          = { https://huggingface.co/datasets/Yehor/opentts-uk },\n    doi          = { 10.57967/hf/4551 }‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/opentts-oleksa.","url":"https://huggingface.co/datasets/speech-uk/opentts-oleksa","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"emova-asr-tts-eval","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tEMOVA-ASR-TTS-Eval\n\t\n\n\n\n\nü§ó EMOVA-Models | ü§ó EMOVA-Datasets | ü§ó EMOVA-Demo \nüìÑ Paper | üåê Project-Page | üíª Github | üíª EMOVA-Speech-Tokenizer-Github\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-ASR-TTS-Eval is a dataset designed for evaluating the ASR and TTS performance of Omni-modal LLMs. It is derived from the test-clean set of the LibriSpeech dataset. This dataset is part of the EMOVA-Datasets collection. We extract the speech units using the EMOVA Speech Tokenizer.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThis‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-asr-tts-eval.","url":"https://huggingface.co/datasets/Emova-ollm/emova-asr-tts-eval","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"emova-asr-tts-eval","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tEMOVA-ASR-TTS-Eval\n\t\n\n\n\n\nü§ó EMOVA-Models | ü§ó EMOVA-Datasets | ü§ó EMOVA-Demo \nüìÑ Paper | üåê Project-Page | üíª Github | üíª EMOVA-Speech-Tokenizer-Github\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-ASR-TTS-Eval is a dataset designed for evaluating the ASR and TTS performance of Omni-modal LLMs. It is derived from the test-clean set of the LibriSpeech dataset. This dataset is part of the EMOVA-Datasets collection. We extract the speech units using the EMOVA Speech Tokenizer.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThis‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-asr-tts-eval.","url":"https://huggingface.co/datasets/Emova-ollm/emova-asr-tts-eval","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ga_multispeaker_audio_transcribed","keyword":"speech","description":"\n\t\n\t\t\n\t\tGa Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Ga Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Ga, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial Inclusion Speech Dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/ga_multispeaker_audio_transcribed.","url":"https://huggingface.co/datasets/michsethowusu/ga_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Irish","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ga_multispeaker_audio_transcribed","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tGa Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Ga Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Ga, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial Inclusion Speech Dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/ga_multispeaker_audio_transcribed.","url":"https://huggingface.co/datasets/michsethowusu/ga_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Irish","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"nepali_speech_to_text","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tNepali Speech-to-Text Dataset\n\t\n\nThis repository contains a dataset for Automatic Speech Recognition (ASR) in the Nepali language. The dataset is designed for supervised learning tasks and includes audio files along with their corresponding transcriptions. The audio samples have been collected from various open-source platforms and other publicly available sources on the internet.  \nEach audio file has an average length of 15 seconds and has been converted into a consistent WAV format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pujanpaudel/nepali_speech_to_text.","url":"https://huggingface.co/datasets/pujanpaudel/nepali_speech_to_text","creator_name":"Pujan Paudel","creator_url":"https://huggingface.co/pujanpaudel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Nepali","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"arabic-tts-wav-24k","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tArabic TTS WAV 24k Dataset\n\t\n\nA high-quality, open-source dataset for Arabic Text-to-Speech (TTS) research, containing paired audio and text samples from both male and female speakers. All audio is provided in 24kHz WAV format, with rich metadata and phonetic transcriptions.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is designed for training and evaluating neural TTS systems in Modern Standard Arabic. It includes:\n\nAudio: Clean, studio-quality WAV files at 24,000 Hz.\nText: Original Arabic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NeoBoy/arabic-tts-wav-24k.","url":"https://huggingface.co/datasets/NeoBoy/arabic-tts-wav-24k","creator_name":"Sharjeel Abid Butt","creator_url":"https://huggingface.co/NeoBoy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Arabic","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"makhuwa-trigrams-speech-text-parallel","keyword":"speech","description":"\n\t\n\t\t\n\t\tMakhuwa Trigrams Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 154253 parallel speech-text pairs for Makhuwa, a language spoken primarily in Mozambique. The dataset consists of audio recordings of trigram segments (3-word sequences) paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Makhuwa - vmw\nTask: Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/makhuwa-trigrams-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/makhuwa-trigrams-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Makhuwa"],"keywords_longer_than_N":true},
	{"name":"makhuwa-trigrams-speech-text-parallel","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tMakhuwa Trigrams Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 154253 parallel speech-text pairs for Makhuwa, a language spoken primarily in Mozambique. The dataset consists of audio recordings of trigram segments (3-word sequences) paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Makhuwa - vmw\nTask: Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/makhuwa-trigrams-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/makhuwa-trigrams-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Makhuwa"],"keywords_longer_than_N":true},
	{"name":"tatoeba_21-dec-2024","keyword":"linguistics","description":"I would recommend anyone to download the most recent version of the files directly from Tatoeba. \nSince the most recent version of the dataset on huggingface is already quite old, I uploaded today's versions of the Tatoeba sentences. I uploaded the full dataset, as well as some files for some individual languages that I happen to speak. Honorable mention to Gronings, language code gos.\nExample code to download the most recent version of the Tatoeba dataset:\nimport requests\n\nwith‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tom9358/tatoeba_21-dec-2024.","url":"https://huggingface.co/datasets/Tom9358/tatoeba_21-dec-2024","creator_name":"Tom","creator_url":"https://huggingface.co/Tom9358","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Dutch","English","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"mabama-v","keyword":"text-to-speech","description":"aztro/mabama-v dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/aztro/mabama-v","creator_name":"Jose Omar Vieyra","creator_url":"https://huggingface.co/aztro","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Spanish","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"makhuwa-trigrams-speech-text-parallel","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tMakhuwa Trigrams Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 154253 parallel speech-text pairs for Makhuwa, a language spoken primarily in Mozambique. The dataset consists of audio recordings of trigram segments (3-word sequences) paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Makhuwa - vmw\nTask: Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/makhuwa-trigrams-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/makhuwa-trigrams-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Makhuwa"],"keywords_longer_than_N":true},
	{"name":"Mycollection","keyword":"text-to-speech","description":"JMaeen25/Mycollection dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/JMaeen25/Mycollection","creator_name":"Jordan K. Maeen","creator_url":"https://huggingface.co/JMaeen25","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["table-question-answering","text-classification","token-classification","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"SINE","keyword":"speech","description":"\n\t\n\t\t\n\t\tSINE Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Speech INfilling Edit (SINE) dataset is a comprehensive collection for speech deepfake detection and audio authenticity verification. This dataset contains ~87GB of audio data distributed across 32 splits, featuring both authentic and synthetically manipulated speech samples.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Size: ~87GB\nNumber of Splits: 32 (split-0.tar.gz to split-31.tar.gz)\nAudio Format: WAV files\nSource: Speech edited from LibriLight‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PeacefulData/SINE.","url":"https://huggingface.co/datasets/PeacefulData/SINE","creator_name":"Peaceful Data","creator_url":"https://huggingface.co/PeacefulData","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"common_voice_21.0_br","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nPartie en breton du jeu de donn√©es Common Voice 21.0.  \n\n\t\n\t\t\n\t\tChamps\n\t\n\n\naudio (dict) : Un dictionnaire contenant le chemin vers le fichier audio t√©l√©charg√©, l'audio d√©cod√© et la fr√©quence d'√©chantillonnage.Notez que lors de l'acc√®s √† la colonne audio : dataset[0][\"audio\"], le fichier audio est automatiquement d√©cod√© et r√©√©chantillonn√© √† dataset.features[\"audio\"].sampling_rate. Le d√©codage et le r√©√©chantillonnage d'un grand nombre de fichiers audio peuvent prendre‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bretagne/common_voice_21.0_br.","url":"https://huggingface.co/datasets/Bretagne/common_voice_21.0_br","creator_name":"Bretagne","creator_url":"https://huggingface.co/Bretagne","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Breton","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Common_Voice_Corpus_22_0_Urdu","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tCommon Voice Corpus 22.0 - Urdu\n\t\n\nThis dataset contains the Urdu subset of the Mozilla Common Voice 22.0 corpus, released in June 2025.It consists of crowdsourced speech recordings and their corresponding text transcriptions, collected to support open-source speech technology.\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Common Voice Corpus 22.0 Urdu dataset provides high-quality speech data for automatic speech recognition (ASR), speaker identification, and linguistic research in Urdu.It includes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/azeem-ahmed/Common_Voice_Corpus_22_0_Urdu.","url":"https://huggingface.co/datasets/azeem-ahmed/Common_Voice_Corpus_22_0_Urdu","creator_name":"Azeem Ahmed","creator_url":"https://huggingface.co/azeem-ahmed","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Urdu","cc0-1.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"MLDSUM_NEW","keyword":"automatic-speech-recognition","description":"sandylolpotty/MLDSUM_NEW dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sandylolpotty/MLDSUM_NEW","creator_name":"sandeep","creator_url":"https://huggingface.co/sandylolpotty","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"tweet_sentiment_multilingual","keyword":"hate-speech-detection","description":"\n  TweetSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA multilingual Sentiment Analysis dataset consisting of tweets in 8 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReferencehttps://aclanthology.org/2022.lrec-1.27\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"TweetSentimentClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/tweet_sentiment_multilingual.","url":"https://huggingface.co/datasets/mteb/tweet_sentiment_multilingual","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"MLDSUM_NEW","keyword":"text-to-speech","description":"sandylolpotty/MLDSUM_NEW dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sandylolpotty/MLDSUM_NEW","creator_name":"sandeep","creator_url":"https://huggingface.co/sandylolpotty","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"ai_hub_summ_train","keyword":"speech","description":"jr-d-analyst24/ai_hub_summ_train dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/jr-d-analyst24/ai_hub_summ_train","creator_name":"dayoungyoun","creator_url":"https://huggingface.co/jr-d-analyst24","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Korean","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"new_data","keyword":"automatic-speech-recognition","description":"Beehzod/new_data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Beehzod/new_data","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"ALFFA-Swahili-News","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tALFFA Swahili News\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe ALFFA Swahili News dataset is a speech corpus designed for automatic speech recognition (ASR) research in Swahili, an under-resourced African language. This dataset is part of the ALFFA (African Languages in the Field: speech Fundamentals and Automation) project and contains approximately 11.8 hours of broadcast news audio from Radio France International's Swahili service, recorded between November 2010 and March 2011.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nickdee96/ALFFA-Swahili-News.","url":"https://huggingface.co/datasets/nickdee96/ALFFA-Swahili-News","creator_name":"Nick Mumero Mwangi","creator_url":"https://huggingface.co/nickdee96","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","audio-classification","speaker-identification","audio-language-identification"],"keywords_longer_than_N":true},
	{"name":"syntetic_necoarc_rus","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞\n\t\n\n–≠—Ç–æ—Ç –¥–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –∞—É–¥–∏–æ–∑–∞–ø–∏—Å–∏ —Ä—É—Å—Å–∫–æ–π —Ä–µ—á–∏, –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ RVC (Retrieval-based Voice Conversion) NecoArc. –î–∞—Ç–∞—Å–µ—Ç –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π —Å–∏–Ω—Ç–µ–∑–∞ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.\n–Ø –Ω–µ –æ—Å–∏–ª–∏–ª —Ñ–∞–π–Ω—Ç—é–Ω TTS –º–æ–¥–µ–ª–∏ –ª–µ–≥–∫–æ–≤–µ—Å–Ω–æ–π , —Ç–∞–∫ —á—Ç–æ –µ—Å–ª–∏ —Å–º–æ–∂–µ—Ç–µ —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ –±—É–¥—É –±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω –∑–∞ –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å\n\n–Ø–∑—ã–∫: –†—É—Å—Å–∫–∏–π\n–õ–∏—Ü–µ–Ω–∑–∏—è: MIT\n\n\n\t\n\t\t\n\t\n\t\n\t\t–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n\t\n\n–î–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ª–µ–¥—É—é—â–∏–µ –ø–æ–ª—è:\n\ntext‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kostya165/syntetic_necoarc_rus.","url":"https://huggingface.co/datasets/Kostya165/syntetic_necoarc_rus","creator_name":"pleroma_cascade","creator_url":"https://huggingface.co/Kostya165","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"ALFFA-Swahili-News","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tALFFA Swahili News\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe ALFFA Swahili News dataset is a speech corpus designed for automatic speech recognition (ASR) research in Swahili, an under-resourced African language. This dataset is part of the ALFFA (African Languages in the Field: speech Fundamentals and Automation) project and contains approximately 11.8 hours of broadcast news audio from Radio France International's Swahili service, recorded between November 2010 and March 2011.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nickdee96/ALFFA-Swahili-News.","url":"https://huggingface.co/datasets/nickdee96/ALFFA-Swahili-News","creator_name":"Nick Mumero Mwangi","creator_url":"https://huggingface.co/nickdee96","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","audio-classification","speaker-identification","audio-language-identification"],"keywords_longer_than_N":true},
	{"name":"nchlt_speech_ven","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tNCHLT Speech Corpus -- Tshivenda\n\t\n\nThis is the Tshivenda language part of the NCHLT Speech Corpus of the South African languages.\nLanguage code (ISO 639): ven\nURI: https://hdl.handle.net/20.500.12185/276\n\n\t\n\t\t\n\t\tLicence:\n\t\n\nCreative Commons Attribution 3.0 Unported License (CC BY 3.0): http://creativecommons.org/licenses/by/3.0/legalcode\n\n\t\n\t\t\n\t\tAttribution:\n\t\n\nThe Department of Arts and Culture of the government of the Republic of South Africa (DAC), Council for Scientific and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/danielshaps/nchlt_speech_ven.","url":"https://huggingface.co/datasets/danielshaps/nchlt_speech_ven","creator_name":"Daniel van Niekerk","creator_url":"https://huggingface.co/danielshaps","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Venda","cc-by-3.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"raw-speech-whispervq-v1","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset contains over 2,4M English ASR samples, using:\n\nThe a training set of parler-tts/mls_eng_10k\nTokenized using WhisperVQ.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset, Audio\n# Load Instruction Speech dataset\n\ndataset = load_dataset(\"homebrewltd/raw-speech-whispervq-v1\",split='train')\n\n\n\t\n\t\t\n\t\tDataset Fields\n\t\n\n\n\t\n\t\t\nField\nType\nDescription\n\n\n\t\t\ntokens\nsequence\nTokenized using Encodec\n\n\ntext\nsequence\nConverted audio tokens\n\n\n\t\n\n\n\t\n\t\t\n\t\tBias, Risks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Menlo/raw-speech-whispervq-v1.","url":"https://huggingface.co/datasets/Menlo/raw-speech-whispervq-v1","creator_name":"Menlo Research","creator_url":"https://huggingface.co/Menlo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"Vedavani-Dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tVedavani: A Benchmark Corpus for ASR on Vedic Sanskrit Poetry\n\t\n\nVedavani is the first benchmark dataset for automatic speech recognition (ASR) on Vedic Sanskrit poetry, consisting of richly annotated verses from the Rig Veda and Atharva Veda. This corpus captures the unique prosodic structure, phonetic complexity, and chanting style found in traditional Vedic recitation.\nüîó Paper: Vedavani: A Benchmark Corpus for ASR on Vedic Sanskrit Poetry (ACL 2025)üìÅ GitHub Repository:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sanganaka/Vedavani-Dataset.","url":"https://huggingface.co/datasets/sanganaka/Vedavani-Dataset","creator_name":"Sanganaka, IIT Kharagpur","creator_url":"https://huggingface.co/sanganaka","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","monolingual","Sanskrit","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Vedavani-Dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tVedavani: A Benchmark Corpus for ASR on Vedic Sanskrit Poetry\n\t\n\nVedavani is the first benchmark dataset for automatic speech recognition (ASR) on Vedic Sanskrit poetry, consisting of richly annotated verses from the Rig Veda and Atharva Veda. This corpus captures the unique prosodic structure, phonetic complexity, and chanting style found in traditional Vedic recitation.\nüîó Paper: Vedavani: A Benchmark Corpus for ASR on Vedic Sanskrit Poetry (ACL 2025)üìÅ GitHub Repository:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sanganaka/Vedavani-Dataset.","url":"https://huggingface.co/datasets/sanganaka/Vedavani-Dataset","creator_name":"Sanganaka, IIT Kharagpur","creator_url":"https://huggingface.co/sanganaka","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","monolingual","Sanskrit","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Vedavani-Dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tVedavani: A Benchmark Corpus for ASR on Vedic Sanskrit Poetry\n\t\n\nVedavani is the first benchmark dataset for automatic speech recognition (ASR) on Vedic Sanskrit poetry, consisting of richly annotated verses from the Rig Veda and Atharva Veda. This corpus captures the unique prosodic structure, phonetic complexity, and chanting style found in traditional Vedic recitation.\nüîó Paper: Vedavani: A Benchmark Corpus for ASR on Vedic Sanskrit Poetry (ACL 2025)üìÅ GitHub Repository:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sanganaka/Vedavani-Dataset.","url":"https://huggingface.co/datasets/sanganaka/Vedavani-Dataset","creator_name":"Sanganaka, IIT Kharagpur","creator_url":"https://huggingface.co/sanganaka","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","monolingual","Sanskrit","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Sentiment-Reasoning","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSentiment Reasoning for Healthcare\n\t\n\nACL 2025 Industry Track (Oral)\nKhai-Nguyen Nguyen*, Khai Le-Duc*, Bach Phan Tat, Duy Le, Long Vo-Dang, Truong-Son Hy\n\n*Equal contribution\n\n\nPlease press ‚≠ê button and/or cite papers if you feel helpful.\n\n\n  \n\nSentiment Reasoning pipeline\n\n\nPaper: Sentiment Reasoning for Healthcare\n\nCode: https://github.com/leduckhai/Sentiment-Reasoning\n\nAbstract:Transparency in AI healthcare decision-making is crucial. By incorporating rationales to explain reason‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/leduckhai/Sentiment-Reasoning.","url":"https://huggingface.co/datasets/leduckhai/Sentiment-Reasoning","creator_name":"Le Duc Khai","creator_url":"https://huggingface.co/leduckhai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","audio-classification","automatic-speech-recognition","audio-text-to-text"],"keywords_longer_than_N":true},
	{"name":"KurdishSentimentClassification","keyword":"hate-speech-detection","description":"\n  KurdishSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nKurdish Sentiment Dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://link.springer.com/article/10.1007/s10579-023-09716-6\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"KurdishSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/KurdishSentimentClassification.","url":"https://huggingface.co/datasets/mteb/KurdishSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"sdf_dataset_zh","keyword":"speech","description":"\n\t\n\t\t\n\t\tSpeechDialogueFactory Dataset\n\t\n\n\n\t\n\t\t\n\t\tBackground\n\t\n\nThis dataset is part of the SpeechDialogueFactory project, a comprehensive framework for generating high-quality speech dialogues at scale. Speech dialogue datasets are essential for developing and evaluating Speech-LLMs, but existing datasets face limitations including high collection costs, privacy concerns, and lack of conversational authenticity. This dataset addresses these challenges by providing synthetically generated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/minghanw/sdf_dataset_zh.","url":"https://huggingface.co/datasets/minghanw/sdf_dataset_zh","creator_name":"Minghan Wang","creator_url":"https://huggingface.co/minghanw","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-to-speech","audio-to-audio","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"filatov_24000","keyword":"text-to-speech","description":"patriotyk/filatov_24000 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/patriotyk/filatov_24000","creator_name":"Serhiy Stetskovych ","creator_url":"https://huggingface.co/patriotyk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"sdf_dataset_zh","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tSpeechDialogueFactory Dataset\n\t\n\n\n\t\n\t\t\n\t\tBackground\n\t\n\nThis dataset is part of the SpeechDialogueFactory project, a comprehensive framework for generating high-quality speech dialogues at scale. Speech dialogue datasets are essential for developing and evaluating Speech-LLMs, but existing datasets face limitations including high collection costs, privacy concerns, and lack of conversational authenticity. This dataset addresses these challenges by providing synthetically generated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/minghanw/sdf_dataset_zh.","url":"https://huggingface.co/datasets/minghanw/sdf_dataset_zh","creator_name":"Minghan Wang","creator_url":"https://huggingface.co/minghanw","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-to-speech","audio-to-audio","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"twi_dataset","keyword":"automatic-speech-recognition","description":"d3vnerd/twi_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/d3vnerd/twi_dataset","creator_name":"jeffery crentsil","creator_url":"https://huggingface.co/d3vnerd","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Twi","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Zeroth-STT-Korean","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tZeroth-STT-Korean Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is a shuffled version of the Zeroth-STT-Ko dataset.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nZeroth-Korean Dataset, created by [Lucas Jo(@Atlas Guide Inc.) and Wonkyum Lee(@Gridspace Inc.)], 2023.\nAvailable at https://github.com/goodatlas/zeroth under CC-BY-4.0 license.\nJunhoee/STT_Korean_Dataset_80000 Dataset, created by [Junhoee], 2024.\nAvailable at https://huggingface.co/datasets/Junhoee/STT_Korean_Dataset_80000\n","url":"https://huggingface.co/datasets/o0dimplz0o/Zeroth-STT-Korean","creator_name":"Michele Phan","creator_url":"https://huggingface.co/o0dimplz0o","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Korean","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"el-mal-el-halal-podcast-subtitles","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tEl Mal El Halal Podcast Subtitles\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEl Mal El Halal Podcast Subtitles is a collection of manual subtitles for 18 episodes of the El Mal El Halal podcast by Eng. Mohamed Aboulnaga, covering Arabic content. This dataset is designed for research on speech processing, translation, semantic search, and Arabic NLP.\n\nTotal episodes: 18 - untill the date of 03/08/2025\nTotal segments: 13‚ÄØ970\nTotal words: 166‚ÄØ505\nTotal duration: 20‚ÄØh‚ÄØ50‚ÄØm‚ÄØ56‚ÄØs (75‚ÄØ057‚ÄØs)\nAverage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hossam87/el-mal-el-halal-podcast-subtitles.","url":"https://huggingface.co/datasets/hossam87/el-mal-el-halal-podcast-subtitles","creator_name":"Hossam El-Kharbotly","creator_url":"https://huggingface.co/hossam87","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","sentence-similarity","text-to-speech","translation","text-classification"],"keywords_longer_than_N":true},
	{"name":"fluke","keyword":"linguistics","description":"\n\t\n\t\t\n\t\tFLUKE: A Task-Agnostic Framework for Linguistic Capability Testing\n\t\n\nPaper: FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness EvaluationDataset: huggingface.co/datasets/joey234/fluke\nAuthors: Yulia Otmakhova¬π*, Hung Thinh Truong¬π*, Rahmad Mahendra¬≤, Zenan Zhai¬≥, Rongxin Zhu¬π'¬≥, Daniel Beck¬≤, Jey Han Lau¬π\n¬πThe University of Melbourne, ¬≤RMIT University, ¬≥Oracle\n*Equal contribution\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nFLUKE (Framework for Linguistic Capability‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joey234/fluke.","url":"https://huggingface.co/datasets/joey234/fluke","creator_name":"Thinh Truong","creator_url":"https://huggingface.co/joey234","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","zero-shot-classification","English","mit"],"keywords_longer_than_N":true},
	{"name":"el-mal-el-halal-podcast-subtitles","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tEl Mal El Halal Podcast Subtitles\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEl Mal El Halal Podcast Subtitles is a collection of manual subtitles for 18 episodes of the El Mal El Halal podcast by Eng. Mohamed Aboulnaga, covering Arabic content. This dataset is designed for research on speech processing, translation, semantic search, and Arabic NLP.\n\nTotal episodes: 18 - untill the date of 03/08/2025\nTotal segments: 13‚ÄØ970\nTotal words: 166‚ÄØ505\nTotal duration: 20‚ÄØh‚ÄØ50‚ÄØm‚ÄØ56‚ÄØs (75‚ÄØ057‚ÄØs)\nAverage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hossam87/el-mal-el-halal-podcast-subtitles.","url":"https://huggingface.co/datasets/hossam87/el-mal-el-halal-podcast-subtitles","creator_name":"Hossam El-Kharbotly","creator_url":"https://huggingface.co/hossam87","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","sentence-similarity","text-to-speech","translation","text-classification"],"keywords_longer_than_N":true},
	{"name":"blab_long_audio","keyword":"speech","description":"\n\t\n\t\t\n\t\tBLAB: Brutally Long Audio Bench\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBrutally Long Audio Bench (BLAB) is a challenging long-form audio benchmark that evaluates audio LMs on localization, duration estimation, emotion, and counting tasks using audio segments averaging 51 minutes in length. BLAB consists of 833+ hours of diverse, full-length Youtube audio clips, each paired with human-annotated, text-based natural language questions and answers. Our audio data were collected from permissively‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oreva/blab_long_audio.","url":"https://huggingface.co/datasets/oreva/blab_long_audio","creator_name":"Orevaoghene Ahia","creator_url":"https://huggingface.co/oreva","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-text-to-text","original","cc-by-4.0","1K<n<10K","Audio"],"keywords_longer_than_N":true},
	{"name":"GLOBE_V3","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tImportant notice\n\t\n\nDifferences between V3 version and two previous versions (V1|V2):\n\nThis version is built base on Common Voice 21.0 English Subset.\n   This version only includes utterance that are an exact match with the transcription from Whisper V3 LARGE (CER == 0).\n   This version includes the original Common Voice metadata (age, gender, accent, and ID).\n   All audio files in this version are at 24kHz sampling rate.\n   All audio files in this version are unenhanced. (We‚Äôd greatly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE_V3.","url":"https://huggingface.co/datasets/MushanW/GLOBE_V3","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"yodas_owsmv4","keyword":"automatic-speech-recognition","description":"üèÜ News: Our OWSM v4 paper won the Best Student Paper Award at INTERSPEECH 2025!\n\n\t\n\t\t\n\t\tDataset Card for YODAS_OWSMv4\n\t\n\n\nPaper: OWSM v4: Improving Open Whisper-Style Speech Models via Data Scaling and Cleaning (Best Student Paper at INTERSPEECH 2025)\nAuthors: Yifan Peng, Muhammad Shakeel, Yui Sudo, William Chen, Jinchuan Tian, Chyi-Jiunn Lin, Shinji Watanabe\n\n\nData Cleaning Scripts: ESPnet\nModel Demo: Gradio\n\n\n\t\n\t\n\t\n\t\tDataset Description\n\t\n\nOpen Whisper-style Speech Model (OWSM)is the first‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/espnet/yodas_owsmv4.","url":"https://huggingface.co/datasets/espnet/yodas_owsmv4","creator_name":"ESPnet","creator_url":"https://huggingface.co/espnet","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","cc-by-3.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"ESpeech-buldjat","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tBuldjat YouTube Audio Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 54 hours of processed audio segments extracted from the \"Buldjat\" YouTube channel with corresponding metadata. Each audio file represents a segment from the channel's videos and content, processed at 44.1kHz sample rate.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Russian\nTask: TTS, ASR, Quality Assessment\nAudio format: MP3, 44.1kHz sample rate\nStructure: Segmented audio files with JSON metadata\nSource:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ESpeech/ESpeech-buldjat.","url":"https://huggingface.co/datasets/ESpeech/ESpeech-buldjat","creator_name":"Ebany Speech","creator_url":"https://huggingface.co/ESpeech","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Russian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ESpeech-buldjat","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tBuldjat YouTube Audio Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 54 hours of processed audio segments extracted from the \"Buldjat\" YouTube channel with corresponding metadata. Each audio file represents a segment from the channel's videos and content, processed at 44.1kHz sample rate.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Russian\nTask: TTS, ASR, Quality Assessment\nAudio format: MP3, 44.1kHz sample rate\nStructure: Segmented audio files with JSON metadata\nSource:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ESpeech/ESpeech-buldjat.","url":"https://huggingface.co/datasets/ESpeech/ESpeech-buldjat","creator_name":"Ebany Speech","creator_url":"https://huggingface.co/ESpeech","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Russian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"recitation-segmentation","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tRecitation Segmentation Dataset for Holy Quran Pronunciation Error Detection\n\t\n\nThis dataset is used for building models that segment Holy Quran recitations based on pause points (waqf) with high accuracy. The segments are crucial for tasks like Automatic Pronunciation Error Detection and Correction, leveraging the rigorous recitation rules (tajweed) of the Holy Quran.\nThe dataset was presented in the paper Automatic Pronunciation Error Detection and Correction of the Holy Quran's‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/obadx/recitation-segmentation.","url":"https://huggingface.co/datasets/obadx/recitation-segmentation","creator_name":"Abdullah","creator_url":"https://huggingface.co/obadx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Mitakihara-DeepSeek-R1-0528","keyword":"linguistics","description":"Click here to support our open-source dataset and model releases!\nMitakihara-DeepSeek-R1-0528 is a dataset focused on artificial intelligence, testing the limits of DeepSeek R1 0528's AI-reasoning skills!\nThis dataset contains:\n\n16.9k synthetically generated prompts about AI, with all responses generated using DeepSeek R1 0528.\nSubjects include computer science, artificial intelligence, MLOps, LLMs and diffusion models, math and CUDA, cutting-edge and future technologies, complex adaptive and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Mitakihara-DeepSeek-R1-0528.","url":"https://huggingface.co/datasets/sequelbox/Mitakihara-DeepSeek-R1-0528","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"elcc","keyword":"linguistics","description":"\n\t\n\t\t\n\t\n\t\n\t\tELCC\n\t\n\nThe Emergent Language Corpus Collection is collection of corpora and metadata\nfrom a variety of emergent communication simulations.\n\n\t\n\t\t\n\t\n\t\n\t\tUsing ELCC\n\t\n\nYou can clone this repository with git LFS and use the data directly or load\nthe data via the mlcroissant library.  To install the mlcroissant library and\nnecessary dependencies, see the conda environment at util/environment.yml.\nBelow we show an example of loading ELCC's data via mlcroissant.\nimport mlcroissant as mlc‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bboldt/elcc.","url":"https://huggingface.co/datasets/bboldt/elcc","creator_name":"Brendon Boldt","creator_url":"https://huggingface.co/bboldt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["cc-by-4.0","10M<n<100M","arxiv:2407.04158","doi:10.57967/hf/2533","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part004","keyword":"speech","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 4 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 4 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part004.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part004","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part004","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 4 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 4 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part004.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part004","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"librispeech-alignments_clean100","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tlibrispeech-alignments_clean100\n\t\n\nThis is a subset of librispeech-alignments (https://huggingface.co/datasets/gilkeyio/librispeech-alignments) which only includes train_clean_100 and test_clean splits for small experiments and tutorials.\nCite:\n@inproceedings{panayotov2015librispeech,  \n  title={Librispeech: an ASR corpus based on public domain audio books},\n  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},  \n  booktitle={ICASSP},   \n  year={2015}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ErfanAShams/librispeech-alignments_clean100.","url":"https://huggingface.co/datasets/ErfanAShams/librispeech-alignments_clean100","creator_name":"Erfan Shams","creator_url":"https://huggingface.co/ErfanAShams","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part004","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 4 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 4 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part004.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part004","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"BibleMMS","keyword":"text-to-speech","description":"The Dataset associated with the Paper \"Meta Learning Text-to-Speech Synthesis in over 7000 Languages\" by Florian Lux, Sarina Meyer, Lyonel Behringer, Frank Zalkow, Phat Do, Matt Coler, Emanu√´l A. P. Habets and Ngoc Thang Vu (Interspeech 2024).\nWe generate 2000 spoken utterances per language using the subsets of the eBible dataset [1] that are under free licenses as the text input to the MMS TTS models [2]. \nThe languages associated with the following ISO-639-3 codes are represented in this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Flux9665/BibleMMS.","url":"https://huggingface.co/datasets/Flux9665/BibleMMS","creator_name":"Florian Lux","creator_url":"https://huggingface.co/Flux9665","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","mit","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"tts-hindi-stts2","keyword":"text-to-speech","description":"SachinTelecmi/tts-hindi-stts2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/SachinTelecmi/tts-hindi-stts2","creator_name":"Sachin Mohanty","creator_url":"https://huggingface.co/SachinTelecmi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Hindi","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"uz-data","keyword":"automatic-speech-recognition","description":"Beehzod/uz-data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Beehzod/uz-data","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"tatar-speech-commands","keyword":"speech","description":"\n\t\n\t\t\n\t\tAn Open-Source Tatar Speech Commands Dataset\n\t\n\nPaper: Paper\nAn Open-Source Tatar Speech Commands Dataset for IoT and Robotics Applications\nGitHub: https://github.com/IS2AI/TatarSCR\nDescription:\nThe dataset covers 35 commands used in robotics, IoT, and smart systems. In total, the dataset contains 3,547 one-second utterances from 153 people. The utterances were saved in the WAV format with a sampling rate of 16 kHz. \nCitation: The project was developed in academic collaboration between‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/tatar-speech-commands.","url":"https://huggingface.co/datasets/issai/tatar-speech-commands","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Tatar","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"casablanca","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tCasablanca Evaluation Dataset\n\t\n\nThis is a processed version of the UBC-NLP/Casablanca dataset, optimized for evaluation purposes.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset maintains the same structure as the original Casablanca dataset, with each country as a separate configuration. The main difference is that audio files are referenced by paths instead of being embedded in the dataset.\n\n\t\n\t\t\n\t\tDataset Configurations\n\t\n\nThe dataset has 8 configurations, one for each country:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tii-audio/casablanca.","url":"https://huggingface.co/datasets/tii-audio/casablanca","creator_name":"TII Audio","creator_url":"https://huggingface.co/tii-audio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"casablanca","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tCasablanca Evaluation Dataset\n\t\n\nThis is a processed version of the UBC-NLP/Casablanca dataset, optimized for evaluation purposes.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset maintains the same structure as the original Casablanca dataset, with each country as a separate configuration. The main difference is that audio files are referenced by paths instead of being embedded in the dataset.\n\n\t\n\t\t\n\t\tDataset Configurations\n\t\n\nThe dataset has 8 configurations, one for each country:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tii-audio/casablanca.","url":"https://huggingface.co/datasets/tii-audio/casablanca","creator_name":"TII Audio","creator_url":"https://huggingface.co/tii-audio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"YouTube_Video_Transkriptleri_TR","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of nearly 5 hours of video from over 40 Creative Commons-licensed videos on YouTube. The videos contain the voices of more than 100 different people. The audio files have been resampled to 16 kHz. The videos have been divided into chunks of up to 25 seconds. This dataset is intended for developing Turkish STT (Speech-to-Text) models.\n\n\t\n\t\t\n\t\tDatasets Preparetion\n\t\n\nThe audio files and transcript data were scraped from YouTube. The scraped‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Anilosan15/YouTube_Video_Transkriptleri_TR.","url":"https://huggingface.co/datasets/Anilosan15/YouTube_Video_Transkriptleri_TR","creator_name":"H√ºseyin Anƒ±l √áakmak","creator_url":"https://huggingface.co/Anilosan15","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Turkish","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"AfriSentiClassification","keyword":"hate-speech-detection","description":"\n  AfriSentiClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAfriSenti is the largest sentiment analysis dataset for under-represented African languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReferencehttps://arxiv.org/abs/2302.08956\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AfriSentiClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AfriSentiClassification.","url":"https://huggingface.co/datasets/mteb/AfriSentiClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_3k","keyword":"speech","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (3k)\n\t\n\nThis dataset contains 6000 synthetic speech recordings in the Pashto language,\nwith 3000 male voice recordings and 3000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 3000 sentences\nTotal Recordings: 6000 audio files (3000 male + 3000 female)\nAudio Format: WAV, 44.1kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 44.1kHz (44100‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_3k.","url":"https://huggingface.co/datasets/ihanif/pashto_speech_3k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_3k","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (3k)\n\t\n\nThis dataset contains 6000 synthetic speech recordings in the Pashto language,\nwith 3000 male voice recordings and 3000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 3000 sentences\nTotal Recordings: 6000 audio files (3000 male + 3000 female)\nAudio Format: WAV, 44.1kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 44.1kHz (44100‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_3k.","url":"https://huggingface.co/datasets/ihanif/pashto_speech_3k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MMMG","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for MMMG\n\t\n\n\nWe present MMMG, a comprehensive and human-aligned benchmark for multimodal generation across 4 modality combinations (image, audio, interleaved text and image, interleaved text and audio), with a focus on tasks that present significant challenges for generation models, while still enabling reliable automatic evaluation. \nThis huggingface page only contains the raw dataset of MMMG, for full evaluation suite, please refer to our github page:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UW-FMRL2/MMMG.","url":"https://huggingface.co/datasets/UW-FMRL2/MMMG","creator_name":"Foundation Model and RL Research Lab @ UW","creator_url":"https://huggingface.co/UW-FMRL2","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-audio","text-to-image","text-to-speech","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"audio-dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tAudio Transcription Dataset\n\t\n\nThis dataset contains 99 audio recordings with their corresponding transcriptions for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset includes:\n\nAudio files: High-quality voice recordings (.wav format)\nTranscriptions: Accurate text transcriptions of the spoken content\nProper Audio feature type: Ready for model training (not just file paths!)\n\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal samples: 99\nAudio format: WAV files at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aashish17405/audio-dataset.","url":"https://huggingface.co/datasets/Aashish17405/audio-dataset","creator_name":"Jaini Aashish","creator_url":"https://huggingface.co/Aashish17405","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Laurie-Ann-Walden","keyword":"speech","description":"\n\t\n\t\t\n\t\tAudio Dataset for ASR\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio recordings with corresponding transcriptions for Automatic Speech Recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal samples: 3529\nTrain samples: 2823\nValidation samples: 706\nAudio format: WAV, 16kHz, mono\nLanguage: Indonesian (adjust as needed)\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n{\n    'id': str,\n    'audio': Audio(sampling_rate=16000),\n    'text': str,\n    'text_cleaned': str\n}\n\n\n\t\n\t\t\n\t\tUsage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ngademin/Laurie-Ann-Walden.","url":"https://huggingface.co/datasets/ngademin/Laurie-Ann-Walden","creator_name":"Fajar M","creator_url":"https://huggingface.co/ngademin","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Indonesian","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"audio-dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tAudio Transcription Dataset\n\t\n\nThis dataset contains 99 audio recordings with their corresponding transcriptions for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset includes:\n\nAudio files: High-quality voice recordings (.wav format)\nTranscriptions: Accurate text transcriptions of the spoken content\nProper Audio feature type: Ready for model training (not just file paths!)\n\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal samples: 99\nAudio format: WAV files at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aashish17405/audio-dataset.","url":"https://huggingface.co/datasets/Aashish17405/audio-dataset","creator_name":"Jaini Aashish","creator_url":"https://huggingface.co/Aashish17405","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Laurie-Ann-Walden","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tAudio Dataset for ASR\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio recordings with corresponding transcriptions for Automatic Speech Recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal samples: 3529\nTrain samples: 2823\nValidation samples: 706\nAudio format: WAV, 16kHz, mono\nLanguage: Indonesian (adjust as needed)\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n{\n    'id': str,\n    'audio': Audio(sampling_rate=16000),\n    'text': str,\n    'text_cleaned': str\n}\n\n\n\t\n\t\t\n\t\tUsage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ngademin/Laurie-Ann-Walden.","url":"https://huggingface.co/datasets/ngademin/Laurie-Ann-Walden","creator_name":"Fajar M","creator_url":"https://huggingface.co/ngademin","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Indonesian","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"farsi-asr-dataset","keyword":"automatic-speech-recognition","description":"\n\n\t\n\t\t\n\t\tFarsi ASR Dataset\n\t\n\nThe largest open-source Persian Automatic Speech Recognition (ASR) dataset, collected from various sources. The codes associated with the collection of this dataset is also available in the Farsi ASR Dataset GitHub repository.\n","url":"https://huggingface.co/datasets/farsi-asr/farsi-asr-dataset","creator_name":"Farsi ASR","creator_url":"https://huggingface.co/farsi-asr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","mit","1M<n<10M","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"TV-44kHz-Full","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tThe \"Thorsten-Voice\" dataset\n\t\n\nThis truly open source (CC0 license) german (üá©üá™) voice dataset contains about 40 hours of transcribed voice recordings by Thorsten M√ºller, \na single male, native speaker in over 38.000 wave files.\n\nMono\nSamplerate: 44.100Hz\nTrimmed silence at begin/end\nDenoised\nNormalized to -24dB\n\n\n\t\n\t\t\n\t\tDisclaimer\n\t\n\n\"Please keep in mind, I am not a professional speaker, just an open source speech technology enthusiast who donates his voice. I contribute my personal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Thorsten-Voice/TV-44kHz-Full.","url":"https://huggingface.co/datasets/Thorsten-Voice/TV-44kHz-Full","creator_name":"Thorsten M√ºller","creator_url":"https://huggingface.co/Thorsten-Voice","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","German","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ksponspeech-eval","keyword":"automatic-speech-recognition","description":"paper link: https://www.mdpi.com/846876\n","url":"https://huggingface.co/datasets/yfyeung/ksponspeech-eval","creator_name":"Yifan Yang","creator_url":"https://huggingface.co/yfyeung","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Korean","cc-by-4.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"ToxicChatClassification","keyword":"hate-speech-detection","description":"\n  ToxicChatClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset contains toxicity annotations on 10K user\n            prompts collected from the Vicuna online demo. We utilize a human-AI\n            collaborative annotation framework to guarantee the quality of annotation\n            while maintaining a feasible annotation workload. The details of data\n            collection, pre-processing, and annotation can be found in our paper.\n            We believe that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ToxicChatClassification.","url":"https://huggingface.co/datasets/mteb/ToxicChatClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"akuapem_multispeaker_audio_transcribed","keyword":"speech","description":"\n\t\n\t\t\n\t\tAkuapem Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Akuapem Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Akuapem Twi, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/akuapem_multispeaker_audio_transcribed.","url":"https://huggingface.co/datasets/michsethowusu/akuapem_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Twi","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"akuapem_multispeaker_audio_transcribed","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tAkuapem Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Akuapem Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Akuapem Twi, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/akuapem_multispeaker_audio_transcribed.","url":"https://huggingface.co/datasets/michsethowusu/akuapem_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Twi","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"babbling_kinova","keyword":"text-to-speech","description":"mvnagakishan/babbling_kinova dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/mvnagakishan/babbling_kinova","creator_name":"Venkata Naga Kishan Munjulury","creator_url":"https://huggingface.co/mvnagakishan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","text-classification","token-classification","table-question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"nchlt_speech_eng","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tNCHLT Speech Corpus -- South African English\n\t\n\nThis is the South African English language part of the NCHLT Speech Corpus of the South African languages.\nLanguage code (ISO 639): eng\nURI: https://hdl.handle.net/20.500.12185/274\n\n\t\n\t\t\n\t\tLicence:\n\t\n\nCreative Commons Attribution 3.0 Unported License (CC BY 3.0): http://creativecommons.org/licenses/by/3.0/legalcode\n\n\t\n\t\t\n\t\tAttribution:\n\t\n\nThe Department of Arts and Culture of the government of the Republic of South Africa (DAC), Council‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/danielshaps/nchlt_speech_eng.","url":"https://huggingface.co/datasets/danielshaps/nchlt_speech_eng","creator_name":"Daniel van Niekerk","creator_url":"https://huggingface.co/danielshaps","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-3.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"virc","keyword":"hate-speech","description":"\n\t\n\t\t\n\t\tVulnerable Identities Recognition Corpus (VIRC) for Hate Speech Analysis\n\t\n\nWelcome to the Vulnerable Identities Recognition Corpus (VIRC), a dataset created to enhance hate speech analysis in Italian and Spanish news headlines. VIRC provides annotated headlines aimed at identifying vulnerable identities, dangerous discourse, derogatory mentions, and entities. This corpus contributes to developing more sophisticated hate speech detection tools and policies for creating a safer online‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oeg/virc.","url":"https://huggingface.co/datasets/oeg/virc","creator_name":"Ontology Engineering Group","creator_url":"https://huggingface.co/oeg","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","text-classification","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"mosel","keyword":"speech","description":"\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel.","url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"vibravox","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for VibraVox\n\t\n\n\n  \n\n\n\nüëÄ While waiting for the TooBigContentError issue to be resolved by the HuggingFace team, you can explore the dataset viewer of vibravox-test\nwhich has exactly the same architecture.\n\n\t\n\t\t\n\t\n\t\n\t\tDATASET SUMMARY\n\t\n\nThe VibraVox dataset is a general purpose audio dataset of french speech captured with body-conduction transducers.\nThis dataset can be used for various audio machine learning tasks :\n\nAutomatic Speech Recognition (ASR) (Speech-to-Text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox.","url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"mosel","keyword":"automatic-speech-recognition","description":"\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel.","url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"nigerian_accented_english_dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Nigerian Accent English Speech Data 1.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Nigerian Accent Speech Data is a comprehensive dataset of about 8 hours of audio recordings featuring speakers from various regions of Nigeria, \ncapturing the rich diversity of Nigerian accents. This dataset is specifically curated to address the gap in speech and language \ndatasets for African accents, making it a valuable resource for researchers and developers working on Automatic Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjaminogbonna/nigerian_accented_english_dataset.","url":"https://huggingface.co/datasets/benjaminogbonna/nigerian_accented_english_dataset","creator_name":"Benjamin Ogbonna","creator_url":"https://huggingface.co/benjaminogbonna","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","crowdsourced","English"],"keywords_longer_than_N":true},
	{"name":"vibravox","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for VibraVox\n\t\n\n\n  \n\n\n\nüëÄ While waiting for the TooBigContentError issue to be resolved by the HuggingFace team, you can explore the dataset viewer of vibravox-test\nwhich has exactly the same architecture.\n\n\t\n\t\t\n\t\n\t\n\t\tDATASET SUMMARY\n\t\n\nThe VibraVox dataset is a general purpose audio dataset of french speech captured with body-conduction transducers.\nThis dataset can be used for various audio machine learning tasks :\n\nAutomatic Speech Recognition (ASR) (Speech-to-Text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox.","url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"mosel","keyword":"text-to-speech","description":"\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel.","url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"nigerian_accented_english_dataset","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Nigerian Accent English Speech Data 1.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Nigerian Accent Speech Data is a comprehensive dataset of about 8 hours of audio recordings featuring speakers from various regions of Nigeria, \ncapturing the rich diversity of Nigerian accents. This dataset is specifically curated to address the gap in speech and language \ndatasets for African accents, making it a valuable resource for researchers and developers working on Automatic Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjaminogbonna/nigerian_accented_english_dataset.","url":"https://huggingface.co/datasets/benjaminogbonna/nigerian_accented_english_dataset","creator_name":"Benjamin Ogbonna","creator_url":"https://huggingface.co/benjaminogbonna","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","crowdsourced","English"],"keywords_longer_than_N":true},
	{"name":"common_voice_22.0_br","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nPartie en breton du jeu de donn√©es Common Voice 22.0.  \n\n\t\n\t\t\n\t\tChamps\n\t\n\n\naudio (dict) : Un dictionnaire contenant le chemin vers le fichier audio t√©l√©charg√©, l'audio d√©cod√© et la fr√©quence d'√©chantillonnage.Notez que lors de l'acc√®s √† la colonne audio : dataset[0][\"audio\"], le fichier audio est automatiquement d√©cod√© et r√©√©chantillonn√© √† dataset.features[\"audio\"].sampling_rate. Le d√©codage et le r√©√©chantillonnage d'un grand nombre de fichiers audio peuvent prendre‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bretagne/common_voice_22.0_br.","url":"https://huggingface.co/datasets/Bretagne/common_voice_22.0_br","creator_name":"Bretagne","creator_url":"https://huggingface.co/Bretagne","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Breton","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Spanish_spain_dataset_100h","keyword":"text-to-speech","description":"Total hours: 120h.\nLanguage: Spanish.\nSource: Librivox (https://librivox.org/search?primary_key=5&search_category=language&search_page=1&search_form=get_results)\nNumber of speakers: 17 without counting the collaborative audio books.\nCollection: Cutted by the windows speech recognition using the source text as grammars, then validated with Deep Speech Spanish model.\nType of speech: Clean speech.\nCollected by: Carlos Fonseca M @ https://github.com/carlfm01\nLicense : Public Domain\nQuality: low‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Blakus/Spanish_spain_dataset_100h.","url":"https://huggingface.co/datasets/Blakus/Spanish_spain_dataset_100h","creator_name":"ECD","creator_url":"https://huggingface.co/Blakus","license_name":"Public Domain Dedication & License","license_url":"https://scancode-licensedb.aboutcode.org/pddl-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-to-speech","pddl","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"spanish-corpus-xix","keyword":"hate-speech-detection","description":"Flaglab/spanish-corpus-xix dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Flaglab/spanish-corpus-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-retrieval","text-classification","slot-filling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"twi_bible_v2_tts","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tText-to-Speech Dataset\n\t\n\n","url":"https://huggingface.co/datasets/worldboss/twi_bible_v2_tts","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Twi","Akan"],"keywords_longer_than_N":true},
	{"name":"twi_bible_v2_tts","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tText-to-Speech Dataset\n\t\n\n","url":"https://huggingface.co/datasets/worldboss/twi_bible_v2_tts","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Twi","Akan"],"keywords_longer_than_N":true},
	{"name":"banking-customersupport-hinglish-audio","keyword":"speech","description":"\n\t\n\t\t\n\t\tBanking Customer Support Hinglish Audio Dataset\n\t\n\nText spoken by all participants:\n\"Mera online banking password bhool gaya, kaise reset karoon? Mera account lock ho gaya hai aur mujhe jaldi bill pay karna hai. Please guide karein.\"\nThe dataset supports training and evaluation of models in:\n\nAutomatic Speech Recognition (ASR)\nEmotional tone classification\nVoice synthesis and generation\nEmotion-aware conversational agents\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntended Uses\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t‚úÖ Direct Use‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/banking-customersupport-hinglish-audio.","url":"https://huggingface.co/datasets/Kratos-AI/banking-customersupport-hinglish-audio","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"nigerian-pidgin-1.0","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tLanguage:\n- Nigerian Pidgin English (West African Pidgin variant)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nDataset Summary\nThe Nigerian Pidgin ASR dataset (v1.0) is the first publicly released speech-to-text corpus for Nigerian Pidgin English, a widely spoken lingua franca across Nigeria and West Africa. This dataset comprises over 3,000 audio recordings paired with sentence-level transcriptions, recorded by native speakers across different genders and age groups. It is tailored for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/asr-nigerian-pidgin/nigerian-pidgin-1.0.","url":"https://huggingface.co/datasets/asr-nigerian-pidgin/nigerian-pidgin-1.0","creator_name":"Nigerian Pidgin Research","creator_url":"https://huggingface.co/asr-nigerian-pidgin","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","cc-by-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Balanced_hate_speech18","keyword":"hate-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/architrawat25/Balanced_hate_speech18.","url":"https://huggingface.co/datasets/architrawat25/Balanced_hate_speech18","creator_name":"Archit Rawat","creator_url":"https://huggingface.co/architrawat25","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"testtr43","keyword":"speech","description":"\n\t\n\t\t\n\t\ttesttr43\n\t\n\nThis is a merged speech dataset containing 2655 audio segments from 3 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 2655\nSpeakers: 13\nLanguages: tr\nEmotions: angry, happy, neutral\nOriginal Datasets: 3\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/testtr43.","url":"https://huggingface.co/datasets/Codyfederer/testtr43","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"havacilik-veriseti","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tATC Veri K√ºmesi - Whisper Modeli ile ƒ∞nce Ayar\n\t\n\nBu veri k√ºmesi, OpenAI'nin Whisper modelini, Hava Trafik Kontrol√º (ATC) ileti≈üimlerinde transkripsiyon doƒüruluƒüunu artƒ±rmak amacƒ±yla ince ayar yapmak i√ßin olu≈üturulmu≈ütur. Veri k√ºmesi, iki ana kaynaktan alƒ±nan transkripsiyonlar ve kar≈üƒ±lƒ±k gelen ses dosyalarƒ±nƒ± i√ßermektedir: ATCO2 ve UWB-ATCC korpusu, √∂zellikle havacƒ±lƒ±kla ilgili ileti≈üimler i√ßin se√ßilmi≈ütir. Veri k√ºmesi, Otomatik Konu≈üma Tanƒ±ma (ASR) projelerinde kullanƒ±lmak √ºzere‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mehmedadymn/havacilik-veriseti.","url":"https://huggingface.co/datasets/mehmedadymn/havacilik-veriseti","creator_name":"adƒ±yaman","creator_url":"https://huggingface.co/mehmedadymn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","Turkish","English","mit"],"keywords_longer_than_N":true},
	{"name":"testtr43","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\ttesttr43\n\t\n\nThis is a merged speech dataset containing 2655 audio segments from 3 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 2655\nSpeakers: 13\nLanguages: tr\nEmotions: angry, happy, neutral\nOriginal Datasets: 3\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/testtr43.","url":"https://huggingface.co/datasets/Codyfederer/testtr43","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"testtr43","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\ttesttr43\n\t\n\nThis is a merged speech dataset containing 2655 audio segments from 3 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 2655\nSpeakers: 13\nLanguages: tr\nEmotions: angry, happy, neutral\nOriginal Datasets: 3\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/testtr43.","url":"https://huggingface.co/datasets/Codyfederer/testtr43","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"VietMed_unlabeled","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tunofficial mirror of VietMed (Vietnamese speech data in medical domain) unlabeled set\n\t\n\nofficial announcement: https://arxiv.org/abs/2404.05659\nofficial download: https://huggingface.co/datasets/leduckhai/VietMed\nthis repo contains the unlabeled set: 966h - 230k samples\ni also gather the metadata: see info.csv\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/vietmed-unlabeled.py\nneed to do: check misspelling, restore foreign words phonetised to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/VietMed_unlabeled.","url":"https://huggingface.co/datasets/doof-ferb/VietMed_unlabeled","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"VietMed_unlabeled","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tunofficial mirror of VietMed (Vietnamese speech data in medical domain) unlabeled set\n\t\n\nofficial announcement: https://arxiv.org/abs/2404.05659\nofficial download: https://huggingface.co/datasets/leduckhai/VietMed\nthis repo contains the unlabeled set: 966h - 230k samples\ni also gather the metadata: see info.csv\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/vietmed-unlabeled.py\nneed to do: check misspelling, restore foreign words phonetised to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/VietMed_unlabeled.","url":"https://huggingface.co/datasets/doof-ferb/VietMed_unlabeled","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"TikTok_Most_Shared_Video_Transcription_Example","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tüì≤ Example Dataset: TikTok Scraper Tool\n\t\n\nüëâ Start Scraping TikTok: TikTok Scraper Tool\n\n\n\t\n\t\t\n\t\t‚ú® Key Features\n\t\n\n\n‚ö° Instant Transcription ‚Äì Turn any TikTok video into an AI-ready transcript  \nüéØ Metadata ‚Äì Get the title, language description, and video hashtags  \nüîó URL-Based Access ‚Äì Just drop in a TikTok video URL to start scraping  \nüß© LLM-Ready Output ‚Äì Receive clean JSON ready for agents, RAG, or AI tools  \nüí∏ Free Tier ‚Äì Use up to 100 queries during the beta period  \nüí´ Easy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/TikTok_Most_Shared_Video_Transcription_Example.","url":"https://huggingface.co/datasets/Gopher-Lab/TikTok_Most_Shared_Video_Transcription_Example","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"ljspeech-enhanced","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tljspeech-enhanced\n\t\n\nThis dataset contains ~10 hours of 1 to 14 seconds audio files from LJSpeech dataset in similar format 0.txt|phonemes|speaker_id|text\nThe dataset enhanced using Adobe speech enhance v2 and phonemized using espeak-ng\nExtracted data size is ~14GB\n","url":"https://huggingface.co/datasets/thewh1teagle/ljspeech-enhanced","creator_name":"thewh1teagle","creator_url":"https://huggingface.co/thewh1teagle","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"constituicao","keyword":"automatic-speech-recognition","description":"falabrasil/constituicao dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/falabrasil/constituicao","creator_name":"Grupo FalaBrasil","creator_url":"https://huggingface.co/falabrasil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","1K - 10K","webdataset"],"keywords_longer_than_N":true},
	{"name":"libritts_r_filtered","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Filtered LibriTTS-R\n\t\n\nThis is a filtered version of LibriTTS-R. It has been filtered based on two sources:\n\nLibriTTS-R paper [1], which lists samples for which speech restoration have failed\nLibriTTS-P [2] list of excluded speakers for which multiple speakers have been detected.\n\nLibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus which is a multi-speaker English corpus of approximately \n585 hours of read English speech at 24kHz sampling rate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/libritts_r_filtered.","url":"https://huggingface.co/datasets/parler-tts/libritts_r_filtered","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"MediBeng","keyword":"automatic-speech-recognition","description":"\n  \n    \n    \n  \n\n  \n    \n    \n  \n\n  \n    \n    \n  \n\n  \n    \n    \n  \n\n  \n    \n    \n  \n\n  \n    \n    \n    \n    \n  \n\n  \n    \n    \n  \n\n  \n    \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n  \n\n\n\n\n\t\t\n\t\tDataset Card for MediBeng\n\t\n\nThis dataset includes synthetic code-switched conversations in Bengali and English. It is designed to help train models for tasks like speech recognition (ASR), text-to-speech (TTS), and machine translation, focusing on bilingual code-switching in healthcare settings. The dataset is free to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng.","url":"https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng","creator_name":"Promila Ghosh","creator_url":"https://huggingface.co/pr0mila-gh0sh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-audio","text-to-speech","translation"],"keywords_longer_than_N":true},
	{"name":"ToneSpeak","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tToneSpeak\n\t\n\nToneSpeak ‚Äî –±–æ–ª—å—à–æ–π —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –∞—É–¥–∏–æ–¥–∞—Ç–∞—Å–µ—Ç —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –æ–ø–∏—Å–∞–Ω–∏–µ–º –∏–Ω—Ç–æ–Ω–∞—Ü–∏–π, —Ç–µ–º–±—Ä–∞ –∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≥–æ–ª–æ—Å–∞. –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ 26.33 —á–∞—Å–∞ –∞—É–¥–∏–æ –¥–ª—è train —Å–ø–ª–∏—Ç–∞ –∏ 2.91 —á–∞—Å–∞ –¥–ª—è valitation.\n\n\n\t\n\t\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ\n\t\n\n–î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –∞—É–¥–∏–æ —Å–æ–±—Ä–∞–Ω—ã:\n\n–¢–µ–∫—Å—Ç–æ–≤–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ (text)\n–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–Ω—Ç–æ–Ω–∞—Ü–∏–∏ –∏ —ç–º–æ—Ü–∏–π (text_description), —Ä–∞–∑–±–∏—Ç–æ–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º:\nAccent/Affect  \nVoice Affect  \nTone  \nPhrasing  \nPunctuation  \nEmotion  \nEmphasis  \nPronunciation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneSpeak.","url":"https://huggingface.co/datasets/Vikhrmodels/ToneSpeak","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Russian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"GeorgianSentimentClassification","keyword":"hate-speech-detection","description":"\n  GeorgianSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nGoergian Sentiment Dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://aclanthology.org/2022.lrec-1.173\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GeorgianSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GeorgianSentimentClassification.","url":"https://huggingface.co/datasets/mteb/GeorgianSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"libritts_r_filtered","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Filtered LibriTTS-R\n\t\n\nThis is a filtered version of LibriTTS-R. It has been filtered based on two sources:\n\nLibriTTS-R paper [1], which lists samples for which speech restoration have failed\nLibriTTS-P [2] list of excluded speakers for which multiple speakers have been detected.\n\nLibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus which is a multi-speaker English corpus of approximately \n585 hours of read English speech at 24kHz sampling rate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/libritts_r_filtered.","url":"https://huggingface.co/datasets/parler-tts/libritts_r_filtered","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"MediBeng","keyword":"text-to-speech","description":"\n  \n    \n    \n  \n\n  \n    \n    \n  \n\n  \n    \n    \n  \n\n  \n    \n    \n  \n\n  \n    \n    \n  \n\n  \n    \n    \n    \n    \n  \n\n  \n    \n    \n  \n\n  \n    \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n  \n\n\n\n\n\t\t\n\t\tDataset Card for MediBeng\n\t\n\nThis dataset includes synthetic code-switched conversations in Bengali and English. It is designed to help train models for tasks like speech recognition (ASR), text-to-speech (TTS), and machine translation, focusing on bilingual code-switching in healthcare settings. The dataset is free to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng.","url":"https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng","creator_name":"Promila Ghosh","creator_url":"https://huggingface.co/pr0mila-gh0sh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-audio","text-to-speech","translation"],"keywords_longer_than_N":true},
	{"name":"MediBeng","keyword":"text-to-speech","description":"\n  \n    \n    \n  \n\n  \n    \n    \n  \n\n  \n    \n    \n  \n\n  \n    \n    \n  \n\n  \n    \n    \n  \n\n  \n    \n    \n    \n    \n  \n\n  \n    \n    \n  \n\n  \n    \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n  \n\n\n\n\n\t\t\n\t\tDataset Card for MediBeng\n\t\n\nThis dataset includes synthetic code-switched conversations in Bengali and English. It is designed to help train models for tasks like speech recognition (ASR), text-to-speech (TTS), and machine translation, focusing on bilingual code-switching in healthcare settings. The dataset is free to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng.","url":"https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng","creator_name":"Promila Ghosh","creator_url":"https://huggingface.co/pr0mila-gh0sh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-audio","text-to-speech","translation"],"keywords_longer_than_N":true},
	{"name":"ToneSpeak","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tToneSpeak\n\t\n\nToneSpeak ‚Äî –±–æ–ª—å—à–æ–π —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –∞—É–¥–∏–æ–¥–∞—Ç–∞—Å–µ—Ç —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –æ–ø–∏—Å–∞–Ω–∏–µ–º –∏–Ω—Ç–æ–Ω–∞—Ü–∏–π, —Ç–µ–º–±—Ä–∞ –∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≥–æ–ª–æ—Å–∞. –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ 26.33 —á–∞—Å–∞ –∞—É–¥–∏–æ –¥–ª—è train —Å–ø–ª–∏—Ç–∞ –∏ 2.91 —á–∞—Å–∞ –¥–ª—è valitation.\n\n\n\t\n\t\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ\n\t\n\n–î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –∞—É–¥–∏–æ —Å–æ–±—Ä–∞–Ω—ã:\n\n–¢–µ–∫—Å—Ç–æ–≤–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ (text)\n–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–Ω—Ç–æ–Ω–∞—Ü–∏–∏ –∏ —ç–º–æ—Ü–∏–π (text_description), —Ä–∞–∑–±–∏—Ç–æ–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º:\nAccent/Affect  \nVoice Affect  \nTone  \nPhrasing  \nPunctuation  \nEmotion  \nEmphasis  \nPronunciation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneSpeak.","url":"https://huggingface.co/datasets/Vikhrmodels/ToneSpeak","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Russian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"singaporean_district_noise_snr_2_7","keyword":"speech","description":"\n\t\n\t\t\n\t\tSingaporean district with noise\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSingaporean district speech dataset with controlled noise augmentation for ASR training\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: EN\nTask: Automatic Speech Recognition  \nTotal Samples: 2,288\nAudio Sample Rate: 16kHz\nBase Dataset: Custom dataset\nProcessing: Noise-augmented\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (16kHz WAV format)\ntext: Transcription text\nnoise_type: Type of background noise‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_2_7.","url":"https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_2_7","creator_name":"DANG VAN THUC","creator_url":"https://huggingface.co/thucdangvan020999","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"singaporean_district_noise_snr_2_7","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSingaporean district with noise\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSingaporean district speech dataset with controlled noise augmentation for ASR training\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: EN\nTask: Automatic Speech Recognition  \nTotal Samples: 2,288\nAudio Sample Rate: 16kHz\nBase Dataset: Custom dataset\nProcessing: Noise-augmented\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (16kHz WAV format)\ntext: Transcription text\nnoise_type: Type of background noise‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_2_7.","url":"https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise_snr_2_7","creator_name":"DANG VAN THUC","creator_url":"https://huggingface.co/thucdangvan020999","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"multilingual-dataset-index","keyword":"linguistics","description":"\n\t\n\t\t\n\t\tMultilingual Dataset Index\n\t\n\nA curated list of multilingual text datasets available on Huggingface, designed to help users easily find datasets by language‚Äîincluding those for low-resource languages.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nThis index aims to make it easier to find datasets by language, addressing the common issue of inconsistent or unclear language codes across different datasets.\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe index is provided as a CSV file with the following columns:\n\nlanguage: The English name‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/multilingual-dataset-index.","url":"https://huggingface.co/datasets/agentlans/multilingual-dataset-index","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","cc0-1.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"uts2025_vietipa","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tVietnamese IPA Dataset\n\t\n\nA comprehensive Vietnamese IPA (International Phonetic Alphabet) dataset with word pronunciations and MP3 audio files for text-to-speech and pronunciation learning applications.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 50 common Vietnamese words with their IPA (International Phonetic Alphabet) transcriptions and corresponding audio files. It's designed for:\n\nText-to-speech systems development\nVietnamese pronunciation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/undertheseanlp/uts2025_vietipa.","url":"https://huggingface.co/datasets/undertheseanlp/uts2025_vietipa","creator_name":"undertheseanlp","creator_url":"https://huggingface.co/undertheseanlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Vietnamese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"hi_luna_synthetic_audio_v1","keyword":"automatic-speech-recognition","description":"300k audio files synthetically generated by VITS using https://github.com/dscripka/synthetic_speech_dataset_generation?tab=readme-ov-file\n\nCommand used\npython generate_clips.py \\\n    --model VITS \\\n    --enable_gpu \\\n    --text \"Hey, Luna\" \\\n    --N 300000 \\\n    --max_per_speaker 1 \\\n    --output_dir /luna_audio\n\n","url":"https://huggingface.co/datasets/ThomasTheMaker/hi_luna_synthetic_audio_v1","creator_name":"Thomas Nguyen","creator_url":"https://huggingface.co/ThomasTheMaker","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","apache-2.0","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"voxceleb2","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tVoxCeleb2 Dataset\n\t\n\nThis is the VoxCeleb2 dataset, a large-scale speaker identification dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nVoxCeleb2 contains over 1 million utterances for 6,112 celebrities, extracted from videos uploaded to YouTube.\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\nvox2_dev_mp4_part*: Multipart archive containing MP4 video files\nvox2_dev_txt: Text files with speaker/utterance metadata  \nvox2_meta.csv: Dataset metadata\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nTo extract the multipart archive:\n# Using 7zip\n7z x‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Reverb/voxceleb2.","url":"https://huggingface.co/datasets/Reverb/voxceleb2","creator_name":"basel wael anaya","creator_url":"https://huggingface.co/Reverb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","English","mit","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"uts2025_vietipa","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tVietnamese IPA Dataset\n\t\n\nA comprehensive Vietnamese IPA (International Phonetic Alphabet) dataset with word pronunciations and MP3 audio files for text-to-speech and pronunciation learning applications.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 50 common Vietnamese words with their IPA (International Phonetic Alphabet) transcriptions and corresponding audio files. It's designed for:\n\nText-to-speech systems development\nVietnamese pronunciation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/undertheseanlp/uts2025_vietipa.","url":"https://huggingface.co/datasets/undertheseanlp/uts2025_vietipa","creator_name":"undertheseanlp","creator_url":"https://huggingface.co/undertheseanlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Vietnamese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"uts2025_vietipa","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tVietnamese IPA Dataset\n\t\n\nA comprehensive Vietnamese IPA (International Phonetic Alphabet) dataset with word pronunciations and MP3 audio files for text-to-speech and pronunciation learning applications.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 50 common Vietnamese words with their IPA (International Phonetic Alphabet) transcriptions and corresponding audio files. It's designed for:\n\nText-to-speech systems development\nVietnamese pronunciation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/undertheseanlp/uts2025_vietipa.","url":"https://huggingface.co/datasets/undertheseanlp/uts2025_vietipa","creator_name":"undertheseanlp","creator_url":"https://huggingface.co/undertheseanlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Vietnamese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BinauralLibriSpeech","keyword":"speech","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis is a Binaural version of LibriSpeech, created using HRTFs from the ARI database and reverberation using simulated RIRs from the SLR28 Room Impulse Response and Noise Database.\nThe dataset has annotations of the source direction as well as microphone array geometry. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nLanguage(s) (NLP): English\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech.","url":"https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech","creator_name":"Holger Severin Bovbjerg","creator_url":"https://huggingface.co/Holger1997","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"BinauralLibriSpeech","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis is a Binaural version of LibriSpeech, created using HRTFs from the ARI database and reverberation using simulated RIRs from the SLR28 Room Impulse Response and Noise Database.\nThe dataset has annotations of the source direction as well as microphone array geometry. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nLanguage(s) (NLP): English\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech.","url":"https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech","creator_name":"Holger Severin Bovbjerg","creator_url":"https://huggingface.co/Holger1997","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"sinhala-bank-speech","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThis dataset contains 100 audio files, one male voice in the format .wav. \nThe domain of this dataset is Banking.Only Language is Sinhalese(Sinhala,si)\nTotal Duration: 700.283 seconds.\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IshanSuga/sinhala-bank-speech.","url":"https://huggingface.co/datasets/IshanSuga/sinhala-bank-speech","creator_name":"Ishan Sugathadasa","creator_url":"https://huggingface.co/IshanSuga","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Sinhala","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"benchmark_eseu_testsets","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tBenchmark Test-sets for evaluations on Spanish and Basque\n\t\n\nThis test-sets are a reduced version of public available datasets. The datasets are balanced with more or less the same amount of hours in each dataset, for equal evaluation tasks.\n\n\t\n\t\t\n\t\tTest splits:\n\t\n\n\nmozilla-foundation/common_voice_18_0/es: a small split made from the official \"test\" split for spanish.\nmozilla-foundation/common_voice_18_0/eu: a small split made from the official \"test\" split for basque.\nopenslr/es: a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/benchmark_eseu_testsets.","url":"https://huggingface.co/datasets/HiTZ/benchmark_eseu_testsets","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Basque","Spanish","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech_test_vad","keyword":"speech","description":"Voice Activity Detection (VAD) Test Dataset\nThis dataset is based on the test splits found in\nmultilingual_librispeech\ndataset.  It includes two binary labels:\n\nspeech: Indicates presence of speech ([0, 1]), computed using a dynamic threshold method with background noise estimation and smoothing.\n\nconfidence: A post-processing flag to optionally correct transient dropouts in speech. It is set to 1 by default, but switches to 0 for up to ~0.1 seconds (3 chunks of audio) following a transition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/guynich/multilingual_librispeech_test_vad.","url":"https://huggingface.co/datasets/guynich/multilingual_librispeech_test_vad","creator_name":"Guy Nicholson","creator_url":"https://huggingface.co/guynich","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"floras","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tFLORAS\n\t\n\nFLORAS is a 50-language benchmark For LOng-form Recognition And Summarization of spoken language. \nThe goal of FLORAS is to create a more realistic benchmarking environment for speech recognition, translation, and summarization models. \nUnlike typical academic benchmarks like LibriSpeech and FLEURS that uses pre-segmented single-speaker read-speech, FLORAS tests the capabilities of models on raw long-form conversational audio, which can have one or many speakers.\nTo encourage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/espnet/floras.","url":"https://huggingface.co/datasets/espnet/floras","creator_name":"ESPnet","creator_url":"https://huggingface.co/espnet","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","summarization","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"urdu-tts","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tXCollab/urdu-tts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCombined Urdu Text-to-Speech dataset with 17,575 high-quality audio-text pairs.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n{\n    'index': int,           # Sample index\n    'text': str,           # Urdu text transcription  \n    'audio': {             # Audio data\n        'path': str,        # Path to audio file\n        'sampling_rate': 16000\n    },\n    'source_dataset': str  # Original dataset name\n}\n\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/XCollab/urdu-tts.","url":"https://huggingface.co/datasets/XCollab/urdu-tts","creator_name":"XCollab","creator_url":"https://huggingface.co/XCollab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Urdu","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"StepEval-Audio-Toolcall","keyword":"speech-recognition","description":"\n\t\n\t\t\n\t\tStepEval-Audio-Toolcall\n\t\n\nPaper: Step-Audio 2 Technical ReportCode: https://github.com/stepfun-ai/Step-Audio2Project Page: https://www.stepfun.com/docs/en/step-audio2  \n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nStepEval Audio Toolcall evaluates the invocation performance of four tool types. For each tool, the benchmark contains approximately 200 multi-turn dialogue sets for both positive and negative scenarios:\n\nPositive samples: The assistant is required to invoke the specified tool in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stepfun-ai/StepEval-Audio-Toolcall.","url":"https://huggingface.co/datasets/stepfun-ai/StepEval-Audio-Toolcall","creator_name":"StepFun","creator_url":"https://huggingface.co/stepfun-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["audio-text-to-text","apache-2.0","arxiv:2507.16632","üá∫üá∏ Region: US","benchmark"],"keywords_longer_than_N":true},
	{"name":"MiSide-Japanese","keyword":"text-to-speech","description":"AkitoP/MiSide-Japanese dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/AkitoP/MiSide-Japanese","creator_name":"L","creator_url":"https://huggingface.co/AkitoP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Japanese","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"wolof-audio-data","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tWolof Audio Dataset\n\t\n\nThe Wolof Audio Dataset is a collection of audio recordings and their corresponding transcriptions in Wolof. This dataset is designed to support the development of Automatic Speech Recognition (ASR) models for the Wolof language. It was created by combining three existing datasets:\n\nALFFA: Available at serge-wilson/wolof_speech_transcription\nFLEURS: Available at vonewman/fleurs-wolof-dataset\nUrban Bus Wolof Speech Dataset: Available at vonewman/urban-bus-wolof‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vonewman/wolof-audio-data.","url":"https://huggingface.co/datasets/vonewman/wolof-audio-data","creator_name":"Abdoulaye Diallo","creator_url":"https://huggingface.co/vonewman","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Wolof","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Latin-Audio","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nVox Classica is a Latin speech corpus of ~73 hours of audio, segmented into short audio clips by sentence. Vox Classica is a large-scale, ML-ready dataset of human-read Classical Latin. It was designed to address the absence of a publicly available human-read Latin corpus large enough for model training.\n\nAlignment and curation: Kaiyuan Zhao\nLanguage: Latin (Classical)\n\n\n\t\n\t\t\n\t\tUses\n\t\n\nThis dataset is built for training and evaluating speech processing models for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ken-Z/Latin-Audio.","url":"https://huggingface.co/datasets/Ken-Z/Latin-Audio","creator_name":"Ken Zhao","creator_url":"https://huggingface.co/Ken-Z","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Latin","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Latin-Audio","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nVox Classica is a Latin speech corpus of ~73 hours of audio, segmented into short audio clips by sentence. Vox Classica is a large-scale, ML-ready dataset of human-read Classical Latin. It was designed to address the absence of a publicly available human-read Latin corpus large enough for model training.\n\nAlignment and curation: Kaiyuan Zhao\nLanguage: Latin (Classical)\n\n\n\t\n\t\t\n\t\tUses\n\t\n\nThis dataset is built for training and evaluating speech processing models for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ken-Z/Latin-Audio.","url":"https://huggingface.co/datasets/Ken-Z/Latin-Audio","creator_name":"Ken Zhao","creator_url":"https://huggingface.co/Ken-Z","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Latin","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Latin-Audio","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nVox Classica is a Latin speech corpus of ~73 hours of audio, segmented into short audio clips by sentence. Vox Classica is a large-scale, ML-ready dataset of human-read Classical Latin. It was designed to address the absence of a publicly available human-read Latin corpus large enough for model training.\n\nAlignment and curation: Kaiyuan Zhao\nLanguage: Latin (Classical)\n\n\n\t\n\t\t\n\t\tUses\n\t\n\nThis dataset is built for training and evaluating speech processing models for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ken-Z/Latin-Audio.","url":"https://huggingface.co/datasets/Ken-Z/Latin-Audio","creator_name":"Ken Zhao","creator_url":"https://huggingface.co/Ken-Z","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Latin","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Latin-Audio","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nVox Classica is a Latin speech corpus of ~73 hours of audio, segmented into short audio clips by sentence. Vox Classica is a large-scale, ML-ready dataset of human-read Classical Latin. It was designed to address the absence of a publicly available human-read Latin corpus large enough for model training.\n\nAlignment and curation: Kaiyuan Zhao\nLanguage: Latin (Classical)\n\n\n\t\n\t\t\n\t\tUses\n\t\n\nThis dataset is built for training and evaluating speech processing models for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ken-Z/Latin-Audio.","url":"https://huggingface.co/datasets/Ken-Z/Latin-Audio","creator_name":"Ken Zhao","creator_url":"https://huggingface.co/Ken-Z","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Latin","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"audio-data","keyword":"automatic-speech-recognition","description":"SachinTelecmi/audio-data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/SachinTelecmi/audio-data","creator_name":"Sachin Mohanty","creator_url":"https://huggingface.co/SachinTelecmi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Hindi","mit","1K<n<10K","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"gujarati-f-openslr","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tGujarati OpenSLR Female\n\t\n\nInterspeech data downloaded from https://www.openslr.org/resources/78/gu_in_female.zip\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nGujarati Data (Most of the entries are <30 seconds and hence Whisper Models can be used for accurate timestamp prediction)\nAlso, the audio seems to have been spoken by a single female.\n\n","url":"https://huggingface.co/datasets/1rsh/gujarati-f-openslr","creator_name":"Irsh Vijay","creator_url":"https://huggingface.co/1rsh","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Gujarati","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"TOSD","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Tamazight Open Speech Dataset\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tamazight-NLP/TOSD.","url":"https://huggingface.co/datasets/Tamazight-NLP/TOSD","creator_name":"Tamazight NLP","creator_url":"https://huggingface.co/Tamazight-NLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Standard Moroccan Tamazight","ber","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"TOSD","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Tamazight Open Speech Dataset\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tamazight-NLP/TOSD.","url":"https://huggingface.co/datasets/Tamazight-NLP/TOSD","creator_name":"Tamazight NLP","creator_url":"https://huggingface.co/Tamazight-NLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Standard Moroccan Tamazight","ber","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"jolly_wizard","keyword":"speech","description":"rixprior/jolly_wizard dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rixprior/jolly_wizard","creator_name":"Nori Gami","creator_url":"https://huggingface.co/rixprior","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","Spanish","cc0-1.0","< 1K","Video"],"keywords_longer_than_N":true},
	{"name":"speech","keyword":"automatic-speech-recognition","description":"peanut999/speech dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/peanut999/speech","creator_name":"butter","creator_url":"https://huggingface.co/peanut999","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","English","Malay","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ESpeech-webinars2","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tWebinar Audio Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 850 hours processed webinar audio segments with corresponding metadata. Each audio file represents a segment extracted from webinar recordings, processed at 44.1kHz sample rate.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Russian\nTask: TTS, ASR, Quality Asessment\nAudio format: MP3, 44.1kHz sample rate\nStructure: Segmented audio files with JSON metadata\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ESpeech/ESpeech-webinars2.","url":"https://huggingface.co/datasets/ESpeech/ESpeech-webinars2","creator_name":"Ebany Speech","creator_url":"https://huggingface.co/ESpeech","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Russian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"cv-corpus-17.0-ja-client_id-grouped","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tcv-corpus-17.0-ja-client_id-grouped\n\t\n\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nThe dataset is derived from the Common Voice dataset.\nThe original dataset is available at Common Voice Dataset.\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\nEach group is filtered to include only client IDs with a minimum of 30 samples and a maximum of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-ja-client_id-grouped.","url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-ja-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","commonvoice","Japanese"],"keywords_longer_than_N":true},
	{"name":"myanmar-english-accent-speech","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tMyanmar English Accent Speech (PVTV & FOEIM)\n\t\n\nThis dataset contains English speech by Myanmar speakers, collected from public videos published by PVTV and FOEIM ‚Äî two media channels operating under the National Unity Government (NUG).\nThe clips reflect a wide range of spoken English contexts: interviews, announcements, sermons, and educational content. The speakers vary in tone, pace, and emotion ‚Äî but all share the characteristic sound of Burmese-accented English.\nThis dataset was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/myanmar-english-accent-speech.","url":"https://huggingface.co/datasets/freococo/myanmar-english-accent-speech","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc0-1.0","1K - 10K","webdataset"],"keywords_longer_than_N":true},
	{"name":"myanmar-english-accent-speech","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tMyanmar English Accent Speech (PVTV & FOEIM)\n\t\n\nThis dataset contains English speech by Myanmar speakers, collected from public videos published by PVTV and FOEIM ‚Äî two media channels operating under the National Unity Government (NUG).\nThe clips reflect a wide range of spoken English contexts: interviews, announcements, sermons, and educational content. The speakers vary in tone, pace, and emotion ‚Äî but all share the characteristic sound of Burmese-accented English.\nThis dataset was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/myanmar-english-accent-speech.","url":"https://huggingface.co/datasets/freococo/myanmar-english-accent-speech","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc0-1.0","1K - 10K","webdataset"],"keywords_longer_than_N":true},
	{"name":"ESpeech-webinars2","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tWebinar Audio Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 850 hours processed webinar audio segments with corresponding metadata. Each audio file represents a segment extracted from webinar recordings, processed at 44.1kHz sample rate.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Russian\nTask: TTS, ASR, Quality Asessment\nAudio format: MP3, 44.1kHz sample rate\nStructure: Segmented audio files with JSON metadata\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ESpeech/ESpeech-webinars2.","url":"https://huggingface.co/datasets/ESpeech/ESpeech-webinars2","creator_name":"Ebany Speech","creator_url":"https://huggingface.co/ESpeech","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Russian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"AudioSkills-Llama3","keyword":"speech","description":"\n\t\n\t\t\n\t\tAudioSkills-XL Dataset\n\t\n\n\n\t\n\t\t\n\t\tTo promote the development of open source models, we have released AudioSkills using the exact same method generated with Llama 3.1-8B Instruct instead of GPT4o in the original.\n\t\n\nProject page | Paper | Code\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAudioSkills-XL is a large-scale audio question-answering (AQA) dataset designed to develop (large) audio-language models on expert-level reasoning and problem-solving tasks over short audio clips (‚â§30 seconds). It‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sonalkum/AudioSkills-Llama3.","url":"https://huggingface.co/datasets/sonalkum/AudioSkills-Llama3","creator_name":"Sonal Kumar","creator_url":"https://huggingface.co/sonalkum","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["audio-text-to-text","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"odia-english-ASR","keyword":"automatic-speech-recognition","description":"Mohan-diffuser/odia-english-ASR dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Mohan-diffuser/odia-english-ASR","creator_name":"Mohan Dash","creator_url":"https://huggingface.co/Mohan-diffuser","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Oriya","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"synthetic_transcript_pt","keyword":"speech","description":"\n\t\n\t\t\n\t\tPortuguese Speech Dataset with Multiple Training Configurations\n\t\n\nA comprehensive Portuguese speech dataset offering three distinct training configurations for speech recognition research, each designed for different experimental scenarios and training paradigms.\n\n\t\n\t\t\n\t\tüéØ Dataset Configurations Overview\n\t\n\nThis dataset provides three carefully curated subsets to enable comprehensive speech recognition research:\n\n\t\n\t\t\nConfiguration\nTraining Data\nValidation\nTest\nTotal Samples\nUse Case‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt.","url":"https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt","creator_name":"Yuriy Perezhohin","creator_url":"https://huggingface.co/yuriyvnv","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","audio-classification","Portuguese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"jl-speech","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tJL Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nJL Speech is a male voice version of the LJ Speech dataset. It contains 13,100 short audio clips of a single speaker reading passages from books. The total audio duration is approximately 24 hours, with audio quality improved to 48 kHz sampling rate.\nThis dataset is licensed under the CC-BY-4.0 License.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tCreation\n\t\n\nThe JL Speech dataset was created by converting the original LJ Speech dataset to a male‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JacobLinCool/jl-speech.","url":"https://huggingface.co/datasets/JacobLinCool/jl-speech","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"synthetic_transcript_pt","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tPortuguese Speech Dataset with Multiple Training Configurations\n\t\n\nA comprehensive Portuguese speech dataset offering three distinct training configurations for speech recognition research, each designed for different experimental scenarios and training paradigms.\n\n\t\n\t\t\n\t\tüéØ Dataset Configurations Overview\n\t\n\nThis dataset provides three carefully curated subsets to enable comprehensive speech recognition research:\n\n\t\n\t\t\nConfiguration\nTraining Data\nValidation\nTest\nTotal Samples\nUse Case‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt.","url":"https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt","creator_name":"Yuriy Perezhohin","creator_url":"https://huggingface.co/yuriyvnv","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","audio-classification","Portuguese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ru_en_linguistic_exchange","keyword":"grammar","description":"\n\t\n\t\t\n\t\tRussian-English Linguistic Exchange Corpus (RELEC)\n\t\n\n\nüá∑üá∫ –†—É—Å—Å–∫–∞—è –≤–µ—Ä—Å–∏—è / Russian version...\n\n\n\t\n\t\t\n\t\t–ö–æ—Ä–ø—É—Å \"RELEC\": –õ–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –æ–±–º–µ–Ω –º–µ–∂–¥—É —Ä—É—Å—Å–∫–∏–º –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–º\n\t\n\n–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –ø–æ–Ω–∏–º–∞–Ω–∏—é –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤, —Ñ–æ–∫—É—Å–∏—Ä—É—é—â–∏—Ö—Å—è –Ω–∞ –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—è—Ö –∏ —Ä–∞–∑–ª–∏—á–∏—è—Ö –º–µ–∂–¥—É —Ä—É—Å—Å–∫–∏–º –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–º —è–∑—ã–∫–∞–º–∏. –ö–∞–∂–¥–∞—è —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–∞—Ä–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –¥–∏–∞–ª–æ–≥–∏ –Ω–∞ –æ–±–æ–∏—Ö —è–∑—ã–∫–∞—Ö, –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—â–∏–µ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ, —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–µ –∏‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/loim/ru_en_linguistic_exchange.","url":"https://huggingface.co/datasets/loim/ru_en_linguistic_exchange","creator_name":"Arsen Arutunan","creator_url":"https://huggingface.co/loim","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Russian","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ru_en_linguistic_exchange","keyword":"linguistics","description":"\n\t\n\t\t\n\t\tRussian-English Linguistic Exchange Corpus (RELEC)\n\t\n\n\nüá∑üá∫ –†—É—Å—Å–∫–∞—è –≤–µ—Ä—Å–∏—è / Russian version...\n\n\n\t\n\t\t\n\t\t–ö–æ—Ä–ø—É—Å \"RELEC\": –õ–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –æ–±–º–µ–Ω –º–µ–∂–¥—É —Ä—É—Å—Å–∫–∏–º –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–º\n\t\n\n–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –ø–æ–Ω–∏–º–∞–Ω–∏—é –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤, —Ñ–æ–∫—É—Å–∏—Ä—É—é—â–∏—Ö—Å—è –Ω–∞ –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—è—Ö –∏ —Ä–∞–∑–ª–∏—á–∏—è—Ö –º–µ–∂–¥—É —Ä—É—Å—Å–∫–∏–º –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–º —è–∑—ã–∫–∞–º–∏. –ö–∞–∂–¥–∞—è —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–∞—Ä–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –¥–∏–∞–ª–æ–≥–∏ –Ω–∞ –æ–±–æ–∏—Ö —è–∑—ã–∫–∞—Ö, –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—â–∏–µ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ, —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–µ –∏‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/loim/ru_en_linguistic_exchange.","url":"https://huggingface.co/datasets/loim/ru_en_linguistic_exchange","creator_name":"Arsen Arutunan","creator_url":"https://huggingface.co/loim","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Russian","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"jl-speech","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tJL Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nJL Speech is a male voice version of the LJ Speech dataset. It contains 13,100 short audio clips of a single speaker reading passages from books. The total audio duration is approximately 24 hours, with audio quality improved to 48 kHz sampling rate.\nThis dataset is licensed under the CC-BY-4.0 License.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tCreation\n\t\n\nThe JL Speech dataset was created by converting the original LJ Speech dataset to a male‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JacobLinCool/jl-speech.","url":"https://huggingface.co/datasets/JacobLinCool/jl-speech","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"synthetic_transcript_pt","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tPortuguese Speech Dataset with Multiple Training Configurations\n\t\n\nA comprehensive Portuguese speech dataset offering three distinct training configurations for speech recognition research, each designed for different experimental scenarios and training paradigms.\n\n\t\n\t\t\n\t\tüéØ Dataset Configurations Overview\n\t\n\nThis dataset provides three carefully curated subsets to enable comprehensive speech recognition research:\n\n\t\n\t\t\nConfiguration\nTraining Data\nValidation\nTest\nTotal Samples\nUse Case‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt.","url":"https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt","creator_name":"Yuriy Perezhohin","creator_url":"https://huggingface.co/yuriyvnv","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","audio-classification","Portuguese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"SynStard-1000","keyword":"speech","description":"\n\t\n\t\t\n\t\tSynStard-1000\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSynStard-1000 is a 1,000-hour synthetic dataset for training and evaluating end-to-end speech-to-speech translation (S2ST) models. It is built from English-Chinese parallel texts in the WMT News Commentary v18 corpus and contains approximately 390,000 sentence pairs with paired synthetic speech.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n.\n‚îú‚îÄ‚îÄ map/\n‚îÇ   ‚îî‚îÄ‚îÄ all.tsv\n‚îÇ‚îÄ‚îÄ text/\n‚îÇ   ‚îú‚îÄ‚îÄ en/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ en.txt\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ en_1.txt\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ...\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cksqs/SynStard-1000.","url":"https://huggingface.co/datasets/cksqs/SynStard-1000","creator_name":"Pu Yu","creator_url":"https://huggingface.co/cksqs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","100K<n<1M","Audio"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr\n\t\n\n\n\t\n\t\t\n\t\tLibriSpeech ASR 2s Splits Dataset\n\t\n\nVersion of LibriSpeech ASR corpus split into 2s clips.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset from the Hub\ndataset = load_dataset(\"pavanyellow/librispeech_asr\")\n\n# Or load a specific split\ndataset = load_dataset(\"pavanyellow/librispeech_asr\", split=\"train\")\n\n# Access the data\nfor example in dataset['train'][:5]:\n   audio = example['audio']\n   text = example['text']\n\n","url":"https://huggingface.co/datasets/pavanyellow/librispeech_asr","creator_name":"Pavan Katta","creator_url":"https://huggingface.co/pavanyellow","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"audio-dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tAudio Transcription Dataset\n\t\n\nThis dataset contains 197 audio recordings with their corresponding transcriptions for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset includes:\n\nAudio files: High-quality voice recordings (.wav format)\nTranscriptions: Accurate text transcriptions of the spoken content\nProper Audio feature type: Ready for model training (not just file paths!)\n\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal samples: 197\nAudio format: WAV files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AJosh/audio-dataset.","url":"https://huggingface.co/datasets/AJosh/audio-dataset","creator_name":"akula","creator_url":"https://huggingface.co/AJosh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"audio-dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tAudio Transcription Dataset\n\t\n\nThis dataset contains 197 audio recordings with their corresponding transcriptions for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset includes:\n\nAudio files: High-quality voice recordings (.wav format)\nTranscriptions: Accurate text transcriptions of the spoken content\nProper Audio feature type: Ready for model training (not just file paths!)\n\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal samples: 197\nAudio format: WAV files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AJosh/audio-dataset.","url":"https://huggingface.co/datasets/AJosh/audio-dataset","creator_name":"akula","creator_url":"https://huggingface.co/AJosh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"zh-taiwan","keyword":"text-to-speech","description":"ivanzhu109/zh-taiwan dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ivanzhu109/zh-taiwan","creator_name":"IvanZhu","creator_url":"https://huggingface.co/ivanzhu109","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Chinese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_5k","keyword":"speech","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (5k)\n\t\n\nThis dataset contains 10000 synthetic speech recordings in the Pashto language,\nwith 5000 male voice recordings and 5000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 5000 sentences\nTotal Recordings: 10000 audio files (5000 male + 5000 female)\nAudio Format: WAV, 24kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 24kHz (24000 Hz)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_5k.","url":"https://huggingface.co/datasets/ihanif/pashto_speech_5k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"one-by-one","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tAudio Dataset\n\t\n\nThis dataset contains audio segments with transcriptions for speech recognition and text-to-speech tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\ndataset.json: Complete dataset in JSON format\ntrain.jsonl: Dataset in JSONL format for use with Hugging Face datasets library\ndataset_info.json: Metadata about the dataset structure\n\nEach entry contains:\n\nfile: Original filename\naudio: Audio data with sampling rate\ntranscription: Text transcription\nduration: Audio duration in seconds\n\n","url":"https://huggingface.co/datasets/jsbeaudry/one-by-one","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"pashto_speech_5k","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tPashto Synthetic Speech Dataset Parquet (5k)\n\t\n\nThis dataset contains 10000 synthetic speech recordings in the Pashto language,\nwith 5000 male voice recordings and 5000 female voice recordings, stored in Parquet format.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nDataset Size: 5000 sentences\nTotal Recordings: 10000 audio files (5000 male + 5000 female)\nAudio Format: WAV, 24kHz, 16-bit PCM, embedded directly in Parquet files\nDataset Format: Parquet with 500MB shards\nSampling Rate: 24kHz (24000 Hz)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_5k.","url":"https://huggingface.co/datasets/ihanif/pashto_speech_5k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Pashto","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"vietnam-normalize-24k","keyword":"text-to-speech","description":"thanhkt/vietnam-normalize-24k dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/thanhkt/vietnam-normalize-24k","creator_name":"Tran Khanh Thanh","creator_url":"https://huggingface.co/thanhkt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","text-to-speech","summarization","sentence-similarity"],"keywords_longer_than_N":true},
	{"name":"one-by-one","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tAudio Dataset\n\t\n\nThis dataset contains audio segments with transcriptions for speech recognition and text-to-speech tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\ndataset.json: Complete dataset in JSON format\ntrain.jsonl: Dataset in JSONL format for use with Hugging Face datasets library\ndataset_info.json: Metadata about the dataset structure\n\nEach entry contains:\n\nfile: Original filename\naudio: Audio data with sampling rate\ntranscription: Text transcription\nduration: Audio duration in seconds\n\n","url":"https://huggingface.co/datasets/jsbeaudry/one-by-one","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"tamil-audio-dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tTamil Language Audio Dataset\n\t\n\nText spoken by all participants:\n\"‡Æö‡ØÜ‡ÆØ‡Æ±‡Øç‡Æï‡Øà ‡Æ®‡ØÅ‡Æ£‡Øç‡Æ£‡Æ±‡Æø‡Æµ‡ØÅ (AI) ‡Æµ‡Øá‡Æï‡ÆÆ‡Ææ‡Æï ‡Æµ‡Æ≥‡Æ∞‡Øç‡Æ®‡Øç‡Æ§‡ØÅ ‡Æµ‡Æ∞‡ØÅ‡Æï‡Æø‡Æ±‡Æ§‡ØÅ, ‡ÆÖ‡Æ©‡Øç‡Æ±‡Ææ‡Æü ‡Æµ‡Ææ‡Æ¥‡Øç‡Æï‡Øç‡Æï‡Øà‡ÆØ‡Øà ‡ÆÆ‡Ææ‡Æ±‡Øç‡Æ±‡ØÅ‡Æï‡Æø‡Æ±‡Æ§‡ØÅ. ‡Æá‡Æ§‡Æ©‡Øç ‡Æ™‡ØÅ‡Æ§‡ØÅ‡ÆÆ‡Øà‡Æï‡Æ≥‡Øç ‡Æï‡Æ≤‡Øç‡Æµ‡Æø, ‡ÆÆ‡Æ∞‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Æµ‡ÆÆ‡Øç ‡ÆÆ‡Æ±‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡Æµ‡Øá‡Æ≤‡Øà‡ÆØ‡Øà ‡ÆÆ‡Øá‡ÆÆ‡Øç‡Æ™‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Æï‡Æø‡Æ©‡Øç‡Æ±‡Æ©, ‡Æ™‡ØÅ‡Æ§‡Æø‡ÆØ ‡Æµ‡Ææ‡ÆØ‡Øç‡Æ™‡Øç‡Æ™‡ØÅ‡Æï‡Æ≥‡Øà ‡Æâ‡Æ∞‡ØÅ‡Æµ‡Ææ‡Æï‡Øç‡Æï‡ØÅ‡Æï‡Æø‡Æ©‡Øç‡Æ±‡Æ©‡•§\"\nThe dataset supports training and evaluation of models in:\n\nAutomatic Speech Recognition (ASR)\nEmotional tone classification\nVoice synthesis and generation\nEmotion-aware conversational agents\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntended Uses\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t‚úÖ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/tamil-audio-dataset.","url":"https://huggingface.co/datasets/Kratos-AI/tamil-audio-dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Tamil","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"AngryTweetsClassification","keyword":"hate-speech-detection","description":"\n  AngryTweetsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA sentiment dataset with 3 classes (positiv, negativ, neutral) for Danish tweets\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReference\nhttps://aclanthology.org/2021.nodalida-main.53/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AngryTweetsClassification\"])\nevaluator = mteb.MTEB(task)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AngryTweetsClassification.","url":"https://huggingface.co/datasets/mteb/AngryTweetsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"kazakh-speech-commands","keyword":"speech","description":"\n\t\n\t\t\n\t\tKazakh Speech Commands Dataset\n\t\n\nPaper: Speech Command Recognition: Text-to-Speech and Speech Corpus Scraping Are All You Need\nRepository: https://github.com/IS2AI/Kazakh-Speech-Commands-Dataset\nDescription: The dataset contains 3,623 utterances for 35 commands. The utterances were saved in the WAV format with a sampling rate of 16 kHz. The dataset was collected from 119 participants (62 males, 57 females) from different regions of Kazakhstan.\n\n\t\n\t\t\nID\nCommand (en)\nCommand (kk)\n#‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/kazakh-speech-commands.","url":"https://huggingface.co/datasets/issai/kazakh-speech-commands","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Kazakh","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"voa_myanmar_asr_audio_2","keyword":"speech","description":"‚∏ª\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset was created by scraping and segmenting over 4,000 episodes of the VOA Burmese morning radio program. From that archive, 3,687 MP3 files were extracted and processed. This dataset contains sentence-level audio chunks suitable for ASR and speech-related model training.\nThe current release (voa_batch_001.tar and voa_batch_003.tar) contains a combined total of ~152,300 sentence-level audio chunks derived from the first 420 MP3 files in the archive, totaling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/voa_myanmar_asr_audio_2.","url":"https://huggingface.co/datasets/freococo/voa_myanmar_asr_audio_2","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Public Domain Dedication & License","license_url":"https://scancode-licensedb.aboutcode.org/pddl-1.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","pddl"],"keywords_longer_than_N":true},
	{"name":"voa_myanmar_asr_audio_2","keyword":"automatic-speech-recognition","description":"‚∏ª\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset was created by scraping and segmenting over 4,000 episodes of the VOA Burmese morning radio program. From that archive, 3,687 MP3 files were extracted and processed. This dataset contains sentence-level audio chunks suitable for ASR and speech-related model training.\nThe current release (voa_batch_001.tar and voa_batch_003.tar) contains a combined total of ~152,300 sentence-level audio chunks derived from the first 420 MP3 files in the archive, totaling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/voa_myanmar_asr_audio_2.","url":"https://huggingface.co/datasets/freococo/voa_myanmar_asr_audio_2","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Public Domain Dedication & License","license_url":"https://scancode-licensedb.aboutcode.org/pddl-1.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","pddl"],"keywords_longer_than_N":true},
	{"name":"cv-corpus-17.0-zh-CN-client_id-grouped","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tcv-corpus-17.0-zh-CN-client_id-grouped\n\t\n\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nThe dataset is derived from the Common Voice dataset.\nThe original dataset is available at Common Voice Dataset.\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\nEach group is filtered to include only client IDs with a minimum of 30 samples and a maximum‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-CN-client_id-grouped.","url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-CN-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","commonvoice","Chinese"],"keywords_longer_than_N":true},
	{"name":"GLOBE_V2","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tImportant notice\n\t\n\nDifferences between V2 version and the version described in paper:\n\nThe V2 version provide audio in 44.1kHz sample rate. (Supersampling)\nThe V2 versionn removed some samples (~5%) due to the volumn and text aligment issues.\n\n\n\t\n\t\t\n\t\tGlobe\n\t\n\nThe full paper can be accessed here: arXiv\nAn online demo can be accessed here: Github\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nThis paper introduces GLOBE, a high-quality English corpus with worldwide accents, specifically designed to address the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE_V2.","url":"https://huggingface.co/datasets/MushanW/GLOBE_V2","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"sitata","keyword":"automatic-speech-recognition","description":"This dataset contains an audio recording of each sentence in the book jan Sitata.\nThe author pronoucned each sentence, including questions and exclamations,\nwith the intonation as that of a declarative sentence.\nThis makes the dataset quite homogeneous.\nEvery tenth fragment is in the test folder; the rest is in the train folder.\nEach is a .wav file with a bit rate of 16¬†kHz. In total, there is 63¬†minutes of audio in this dataset.\n","url":"https://huggingface.co/datasets/casperdewith/sitata","creator_name":"Casper de With","creator_url":"https://huggingface.co/casperdewith","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Toki Pona","cc0-1.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"ro-offense-fb","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-FB-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFB-RO-Offense corpus, an offensive speech dataset containing 4,455 user-generated comments from Facebook live broadcasts available in Romanian\nThe annotation follows the hierarchical tagset proposed in the Germeval 2018 Dataset. \nThe following Classes are available:\n\nOTHER: Non-Offensive Language\nOFFENSIVE:\nPROFANITY\nINSULT\nABUSE\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/upb-nlp/ro-offense-fb.","url":"https://huggingface.co/datasets/upb-nlp/ro-offense-fb","creator_name":"POLITEHNICA Bucharest NLP Group","creator_url":"https://huggingface.co/upb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ro-offense-fb","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-FB-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFB-RO-Offense corpus, an offensive speech dataset containing 4,455 user-generated comments from Facebook live broadcasts available in Romanian\nThe annotation follows the hierarchical tagset proposed in the Germeval 2018 Dataset. \nThe following Classes are available:\n\nOTHER: Non-Offensive Language\nOFFENSIVE:\nPROFANITY\nINSULT\nABUSE\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/upb-nlp/ro-offense-fb.","url":"https://huggingface.co/datasets/upb-nlp/ro-offense-fb","creator_name":"POLITEHNICA Bucharest NLP Group","creator_url":"https://huggingface.co/upb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"myanmar-written-corpus","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tMyanmar Written Corpus\n\t\n\nThe Myanmar Written Corpus is a comprehensive collection of high-quality, but not fully CLEAN, written Myanmar text, designed to address the lack of large-scale, openly accessible resources for Myanmar Natural Language Processing (NLP). It is tailored to support various tasks such as text-to-speech (TTS), automatic speech recognition (ASR), translation, text generation, and more.\nThis dataset serves as a critical resource for researchers and developers aiming‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/myanmar-written-corpus.","url":"https://huggingface.co/datasets/freococo/myanmar-written-corpus","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","text-to-speech","Burmese","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"western_poe_karen_asr","keyword":"automatic-speech-recognition","description":"This is the first public Western Poe Karen language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tWestern Poe Karen ASR\n\t\n\nThis dataset contains audio recordings and aligned transcriptions in the Western Poe Karen language (also known in linguistic literature as Western Pwo or Delta Pwo, ISO 639-3: pwo), a Karenic language spoken primarily in the Ayeyarwady Delta region of Myanmar. Although linguists commonly refer to this language as Western Pwo Karen, the community and this project prefer the spelling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/western_poe_karen_asr.","url":"https://huggingface.co/datasets/freococo/western_poe_karen_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"western_poe_karen_asr","keyword":"automatic-speech-recognition","description":"This is the first public Western Poe Karen language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tWestern Poe Karen ASR\n\t\n\nThis dataset contains audio recordings and aligned transcriptions in the Western Poe Karen language (also known in linguistic literature as Western Pwo or Delta Pwo, ISO 639-3: pwo), a Karenic language spoken primarily in the Ayeyarwady Delta region of Myanmar. Although linguists commonly refer to this language as Western Pwo Karen, the community and this project prefer the spelling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/western_poe_karen_asr.","url":"https://huggingface.co/datasets/freococo/western_poe_karen_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"commonvoice-12.0-arabic-voice-converted","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Voice Converted Arabic Common Voice 12.0\n\t\n\nThis dataset is derived from the Common Voice Arabic Corpus 12.0 and includes automatically diacritized transcriptions and phoneme representations for the original augmented audio data. The recordings feature Arabic text read aloud by users, where the text was initially undiacritized, allowing for potential reading errors. The diacritization and phonemes were generated automatically, resulting in a dataset that is valuable‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xmodar/commonvoice-12.0-arabic-voice-converted.","url":"https://huggingface.co/datasets/xmodar/commonvoice-12.0-arabic-voice-converted","creator_name":"Modar M. Alfadly","creator_url":"https://huggingface.co/xmodar","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","cc0-1.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"e-commerce-customersupport-hinglish-audio","keyword":"speech","description":"\n\t\n\t\t\n\t\tE-Commerce Customer Support Hinglish Audio Dataset\n\t\n\nText spoken by all participants:\n\"Mera order abhi tak nahi aaya, uska tracking kar sakte hain? Kal tak aana tha, mujhe lagta hai kahin kho gaya. Please update dein.\"\nThe dataset supports training and evaluation of models in:\n\nAutomatic Speech Recognition (ASR)\nEmotional tone classification\nVoice synthesis and generation\nEmotion-aware conversational agents\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntended Uses\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t‚úÖ Direct Use\n\t\n\n\nTraining and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/e-commerce-customersupport-hinglish-audio.","url":"https://huggingface.co/datasets/Kratos-AI/e-commerce-customersupport-hinglish-audio","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"toxic_conversations_50k","keyword":"hate-speech-detection","description":"\n  ToxicConversationsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nCollection of comments from the Civil Comments platform together with annotations if the comment is toxic or not.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\nReference\nhttps://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification/overview\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/toxic_conversations_50k.","url":"https://huggingface.co/datasets/mteb/toxic_conversations_50k","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"omega-multimodal","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tOMEGA Labs Bittensor Subnet: Multimodal Dataset for AGI Research\n\t\n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThe OMEGA Labs Bittensor Subnet Dataset is a groundbreaking resource for accelerating Artificial General Intelligence (AGI) research and development. This dataset, powered by the Bittensor decentralized network, aims to be the world's largest multimodal dataset, capturing the vast landscape of human knowledge and creation.\nWith over 1 million hours of footage and 30 million+ 2-minute video‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/omegalabsinc/omega-multimodal.","url":"https://huggingface.co/datasets/omegalabsinc/omega-multimodal","creator_name":"OMEGA Labs, Inc.","creator_url":"https://huggingface.co/omegalabsinc","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["video-text-to-text","video-classification","image-classification","image-to-text","image-to-video"],"keywords_longer_than_N":true},
	{"name":"persian-voice-v1","keyword":"speech","description":"\n\t\n\t\t\n\t\tüó£Ô∏è Common Voice 17 ‚Äî Persian (Spelling-Corrected Edition)\n\t\n\nThis is a refined version of the Persian subset of Mozilla's Common Voice 17 dataset, specially curated to enhance the performance of ASR (Automatic Speech Recognition) systems in Persian.\n\n\t\n\t\t\n\t\tüõ†Ô∏è Why this matters\n\t\n\nThe original dataset contained a significant number of spelling inconsistencies and typographical errors, which negatively impacted transcription accuracy and model alignment.\n\n\t\n\t\t\n\t\t‚ú® What‚Äôs improved‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vhdm/persian-voice-v1.","url":"https://huggingface.co/datasets/vhdm/persian-voice-v1","creator_name":"Vahid Mahmoudian","creator_url":"https://huggingface.co/vhdm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Vibravox_dummy","keyword":"automatic-speech-recognition","description":"zinc75/Vibravox_dummy dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zinc75/Vibravox_dummy","creator_name":"√âric Bavu","creator_url":"https://huggingface.co/zinc75","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"persian-voice-v1","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tüó£Ô∏è Common Voice 17 ‚Äî Persian (Spelling-Corrected Edition)\n\t\n\nThis is a refined version of the Persian subset of Mozilla's Common Voice 17 dataset, specially curated to enhance the performance of ASR (Automatic Speech Recognition) systems in Persian.\n\n\t\n\t\t\n\t\tüõ†Ô∏è Why this matters\n\t\n\nThe original dataset contained a significant number of spelling inconsistencies and typographical errors, which negatively impacted transcription accuracy and model alignment.\n\n\t\n\t\t\n\t\t‚ú® What‚Äôs improved‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vhdm/persian-voice-v1.","url":"https://huggingface.co/datasets/vhdm/persian-voice-v1","creator_name":"Vahid Mahmoudian","creator_url":"https://huggingface.co/vhdm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"persian-voice-v1","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tüó£Ô∏è Common Voice 17 ‚Äî Persian (Spelling-Corrected Edition)\n\t\n\nThis is a refined version of the Persian subset of Mozilla's Common Voice 17 dataset, specially curated to enhance the performance of ASR (Automatic Speech Recognition) systems in Persian.\n\n\t\n\t\t\n\t\tüõ†Ô∏è Why this matters\n\t\n\nThe original dataset contained a significant number of spelling inconsistencies and typographical errors, which negatively impacted transcription accuracy and model alignment.\n\n\t\n\t\t\n\t\t‚ú® What‚Äôs improved‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vhdm/persian-voice-v1.","url":"https://huggingface.co/datasets/vhdm/persian-voice-v1","creator_name":"Vahid Mahmoudian","creator_url":"https://huggingface.co/vhdm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Vibravox_dummy","keyword":"text-to-speech","description":"zinc75/Vibravox_dummy dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zinc75/Vibravox_dummy","creator_name":"√âric Bavu","creator_url":"https://huggingface.co/zinc75","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","audio-classification","text-to-speech","speaker-identification"],"keywords_longer_than_N":true},
	{"name":"Theresa-Recording","keyword":"text-to-speech","description":"None1145/Theresa-Recording dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/None1145/Theresa-Recording","creator_name":"None","creator_url":"https://huggingface.co/None1145","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Japanese","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Lappland","keyword":"text-to-speech","description":"None1145/Lappland dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/None1145/Lappland","creator_name":"None","creator_url":"https://huggingface.co/None1145","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","English"],"keywords_longer_than_N":true},
	{"name":"airline-customersupport-Hinglish-audio","keyword":"speech","description":"\n\t\n\t\t\n\t\tAirline Customer Support Hinglish Audio Dataset\n\t\n\n*This dataset contains intentionally low-quality (‚ÄúB-grade‚Äù) data. It has been curated to include noisy, imperfect, or otherwise suboptimal samples for the purpose of testing model robustness and performance under degraded input conditions\nText spoken by all participants:\n\"Meri flight delay ho gayi, next flight mein seat book kar sakte hain? Main airport par phasa hoon aur jaldi destination pahunchna chahta hoon.\"\nThe dataset supports‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/airline-customersupport-Hinglish-audio.","url":"https://huggingface.co/datasets/Kratos-AI/airline-customersupport-Hinglish-audio","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"spelling-correction-french-news","keyword":"grammar","description":"\n\t\n\t\t\n\t\tSpelling correction dataset (French)\n\t\n\nThis dataset is generated by transforming/corrupting sentences of a French news corpus\nprovided by the University of Leipzig.\nThe following transformations are applied to words in the sentences:\n\nconcatenation of pairs of words\nswapping of neighboring letters in words\ninsertion\ndeletion\nreplacement (by neighboring characters in AZERTY keyboard)\n\n\n\t\n\t\t\n\t\n\t\n\t\tGeneration\n\t\n\n./scripts/get_data.py -t news -y 2023 -s 10K\n./scripts/generate_dataset.py‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/spelling-correction-french-news.","url":"https://huggingface.co/datasets/fdemelo/spelling-correction-french-news","creator_name":"Fl√°vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["French","mit","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"nchlt_speech_tsn","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tNCHLT Speech Corpus -- Setswana\n\t\n\nThis is the Setswana language part of the NCHLT Speech Corpus of the South African languages.\nLanguage code (ISO 639): tsn\nURI: https://hdl.handle.net/20.500.12185/281\n\n\t\n\t\t\n\t\tLicence:\n\t\n\nCreative Commons Attribution 3.0 Unported License (CC BY 3.0): http://creativecommons.org/licenses/by/3.0/legalcode\n\n\t\n\t\t\n\t\tAttribution:\n\t\n\nThe Department of Arts and Culture of the government of the Republic of South Africa (DAC), Council for Scientific and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/danielshaps/nchlt_speech_tsn.","url":"https://huggingface.co/datasets/danielshaps/nchlt_speech_tsn","creator_name":"Daniel van Niekerk","creator_url":"https://huggingface.co/danielshaps","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Tswana","cc-by-3.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"MCEval8K","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tMCEval8K\n\t\n\nMCEval8K is a diverse multiple-choice evaluation benchmark for probing language models‚Äô (LMs) understanding of a broad range of language skills using neuron-level analysis. \nIt was introduced in the ACL 2025 paper - \"Neuron Empirical Gradient: Discovering and Quantifying Neurons‚Äô Global Linear Controllability\".\n\n\t\n\t\t\n\t\tüîç Overview\n\t\n\nMCEval8K consists of 22 tasks grouped into six skill genres, covering linguistic analysis, content classification, reasoning, factuality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iszhaoxin/MCEval8K.","url":"https://huggingface.co/datasets/iszhaoxin/MCEval8K","creator_name":"XIN ZHAO","creator_url":"https://huggingface.co/iszhaoxin","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","natural-language-inference","acceptability-classification"],"keywords_longer_than_N":true},
	{"name":"dataset_for_STT_TTSmodels","keyword":"text-to-speech","description":"Beehzod/dataset_for_STT_TTSmodels dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Beehzod/dataset_for_STT_TTSmodels","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Uzbek","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"CommonVoicesDelta21_ro","keyword":"speech","description":"\n\t\n\t\t\n\t\tCommon Voices Delta 21.0 (Romanian)\n\t\n\n\nCommon Voices is an open-source dataset of speech recordings created by \nMozilla to improve speech recognition technologies. \nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\n\n\n\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \nessential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ionut-visan/CommonVoicesDelta21_ro.","url":"https://huggingface.co/datasets/ionut-visan/CommonVoicesDelta21_ro","creator_name":"Ionut Visan","creator_url":"https://huggingface.co/ionut-visan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"CommonVoicesDelta21_ro","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tCommon Voices Delta 21.0 (Romanian)\n\t\n\n\nCommon Voices is an open-source dataset of speech recordings created by \nMozilla to improve speech recognition technologies. \nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\n\n\n\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \nessential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ionut-visan/CommonVoicesDelta21_ro.","url":"https://huggingface.co/datasets/ionut-visan/CommonVoicesDelta21_ro","creator_name":"Ionut Visan","creator_url":"https://huggingface.co/ionut-visan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"CommonVoicesDelta21_ro","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tCommon Voices Delta 21.0 (Romanian)\n\t\n\n\nCommon Voices is an open-source dataset of speech recordings created by \nMozilla to improve speech recognition technologies. \nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\n\n\n\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \nessential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ionut-visan/CommonVoicesDelta21_ro.","url":"https://huggingface.co/datasets/ionut-visan/CommonVoicesDelta21_ro","creator_name":"Ionut Visan","creator_url":"https://huggingface.co/ionut-visan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"vai-speech-text-parallel","keyword":"speech","description":"\n\t\n\t\t\n\t\tVai Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 23286 parallel speech-text pairs for Vai, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Vai - vai\nTask: Speech Recognition, Text-to-Speech\nSize: 23286 audio files > 1KB (small/corrupted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/vai-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/vai-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Vai"],"keywords_longer_than_N":true},
	{"name":"vai-speech-text-parallel","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tVai Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 23286 parallel speech-text pairs for Vai, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Vai - vai\nTask: Speech Recognition, Text-to-Speech\nSize: 23286 audio files > 1KB (small/corrupted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/vai-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/vai-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Vai"],"keywords_longer_than_N":true},
	{"name":"samromur_asr","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for samromur_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a modfied copy of the dataset from The Language and Voice Laboratory in RU.\nThis is the first release of the Samr√≥mur Icelandic Speech corpus that contains 100.000 validated utterances.\nThe corpus is a result of the crowd-sourcing effort run by the Language and Voice Lab at the Reykjavik University, in cooperation with Almannar√≥mur, Center for Language Technology.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe audio is in Icelandic.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DavidErikMollberg/samromur_asr.","url":"https://huggingface.co/datasets/DavidErikMollberg/samromur_asr","creator_name":"David Erik Mollberg","creator_url":"https://huggingface.co/DavidErikMollberg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"common_voice_13_0_dv_preprocessed","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 13.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Common Voice dataset consists of a unique MP3 and corresponding text file. \nMany of the 27141 recorded hours in the dataset also include demographic metadata like age, sex, and accent \nthat can help improve the accuracy of speech recognition engines.\nThe dataset currently consists of 17689 validated hours in 108 languages, but more voices and languages are always added. \nTake a look at the Languages page to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ssahir/common_voice_13_0_dv_preprocessed.","url":"https://huggingface.co/datasets/ssahir/common_voice_13_0_dv_preprocessed","creator_name":"Saad Sahir","creator_url":"https://huggingface.co/ssahir","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"vai-speech-text-parallel","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tVai Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 23286 parallel speech-text pairs for Vai, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Vai - vai\nTask: Speech Recognition, Text-to-Speech\nSize: 23286 audio files > 1KB (small/corrupted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/vai-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/vai-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Vai"],"keywords_longer_than_N":true},
	{"name":"FLEURS-GA-EN","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis is the Irish-to-English portion of the FLEURS dataset.\nFleurs is the speech version of the FLoRes machine translation benchmark.\nThe Irish portion consists of 3991 utterances, which correspond to approximately 16 hours and 45 minutes (16:45:17) of audio data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'audio', 'text_ga', 'text_en'],\n        num_rows: 3991\n    })\n})\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@article{fleurs2022arxiv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/FLEURS-GA-EN.","url":"https://huggingface.co/datasets/ymoslem/FLEURS-GA-EN","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"KikuyuASR_trainingdataset","keyword":"automatic-speech-recognition","description":"This dataset is obtained as part of AIEP prject by Digital Green and Karya from the extension workers, lead farmers and farmers.\nProcess of collection of data:\nSelected users were given the option of doing a task and getting paid for it.\nThe users were supposed to record the sentence as it appeared on the screen.\nThe audio file thus obtained was validated matched with the sentences to fine tune the model.\nAlso available are the python script that helps in processing and splitting the data into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CGIAR/KikuyuASR_trainingdataset.","url":"https://huggingface.co/datasets/CGIAR/KikuyuASR_trainingdataset","creator_name":"CGIAR","creator_url":"https://huggingface.co/CGIAR","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kikuyu","apache-2.0","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"aozora-text-difficulty","keyword":"linguistics","description":"\n\t\n\t\t\n\t\tAozora Text Difficulty Dataset\n\t\n\nThis dataset contains Japanese literary texts from the Aozora Bunko digital library, enhanced with jReadability-based difficulty analysis for Japanese language learning and curriculum development.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nSource: Aozora Bunko (ÈùíÁ©∫ÊñáÂ∫´) - Japan's premier digital library of public domain literature\nEnhancement: jReadability-based difficulty scoring using research-backed Japanese readability models\nPrimary Methodology: jReadability - A‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ronantakizawa/aozora-text-difficulty.","url":"https://huggingface.co/datasets/ronantakizawa/aozora-text-difficulty","creator_name":"Ronan Takizawa","creator_url":"https://huggingface.co/ronantakizawa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Japanese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"FLEURS-GA-EN","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis is the Irish-to-English portion of the FLEURS dataset.\nFleurs is the speech version of the FLoRes machine translation benchmark.\nThe Irish portion consists of 3991 utterances, which correspond to approximately 16 hours and 45 minutes (16:45:17) of audio data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'audio', 'text_ga', 'text_en'],\n        num_rows: 3991\n    })\n})\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@article{fleurs2022arxiv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/FLEURS-GA-EN.","url":"https://huggingface.co/datasets/ymoslem/FLEURS-GA-EN","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","Irish","English"],"keywords_longer_than_N":true},
	{"name":"testtr12","keyword":"speech","description":"\n\t\n\t\t\n\t\ttesttr12\n\t\n\nThis is a merged speech dataset containing 165 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 165\nSpeakers: 8\nLanguages: en\nEmotions: happy, angry, neutral\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral, happy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/testtr12.","url":"https://huggingface.co/datasets/Codyfederer/testtr12","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"hausa_voice_dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for \"hausa_voice_dataset\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nDataset Name: Hausa Voice Dataset\nDescription: This dataset contains Hausa language audio samples from Common Voice. The dataset includes audio files and their corresponding transcriptions, designed for text-to-speech (TTS) and automatic speech recognition (ASR) research and applications.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nConfigs:\n\ndefault\n\nData Files:\n\nSplit: train\n\nDataset Info:\n\nFeatures:\naudio: Audio file (mono‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mide7x/hausa_voice_dataset.","url":"https://huggingface.co/datasets/mide7x/hausa_voice_dataset","creator_name":"Olumide Adewole","creator_url":"https://huggingface.co/mide7x","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","keyword-spotting","audio-language-identification","Hausa"],"keywords_longer_than_N":true},
	{"name":"testtr12","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\ttesttr12\n\t\n\nThis is a merged speech dataset containing 165 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 165\nSpeakers: 8\nLanguages: en\nEmotions: happy, angry, neutral\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral, happy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/testtr12.","url":"https://huggingface.co/datasets/Codyfederer/testtr12","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"testtr12","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\ttesttr12\n\t\n\nThis is a merged speech dataset containing 165 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 165\nSpeakers: 8\nLanguages: en\nEmotions: happy, angry, neutral\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral, happy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/testtr12.","url":"https://huggingface.co/datasets/Codyfederer/testtr12","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"FeruzaSpeechDualText","keyword":"automatic-speech-recognition","description":"nickoo004/FeruzaSpeechDualText dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/nickoo004/FeruzaSpeechDualText","creator_name":"Nicholas","creator_url":"https://huggingface.co/nickoo004","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"vietnamese-audio-dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tVietnamese Audio Dataset\n\t\n\n*This dataset contains high-quality (‚ÄúA-grade‚Äù) data. It has been carefully curated, cleaned, and verified to ensure accuracy, completeness, and consistency, making it suitable for high-stakes or production-grade model training.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:\n    - anoushka@kgen.io\n    - abhishek.vadapalli@kgen.io\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Categories: Speech Emotion Recognition (SER)\nSupported Tasks:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/vietnamese-audio-dataset.","url":"https://huggingface.co/datasets/Kratos-AI/vietnamese-audio-dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Vietnamese","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"speech-recognition","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"news_youtube_uzbek_speech_dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tNews Youtube Uzbek Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio clips and their corresponding transcriptions in the Uzbek language with differenent dialects. The data was collected from publicly available news videos on YouTube. It is designed for training and evaluating Automatic Speech Recognition (ASR) models.\nMost of the content comes from the Kunuz, Qalampir YouTube channels. The data was transcribed using Gemini 2.5 Pro and was intelligently‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/islomov/news_youtube_uzbek_speech_dataset.","url":"https://huggingface.co/datasets/islomov/news_youtube_uzbek_speech_dataset","creator_name":"Sardor Islomov","creator_url":"https://huggingface.co/islomov","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"MCIF","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nMCIF (Multimodal Crosslingual Instruction Following) is a multilingual human-annotated benchmark \nbased on scientific talks that is designed to evaluate instruction-following in crosslingual, \nmultimodal settings over both short- and long-form inputs. \nMCIF spans three core modalities -- speech, vision, and text -- and four diverse languages (English, German, Italian, and Chinese), \nenabling a comprehensive evaluation of MLLMs' abilities‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/danniliu/MCIF.","url":"https://huggingface.co/datasets/danniliu/MCIF","creator_name":"Danni Liu","creator_url":"https://huggingface.co/danniliu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","question-answering","summarization","visual-question-answering","translation"],"keywords_longer_than_N":true},
	{"name":"Hellenic-greek-parliamentary-speech","keyword":"speech","description":"\n\t\n\t\t\n\t\tHParl: Hellenic Parliamentary Speech Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nNote: This is a processed version of the original HParl dataset. This dataset is not created or maintained by the original authors.\nLink to the original source: https://inventory.clarin.gr/corpus/1602\nHParl is a 120-hour speech corpus for Modern Greek, originally collected from parliamentary proceedings of the Hellenic Parliament by the Institute for Language and Speech Processing. This version has been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Elormiden/Hellenic-greek-parliamentary-speech.","url":"https://huggingface.co/datasets/Elormiden/Hellenic-greek-parliamentary-speech","creator_name":"Elormiden","creator_url":"https://huggingface.co/Elormiden","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Greek","cc-by-4.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"nchlt_speech_nbl","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tNCHLT Speech Corpus -- isiNdebele\n\t\n\nThis is the isiNdebele language part of the NCHLT Speech Corpus of the South African languages.\nLanguage code (ISO 639): nbl\nURI: https://hdl.handle.net/20.500.12185/272\n\n\t\n\t\t\n\t\tLicence:\n\t\n\nCreative Commons Attribution 3.0 Unported License (CC BY 3.0): http://creativecommons.org/licenses/by/3.0/legalcode\n\n\t\n\t\t\n\t\tAttribution:\n\t\n\nThe Department of Arts and Culture of the government of the Republic of South Africa (DAC), Council for Scientific and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/danielshaps/nchlt_speech_nbl.","url":"https://huggingface.co/datasets/danielshaps/nchlt_speech_nbl","creator_name":"Daniel van Niekerk","creator_url":"https://huggingface.co/danielshaps","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Southern Ndebele","cc-by-3.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Urdu_Hate_Speech","keyword":"hate-speech","description":"\n\t\n\t\t\n\t\tUrdu Hate Speech\n\t\n\nA binary Urdu text classification dataset for hate-speech detection.\n\nTask: hate vs. not_hate (2 classes)\nLanguage: Urdu (ur)\nPrimary columns: text, label(In the uploaded files the columns are Tweet and Tag; see ‚ÄúHow to Use‚Äù for renaming.)\nLabels:\n0 ‚Üí not_hate\n1 ‚Üí hate\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains short-form Urdu text (e.g., social media posts) labeled for hate speech. It supports research, moderation assistance, and demos. It should not be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Adnan855570/Urdu_Hate_Speech.","url":"https://huggingface.co/datasets/Adnan855570/Urdu_Hate_Speech","creator_name":"Muhammad Adnan Mushtaq","creator_url":"https://huggingface.co/Adnan855570","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Urdu_Hate_Speech","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tUrdu Hate Speech\n\t\n\nA binary Urdu text classification dataset for hate-speech detection.\n\nTask: hate vs. not_hate (2 classes)\nLanguage: Urdu (ur)\nPrimary columns: text, label(In the uploaded files the columns are Tweet and Tag; see ‚ÄúHow to Use‚Äù for renaming.)\nLabels:\n0 ‚Üí not_hate\n1 ‚Üí hate\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains short-form Urdu text (e.g., social media posts) labeled for hate speech. It supports research, moderation assistance, and demos. It should not be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Adnan855570/Urdu_Hate_Speech.","url":"https://huggingface.co/datasets/Adnan855570/Urdu_Hate_Speech","creator_name":"Muhammad Adnan Mushtaq","creator_url":"https://huggingface.co/Adnan855570","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"gemini-flash-2.0-speech","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tüéôÔ∏è Gemini Flash 2.0 Speech Dataset\n\t\n\n\nThis is a high quality synthetic speech dataset generated by Gemini Flash 2.0 via the Multimodal Live API. It contains speech from 2 speakers - Puck (Male) and Kore (Female) in English.\nüèÖ #1 Trending Audio Dataset in Feb 2025\nüèÖ Used in training of Kokoro TTS and LLaSA 1B\n\n\t\n\t\n\t\n\t\t„ÄΩÔ∏è Stats\n\t\n\nTotal number of audio files: 47,256*2 = 94512Total duration: 1023527.20seconds (284.31 hours)   \nAverage duration: 10.83 seconds   \nShortest file: 0.6‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shb777/gemini-flash-2.0-speech.","url":"https://huggingface.co/datasets/shb777/gemini-flash-2.0-speech","creator_name":"SB","creator_url":"https://huggingface.co/shb777","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"gemini-flash-2.0-speech","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tüéôÔ∏è Gemini Flash 2.0 Speech Dataset\n\t\n\n\nThis is a high quality synthetic speech dataset generated by Gemini Flash 2.0 via the Multimodal Live API. It contains speech from 2 speakers - Puck (Male) and Kore (Female) in English.\nüèÖ #1 Trending Audio Dataset in Feb 2025\nüèÖ Used in training of Kokoro TTS and LLaSA 1B\n\n\t\n\t\n\t\n\t\t„ÄΩÔ∏è Stats\n\t\n\nTotal number of audio files: 47,256*2 = 94512Total duration: 1023527.20seconds (284.31 hours)   \nAverage duration: 10.83 seconds   \nShortest file: 0.6‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shb777/gemini-flash-2.0-speech.","url":"https://huggingface.co/datasets/shb777/gemini-flash-2.0-speech","creator_name":"SB","creator_url":"https://huggingface.co/shb777","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Trump_Voice_Dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tTrump Voice Dataset\n\t\n\nThis dataset contains audio clips of Donald Trump's speech from the World Economic Forum (WEF) 2018, paired with their corresponding transcriptions. The dataset is designed for text-to-speech (TTS) and speech recognition tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Trump Voice Dataset consists of 20 audio samples (10 train, 10 test) extracted from Donald Trump's speech at the World Economic Forum 2018. Each audio clip is approximately 10‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sakchham19/Trump_Voice_Dataset.","url":"https://huggingface.co/datasets/Sakchham19/Trump_Voice_Dataset","creator_name":"Sakchham Singh","creator_url":"https://huggingface.co/Sakchham19","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"darija-speech-to-text","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSpeech To Text Darija dataset\n\t\n\nReupload of adiren7/darija_speech_to_text\n","url":"https://huggingface.co/datasets/BrunoHays/darija-speech-to-text","creator_name":"Bruno Hays","creator_url":"https://huggingface.co/BrunoHays","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","apache-2.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Trump_Voice_Dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTrump Voice Dataset\n\t\n\nThis dataset contains audio clips of Donald Trump's speech from the World Economic Forum (WEF) 2018, paired with their corresponding transcriptions. The dataset is designed for text-to-speech (TTS) and speech recognition tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Trump Voice Dataset consists of 20 audio samples (10 train, 10 test) extracted from Donald Trump's speech at the World Economic Forum 2018. Each audio clip is approximately 10‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sakchham19/Trump_Voice_Dataset.","url":"https://huggingface.co/datasets/Sakchham19/Trump_Voice_Dataset","creator_name":"Sakchham Singh","creator_url":"https://huggingface.co/Sakchham19","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"indicvoices_mr_tagged_transcripts","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_mr_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_mr_tagged_transcripts.","url":"https://huggingface.co/datasets/WhissleAI/indicvoices_mr_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ToxiFrench","keyword":"hate-speech","description":"A curated dataset for fine-tuning toxicity classifiers and reasoning models in French.\nSupports curriculum learning and chain-of-thought annotation variants. DPO datasets are also available.\nThis script also includes configurations for Jigsaw GPT-annotated, GPT-annotated, and non-annotated data.","url":"https://huggingface.co/datasets/Naela00/ToxiFrench","creator_name":"Naela","creator_url":"https://huggingface.co/Naela00","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","French","mit","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"BulgarianStoreReviewSentimentClassfication","keyword":"hate-speech-detection","description":"\n  BulgarianStoreReviewSentimentClassfication\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nBulgarian online store review dataset for sentiment classification.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://doi.org/10.7910/DVN/TXIK9P\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"BulgarianStoreReviewSentimentClassfication\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BulgarianStoreReviewSentimentClassfication.","url":"https://huggingface.co/datasets/mteb/BulgarianStoreReviewSentimentClassfication","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"Trump_Voice_Dataset","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tTrump Voice Dataset\n\t\n\nThis dataset contains audio clips of Donald Trump's speech from the World Economic Forum (WEF) 2018, paired with their corresponding transcriptions. The dataset is designed for text-to-speech (TTS) and speech recognition tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Trump Voice Dataset consists of 20 audio samples (10 train, 10 test) extracted from Donald Trump's speech at the World Economic Forum 2018. Each audio clip is approximately 10‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sakchham19/Trump_Voice_Dataset.","url":"https://huggingface.co/datasets/Sakchham19/Trump_Voice_Dataset","creator_name":"Sakchham Singh","creator_url":"https://huggingface.co/Sakchham19","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"automatic-speech-recognition","description":"KoddaDuck/fleurs dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KoddaDuck/fleurs","creator_name":"Haodong Huang","creator_url":"https://huggingface.co/KoddaDuck","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","apache-2.0","10M<n<100M","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"peoples_speech-clean","keyword":"automatic-speech-recognition","description":"The People's Speech is a free-to-download 30,000-hour and growing supervised \nconversational English speech recognition dataset licensed for academic and \ncommercial usage under CC-BY-SA (with a CC-BY subset).","url":"https://huggingface.co/datasets/distil-whisper/peoples_speech-clean","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"tts-rj-hi-karya","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tRajasthani Hindi Speech Dataset\n\t\n\n\nThis dataset consists of audio recordings of participants reading out stories in Rajasthani Hindi, one sentence at a time. They had 98 participants from Soda, Rajasthan. Each participant read 30 stories. In total, we have 426872 recordings in this dataset. They had roughly 58 male participants and 40 female participants.\n\nPoint to Note:\nWhile random sampling suggests that most users have to their best effort tried to accurately read out the sentences‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/1rsh/tts-rj-hi-karya.","url":"https://huggingface.co/datasets/1rsh/tts-rj-hi-karya","creator_name":"Irsh Vijay","creator_url":"https://huggingface.co/1rsh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Hindi","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"common_voice_13_0","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDistil Whisper: Common Voice 13\n\t\n\nThis is a variant of the Common Voice 13 dataset, augmented to return the pseudo-labelled Whisper \nTranscriptions alongside the original dataset elements. The pseudo-labelled transcriptions were generated by \nlabelling the input audio data with the Whisper large-v2\nmodel with greedy sampling. For information on how the original dataset was curated, refer to the original \ndataset card.\n\n\t\n\t\t\n\t\n\t\n\t\tStandalone Usage\n\t\n\nFirst, install the latest version‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/distil-whisper/common_voice_13_0.","url":"https://huggingface.co/datasets/distil-whisper/common_voice_13_0","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc0-1.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"voxpopuli","keyword":"automatic-speech-recognition","description":"A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation.","url":"https://huggingface.co/datasets/facebook/voxpopuli","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","multilingual","English","German","French"],"keywords_longer_than_N":true},
	{"name":"tts-rj-hi-karya","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tRajasthani Hindi Speech Dataset\n\t\n\n\nThis dataset consists of audio recordings of participants reading out stories in Rajasthani Hindi, one sentence at a time. They had 98 participants from Soda, Rajasthan. Each participant read 30 stories. In total, we have 426872 recordings in this dataset. They had roughly 58 male participants and 40 female participants.\n\nPoint to Note:\nWhile random sampling suggests that most users have to their best effort tried to accurately read out the sentences‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/1rsh/tts-rj-hi-karya.","url":"https://huggingface.co/datasets/1rsh/tts-rj-hi-karya","creator_name":"Irsh Vijay","creator_url":"https://huggingface.co/1rsh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Hindi","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_test_clean_word_timestamp","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tWord-level timestamp annotated Librispeech ASR test set\n\t\n\nThis dataset contains word-level timestamp information for the Librispeech ASR test (clean) dataset.\nIt contains 2620 short files that have been force-aligned with its text to get reasonably accurate word-level timestamp information.\nSuitable for use in timestamp benchmarking of ASR models or audio dataset preprocessing.\nTo request access to more datasets like this, please fill out this form:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/olympusmons/librispeech_asr_test_clean_word_timestamp.","url":"https://huggingface.co/datasets/olympusmons/librispeech_asr_test_clean_word_timestamp","creator_name":"ML","creator_url":"https://huggingface.co/olympusmons","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cahya/fleurs.","url":"https://huggingface.co/datasets/cahya/fleurs","creator_name":"Cahya Wirawan","creator_url":"https://huggingface.co/cahya","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"speech-recognition","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cahya/fleurs.","url":"https://huggingface.co/datasets/cahya/fleurs","creator_name":"Cahya Wirawan","creator_url":"https://huggingface.co/cahya","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"tts-ggl","keyword":"speech","description":"\n\t\n\t\t\n\t\tAudio Dataset\n\t\n\nThis dataset contains audio segments with transcriptions for speech recognition and text-to-speech tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\ndataset.json: Complete dataset in JSON format\ntrain.jsonl: Dataset in JSONL format for use with Hugging Face datasets library\ndataset_info.json: Metadata about the dataset structure\n\nEach entry contains:\n\nfile: Original filename\naudio: Audio data with sampling rate\ntranscription: Text transcription\nduration: Audio duration in seconds\n\n","url":"https://huggingface.co/datasets/jsbeaudry/tts-ggl","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"SER-MSPMEA-Spanish","keyword":"speech","description":"\n\t\n\t\t\n\t\tMSPMEA-Spanish: Synthetic Emotional Speech Dataset üó£Ô∏èüá™üá∏\n\t\n\n\n\t\n\t\t\n\t\tMultilingual Speech Emotion Recognition in Iberian Languages: A Generative AI Framework with LLMs and TTS Data Augmentation\n\t\n\nJaime Bellver-Soler et al., 2025\nüìÑ Read the paper on SSRN\n\n\n\t\n\t\t\n\t\tüóÇ Overview\n\t\n\nMSPMEA-Spanish is the first synthetic Spanish emotional speech extension of the MSP-Podcast dataset, created using the methodology introduced in:\n\nBellver-Soler, J. et al. (2025). Multilingual Speech Emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jaimebellver/SER-MSPMEA-Spanish.","url":"https://huggingface.co/datasets/jaimebellver/SER-MSPMEA-Spanish","creator_name":"Jaime Bellver","creator_url":"https://huggingface.co/jaimebellver","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Spanish","cc-by-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"isizulu-asr-test","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tisiZulu Speech Recognition Augmented Test Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains augmented speech recordings and transcriptions for isiZulu, one of South Africa's official languages.\nThe dataset has been optimized for use with OpenAI's Whisper ASR models.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nNumber of samples: 699\nLanguage: isiZulu (Zul)\nAudio format: WAV, 16kHz, mono, 16-bit\nMaximum duration: 30 seconds (truncated for Whisper compatibility)\nTranscription format:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zionia/isizulu-asr-test.","url":"https://huggingface.co/datasets/zionia/isizulu-asr-test","creator_name":"Zion van Wyk","creator_url":"https://huggingface.co/zionia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Zulu","Xhosa","Southern Ndebele","Pedi"],"keywords_longer_than_N":true},
	{"name":"tts-ggl","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tAudio Dataset\n\t\n\nThis dataset contains audio segments with transcriptions for speech recognition and text-to-speech tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\ndataset.json: Complete dataset in JSON format\ntrain.jsonl: Dataset in JSONL format for use with Hugging Face datasets library\ndataset_info.json: Metadata about the dataset structure\n\nEach entry contains:\n\nfile: Original filename\naudio: Audio data with sampling rate\ntranscription: Text transcription\nduration: Audio duration in seconds\n\n","url":"https://huggingface.co/datasets/jsbeaudry/tts-ggl","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"isizulu-asr-specaugment","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tisiZulu Speech Recognition Augmented Dataset - SpecAugment\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains augmented speech recordings and transcriptions for isiZulu, one of South Africa's official languages.\nThe dataset has been optimized for use with OpenAI's Whisper ASR models.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nNumber of samples: 699\nLanguage: isiZulu (Zul)\nAudio format: WAV, 16kHz, mono, 16-bit\nMaximum duration: 30 seconds (truncated for Whisper compatibility)\nTranscription‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zionia/isizulu-asr-specaugment.","url":"https://huggingface.co/datasets/zionia/isizulu-asr-specaugment","creator_name":"Zion van Wyk","creator_url":"https://huggingface.co/zionia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Zulu","Xhosa","Southern Ndebele","Pedi"],"keywords_longer_than_N":true},
	{"name":"MCIF","keyword":"automatic-speech-recognition","description":"\n\n\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nMCIF (Multimodal Crosslingual Instruction Following) is a multilingual human-annotated benchmark \nbased on scientific talks that is designed to evaluate instruction-following in crosslingual,\nmultimodal settings over both short- and long-form inputs. \nMCIF spans three core modalities -- speech, vision, and text -- and four diverse languages (English, German, Italian, and Chinese), \nenabling a comprehensive evaluation of MLLMs'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/MCIF.","url":"https://huggingface.co/datasets/FBK-MT/MCIF","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","question-answering","summarization","visual-question-answering","translation"],"keywords_longer_than_N":true},
	{"name":"KOTOX","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tKOTOX\n\t\n\n\n\t\n\t\t\n\t\t: A Korean Toxic Dataset for Deobfuscation and Detoxification\n\t\n\nHate Speech Detection dataset üëâ KOTOX-classificationDetoxification or Sanitization dataset üëâ Here!\nüìö paper | \nüêà‚Äç‚¨õ git\n\n\t\n\t\t\n\t\n\t\n\t\tüìù Dataset Summary\n\t\n\nKOTOX is the first Korean dataset designed for both toxic text detoxification and obfuscation robustness.   \nIt provides paired neutral-toxic sentences and their obfuscated counterparts, constructed with 17 linguistically grounded transformation rules‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ssgyejin/KOTOX.","url":"https://huggingface.co/datasets/ssgyejin/KOTOX","creator_name":"leeyejin","creator_url":"https://huggingface.co/ssgyejin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","hate-speech-detection","rule-based","llm-generated"],"keywords_longer_than_N":true},
	{"name":"tts-ggl","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tAudio Dataset\n\t\n\nThis dataset contains audio segments with transcriptions for speech recognition and text-to-speech tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\ndataset.json: Complete dataset in JSON format\ntrain.jsonl: Dataset in JSONL format for use with Hugging Face datasets library\ndataset_info.json: Metadata about the dataset structure\n\nEach entry contains:\n\nfile: Original filename\naudio: Audio data with sampling rate\ntranscription: Text transcription\nduration: Audio duration in seconds\n\n","url":"https://huggingface.co/datasets/jsbeaudry/tts-ggl","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"hausa-tts-csv","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tHausa TTS Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Hausa language text-to-speech (TTS) recordings from multiple speakers. It includes audio files paired with their corresponding Hausa text transcriptions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized as follows:\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îú‚îÄ‚îÄ metadata.csv                    # Metadata (source, audio paths, text)\n‚îÇ   ‚îî‚îÄ‚îÄ audio_files/\n‚îÇ       ‚îú‚îÄ‚îÄ 97f373e8-f6e6-.../          # Speaker 1 audio files\n‚îÇ       ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aybee5/hausa-tts-csv.","url":"https://huggingface.co/datasets/Aybee5/hausa-tts-csv","creator_name":"Ibrahim Abdullahi","creator_url":"https://huggingface.co/Aybee5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","Hausa","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"audio-keyword-spotting","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Audio Keyword Spotting\n\t\n\n \n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe initial version of this dataset is a subset of MLCommons/ml_spoken_words, which is derived from Common Voice, designed for easier loading. Specifically, the subset consists of ml_spoken_words files filtered by the names and placenames transliterated in Bible translations, as found in trabina. For our initial experiment, we have focused only on English, Spanish, and Indonesian, three languages whose name‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sil-ai/audio-keyword-spotting.","url":"https://huggingface.co/datasets/sil-ai/audio-keyword-spotting","creator_name":"SIL Global - AI","creator_url":"https://huggingface.co/sil-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","machine-generated","other","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"ami","keyword":"automatic-speech-recognition","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\nnon-native speakers. \\n","url":"https://huggingface.co/datasets/edinburghcstr/ami","creator_name":"University of Edingburgh - Centre For Speech Technology Research","creator_url":"https://huggingface.co/edinburghcstr","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"librispeech-phones-and-mel","keyword":"automatic-speech-recognition","description":"Dataset containing Mel Spectrograms, Prosody and Phone Alignments for the LibriSpeech dataset.","url":"https://huggingface.co/datasets/cdminix/librispeech-phones-and-mel","creator_name":"Christoph Minixhofer","creator_url":"https://huggingface.co/cdminix","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","100K<n<1M","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"edited_common_voice","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for \"edited_common_voice\"\n\t\n\nMore Information needed\nThis dataset is a Thai TTS dataset that use the voice from Common Voice dataset and modify the voice to not to sound like the original.\nMedium: Text-To-Speech ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏î‡πâ‡∏ß‡∏¢ Tacotron2\n","url":"https://huggingface.co/datasets/lunarlist/edited_common_voice","creator_name":"taetiya taechamatavorn","creator_url":"https://huggingface.co/lunarlist","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Thai","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ami","keyword":"automatic-speech-recognition","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\nnon-native speakers. \\n","url":"https://huggingface.co/datasets/legacy-datasets/ami","creator_name":"Legacy Datasets","creator_url":"https://huggingface.co/legacy-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"vox_celeb","keyword":"automatic-speech-recognition","description":"VoxCeleb is an audio-visual dataset consisting of short clips of human speech, extracted from interview videos uploaded to YouTube","url":"https://huggingface.co/datasets/101arrowz/vox_celeb","creator_name":"Arjun Barrett","creator_url":"https://huggingface.co/101arrowz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","image-classification","speaker-identification","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"malromur_asr","keyword":"automatic-speech-recognition","description":"The M√°lr√≥mur corpus is an open source corpus of Icelandic voice samples.","url":"https://huggingface.co/datasets/language-and-voice-lab/malromur_asr","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ar_sarcasm","keyword":"sarcasm-detection","description":"\n\t\n\t\t\n\t\tDataset Card for ArSarcasm\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nArSarcasm is a new Arabic sarcasm detection dataset.\nThe dataset was created using previously available Arabic sentiment analysis\ndatasets (SemEval 2017\nand ASTD) and adds sarcasm and\ndialect labels to them.\nThe dataset contains 10,547 tweets, 1,682 (16%) of which are sarcastic.\nFor more details, please check the paper\nFrom Arabic Sentiment Analysis to Sarcasm Detection: The ArSarcasm Dataset\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iabufarha/ar_sarcasm.","url":"https://huggingface.co/datasets/iabufarha/ar_sarcasm","creator_name":"Ibrahim","creator_url":"https://huggingface.co/iabufarha","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"raddromur_asr","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for raddromur_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Raddr√≥mur Icelandic Speech 22.09\" (\"Raddr√≥mur Corpus\" for short) is an Icelandic corpus created by the Language and Voice Laboratory (LVL) at Reykjav√≠k University (RU) in 2022. It is made out of radio podcasts mostly taken from R√öV (ruv.is).\n\n\t\n\t\t\n\t\tExample Usage\n\t\n\nThe Raddr√≥mur Corpus counts with the train split only. To load the training split pass its name as a config name:\nfrom datasets import load_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/language-and-voice-lab/raddromur_asr.","url":"https://huggingface.co/datasets/language-and-voice-lab/raddromur_asr","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","machine-generated","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"isindebele-asr","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tisiNdebele Speech Recognition Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains speech recordings and transcriptions for isiNdebele, one of South Africa's official languages.\nThe dataset has been optimized for use with OpenAI's Whisper ASR models.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nNumber of samples: 742\nLanguage: isiNdebele (Nbl)\nAudio format: WAV, 16kHz, mono, 16-bit\nMaximum duration: 30 seconds (truncated for Whisper compatibility)\nTranscription format: Cleaned text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zionia/isindebele-asr.","url":"https://huggingface.co/datasets/zionia/isindebele-asr","creator_name":"Zion van Wyk","creator_url":"https://huggingface.co/zionia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Zulu","Xhosa","Southern Ndebele","Pedi"],"keywords_longer_than_N":true},
	{"name":"arabic_xvector_embeddings","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tArabic Speaker Embeddings extracted from ASC and ClArTTS\n\t\n\nThere is one speaker embedding for each utterance in the validation set of both datasets. The speaker embeddings are 512-element X-vectors.\nArabic Speech Corpus has 100 files for a single male speaker and ClArTTS has 205 files for a single male speaker.\nThe X-vectors were extracted using this script, which uses the speechbrain/spkrec-xvect-voxceleb model.\nUsage:\nfrom datasets import load_dataset\n\nembeddings_dataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/herwoww/arabic_xvector_embeddings.","url":"https://huggingface.co/datasets/herwoww/arabic_xvector_embeddings","creator_name":"Hawau Olamide Toyin","creator_url":"https://huggingface.co/herwoww","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","Arabic","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"japanese-anime-speech","keyword":"speech","description":"\n\t\n\t\t\n\t\tJapanese Anime Speech Dataset\n\t\n\nÊó•Êú¨Ë™û„ÅØ„Åì„Å°„Çâ\njapanese-anime-speech is an audio-text dataset designed for the training of automatic speech recognition models. The dataset is comprised of thousands of audio clips and their corresponding transcriptions from different visual novels.\nThe goal of this dataset is to increase the accuracy of automatic speech recognition models, such as OpenAI's Whisper, in accurately transcribing dialogue from anime and other similar Japanese media. This genre is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joujiboi/japanese-anime-speech.","url":"https://huggingface.co/datasets/joujiboi/japanese-anime-speech","creator_name":"JawGBoi","creator_url":"https://huggingface.co/joujiboi","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Japanese","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"japanese-anime-speech","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tJapanese Anime Speech Dataset\n\t\n\nÊó•Êú¨Ë™û„ÅØ„Åì„Å°„Çâ\njapanese-anime-speech is an audio-text dataset designed for the training of automatic speech recognition models. The dataset is comprised of thousands of audio clips and their corresponding transcriptions from different visual novels.\nThe goal of this dataset is to increase the accuracy of automatic speech recognition models, such as OpenAI's Whisper, in accurately transcribing dialogue from anime and other similar Japanese media. This genre is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joujiboi/japanese-anime-speech.","url":"https://huggingface.co/datasets/joujiboi/japanese-anime-speech","creator_name":"JawGBoi","creator_url":"https://huggingface.co/joujiboi","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Japanese","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"cm.trial","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 11.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Common Voice dataset consists of a unique MP3 and corresponding text file. \nMany of the 24210 recorded hours in the dataset also include demographic metadata like age, sex, and accent \nthat can help improve the accuracy of speech recognition engines.\nThe dataset currently consists of 16413 validated hours in 100 languages, but more voices and languages are always added. \nTake a look at the Languages page to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/taqwa92/cm.trial.","url":"https://huggingface.co/datasets/taqwa92/cm.trial","creator_name":"taqwa mohamed","creator_url":"https://huggingface.co/taqwa92","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"NPSC","keyword":"automatic-speech-recognition","description":"The Norwegian Parliament Speech Corpus (NPSC) is a corpus for training a Norwegian ASR (Automatic Speech Recognition) models. The corpus is created by Spr√•kbanken at the National Library in Norway.\n\nNPSC is based on sound recording from meeting in the Norwegian Parliament. These talks are orthographically transcribed to either Norwegian Bokm√•l or Norwegian Nynorsk. In addition to the data actually included in this dataset, there is a significant amount of metadata that is included in the original corpus. Through the speaker id there is additional information about the speaker, like gender, age, and place of birth (ie dialect). Through the proceedings id the corpus can be linked to the official proceedings from the meetings.\n\nThe corpus is in total sound recordings from 40 entire days of meetings. This amounts to 140 hours of speech, 65,000 sentences or 1.2 million words.","url":"https://huggingface.co/datasets/NbAiLab/NPSC","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"NPSC_test","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for NBAiLab/NPSC\n\t\n\nThe Norwegian Parliament Speech Corpus (NPSC) is a corpus for training a Norwegian ASR (Automatic Speech Recognition) models. The corpus is created by Spr√•kbanken at the National Library in Norway. \nNPSC is based on sound recording from meeting in the Norwegian Parliament. These talks are orthographically transcribed to either Norwegian Bokm√•l or Norwegian Nynorsk. In addition to the data actually included in this dataset, there is a significant amount‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NbAiLab/NPSC_test.","url":"https://huggingface.co/datasets/NbAiLab/NPSC_test","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"common_voice_17_0","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 17.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 17. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_17_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_17_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"fpt_fosd","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tunofficial mirror of FPT Open Speech Dataset (FOSD)\n\t\n\nreleased publicly in 2018 by FPT Corporation\n100h, 25.9k samples\nofficial link (dead): https://fpt.ai/fpt-open-speech-data/\nmirror: https://data.mendeley.com/datasets/k9sxg2twv4/4\nDOI: 10.17632/k9sxg2twv4.4\npre-process:\n\nremove non-sense strings: -N \\r\\n\nremove 4 files because missing transcription:\nSet001_V0.1_008210.mp3\nSet001_V0.1_010753.mp3\nSet001_V0.1_011477.mp3\nSet001_V0.1_011841.mp3\n\n\n\nneed to do: check misspelling\nusage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/fpt_fosd.","url":"https://huggingface.co/datasets/doof-ferb/fpt_fosd","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"fpt_fosd","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tunofficial mirror of FPT Open Speech Dataset (FOSD)\n\t\n\nreleased publicly in 2018 by FPT Corporation\n100h, 25.9k samples\nofficial link (dead): https://fpt.ai/fpt-open-speech-data/\nmirror: https://data.mendeley.com/datasets/k9sxg2twv4/4\nDOI: 10.17632/k9sxg2twv4.4\npre-process:\n\nremove non-sense strings: -N \\r\\n\nremove 4 files because missing transcription:\nSet001_V0.1_008210.mp3\nSet001_V0.1_010753.mp3\nSet001_V0.1_011477.mp3\nSet001_V0.1_011841.mp3\n\n\n\nneed to do: check misspelling\nusage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/fpt_fosd.","url":"https://huggingface.co/datasets/doof-ferb/fpt_fosd","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"toy_corpus_asr_es","keyword":"speech","description":"This is an example of a repository with a standard data loader. The audio files are compressed in tar format. Since this repository contains very few audio files, it can be used to test certain scripts in local machines.\n","url":"https://huggingface.co/datasets/carlosdanielhernandezmena/toy_corpus_asr_es","creator_name":"Carlos Daniel Hern√°ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"bible","keyword":"speech","description":"\n\t\n\t\t\n\t\tAudio Dataset\n\t\n\nThis dataset contains audio segments with transcriptions for speech recognition and text-to-speech tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\ndataset.json: Complete dataset in JSON format\ntrain.jsonl: Dataset in JSONL format for use with Hugging Face datasets library\ndataset_info.json: Metadata about the dataset structure\n\nEach entry contains:\n\nfile: Original filename\naudio: Audio data with sampling rate\ntranscription: Text transcription\nduration: Audio duration in seconds\n\n","url":"https://huggingface.co/datasets/jsbeaudry/bible","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"toy_corpus_asr_es","keyword":"automatic-speech-recognition","description":"This is an example of a repository with a standard data loader. The audio files are compressed in tar format. Since this repository contains very few audio files, it can be used to test certain scripts in local machines.\n","url":"https://huggingface.co/datasets/carlosdanielhernandezmena/toy_corpus_asr_es","creator_name":"Carlos Daniel Hern√°ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"jamaican-patwa-whisper","keyword":"automatic-speech-recognition","description":"A dataset of Jamaican Patwa audio recordings with transcriptions for training speech recognition models.","url":"https://huggingface.co/datasets/shaun3141/jamaican-patwa-whisper","creator_name":"Shaun VanWeelden","creator_url":"https://huggingface.co/shaun3141","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Jamaican Creole English","mit","n<1K","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Treble10-Speech","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTreble10-Speech (16 kHz)\n\t\n\n\nThe Treble10-Speech dataset is a dataset for automatic speech recognition (ASR), containing pre-convolved speech files using high fidelity room-acoustic simulations from 10 different furnished rooms: 2 bathrooms, 2 bedrooms, 2 living rooms with hallway, 2 living rooms without hallway, 2 meeting rooms. \nThe room volumes range between 14 and 46 m3, resulting in reverberation times between 0.17 and 0.84 s.\n\n\t\n\t\n\t\n\t\tExamples: accessing a reverberant mono speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/treble-technologies/Treble10-Speech.","url":"https://huggingface.co/datasets/treble-technologies/Treble10-Speech","creator_name":"Treble Technologies","creator_url":"https://huggingface.co/treble-technologies","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"bible","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tAudio Dataset\n\t\n\nThis dataset contains audio segments with transcriptions for speech recognition and text-to-speech tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\ndataset.json: Complete dataset in JSON format\ntrain.jsonl: Dataset in JSONL format for use with Hugging Face datasets library\ndataset_info.json: Metadata about the dataset structure\n\nEach entry contains:\n\nfile: Original filename\naudio: Audio data with sampling rate\ntranscription: Text transcription\nduration: Audio duration in seconds\n\n","url":"https://huggingface.co/datasets/jsbeaudry/bible","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"bible","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tAudio Dataset\n\t\n\nThis dataset contains audio segments with transcriptions for speech recognition and text-to-speech tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\ndataset.json: Complete dataset in JSON format\ntrain.jsonl: Dataset in JSONL format for use with Hugging Face datasets library\ndataset_info.json: Metadata about the dataset structure\n\nEach entry contains:\n\nfile: Original filename\naudio: Audio data with sampling rate\ntranscription: Text transcription\nduration: Audio duration in seconds\n\n","url":"https://huggingface.co/datasets/jsbeaudry/bible","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"persian_tts_stt","keyword":"text-to-speech","description":"This dataset contains more than 10k records and 15 hours of clear vocal voice aligning with text in csv file.\n","url":"https://huggingface.co/datasets/SmartGitiCorp/persian_tts_stt","creator_name":"Smart Giti Corporation","creator_url":"https://huggingface.co/SmartGitiCorp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Persian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"arctic-hs","keyword":"speech","description":"\n\t\n\t\t\n\t\tARCTIC-HS\n\t\n\nAn extension of the CMU_ARCTIC and L2-ARCTIC datasets for synthetic speech detection using text-to-speech, featured in the paper Synthetic speech detection with Wav2Vec 2.0 in various language settings. Specifically, the symmetric variants were used.\nThis dataset is 1 of 3 used in the paper, the others being:\n\nFLEURS-HS\nthe default train, dev and test sets\n\n\nFLEURS-HS VITS\ntest set containing (generally) more difficult synthetic samples\nseparated due to different licensing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/realnetworks-kontxt/arctic-hs.","url":"https://huggingface.co/datasets/realnetworks-kontxt/arctic-hs","creator_name":"KONTXT by RealNetworks","creator_url":"https://huggingface.co/realnetworks-kontxt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"isizulu-asr-specaug","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tisiZulu Speech Recognition Augmented Dataset - SpecAugment\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains augmented speech recordings and transcriptions for isiZulu, one of South Africa's official languages.\nThe dataset has been optimized for use with OpenAI's Whisper ASR models.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nNumber of samples: 699\nLanguage: isiZulu (Zul)\nAudio format: WAV, 16kHz, mono, 16-bit\nMaximum duration: 30 seconds (truncated for Whisper compatibility)\nTranscription‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zionia/isizulu-asr-specaug.","url":"https://huggingface.co/datasets/zionia/isizulu-asr-specaug","creator_name":"Zion van Wyk","creator_url":"https://huggingface.co/zionia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Zulu","Xhosa","Southern Ndebele","Pedi"],"keywords_longer_than_N":true},
	{"name":"arctic-hs","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tARCTIC-HS\n\t\n\nAn extension of the CMU_ARCTIC and L2-ARCTIC datasets for synthetic speech detection using text-to-speech, featured in the paper Synthetic speech detection with Wav2Vec 2.0 in various language settings. Specifically, the symmetric variants were used.\nThis dataset is 1 of 3 used in the paper, the others being:\n\nFLEURS-HS\nthe default train, dev and test sets\n\n\nFLEURS-HS VITS\ntest set containing (generally) more difficult synthetic samples\nseparated due to different licensing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/realnetworks-kontxt/arctic-hs.","url":"https://huggingface.co/datasets/realnetworks-kontxt/arctic-hs","creator_name":"KONTXT by RealNetworks","creator_url":"https://huggingface.co/realnetworks-kontxt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"isizulu-asr-noisy","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tisiZulu Speech Recognition Augmented Dataset - Gaussian Noise\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains augmented speech recordings and transcriptions for isiZulu, one of South Africa's official languages.\nThe dataset has been optimized for use with OpenAI's Whisper ASR models.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nNumber of samples: 699\nLanguage: isiZulu (Zul)\nAudio format: WAV, 16kHz, mono, 16-bit\nMaximum duration: 30 seconds (truncated for Whisper compatibility)\nTranscription‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zionia/isizulu-asr-noisy.","url":"https://huggingface.co/datasets/zionia/isizulu-asr-noisy","creator_name":"Zion van Wyk","creator_url":"https://huggingface.co/zionia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Zulu","Xhosa","Southern Ndebele","Pedi"],"keywords_longer_than_N":true},
	{"name":"MediaSpeech","keyword":"speech","description":"\n\t\n\t\t\n\t\tMediaSpeech\n\t\n\nMediaSpeech is a dataset of Arabic, French, Spanish, and Turkish media speech built with the purpose of testing Automated Speech Recognition (ASR) systems performance. The dataset contains 10 hours of speech for each language provided.\nThe dataset consists of short speech segments automatically extracted from media videos available on YouTube and manually transcribed, with some pre-processing and post-processing.\nBaseline models and WAV version of the dataset can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/MediaSpeech.","url":"https://huggingface.co/datasets/ymoslem/MediaSpeech","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"MediaSpeech","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tMediaSpeech\n\t\n\nMediaSpeech is a dataset of Arabic, French, Spanish, and Turkish media speech built with the purpose of testing Automated Speech Recognition (ASR) systems performance. The dataset contains 10 hours of speech for each language provided.\nThe dataset consists of short speech segments automatically extracted from media videos available on YouTube and manually transcribed, with some pre-processing and post-processing.\nBaseline models and WAV version of the dataset can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/MediaSpeech.","url":"https://huggingface.co/datasets/ymoslem/MediaSpeech","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"Shrutilipi","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Shrutilipi (Full Version)\n\t\n\n\n\nThis is a full and unfiltered version of the Shrutilipi dataset for languages: Bengali, Hindi, Kannada, Malayalam, Marathi, Odia, Tamil and Telugu - originally described in the paper: Effectiveness of Mining Audio and Text Pairs from Public Data for Improving ASR Systems for Low-Resource Languages.\nThe data for Gujarati, Punjabi and Sanskrit will be uploaded later.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nSince the dataset was automatically curated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/skesiraju/Shrutilipi.","url":"https://huggingface.co/datasets/skesiraju/Shrutilipi","creator_name":"Santosh Kesiraju","creator_url":"https://huggingface.co/skesiraju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Bengali","Hindi","Kannada","Malayalam"],"keywords_longer_than_N":true},
	{"name":"MediaSpeech","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tMediaSpeech\n\t\n\nMediaSpeech is a dataset of Arabic, French, Spanish, and Turkish media speech built with the purpose of testing Automated Speech Recognition (ASR) systems performance. The dataset contains 10 hours of speech for each language provided.\nThe dataset consists of short speech segments automatically extracted from media videos available on YouTube and manually transcribed, with some pre-processing and post-processing.\nBaseline models and WAV version of the dataset can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/MediaSpeech.","url":"https://huggingface.co/datasets/ymoslem/MediaSpeech","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"cmu-arctic-xvectors","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tSpeaker embeddings extracted from CMU ARCTIC\n\t\n\nThere is one .npy file for each utterance in the dataset, 7931 files in total. The speaker embeddings are 512-element X-vectors.\nThe CMU ARCTIC dataset divides the utterances among the following speakers:\n\nbdl (US male)\nslt (US female)\njmk (Canadian male)\nawb (Scottish male)\nrms (US male)\nclb (US female)\nksp (Indian male)\n\nThe X-vectors were extracted using this script, which uses the speechbrain/spkrec-xvect-voxceleb model.\nUsage:\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Dupaja/cmu-arctic-xvectors.","url":"https://huggingface.co/datasets/Dupaja/cmu-arctic-xvectors","creator_name":"Dan D","creator_url":"https://huggingface.co/Dupaja","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"red_ace_asr_error_detection_and_correction","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tRED-ACE\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset can be used to train and evaluate ASR Error Detection or Correction models. It was introduced in the RED-ACE paper (Gekhman et al, 2022).\nThe dataset contains ASR outputs on the LibriSpeech corpus (Panayotov et al., 2015) with annotated transcription errors.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nThe LibriSpeech corpus was decoded using Google Cloud Speech-to-Text API, with the default and video models.\nThe word-level confidence was enabled‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/red_ace_asr_error_detection_and_correction.","url":"https://huggingface.co/datasets/google/red_ace_asr_error_detection_and_correction","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"SUBAK.KO","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for SUBAK.KO\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSUBAK.KO (‡¶∏‡ßÅ‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø), a publicly available annotated Bangladeshi standard Bangla speech corpus, is compiled for automatic speech recognition research. \nThis corpus contains 241 hours of high-quality speech data, including 229 hours of read speech data and 12 hours of broadcast speech data. \nThe read speech segment is recorded in a noise-proof studio environment from 33 male and 28 female native Bangladeshi Bangla speakers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SUST-CSE-Speech/SUBAK.KO.","url":"https://huggingface.co/datasets/SUST-CSE-Speech/SUBAK.KO","creator_name":"SUST CSE Speech Processing Lab","creator_url":"https://huggingface.co/SUST-CSE-Speech","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Bengali","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"SUBAK.KO","keyword":"speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for SUBAK.KO\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSUBAK.KO (‡¶∏‡ßÅ‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø), a publicly available annotated Bangladeshi standard Bangla speech corpus, is compiled for automatic speech recognition research. \nThis corpus contains 241 hours of high-quality speech data, including 229 hours of read speech data and 12 hours of broadcast speech data. \nThe read speech segment is recorded in a noise-proof studio environment from 33 male and 28 female native Bangladeshi Bangla speakers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SUST-CSE-Speech/SUBAK.KO.","url":"https://huggingface.co/datasets/SUST-CSE-Speech/SUBAK.KO","creator_name":"SUST CSE Speech Processing Lab","creator_url":"https://huggingface.co/SUST-CSE-Speech","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Bengali","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"datasets","keyword":"speech","description":"All eight of datasets in ESB can be downloaded and prepared in just a single line of code through the Hugging Face Datasets library:\nfrom datasets import load_dataset\n\nlibrispeech = load_dataset(\"esb/datasets\", \"librispeech\", split=\"train\")\n\n\n\"esb/datasets\": the repository namespace. This is fixed for all ESB datasets.\n\n\"librispeech\": the dataset name. This can be changed to any of any one of the eight datasets in ESB to download that dataset.\n\nsplit=\"train\": the split. Set this to one of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/open-asr-leaderboard/datasets.","url":"https://huggingface.co/datasets/open-asr-leaderboard/datasets","creator_name":"Open ASR Leaderboard","creator_url":"https://huggingface.co/open-asr-leaderboard","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"datasets","keyword":"automatic-speech-recognition","description":"All eight of datasets in ESB can be downloaded and prepared in just a single line of code through the Hugging Face Datasets library:\nfrom datasets import load_dataset\n\nlibrispeech = load_dataset(\"esb/datasets\", \"librispeech\", split=\"train\")\n\n\n\"esb/datasets\": the repository namespace. This is fixed for all ESB datasets.\n\n\"librispeech\": the dataset name. This can be changed to any of any one of the eight datasets in ESB to download that dataset.\n\nsplit=\"train\": the split. Set this to one of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/open-asr-leaderboard/datasets.","url":"https://huggingface.co/datasets/open-asr-leaderboard/datasets","creator_name":"Open ASR Leaderboard","creator_url":"https://huggingface.co/open-asr-leaderboard","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"openstt-uk","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tOpen Speech-to-Text corpus for üá∫üá¶ Ukrainian\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset has transcriptions with other metadata for the VOA Ukrainian dataset (~398h).\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { openstt-uk (Revision 88d95da) },\n    year         = 2025‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Yehor/openstt-uk.","url":"https://huggingface.co/datasets/Yehor/openstt-uk","creator_name":"Smoliakov","creator_url":"https://huggingface.co/Yehor","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Ukrainian","cc-by-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"minds14-mirror","keyword":"automatic-speech-recognition","description":"MINDS-14 is training and evaluation resource for intent\ndetection task with spoken data. It covers 14\nintents extracted from a commercial system\nin the e-banking domain, associated with spoken examples in 14 diverse language varieties.","url":"https://huggingface.co/datasets/a6kme/minds14-mirror","creator_name":"Abhishek Kumar","creator_url":"https://huggingface.co/a6kme","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","keyword-spotting","expert-generated","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"emova-alignment-7m","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tEMOVA-Alignment-7M\n\t\n\n\n\n\nü§ó EMOVA-Models | ü§ó EMOVA-Datasets | ü§ó EMOVA-Demo \nüìÑ Paper | üåê Project-Page | üíª Github | üíª EMOVA-Speech-Tokenizer-Github\n\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-Alignment-7M is a comprehensive dataset curated for omni-modal pre-training, including vision-language and speech-language alignment. \nThis dataset is created using open-sourced image-text pre-training datasets, OCR datasets, and 2,000 hours of ASR and TTS data. \nThis dataset is part of the EMOVA-Datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-alignment-7m.","url":"https://huggingface.co/datasets/Emova-ollm/emova-alignment-7m","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-generation","audio-to-audio","automatic-speech-recognition","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"hatecheck-portuguese","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-portuguese.","url":"https://huggingface.co/datasets/Paul/hatecheck-portuguese","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-mandarin","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-mandarin.","url":"https://huggingface.co/datasets/Paul/hatecheck-mandarin","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hausa-tts","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tHausa TTS Dataset\n\t\n\nMulti-speaker Hausa text-to-speech dataset.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset, Audio\n\n# Load the dataset\nds = load_dataset(\"parquet\", data_files=\"hausa_tts_embedded.parquet\", split=\"train\")\n\n# Cast audio column to Audio type with 24kHz sampling rate\nds = ds.cast_column(\"audio\", Audio(sampling_rate=24000))\n\n# Use with Unsloth TTS\nfrom transformers import AutoProcessor\nprocessor = AutoProcessor.from_pretrained(\"unsloth/csm-1b\")\n\n# Your training code‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aybee5/hausa-tts.","url":"https://huggingface.co/datasets/Aybee5/hausa-tts","creator_name":"Ibrahim Abdullahi","creator_url":"https://huggingface.co/Aybee5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Hausa","cc-by-4.0","1K<n<10K","Audio"],"keywords_longer_than_N":true},
	{"name":"emova-alignment-7m","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tEMOVA-Alignment-7M\n\t\n\n\n\n\nü§ó EMOVA-Models | ü§ó EMOVA-Datasets | ü§ó EMOVA-Demo \nüìÑ Paper | üåê Project-Page | üíª Github | üíª EMOVA-Speech-Tokenizer-Github\n\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-Alignment-7M is a comprehensive dataset curated for omni-modal pre-training, including vision-language and speech-language alignment. \nThis dataset is created using open-sourced image-text pre-training datasets, OCR datasets, and 2,000 hours of ASR and TTS data. \nThis dataset is part of the EMOVA-Datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-alignment-7m.","url":"https://huggingface.co/datasets/Emova-ollm/emova-alignment-7m","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-generation","audio-to-audio","automatic-speech-recognition","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"isizulu-asr-0.9-speed","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tisiZulu Speech Recognition Augmented Dataset - 0.9 Speed\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains augmented speech recordings and transcriptions for isiZulu, one of South Africa's official languages.\nThe dataset has been optimized for use with OpenAI's Whisper ASR models.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nNumber of samples: 699\nLanguage: isiZulu (Zul)\nAudio format: WAV, 16kHz, mono, 16-bit\nMaximum duration: 30 seconds (truncated for Whisper compatibility)\nTranscription‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zionia/isizulu-asr-0.9-speed.","url":"https://huggingface.co/datasets/zionia/isizulu-asr-0.9-speed","creator_name":"Zion van Wyk","creator_url":"https://huggingface.co/zionia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Zulu","Xhosa","Southern Ndebele","Pedi"],"keywords_longer_than_N":true},
	{"name":"fleurs-cs","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tFLEURS (Czech)\n\t\n\nThis dataset contains the Czech part of the FLEURS dataset.\nThe data is based on the FLoRes-101 dataset: ‚Äû3001 sentences extracted\nfrom English Wikipedia and these sentences have been translated in 101 languages by human translators (‚Ä¶) For each sentence (‚Ä¶), we collected three recordings by three different native speakers (‚Ä¶)‚Äù.\nSee more information in the paper: https://huggingface.co/papers/2205.12446.\n","url":"https://huggingface.co/datasets/karmiq/fleurs-cs","creator_name":"Karel Minarik","creator_url":"https://huggingface.co/karmiq","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Czech","cc-by-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"fleurs-cs","keyword":"speech-recognition","description":"\n\t\n\t\t\n\t\tFLEURS (Czech)\n\t\n\nThis dataset contains the Czech part of the FLEURS dataset.\nThe data is based on the FLoRes-101 dataset: ‚Äû3001 sentences extracted\nfrom English Wikipedia and these sentences have been translated in 101 languages by human translators (‚Ä¶) For each sentence (‚Ä¶), we collected three recordings by three different native speakers (‚Ä¶)‚Äù.\nSee more information in the paper: https://huggingface.co/papers/2205.12446.\n","url":"https://huggingface.co/datasets/karmiq/fleurs-cs","creator_name":"Karel Minarik","creator_url":"https://huggingface.co/karmiq","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Czech","cc-by-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"AISHELL-3","keyword":"text-to-speech","description":"AISHELL-3 is a large-scale and high-fidelity multi-speaker Mandarin speech corpus published by Beijing Shell Shell Technology Co.,Ltd. It can be used to train multi-speaker Text-to-Speech (TTS) systems.The corpus contains roughly 85 hours of emotion-neutral recordings spoken by 218 native Chinese mandarin speakers and total 88035 utterances. Their auxiliary attributes such as gender, age group and native accents are explicitly marked and provided in the corpus. Accordingly, transcripts in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AISHELL/AISHELL-3.","url":"https://huggingface.co/datasets/AISHELL/AISHELL-3","creator_name":"aishelltech","creator_url":"https://huggingface.co/AISHELL","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Chinese","apache-2.0","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"Egyptian_People_Speaking_Video_Dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tEgyptian People Speaking Video Dataset\n\t\n\nThis dataset contains high-quality video recordings of Egyptian people speaking on a range of topics. It is curated for AI research in speech recognition, multimodal analysis, topic understanding, and spoken-language modeling.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Categories:  \n\nVideo Classification  \nSpeech-to-Text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Egyptian_People_Speaking_Video_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Egyptian_People_Speaking_Video_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","Arabic","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ami-ihm-timestamped","keyword":"automatic-speech-recognition","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\nnon-native speakers. \\n","url":"https://huggingface.co/datasets/distil-whisper/ami-ihm-timestamped","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"LatinAccents","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jstack32/LatinAccents.","url":"https://huggingface.co/datasets/jstack32/LatinAccents","creator_name":"Joey Stack","creator_url":"https://huggingface.co/jstack32","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","extended|common_voice","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"causalgym","keyword":"linguistics","description":"CausalGym is a benchmark for comparing the performance of causal interpretability methods\non a variety of simple linguistic tasks taken from the SyntaxGym evaluation set\n(Gauthier et al., 2020, Hu et al., 2020)\nand converted into a format suitable for interventional interpretability.\nThe dataset includes train/dev/test splits (exactly as used in the experiments in the paper).\nThe base/src columns are the prompts on which intervention is done. Each of these is a list of strings,\nwith each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aryaman/causalgym.","url":"https://huggingface.co/datasets/aryaman/causalgym","creator_name":"Aryaman Arora","creator_url":"https://huggingface.co/aryaman","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Egyptian_People_Speaking_Video_Dataset","keyword":"speech-recognition","description":"\n\t\n\t\t\n\t\tEgyptian People Speaking Video Dataset\n\t\n\nThis dataset contains high-quality video recordings of Egyptian people speaking on a range of topics. It is curated for AI research in speech recognition, multimodal analysis, topic understanding, and spoken-language modeling.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Categories:  \n\nVideo Classification  \nSpeech-to-Text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Egyptian_People_Speaking_Video_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Egyptian_People_Speaking_Video_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","Arabic","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"LibriQuote","keyword":"speech","description":"This repository contains the LibriQuote dataset, a speech dataset of fictional character utterances for expressive zero-shot speech synthesis.\nYou can find more information in the publication, LibriQuote: A Speech Dataset of Fictional Character Utterances for Expressive Zero-Shot Speech Synthesis.\nPlease refer to the github repository for instructions on how to process the dataset or how to evaluate using the benchmark data.\n\n\t\n\t\t\n\t\n\t\n\t\tUsefull links:\n\t\n\n\nPaper\nGitHub\nDataset\nAudio samples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gasmichel/LibriQuote.","url":"https://huggingface.co/datasets/gasmichel/LibriQuote","creator_name":"Gaspard Michel","creator_url":"https://huggingface.co/gasmichel","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","10M<n<100M","Audio"],"keywords_longer_than_N":true},
	{"name":"partial-asr","keyword":"automatic-speech-recognition","description":"LibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\nprepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\naudiobooks from the LibriVox project, and has been carefully segmented and aligned.87","url":"https://huggingface.co/datasets/omarc/partial-asr","creator_name":"Omar Cobas","creator_url":"https://huggingface.co/omarc","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"libris_clean_100","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been carefully segmented and aligned.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nautomatic-speech-recognition, audio-speaker-identification: The dataset can be used to train a model for Automatic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nguyenvulebinh/libris_clean_100.","url":"https://huggingface.co/datasets/nguyenvulebinh/libris_clean_100","creator_name":"Binh Nguyen","creator_url":"https://huggingface.co/nguyenvulebinh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr_individual","keyword":"automatic-speech-recognition","description":"LibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\nprepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\naudiobooks from the LibriVox project, and has been carefully segmented and aligned.87","url":"https://huggingface.co/datasets/Splend1dchan/librispeech_asr_individual","creator_name":"Ë®±ÊπõÁÑ∂","creator_url":"https://huggingface.co/Splend1dchan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"parlament_parla","keyword":"automatic-speech-recognition","description":"This is the ParlamentParla speech corpus for Catalan prepared by Col¬∑lectivaT. The audio segments were extracted from recordings the Catalan Parliament (Parlament de Catalunya) plenary sessions, which took place between 2007/07/11 - 2018/07/17. We aligned the transcriptions with the recordings and extracted the corpus. The content belongs to the Catalan Parliament and the data is released conforming their terms of use.\n\nPreparation of this corpus was partly supported by the Department of Culture of the Catalan autonomous government, and the v2.0 was supported by the Barcelona Supercomputing Center, within the framework of the project AINA of the Departament de Pol√≠tiques Digitals.\n\nAs of v2.0 the corpus is separated into 211 hours of clean and 400 hours of other quality segments. Furthermore, each speech segment is tagged with its speaker and each speaker with their gender. The statistics are detailed in the readme file.\n\nFor more information, go to https://github.com/CollectivaT-dev/ParlamentParla or mail info@collectivat.cat.","url":"https://huggingface.co/datasets/projecte-aina/parlament_parla","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-generation","language-modeling","speaker-identification","found"],"keywords_longer_than_N":true},
	{"name":"ulca_ml","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tULCA ASR Dataset Malayalam Speech Corpus\n\t\n\nThe labelled Malayalam speech subcorpus from the larger ULCA ASR Corpus.\nThe speech is taken from news broadcasts, and is largely composed of short soundbites with some longer outliers.\n","url":"https://huggingface.co/datasets/thennal/ulca_ml","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","found","monolingual","Malayalam"],"keywords_longer_than_N":true},
	{"name":"malayalam_asr_corpus","keyword":"automatic-speech-recognition","description":"The corpus contains roughly 10 hours of audio and trasncripts in Malayalam language. The transcripts have beedn de-duplicated using exact match deduplication.","url":"https://huggingface.co/datasets/parambharat/malayalam_asr_corpus","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"samromur_asr","keyword":"automatic-speech-recognition","description":"Samr√≥mur Icelandic Speech 1.0.","url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_asr","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ro-offense-sequences","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Teodora-Andreea Ion\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive sequence detection with manually \nannotated offensive sequences from a local Romanian sports news website (gsp.ro):\nResulting in 4800 annotated messages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense-sequences.","url":"https://huggingface.co/datasets/readerbench/ro-offense-sequences","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ro-offense-sequences","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Teodora-Andreea Ion\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive sequence detection with manually \nannotated offensive sequences from a local Romanian sports news website (gsp.ro):\nResulting in 4800 annotated messages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense-sequences.","url":"https://huggingface.co/datasets/readerbench/ro-offense-sequences","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"LibriQuote","keyword":"text-to-speech","description":"This repository contains the LibriQuote dataset, a speech dataset of fictional character utterances for expressive zero-shot speech synthesis.\nYou can find more information in the publication, LibriQuote: A Speech Dataset of Fictional Character Utterances for Expressive Zero-Shot Speech Synthesis.\nPlease refer to the github repository for instructions on how to process the dataset or how to evaluate using the benchmark data.\n\n\t\n\t\t\n\t\n\t\n\t\tUsefull links:\n\t\n\n\nPaper\nGitHub\nDataset\nAudio samples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gasmichel/LibriQuote.","url":"https://huggingface.co/datasets/gasmichel/LibriQuote","creator_name":"Gaspard Michel","creator_url":"https://huggingface.co/gasmichel","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","10M<n<100M","Audio"],"keywords_longer_than_N":true},
	{"name":"whisperspeech","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tThe WhisperSpeech Dataset\n\t\n\nThis dataset contains data to train SPEAR TTS-like text-to-speech models that utilized semantic tokens derived from the OpenAI Whisper\nspeech recognition model.\nWe currently provide semantic and acoustic tokens for the LibriLight and LibriTTS datasets (English only).\nAcoustic tokens:\n\n24kHz EnCodec 6kbps (8 quantizers)\n\nSemantic tokens:\n\nWhisper tiny VQ bottleneck trained on a subset of LibriLight\n\nAvailable LibriLight subsets:\n\nsmall/medium/large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/collabora/whisperspeech.","url":"https://huggingface.co/datasets/collabora/whisperspeech","creator_name":"Collabora","creator_url":"https://huggingface.co/collabora","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","mit","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part002","keyword":"speech","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 2 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 2 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part002.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part002","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"uzbek_stt_data","keyword":"automatic-speech-recognition","description":"Beehzod/uzbek_stt_data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Beehzod/uzbek_stt_data","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","100K - 1M","webdataset"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part002","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 2 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 2 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part002.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part002","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part002","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 2 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 2 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part002.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part002","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"pony-speech","keyword":"text-to-speech","description":"synthbot/pony-speech dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/synthbot/pony-speech","creator_name":"Synthbot Anon","creator_url":"https://huggingface.co/synthbot","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"linto-dataset-audio-ar-tn","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tLinTO DataSet Audio for Arabic Tunisian A collection of Tunisian dialect audio and its annotations for STT task\n\t\n\nThis is the first packaged version of the datasets used to train the Linto Tunisian dialect with code-switching STT\n(linagora/linto-asr-ar-tn).\n\nDataset Summary\nDataset composition\nSources\nData Table\nData sources\nContent Types\nLanguages and Dialects\n\n\nExample use (python)\nLicense\nCitations\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe LinTO DataSet Audio for Arabic Tunisian is a diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn.","url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"chuvash_voice","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tHow to use\n\t\n\nWe recommend using our dataset in conjunction with the Common Voice Corpus. We have attempted to maintain a consistent structure.\nfrom datasets import load_dataset, DatasetDict, concatenate_datasets, Audio\n\ncomm_voice = DatasetDict()\ncomm_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"cv\", split=\"train+validation\", use_auth_token=True)\ncomm_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"cv\", split=\"test\", use_auth_token=True)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexantonov/chuvash_voice.","url":"https://huggingface.co/datasets/alexantonov/chuvash_voice","creator_name":"Alexander Antonov","creator_url":"https://huggingface.co/alexantonov","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Chuvash","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"no-filter-raw-NepaliParliamentDSv2","keyword":"automatic-speech-recognition","description":"kiranpantha/no-filter-raw-NepaliParliamentDSv2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kiranpantha/no-filter-raw-NepaliParliamentDSv2","creator_name":"Kiran Pantha","creator_url":"https://huggingface.co/kiranpantha","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","cc-by-4.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"linto-dataset-audio-ar-tn","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tLinTO DataSet Audio for Arabic Tunisian A collection of Tunisian dialect audio and its annotations for STT task\n\t\n\nThis is the first packaged version of the datasets used to train the Linto Tunisian dialect with code-switching STT\n(linagora/linto-asr-ar-tn).\n\nDataset Summary\nDataset composition\nSources\nData Table\nData sources\nContent Types\nLanguages and Dialects\n\n\nExample use (python)\nLicense\nCitations\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe LinTO DataSet Audio for Arabic Tunisian is a diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn.","url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"chuvash_voice","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tHow to use\n\t\n\nWe recommend using our dataset in conjunction with the Common Voice Corpus. We have attempted to maintain a consistent structure.\nfrom datasets import load_dataset, DatasetDict, concatenate_datasets, Audio\n\ncomm_voice = DatasetDict()\ncomm_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"cv\", split=\"train+validation\", use_auth_token=True)\ncomm_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"cv\", split=\"test\", use_auth_token=True)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexantonov/chuvash_voice.","url":"https://huggingface.co/datasets/alexantonov/chuvash_voice","creator_name":"Alexander Antonov","creator_url":"https://huggingface.co/alexantonov","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Chuvash","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"laions_got_talent_with_voice_emotion_speed_tags_for_orpheus_tuning","keyword":"speech","description":"LAION's Got Talent: Generated Voice Acting Dataset\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\"LAION's Got Talent\" is a synthetic voice acting dataset designed to offer a broad range of emotional expressions, vocal bursts, and multi-language utterances. This dataset is a component of the BUD-E project, led by LAION with support from Intel, and aims to drive forward research in context-aware and empathetic AI voice assistants.\n\n\n\t\n\t\t\n\t\tUpdated Composition\n\t\n\n\nVoices and Languages  \n\nEnglish: 11 OpenAI voices, each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/laion/laions_got_talent_with_voice_emotion_speed_tags_for_orpheus_tuning.","url":"https://huggingface.co/datasets/laion/laions_got_talent_with_voice_emotion_speed_tags_for_orpheus_tuning","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"BERSt","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tBERSt Dataset\n\t\n\nWe release the BERSt Dataset for various speech recognition tasks including Automatic Speech Recognition (ASR) and Speech Emotion Recogniton (SER)\nRead the paper here\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\n4526 single phrase recordings (~3.75h)\n98 professional actors\n19 phone positions\n7 emotion classes\n3 vocal intensity levels\nvaried regional and non-native English accents\nnonsense phrases covering all English Phonemes\n\n\n\t\n\t\t\n\t\tData collection\n\t\n\nThe BERSt dataset represents data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rosie-Lab/BERSt.","url":"https://huggingface.co/datasets/Rosie-Lab/BERSt","creator_name":"SFU Robots with Social Intelligence and Empathy Lab","creator_url":"https://huggingface.co/Rosie-Lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"sampleDental","keyword":"automatic-speech-recognition","description":"srirama/sampleDental dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/srirama/sampleDental","creator_name":"srirama","creator_url":"https://huggingface.co/srirama","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"AudioNormalizationDatasetRVC","keyword":"speech","description":"Illia56/AudioNormalizationDatasetRVC dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Illia56/AudioNormalizationDatasetRVC","creator_name":"Illia Liudogovskyi","creator_url":"https://huggingface.co/Illia56","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","Russian","apache-2.0","1K<n<10K","Audio"],"keywords_longer_than_N":true},
	{"name":"ave-2","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tAVE-2: AudioVisual Event Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAVE-2 is a comprehensive dataset featuring 570,138 audio-visual clips with detailed five-dimensional alignment quality annotations. This dataset enables systematic investigation of how alignment quality affects multimodal model performance across retrieval and generation tasks.\n\n\t\n\t\t\n\t\tüåü Key Features\n\t\n\n\nüé¨ 570k+ annotated clips with granular quality scores (0-10 scale)\nüìè Five-dimensional scoring: temporal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ali-vosoughi/ave-2.","url":"https://huggingface.co/datasets/ali-vosoughi/ave-2","creator_name":"Ali Vosoughi","creator_url":"https://huggingface.co/ali-vosoughi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","visual-question-answering","text-to-audio","text-to-speech","automatic-speech-recognition"],"keywords_longer_than_N":true},
	{"name":"wolof-audio-data","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tWolof Audio Dataset\n\t\n\nThe Wolof Audio Dataset is a collection of audio recordings and their corresponding transcriptions in Wolof. This dataset is designed to support the development of Automatic Speech Recognition (ASR) models for the Wolof language. It was created by combining four existing datasets:\n\nALFFA: Available at serge-wilson/wolof_speech_transcription\nFLEURS: Available at vonewman/fleurs-wolof-dataset\nUrban Bus Wolof Speech Dataset: Available at vonewman/urban-bus-wolof‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/galsenai/wolof-audio-data.","url":"https://huggingface.co/datasets/galsenai/wolof-audio-data","creator_name":"GalsenAI Lab","creator_url":"https://huggingface.co/galsenai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Wolof","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"harmbench","keyword":"hate-speech","description":"\n\t\n\t\t\n\t\tHarmBench\n\t\n\n\nOriginal repo: https://github.com/centerforaisafety/HarmBench/tree/main/data/behavior_datasets\n\nThis HF dataset contains two types of harmful prompts:\n\nDirectRequest: taken from harmbench_behaviors_text_test.csv (test split) and harmbench_behaviors_text_val.csv (val split)\nHumanJailbreaks: manual selection of jailbreaks divided into test and val splits \nMoreover, metadata.csv contains the information about each behavior and can be mapped to the prompts above by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mariagrandury/harmbench.","url":"https://huggingface.co/datasets/mariagrandury/harmbench","creator_name":"Mar√≠a Grandury","creator_url":"https://huggingface.co/mariagrandury","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"tts_nisan_kumru_tur","keyword":"speech-recognition","description":"omersaidd/tts_nisan_kumru_tur dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/omersaidd/tts_nisan_kumru_tur","creator_name":"√ñmer Said Yilmaz","creator_url":"https://huggingface.co/omersaidd","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Turkish","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Audio-Children-Stories-Collection-Large","keyword":"text-to-speech","description":"Audio Chidren Stories Collection Large\nThis dataset has 5600++ audio files in .mp3 format. This has been created using my existing dataset Children-Stories-Collection.\nI have used first 5600++ stories from Children-Stories-1-Final.json file for creating this audio dataset.\nYou can use this for training and research purpose.\nThank you for your love & support.\n","url":"https://huggingface.co/datasets/ajibawa-2023/Audio-Children-Stories-Collection-Large","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"ave-2","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tAVE-2: AudioVisual Event Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAVE-2 is a comprehensive dataset featuring 570,138 audio-visual clips with detailed five-dimensional alignment quality annotations. This dataset enables systematic investigation of how alignment quality affects multimodal model performance across retrieval and generation tasks.\n\n\t\n\t\t\n\t\tüåü Key Features\n\t\n\n\nüé¨ 570k+ annotated clips with granular quality scores (0-10 scale)\nüìè Five-dimensional scoring: temporal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ali-vosoughi/ave-2.","url":"https://huggingface.co/datasets/ali-vosoughi/ave-2","creator_name":"Ali Vosoughi","creator_url":"https://huggingface.co/ali-vosoughi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","visual-question-answering","text-to-audio","text-to-speech","automatic-speech-recognition"],"keywords_longer_than_N":true},
	{"name":"tts_nisan_kumru_tur","keyword":"text-to-speech","description":"omersaidd/tts_nisan_kumru_tur dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/omersaidd/tts_nisan_kumru_tur","creator_name":"√ñmer Said Yilmaz","creator_url":"https://huggingface.co/omersaidd","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Turkish","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"TurkicTTS-Chuvash","keyword":"speech","description":"\n\t\n\t\t\n\t\tTurkic_TTS-Chuvash\n\t\n\n[Original repository] \n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTurkic_TTS-Chuvash is a speech dataset sourced from the Turkic_TTS GitHub repository. The dataset comprises recordings of text extracted from news articles on chuvash.org and list of digits, all read by a single female speaker at a rapid tempo. The dataset is intended for text-to-speech (TTS) research and development in the Chuvash language. The license and citation information presented in this dataset card has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gaydmi/TurkicTTS-Chuvash.","url":"https://huggingface.co/datasets/gaydmi/TurkicTTS-Chuvash","creator_name":"Dmitry Gaynullin","creator_url":"https://huggingface.co/gaydmi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Chuvash","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"TurkicTTS-Chuvash","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTurkic_TTS-Chuvash\n\t\n\n[Original repository] \n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTurkic_TTS-Chuvash is a speech dataset sourced from the Turkic_TTS GitHub repository. The dataset comprises recordings of text extracted from news articles on chuvash.org and list of digits, all read by a single female speaker at a rapid tempo. The dataset is intended for text-to-speech (TTS) research and development in the Chuvash language. The license and citation information presented in this dataset card has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gaydmi/TurkicTTS-Chuvash.","url":"https://huggingface.co/datasets/gaydmi/TurkicTTS-Chuvash","creator_name":"Dmitry Gaynullin","creator_url":"https://huggingface.co/gaydmi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Chuvash","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"TurkicTTS-Chuvash","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tTurkic_TTS-Chuvash\n\t\n\n[Original repository] \n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTurkic_TTS-Chuvash is a speech dataset sourced from the Turkic_TTS GitHub repository. The dataset comprises recordings of text extracted from news articles on chuvash.org and list of digits, all read by a single female speaker at a rapid tempo. The dataset is intended for text-to-speech (TTS) research and development in the Chuvash language. The license and citation information presented in this dataset card has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gaydmi/TurkicTTS-Chuvash.","url":"https://huggingface.co/datasets/gaydmi/TurkicTTS-Chuvash","creator_name":"Dmitry Gaynullin","creator_url":"https://huggingface.co/gaydmi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Chuvash","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"AffordancesAndSpeech","keyword":"speech","description":"giampierosalvi/AffordancesAndSpeech dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/giampierosalvi/AffordancesAndSpeech","creator_name":"Giampiero Salvi","creator_url":"https://huggingface.co/giampierosalvi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["English","apache-2.0","üá∫üá∏ Region: US","affordances","speech"],"keywords_longer_than_N":true},
	{"name":"twi_bible_v1","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTwi Text-to-Speech\n\t\n\n","url":"https://huggingface.co/datasets/worldboss/twi_bible_v1","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","text-to-speech","text-to-audio","Twi"],"keywords_longer_than_N":true},
	{"name":"bigbench_jsonl","keyword":"hate-speech-detection","description":"BIG-Bench but it doesn't require the hellish dependencies (tensorflow, pypi-bigbench, protobuf) of the official version.\ndataset = load_dataset(\"tasksource/bigbench\",'movie_recommendation')\n\nCode to reproduce:\nhttps://colab.research.google.com/drive/1MKdLdF7oqrSQCeavAcsEnPdI85kD0LzU?usp=sharing\nDatasets are capped to 50k examples to keep things light.\nI also removed the default split when train was available also to save space, as default=train+val.\n@article{srivastava2022beyond‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NJUDeepEngine/bigbench_jsonl.","url":"https://huggingface.co/datasets/NJUDeepEngine/bigbench_jsonl","creator_name":"NJUDeepEngine","creator_url":"https://huggingface.co/NJUDeepEngine","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","text-generation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"twi_bible_v1","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tTwi Text-to-Speech\n\t\n\n","url":"https://huggingface.co/datasets/worldboss/twi_bible_v1","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","text-to-speech","text-to-audio","Twi"],"keywords_longer_than_N":true},
	{"name":"medical-prescription-english-audio","keyword":"speech","description":"\n\t\n\t\t\n\t\tMedical Prescription English Audio Dataset\n\t\n\nText spoken by all participants:\n\"Doctor, my third visit, and I'm hopeful but not fully better. Joint pain eased slightly, yet mornings are tough, and I'm exhausted. The last prescription helped a bit. Can we adjust it? I want to feel like myself again.\"\nThe dataset supports training and evaluation of models in:\n\nAutomatic Speech Recognition (ASR)\nEmotional tone classification\nVoice synthesis and generation\nEmotion-aware conversational‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/medical-prescription-english-audio.","url":"https://huggingface.co/datasets/Kratos-AI/medical-prescription-english-audio","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"ESpeech-igm","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tIGM YouTube Audio Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 220 hours of processed audio segments extracted from the IGM YouTube channel with corresponding metadata. Each audio file represents a segment from IGM's educational videos and lectures, processed at 44.1kHz sample rate.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Russian\nTask: TTS, ASR, Quality Assessment\nAudio format: MP3, 44.1kHz sample rate\nStructure: Segmented audio files with JSON metadata\nSource: IGM‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ESpeech/ESpeech-igm.","url":"https://huggingface.co/datasets/ESpeech/ESpeech-igm","creator_name":"Ebany Speech","creator_url":"https://huggingface.co/ESpeech","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Russian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"ESpeech-igm","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tIGM YouTube Audio Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 220 hours of processed audio segments extracted from the IGM YouTube channel with corresponding metadata. Each audio file represents a segment from IGM's educational videos and lectures, processed at 44.1kHz sample rate.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Russian\nTask: TTS, ASR, Quality Assessment\nAudio format: MP3, 44.1kHz sample rate\nStructure: Segmented audio files with JSON metadata\nSource: IGM‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ESpeech/ESpeech-igm.","url":"https://huggingface.co/datasets/ESpeech/ESpeech-igm","creator_name":"Ebany Speech","creator_url":"https://huggingface.co/ESpeech","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Russian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"grammar-correctable-texts","keyword":"grammar","description":"\n\t\n\t\t\n\t\tGrammar Correctable Texts\n\t\n\nThese are collected texts sampled from various sources, which have been screened across several dimensions using google flash 2.0:\n\nis_english\nmeaning_is_recoverable (Intended meaning is clear enough that correction won't change it.)\ncoherent_and_on_topic (Sentences cohere; not random fragments or spam.)\nnot_style_or_dialect_intent (Oddities are not intentional dialect/poetry/stylized voice.)\nerror_density_not_extreme\nnot_code_or_markup_heavy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dleemiller/grammar-correctable-texts.","url":"https://huggingface.co/datasets/dleemiller/grammar-correctable-texts","creator_name":"Lee Miller","creator_url":"https://huggingface.co/dleemiller","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"text-to-speech-sentences","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tTexts for Ukrainian Text to Speech dataset\n\t\n\nCode for this dataset is here: https://github.com/egorsmkv/uk-tts-dataset-text\n","url":"https://huggingface.co/datasets/speech-uk/text-to-speech-sentences","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"commonvoice_17_tr_fixed","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tImproving CommonVoice 17 Turkish Dataset\n\t\n\nI recently worked on enhancing the Mozilla CommonVoice 17 Turkish dataset to create a higher quality training set for speech recognition models.Here's an overview of my process and findings.\n\n\t\n\t\t\n\t\tInitial Analysis and Split Organization\n\t\n\nMy first step was analyzing the dataset organization to understand its structure.Through analysis of filename stems as unique keys, I revealed and documented an important aspect of CommonVoice's design‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ysdede/commonvoice_17_tr_fixed.","url":"https://huggingface.co/datasets/ysdede/commonvoice_17_tr_fixed","creator_name":"Yunus Dede","creator_url":"https://huggingface.co/ysdede","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Turkish","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"test_hf_dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\ttest_hf_dataset\n\t\n\nThis dataset was created to document how to create an audio dataset and upload\nit to HuggingFace see GitHub repo.\nNext step: add more documentation.\ne.g.:\n\ncontents of the dataset\ncontext for how the dataset should be used, e.g.: datasets package\nexisting dataset cards, such as the ELI5 dataset card, show common conventions\n\n\n\t\n\t\t\n\t\n\t\n\t\tExample usage of dataset\n\t\n\nExample of transcription.\nFirst install extra dependencies, typically within virtual environment.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/guynich/test_hf_dataset.","url":"https://huggingface.co/datasets/guynich/test_hf_dataset","creator_name":"Guy Nicholson","creator_url":"https://huggingface.co/guynich","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"ar-eg-dataset","keyword":"automatic-speech-recognition","description":"An in-progress dataset for arabic-egyptian-dialect, specifically made from transcripton of DrAliGomaa videos on youtube.\nDr Ali Gomaa is a famous Egyptian Islamic Scholar and he was the mufti of Egypt from 2003-2013\n\nLink to his youtube channel: https://www.youtube.com/@DrAliGomaa\nLink to his page on facebook: https://www.facebook.com/DrAliGomaa\n\n","url":"https://huggingface.co/datasets/siddiqiya/ar-eg-dataset","creator_name":"Siddiqiya Shazoulia","creator_url":"https://huggingface.co/siddiqiya","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"NURC-SP_ENTOA_TTS","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tHow to Load the Dataset\n\t\n\nThere are 4 configurations: \"prosodic\", \"automatic\", \"audioCorpus\" and test. To load the dataset with the HuggingFace datasets library, use the following code: \nprosodic = load_dataset(\"nilc-nlp/NURC-SP_ENTOA_TTS\", name=\"prosodic\")\nautomatic = load_dataset(\"nilc-nlp/NURC-SP_ENTOA_TTS\", name = \"automatic\")\naudioCorpus = load_dataset(\"nilc-nlp/NURC-SP_ENTOA_TTS\", name = \"audioCorpus\")\ntest = load_dataset(\"nilc-nlp/NURC-SP_ENTOA_TTS\", name=\"test\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nilc-nlp/NURC-SP_ENTOA_TTS.","url":"https://huggingface.co/datasets/nilc-nlp/NURC-SP_ENTOA_TTS","creator_name":"NILC NLP","creator_url":"https://huggingface.co/nilc-nlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Portuguese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"gigaspeech2_vie","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tVietnamse subset of the Gigaspeech2 dataset\n\t\n\nextracted from: https://huggingface.co/datasets/speechcolab/gigaspeech2\n","url":"https://huggingface.co/datasets/doof-ferb/gigaspeech2_vie","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Vietnamese","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"indicvoices_pa_tagged_transcripts","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_pa_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_pa_tagged_transcripts.","url":"https://huggingface.co/datasets/WhissleAI/indicvoices_pa_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"parczech4speech-unsegmented","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tParCzech4Speech (Unsegmented Variant)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nParCzech4Speech (Unsegmented Variant) is a large-scale Czech speech dataset derived from parliamentary recordings and official transcripts. \nThis variant captures continuous speech segments without enforcing sentence boundaries, making it well-suited for real-world streaming ASR scenarios \nand speech modeling tasks that benefit from natural discourse flow.\nThe dataset is created using a combination of WhisperX and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ufal/parczech4speech-unsegmented.","url":"https://huggingface.co/datasets/ufal/parczech4speech-unsegmented","creator_name":"Institute of Formal and Applied Linguistics, Charles University, Prague","creator_url":"https://huggingface.co/ufal","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Czech","cc-by-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"nchlt_speech_nso","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tNCHLT Speech Corpus -- Sepedi\n\t\n\nThis is the Sepedi language part of the NCHLT Speech Corpus of the South African languages.\nLanguage code (ISO 639): nso\nURI: https://hdl.handle.net/20.500.12185/270\n\n\t\n\t\t\n\t\tLicence:\n\t\n\nCreative Commons Attribution 3.0 Unported License (CC BY 3.0): http://creativecommons.org/licenses/by/3.0/legalcode\n\n\t\n\t\t\n\t\tAttribution:\n\t\n\nThe Department of Arts and Culture of the government of the Republic of South Africa (DAC), Council for Scientific and Industrial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/danielshaps/nchlt_speech_nso.","url":"https://huggingface.co/datasets/danielshaps/nchlt_speech_nso","creator_name":"Daniel van Niekerk","creator_url":"https://huggingface.co/danielshaps","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","cc-by-3.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"parczech4speech-unsegmented","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tParCzech4Speech (Unsegmented Variant)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nParCzech4Speech (Unsegmented Variant) is a large-scale Czech speech dataset derived from parliamentary recordings and official transcripts. \nThis variant captures continuous speech segments without enforcing sentence boundaries, making it well-suited for real-world streaming ASR scenarios \nand speech modeling tasks that benefit from natural discourse flow.\nThe dataset is created using a combination of WhisperX and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ufal/parczech4speech-unsegmented.","url":"https://huggingface.co/datasets/ufal/parczech4speech-unsegmented","creator_name":"Institute of Formal and Applied Linguistics, Charles University, Prague","creator_url":"https://huggingface.co/ufal","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Czech","cc-by-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"tttttt","keyword":"speech","description":"\n\t\n\t\t\n\t\ttttttt\n\t\n\nThis is a merged speech dataset containing 123 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 123\nSpeakers: 4\nLanguages: tr\nEmotions: angry, happy, neutral, sad\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/tttttt.","url":"https://huggingface.co/datasets/Codyfederer/tttttt","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"tttttt","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\ttttttt\n\t\n\nThis is a merged speech dataset containing 123 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 123\nSpeakers: 4\nLanguages: tr\nEmotions: angry, happy, neutral, sad\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/tttttt.","url":"https://huggingface.co/datasets/Codyfederer/tttttt","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"QuantumAI","keyword":"automatic-speech-recognition","description":"Groovy-123/QuantumAI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Groovy-123/QuantumAI","creator_name":"KWAME MARFO","creator_url":"https://huggingface.co/Groovy-123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"tttttt","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\ttttttt\n\t\n\nThis is a merged speech dataset containing 123 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 123\nSpeakers: 4\nLanguages: tr\nEmotions: angry, happy, neutral, sad\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/tttttt.","url":"https://huggingface.co/datasets/Codyfederer/tttttt","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"QuantumAI","keyword":"text-to-speech","description":"Groovy-123/QuantumAI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Groovy-123/QuantumAI","creator_name":"KWAME MARFO","creator_url":"https://huggingface.co/Groovy-123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-15lang-zip","keyword":"speech","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (15 Languages, Augmented)\n\t\n\nThis dataset contains augmented speech command samples in 15 languages, derived from multiple public datasets. Only commands that overlap with the Google Speech Commands (GSC) vocabulary are included, making the dataset suitable for multilingual keyword spotting tasks aligned with GSC-style classification.\nAudio samples have been augmented using standard audio techniques to improve model robustness (e.g., time-shifting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang-zip.","url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang-zip","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Russian","Kazakh","Tatar","Arabic"],"keywords_longer_than_N":true},
	{"name":"cretan-speech-corpus","keyword":"automatic-speech-recognition","description":"Cretan is a variety of Modern Greek predominantly used by\nspeakers who reside on the island of Crete or belong to the Cretan\ndiaspora. This includes communities of Cretan origin that were\nrelocated to the village of Hamidieh in Syria and to Western\nAsia Minor, following the population exchange between Greece\nand Turkey in 1923. The historical and geographical factors\nthat have shaped the development and preservation of the dialect\ninclude the long-term isolation of Crete from the mainland, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ilsp/cretan-speech-corpus.","url":"https://huggingface.co/datasets/ilsp/cretan-speech-corpus","creator_name":"Institute for Language and Speech Processing","creator_url":"https://huggingface.co/ilsp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","cc-by-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"CADE","keyword":"hate-speech","description":"\n\t\n\t\t\n\t\tThe Canceling Attitudes Detection (CADE) Dataset\n\t\n\nCADE is a dataset created in the context of the research That is Unacceptable: the Moral Foundations of Canceling. Here you can find the abstract.\nCanceling is a morally-driven phenomenon that hinders the development of safe social media platforms and contributes to ideological polarization. To address this issue we present the Canceling Attitudes Detection (CADE) dataset, an annotated corpus of canceling incidents aimed at exploring‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aequa-tech/CADE.","url":"https://huggingface.co/datasets/aequa-tech/CADE","creator_name":"aequa-tech","creator_url":"https://huggingface.co/aequa-tech","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"acl-paper","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tACL Entire\n\t\n\n\n  \n\n\nACL Entire is a comprehensive dataset containing all papers from both ACL and Non-ACL events listed on the ACL Anthology website. This dataset includes complete bibliographic information for all years.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nEvents Covered: Papers from ACL and Non-ACL events.\nBibliography: Includes complete bibliographic details for every paper.\nYears Covered: Comprehensive data spanning all available years.\n\n\n\t\n\t\t\n\t\tSource\n\t\n\nAll data has been compiled from the ACL‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sleeping-ai/acl-paper.","url":"https://huggingface.co/datasets/sleeping-ai/acl-paper","creator_name":"Sleeping AI","creator_url":"https://huggingface.co/sleeping-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","summarization","text2text-generation","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"tts-indo","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tagufsamudra/tts-indo\n\t\n\nagufsamudra/tts-indo is a preprocessed Indonesian speech dataset designed for training Text-to-Speech (TTS) models. This dataset is derived from the original Dataset TTS Indo available on Kaggle.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nNumber of Examples: 114,036\nDataset Size: ~4GB\nAudio Sampling Rate: 16,000 Hz\nFeatures:\naudio: WAV audio recordings\ntext: Transcription of the audio\n\n\n\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach sample in the dataset contains:\n\naudio: A dictionary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agufsamudra/tts-indo.","url":"https://huggingface.co/datasets/agufsamudra/tts-indo","creator_name":"Gufranaka Samudra","creator_url":"https://huggingface.co/agufsamudra","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Indonesian","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"DanCarlinVoice","keyword":"text-to-speech","description":"A GPT-SoVITS dataset containing 60+ minutes of Dan Carlin's voice samples, taken from his show Supernova in the East I. \nThe dataset also contains 45+ minutes of Dan Carlin's 'quote' voice, with samples taken from both Supernova in the East I and Supernova in the East II.\n","url":"https://huggingface.co/datasets/deboradum/DanCarlinVoice","creator_name":"Pepijn","creator_url":"https://huggingface.co/deboradum","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"VNAVC","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tContributors\n\t\n\n\nMain author: qhuy242 (GitHub)\nMain annotator: ttnghii (GitHub)\n\n","url":"https://huggingface.co/datasets/qhuy242/VNAVC","creator_name":"Truong Quoc Huy","creator_url":"https://huggingface.co/qhuy242","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"VNAVC","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tContributors\n\t\n\n\nMain author: qhuy242 (GitHub)\nMain annotator: ttnghii (GitHub)\n\n","url":"https://huggingface.co/datasets/qhuy242/VNAVC","creator_name":"Truong Quoc Huy","creator_url":"https://huggingface.co/qhuy242","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"process_dataset_mini","keyword":"text-to-speech","description":"doublesizebed/process_dataset_mini dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/doublesizebed/process_dataset_mini","creator_name":"chong","creator_url":"https://huggingface.co/doublesizebed","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Malay","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"shkolkovo-bobr.video-webinars-audio","keyword":"speech","description":"\n\t\n\t\t\n\t\tshkolkovo-bobr.video-webinars-audio\n\t\n\nDataset of audio of ‚âà2573 webinars from bobr.video with text transcription made with whisper and VAD. Webinars are parts of free online school exams training courses made by Shkolkovo.\nLanguage: Russian, includes some webinars on English\nDataset structure:\n\nmp3 files in format ID.mp3, where ID is webinar ID. You can check original webinar with url like bobr.video/watch/ID. Some webinars may contain multiple speakers and music.\ntxt file in format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZeroAgency/shkolkovo-bobr.video-webinars-audio.","url":"https://huggingface.co/datasets/ZeroAgency/shkolkovo-bobr.video-webinars-audio","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Russian","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"VietMed","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tVietMed: A Dataset and Benchmark for Automatic Speech Recognition of Vietnamese in the Medical Domain (LREC-COLING 2024, Oral)\n\t\n\n\n\t\n\t\t\n\t\tDescription:\n\t\n\nWe introduced a Vietnamese speech recognition dataset in the medical domain comprising 16h of labeled medical speech, 1000h of unlabeled medical speech and 1200h of unlabeled general-domain speech. \nTo our best knowledge, VietMed is by far the world‚Äôs largest public medical speech recognition dataset in 7 aspects:\ntotal duration‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/leduckhai/VietMed.","url":"https://huggingface.co/datasets/leduckhai/VietMed","creator_name":"Le Duc Khai","creator_url":"https://huggingface.co/leduckhai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Vietnamese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"shkolkovo-bobr.video-webinars-audio","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tshkolkovo-bobr.video-webinars-audio\n\t\n\nDataset of audio of ‚âà2573 webinars from bobr.video with text transcription made with whisper and VAD. Webinars are parts of free online school exams training courses made by Shkolkovo.\nLanguage: Russian, includes some webinars on English\nDataset structure:\n\nmp3 files in format ID.mp3, where ID is webinar ID. You can check original webinar with url like bobr.video/watch/ID. Some webinars may contain multiple speakers and music.\ntxt file in format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZeroAgency/shkolkovo-bobr.video-webinars-audio.","url":"https://huggingface.co/datasets/ZeroAgency/shkolkovo-bobr.video-webinars-audio","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Russian","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"nug_myanmar_asr","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\t366 Hours NUG Myanmar ASR Dataset\n\t\n\nThe NUG Myanmar ASR Dataset is the first large-scale open Burmese speech dataset ‚Äî now expanded to over 521,476 audio-text pairs, totaling ~366 hours of clean, segmented audio. All data was collected from public-service educational broadcasts by the National Unity Government (NUG) of Myanmar and the FOEIM Academy.\nThis dataset is released under a CC0 1.0 Universal license ‚Äî fully open and public domain. No attribution required.\n\n\t\n\t\t\n\t\n\t\n\t\tüïäÔ∏è‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/nug_myanmar_asr.","url":"https://huggingface.co/datasets/freococo/nug_myanmar_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"nug_myanmar_asr","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\t366 Hours NUG Myanmar ASR Dataset\n\t\n\nThe NUG Myanmar ASR Dataset is the first large-scale open Burmese speech dataset ‚Äî now expanded to over 521,476 audio-text pairs, totaling ~366 hours of clean, segmented audio. All data was collected from public-service educational broadcasts by the National Unity Government (NUG) of Myanmar and the FOEIM Academy.\nThis dataset is released under a CC0 1.0 Universal license ‚Äî fully open and public domain. No attribution required.\n\n\t\n\t\t\n\t\n\t\n\t\tüïäÔ∏è‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/nug_myanmar_asr.","url":"https://huggingface.co/datasets/freococo/nug_myanmar_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"mm","keyword":"text-to-speech","description":"MARKETMECHANIK/mm dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/MARKETMECHANIK/mm","creator_name":"AMIR","creator_url":"https://huggingface.co/MARKETMECHANIK","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","table-question-answering","translation","fill-mask","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"audio_data_russian_backup","keyword":"speech","description":"\n\t\n\t\t\n\t\tDataset Audio Russian Backup\n\t\n\nThis is a backup dataset with Russian audio data, split into train_0 to train_49 for tasks like text-to-speech, speech recognition, and speaker identification.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\ntext: Audio transcription (string).\nspeaker_name: Speaker identifier (string).\n\n\naudio: Audio file.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nLoad the dataset like this:\nfrom datasets import load_dataset\ndataset = load_dataset(\"kijjjj/audio_data_russian_backup\", split=\"train_0\")  # Or any train_X‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kijjjj/audio_data_russian_backup.","url":"https://huggingface.co/datasets/kijjjj/audio_data_russian_backup","creator_name":"fgfd","creator_url":"https://huggingface.co/kijjjj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","100K<n<1M","Audio"],"keywords_longer_than_N":true},
	{"name":"ChFT","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for ChFT\n\t\n\n\n\nThis dataset is published with the paper Full-text Error Correction for Chinese Speech Recognition with Large Language Model in ICASSP 2025.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tzyll/ChFT.","url":"https://huggingface.co/datasets/tzyll/ChFT","creator_name":"Zhiyuan Tang","creator_url":"https://huggingface.co/tzyll","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","apache-2.0","arxiv:2409.07790","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"audio_data_russian_backup","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Audio Russian Backup\n\t\n\nThis is a backup dataset with Russian audio data, split into train_0 to train_49 for tasks like text-to-speech, speech recognition, and speaker identification.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\ntext: Audio transcription (string).\nspeaker_name: Speaker identifier (string).\n\n\naudio: Audio file.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nLoad the dataset like this:\nfrom datasets import load_dataset\ndataset = load_dataset(\"kijjjj/audio_data_russian_backup\", split=\"train_0\")  # Or any train_X‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kijjjj/audio_data_russian_backup.","url":"https://huggingface.co/datasets/kijjjj/audio_data_russian_backup","creator_name":"fgfd","creator_url":"https://huggingface.co/kijjjj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","100K<n<1M","Audio"],"keywords_longer_than_N":true},
	{"name":"wordnet-definitions","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tWordNet Multiple Definitions - Columnar Format\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is an optimized columnar version of WordNet multiple definitions, designed for high-performance queries and rapid extraction.\nEach definition was sourced by GPT-5 Nano. I may update this to include additional definitions in the future, but I will not break the format.\nThe original dataset has a more unabridged and noisy set of data; so I'm definitely going to leave it intact. Noisy training is important‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AbstractPhil/wordnet-definitions.","url":"https://huggingface.co/datasets/AbstractPhil/wordnet-definitions","creator_name":"AbstractPhila","creator_url":"https://huggingface.co/AbstractPhil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","translation","text-classification","question-answering"],"keywords_longer_than_N":true},
	{"name":"multivsr","keyword":"speech","description":"\n\t\n\t\t\n\t\tDataset: MultiVSR\n\t\n\nWe introduce a large-scale multilingual lip-reading dataset: MultiVSR. The dataset comprises a total of 12,000 hours of video footage, covering English + 12 non-English languages. MultiVSR is a massive dataset with a huge diversity in terms of the speakers as well as languages, with approximately 1.6M video clips across 123K YouTube videos. Please check the website for samples.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDownload instructions\n\t\n\nPlease check the GitHub repo to download‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sindhuhegde/multivsr.","url":"https://huggingface.co/datasets/sindhuhegde/multivsr","creator_name":"Sindhu Hegde","creator_url":"https://huggingface.co/sindhuhegde","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"medreport_audio_204","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tMedReport - Audio Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains medical report audio files with their transcriptions, formatted according to HuggingFace Audio Dataset specifications. It's suitable for training speech-to-text models and instruction-following models in the medical domain.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset follows the official HuggingFace Audio Dataset format:\ndataset/\n‚îî‚îÄ‚îÄ train/\n    ‚îú‚îÄ‚îÄ audio/\n    ‚îÇ   ‚îú‚îÄ‚îÄ 20240315143022.wav\n    ‚îÇ   ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wouk1805/medreport_audio_204.","url":"https://huggingface.co/datasets/wouk1805/medreport_audio_204","creator_name":"Young-Wouk Kim","creator_url":"https://huggingface.co/wouk1805","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-generation","French","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Lyrics1M","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Lyrics1M\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLyrics for approximately 1 million tracks. Entries include unique ID, artist, track title, lyrics and language.\nThis is a subset of bigdata-pw/Spotify, filtered for popularity >= 20 and deduplicated by track title.\n\nCurated by: hlky\nLicense: Open Data Commons Attribution License (ODC-By) v1.0\n\n\n\t\n\t\t\n\t\n\t\n\t\tCitation Information\n\t\n\n@misc{Lyrics1M,\n  author = {hlky},\n  title = {Lyrics1M},\n  year = {2024}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bigdata-pw/Lyrics1M.","url":"https://huggingface.co/datasets/bigdata-pw/Lyrics1M","creator_name":"BIG data","creator_url":"https://huggingface.co/bigdata-pw","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","text-to-speech","text-to-audio","text-generation","odc-by"],"keywords_longer_than_N":true},
	{"name":"imasc_slr","keyword":"automatic-speech-recognition","description":"Clone of : thennal/IMaSC\n","url":"https://huggingface.co/datasets/vrclc/imasc_slr","creator_name":"Virtual Resource Centre for Language Computing (Digital University Kerala)","creator_url":"https://huggingface.co/vrclc","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Malayalam","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Attention2Probability","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tAttention2Probability: Attention-Driven Terminology Probability Estimation for Robust Speech-to-Text System\n\t\n\n\n  \n  \n  \n\n\nAttention2Probability (A2P) is a lightweight intervention scheme for speech terminology. The core approach is to use the cross-attention mechanism to retrieve the terms that may appear in the audio and add these terms to the prompt of the llm to complete the term intervention.\n\n\t\t\n\t\tData description\n\t\n\nThis project does not provide audio data for librispeech and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ByteDance/Attention2Probability.","url":"https://huggingface.co/datasets/ByteDance/Attention2Probability","creator_name":"ByteDance","creator_url":"https://huggingface.co/ByteDance","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","automatic-speech-recognition","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"0.1_augmented_implicit_hate_speech_dataset","keyword":"hate-speech","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is a public release of the dataset described in ElSherief et al. (2022) and augmented by Adar and Wiberg (2025).\nThis dataset card is a work in progress and will be improved over time.\n\n\t\n\t\t\n\t\tContributions\n\t\n\nDataset augmented by @emradar and @Wiberacci.\n\n\t\n\t\t\n\t\tReferences\n\t\n\nElSherief, M., Ziems, C., Muchlinski, D., Anupindi, V., Seybolt, J., De Choudhury, M., & Yang, D. (2021). Latent Hatred: A Benchmark for Understanding Implicit Hate Speech. In Proceedings of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/emradar/0.1_augmented_implicit_hate_speech_dataset.","url":"https://huggingface.co/datasets/emradar/0.1_augmented_implicit_hate_speech_dataset","creator_name":"Emir Adar","creator_url":"https://huggingface.co/emradar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","10K - 100K","arrow"],"keywords_longer_than_N":true},
	{"name":"Tamazight-Speech-to-Arabic-Text","keyword":"speech","description":"\n\t\n\t\t\n\t\tTamazight-Arabic Speech Recognition Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the EMINES organization-hosted version of the Tamazight-Arabic Speech Recognition Dataset, synchronized with the original dataset. It contains ~15.5 hours of Tamazight speech (Tachelhit dialect) paired with Arabic transcriptions, designed for developing ASR and translation systems.\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text.","url":"https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text","creator_name":"EMINES, UM6P, Benguerir, Maroc","creator_url":"https://huggingface.co/EMINES","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","Standard Moroccan Tamazight","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"hindi-language-audio","keyword":"speech","description":"\n\t\n\t\t\n\t\tHindi Language Audio Dataset\n\t\n\nText spoken by all participants:\n\"‡§ï‡•É‡§§‡•ç‡§∞‡§ø‡§Æ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§§‡•ç‡§§‡§æ (AI) ‡§§‡•á‡§ú‡•Ä ‡§∏‡•á ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à, ‡§ú‡•ã ‡§∞‡•ã‡§ú‡§Æ‡§∞‡•ç‡§∞‡§æ ‡§ï‡•Ä ‡§ú‡§ø‡§Ç‡§¶‡§ó‡•Ä ‡§ï‡•ã ‡§¨‡§¶‡§≤ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§ ‡§á‡§∏‡§ï‡•á ‡§®‡§µ‡§æ‡§ö‡§æ‡§∞ ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ, ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§∏‡•á‡§µ‡§æ ‡§î‡§∞ ‡§ï‡§æ‡§Æ ‡§ï‡•ã ‡§¨‡•á‡§π‡§§‡§∞ ‡§¨‡§®‡§æ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§®‡§è ‡§Ö‡§µ‡§∏‡§∞ ‡§™‡•à‡§¶‡§æ ‡§π‡•ã ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§\"\nThe dataset supports training and evaluation of models in:\n\nAutomatic Speech Recognition (ASR)\nEmotional tone classification\nVoice synthesis and generation\nEmotion-aware conversational agents\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntended Uses\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t‚úÖ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/hindi-language-audio.","url":"https://huggingface.co/datasets/Kratos-AI/hindi-language-audio","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","cc-by-4.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"Tamazight-Speech-to-Arabic-Text","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTamazight-Arabic Speech Recognition Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the EMINES organization-hosted version of the Tamazight-Arabic Speech Recognition Dataset, synchronized with the original dataset. It contains ~15.5 hours of Tamazight speech (Tachelhit dialect) paired with Arabic transcriptions, designed for developing ASR and translation systems.\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text.","url":"https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text","creator_name":"EMINES, UM6P, Benguerir, Maroc","creator_url":"https://huggingface.co/EMINES","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","Standard Moroccan Tamazight","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"nchlt_speech_tso","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tNCHLT Speech Corpus -- Xitsonga\n\t\n\nThis is the Xitsonga language part of the NCHLT Speech Corpus of the South African languages.\nLanguage code (ISO 639): tso\nURI: https://hdl.handle.net/20.500.12185/277\n\n\t\n\t\t\n\t\tLicence:\n\t\n\nCreative Commons Attribution 3.0 Unported License (CC BY 3.0): http://creativecommons.org/licenses/by/3.0/legalcode\n\n\t\n\t\t\n\t\tAttribution:\n\t\n\nThe Department of Arts and Culture of the government of the Republic of South Africa (DAC), Council for Scientific and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/danielshaps/nchlt_speech_tso.","url":"https://huggingface.co/datasets/danielshaps/nchlt_speech_tso","creator_name":"Daniel van Niekerk","creator_url":"https://huggingface.co/danielshaps","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Tsonga","cc-by-3.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"LnNor","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for the LnNor Corpus\n\t\n\n\nA multilingual dataset of high-quality speech recordings in Norwegian, English, and Polish, designed for research into cross-linguistic influence, multilingual language acquisition, and applications in NLP and speech processing such as ASR, TTS, and linguistic variability modeling. The dataset features structured experimental tasks such as reading, picture and video description, and spontaneous conversation to capture phonological, syntactic, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MultiBridge/LnNor.","url":"https://huggingface.co/datasets/MultiBridge/LnNor","creator_name":"MultiBridge","creator_url":"https://huggingface.co/MultiBridge","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","text-classification","automatic-speech-recognition","audio-classification","Norwegian"],"keywords_longer_than_N":true},
	{"name":"banking-customersupport-english-audio","keyword":"speech","description":"\n\t\n\t\t\n\t\tBanking Customer Support English Audio Dataset\n\t\n\nText spoken by all participants:\n\"I forgot my online banking password; how do I reset it? I‚Äôm locked out of my account and need to pay a bill urgently. Please guide me through the steps.\"\nThe dataset supports training and evaluation of models in:\n\nAutomatic Speech Recognition (ASR)\nEmotional tone classification\nVoice synthesis and generation\nEmotion-aware conversational agents\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntended Uses\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t‚úÖ Direct Use‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/banking-customersupport-english-audio.","url":"https://huggingface.co/datasets/Kratos-AI/banking-customersupport-english-audio","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"e-commerce-customersupport-english-audio","keyword":"speech","description":"\n\t\n\t\t\n\t\tE-Commerce Customer Support English Audio Dataset\n\t\n\nText spoken by all participants:\n\"My order hasn‚Äôt arrived yet; can you track it? It was supposed to be delivered yesterday, and I‚Äôm worried it‚Äôs lost. Please provide an update.\"\nThe dataset supports training and evaluation of models in:\n\nAutomatic Speech Recognition (ASR)\nEmotional tone classification\nVoice synthesis and generation\nEmotion-aware conversational agents\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntended Uses\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t‚úÖ Direct Use‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/e-commerce-customersupport-english-audio.","url":"https://huggingface.co/datasets/Kratos-AI/e-commerce-customersupport-english-audio","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"my_smolvla123456789","keyword":"automatic-speech-recognition","description":"Amanpatel81/my_smolvla123456789 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Amanpatel81/my_smolvla123456789","creator_name":"Amankumar Patel","creator_url":"https://huggingface.co/Amanpatel81","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","table-question-answering","question-answering","translation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"my_smolvla123456789","keyword":"text-to-speech","description":"Amanpatel81/my_smolvla123456789 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Amanpatel81/my_smolvla123456789","creator_name":"Amankumar Patel","creator_url":"https://huggingface.co/Amanpatel81","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","table-question-answering","question-answering","translation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"2hr_myanmar_asr_raw_audio","keyword":"speech","description":"\n\t\n\t\t\n\t\tüá≤üá≤ Raw 2-Hour Burmese ASR Audio Dataset\n\t\n\nA ~2-hour Burmese (Myanmar language) ASR dataset featuring 1,612 audio clips with aligned transcripts, curated from official public-service educational broadcasts by FOEIM Academy ‚Äî a civic media arm of FOEIM.ORG, operating under the Myanmar National Unity Government (NUG).\nThis dataset is MIT-licensed as a public good ‚Äî a shared asset for the Burmese-speaking world. It serves speech technology, education, and cultural preservation efforts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/2hr_myanmar_asr_raw_audio.","url":"https://huggingface.co/datasets/freococo/2hr_myanmar_asr_raw_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","mit"],"keywords_longer_than_N":true},
	{"name":"qdat","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tQ-dat\n\t\n\nqdat dataset was introudced in this paper cleaned and downsampled to 16000 HZ with the following specs:\n\nDownsampled to 16000 HZ\nFixed mislabeling for origianl_id: s18\nFixed typos in the metadata as\n\nDuplicate Items\n{'file_name': 's11_6.wav', 'separate_tide': 0, 'the_tight_noon': 0, 'concealment': 0, 'target': 0, 'age': 18, 'gender': 0, 'id': '147feec0'}\n{'file_name': 's11_6.wav', 'separate_tide': 0, 'the_tight_noon': 0, 'concealment': 0, 'target': 0, 'age': 18, 'gender': 0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/obadx/qdat.","url":"https://huggingface.co/datasets/obadx/qdat","creator_name":"Abdullah","creator_url":"https://huggingface.co/obadx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"2hr_myanmar_asr_raw_audio","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tüá≤üá≤ Raw 2-Hour Burmese ASR Audio Dataset\n\t\n\nA ~2-hour Burmese (Myanmar language) ASR dataset featuring 1,612 audio clips with aligned transcripts, curated from official public-service educational broadcasts by FOEIM Academy ‚Äî a civic media arm of FOEIM.ORG, operating under the Myanmar National Unity Government (NUG).\nThis dataset is MIT-licensed as a public good ‚Äî a shared asset for the Burmese-speaking world. It serves speech technology, education, and cultural preservation efforts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/2hr_myanmar_asr_raw_audio.","url":"https://huggingface.co/datasets/freococo/2hr_myanmar_asr_raw_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","mit"],"keywords_longer_than_N":true},
	{"name":"Common-Voice-17-Arabic-for-Seasme-CSM-Finetuning","keyword":"speech","description":"\n\t\n\t\t\n\t\tCurated Arabic Speech Dataset for Seasme (from MCV17)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a curated and preprocessed version of the Arabic (ar) subset from Mozilla Common Voice (MCV) 17.0. It has been specifically prepared for fine-tuning conversational speech models, with a primary focus on the Seasme-CSM model architecture. The dataset consists of audio clips in WAV format (24kHz, mono) and their corresponding transcripts, along with integer speaker IDs.\nThe original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MAdel121/Common-Voice-17-Arabic-for-Seasme-CSM-Finetuning.","url":"https://huggingface.co/datasets/MAdel121/Common-Voice-17-Arabic-for-Seasme-CSM-Finetuning","creator_name":"MAdel","creator_url":"https://huggingface.co/MAdel121","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc0-1.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"sauatai-ertegiler-kz-misspellings-kk-s170-len60-n6-m1-v1","keyword":"grammar","description":"\n\t\n\t\t\n\t\tSauatAI ‚Äî Kazakh Misspelled Sentences from Ertegiler.kz\n\t\n\nSauatAI is a grammar-focused dataset built from 170 children‚Äôs stories scraped from ertegiler.kz on July 5, 2025. The dataset was designed to support Kazakh language grammar correction, error detection, and text augmentation research.\n\n\t\n\t\t\n\t\tüìå Dataset Details\n\t\n\n\ns170 ‚Äî 170 unique stories were scraped and sentence-tokenized.\nlen60 ‚Äî Only sentences with ‚â§60 characters were retained.\nn6 ‚Äî Each correct sentence has 5‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alphazhan/sauatai-ertegiler-kz-misspellings-kk-s170-len60-n6-m1-v1.","url":"https://huggingface.co/datasets/alphazhan/sauatai-ertegiler-kz-misspellings-kk-s170-len60-n6-m1-v1","creator_name":"Alzhan Nurgaliyev","creator_url":"https://huggingface.co/alphazhan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","Kazakh","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"voices-libritts","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tLibriTTS Speaker Voices & Embeddings\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset provides a collection of speaker voice samples from the LibriTTS corpus. For each speaker, a single 30-second audio clip is provided, created by concatenating their speech segments.\nThe dataset is designed for tasks such as speaker identification, speaker verification, and as a voice bank for Text-to-Speech (TTS) models, particularly for voice cloning.\nIn addition to the audio files and their metadata‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sdialog/voices-libritts.","url":"https://huggingface.co/datasets/sdialog/voices-libritts","creator_name":"SDialog","creator_url":"https://huggingface.co/sdialog","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"rel_dataset","keyword":"text-to-speech","description":"m522t/rel_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/m522t/rel_dataset","creator_name":"Mehrshad Taji","creator_url":"https://huggingface.co/m522t","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Persian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"speakeroverlap_multiseg","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tMultiSeg Dataset for ASR Hallucinations\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nMultiSeg is a perturbed and altered version of the TEDLIUM3 dataset, specifically created for evaluating the robustness of Automatic Speech Recognition (ASR) systems. This dataset is derived from the 'speakeroverlap' subset, which consists of held-back training data from TEDLIUM3.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nThe primary purpose of the MultiSeg dataset is to:\n\nElicit hallucinations from ASR systems\nEvaluate ASR performance under‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zbrunner/speakeroverlap_multiseg.","url":"https://huggingface.co/datasets/zbrunner/speakeroverlap_multiseg","creator_name":"Zoe Brunner","creator_url":"https://huggingface.co/zbrunner","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"arabic-audio-dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tArabic Audio Dataset\n\t\n\n*This dataset contains high-quality (‚ÄúA-grade‚Äù) data. It has been carefully curated, cleaned, and verified to ensure accuracy, completeness, and consistency, making it suitable for high-stakes or production-grade model training.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:\n    - anoushka@kgen.io\n    - abhishek.vadapalli@kgen.io\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Categories: Speech Emotion Recognition (SER)\nSupported Tasks:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/arabic-audio-dataset.","url":"https://huggingface.co/datasets/Kratos-AI/arabic-audio-dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Arabic","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"noun-phrases","keyword":"grammar","description":"\n\t\n\t\t\n\t\tNoun Phrases Dataset\n\t\n\nThis dataset contains noun phrases extracted from allenai/c4.\nIt includes two configurations: uncased and cased, with 1‚Äâ895‚Äâ908 and 2‚Äâ000‚Äâ002 entries, respectively.\n\n\t\n\t\t\n\t\tJSONL Fields\n\t\n\nEach entry contains:\n\nnoun_phrase: The extracted noun phrase.\ncount: Frequency of occurrence.\n\n\n\t\n\t\t\n\t\tExample Rows\n\t\n\n{\"noun_phrase\": \"ship invoices\", \"count\": 1}\n{\"noun_phrase\": \"\\\"river\", \"count\": 1}\n{\"noun_phrase\": \"no boiler system\", \"count\": 1}\n\n\n\t\n\t\t\n\t\tConstruction‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/noun-phrases.","url":"https://huggingface.co/datasets/agentlans/noun-phrases","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","odc-by","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"noun-phrases","keyword":"linguistics","description":"\n\t\n\t\t\n\t\tNoun Phrases Dataset\n\t\n\nThis dataset contains noun phrases extracted from allenai/c4.\nIt includes two configurations: uncased and cased, with 1‚Äâ895‚Äâ908 and 2‚Äâ000‚Äâ002 entries, respectively.\n\n\t\n\t\t\n\t\tJSONL Fields\n\t\n\nEach entry contains:\n\nnoun_phrase: The extracted noun phrase.\ncount: Frequency of occurrence.\n\n\n\t\n\t\t\n\t\tExample Rows\n\t\n\n{\"noun_phrase\": \"ship invoices\", \"count\": 1}\n{\"noun_phrase\": \"\\\"river\", \"count\": 1}\n{\"noun_phrase\": \"no boiler system\", \"count\": 1}\n\n\n\t\n\t\t\n\t\tConstruction‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/noun-phrases.","url":"https://huggingface.co/datasets/agentlans/noun-phrases","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","odc-by","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"NonverbalTTS","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tNonverbalTTS Dataset üéµüó£Ô∏è\n\t\n\n\n\nNonverbalTTS is a 17-hour open-access English speech corpus with aligned text annotations for nonverbal vocalizations (NVs) and emotional categories, designed to advance expressive text-to-speech (TTS) research.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Features ‚ú®\n\t\n\n\n17 hours of high-quality speech data\n10 NV types: Breathing, laughter, sighing, sneezing, coughing, throat clearing, groaning, grunting, snoring, sniffing\n8 emotion categories: Angry, disgusted, fearful, happy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/deepvk/NonverbalTTS.","url":"https://huggingface.co/datasets/deepvk/NonverbalTTS","creator_name":"deep vk","creator_url":"https://huggingface.co/deepvk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"audiobooks","keyword":"speech","description":"170 hours of aligned audiobooks taken from tatkniga.ru. There are 4 speakers with 17+ hours of audio and 20 speakers in total. All the books are in free access and most of them in public domain.\n","url":"https://huggingface.co/datasets/yasalma/audiobooks","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"hatevolution-time-sensitive-shifts","keyword":"speech","description":"\n\t\n\t\t\n\t\tDataset Info\n\t\n\nThe hatevolution-time-sensitive-shifts dataset contains the data used for Experiment 1 in the paper Hatevolution: What Static Benchmarks Don't Tell Us (Di Bonaventura et al., 2025). \nIt is built using the test set of the English version of the Singapore Online Attack dataset (Haber et al., 2023).\n","url":"https://huggingface.co/datasets/dibo/hatevolution-time-sensitive-shifts","creator_name":"Chiara Di Bonaventura","creator_url":"https://huggingface.co/dibo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","n<1K","arxiv:2506.12148"],"keywords_longer_than_N":true},
	{"name":"audiobooks","keyword":"automatic-speech-recognition","description":"170 hours of aligned audiobooks taken from tatkniga.ru. There are 4 speakers with 17+ hours of audio and 20 speakers in total. All the books are in free access and most of them in public domain.\n","url":"https://huggingface.co/datasets/yasalma/audiobooks","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"wiki-en-in-neerja-speech","keyword":"automatic-speech-recognition","description":"This dataset contains 10K audio samples generated using Microsoft Edge Text-to-Speech via EdgeTTS. \n\nTotal samples: 10K\nAudio format: MP3\nSample rate: 24kHz\nTotal duration: 95735.86 seconds (26.59 hours)\nAverage duration: 9.57 seconds\nLanguages included: English\nVoices used: en-IN-NeerjaExpressiveNeural\n\nOverall this is low quality and should only be used for training toy tts models.\nIn my case this was for finetuning a low quality Piper TTS model.\nInput sentences were randomly sampled from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shb777/wiki-en-in-neerja-speech.","url":"https://huggingface.co/datasets/shb777/wiki-en-in-neerja-speech","creator_name":"SB","creator_url":"https://huggingface.co/shb777","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"hatevolution-time-sensitive-shifts","keyword":"hate-speech","description":"\n\t\n\t\t\n\t\tDataset Info\n\t\n\nThe hatevolution-time-sensitive-shifts dataset contains the data used for Experiment 1 in the paper Hatevolution: What Static Benchmarks Don't Tell Us (Di Bonaventura et al., 2025). \nIt is built using the test set of the English version of the Singapore Online Attack dataset (Haber et al., 2023).\n","url":"https://huggingface.co/datasets/dibo/hatevolution-time-sensitive-shifts","creator_name":"Chiara Di Bonaventura","creator_url":"https://huggingface.co/dibo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","n<1K","arxiv:2506.12148"],"keywords_longer_than_N":true},
	{"name":"audiobooks","keyword":"text-to-speech","description":"170 hours of aligned audiobooks taken from tatkniga.ru. There are 4 speakers with 17+ hours of audio and 20 speakers in total. All the books are in free access and most of them in public domain.\n","url":"https://huggingface.co/datasets/yasalma/audiobooks","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"tts_mazlum_kiper_tur","keyword":"text-to-speech","description":"omersaidd/tts_mazlum_kiper_tur dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/omersaidd/tts_mazlum_kiper_tur","creator_name":"√ñmer Said Yilmaz","creator_url":"https://huggingface.co/omersaidd","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Turkish","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"wolof_tts","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tWolof TTS\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a Wolof Text To Speech (TTS) dataset collected by Baamtu Datamation as part of the AI4D African language program. \nThe original dataset is hosted on Zenodo and it contains recordings from two (02) natif Wolof speakers (a male and female voice). Each speaker recored more than 20,000 sentences.\n\n\t\n\t\t\n\t\n\t\n\t\tSpeaking time:\n\t\n\n-- Male: 22h 28mn 41s\n-- Female: 18h 47mn 19s\n\nThe text dataset comes from news websites, Wikipedia and self‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/galsenai/wolof_tts.","url":"https://huggingface.co/datasets/galsenai/wolof_tts","creator_name":"GalsenAI Lab","creator_url":"https://huggingface.co/galsenai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Wolof","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"arabic_myanmar_quran_voices","keyword":"speech","description":"\n\t\n\t\t\n\t\tüìñ Arabic-Myanmar Quran Voice Dataset\n\t\n\n\n\t\n\t\t\n\t\tüïå Overview\n\t\n\nThis dataset contains high-quality MP3 audio recordings of the entire Holy Qur‚Äôan with:\n\nArabic recitation of each verse\nFollowed immediately by its Myanmar (Burmese) translation\n\nIt is the first complete Arabic-Myanmar Quran audio interpretation of its kind publicly released in Myanmar. The goal is to make the Qur‚Äôan more accessible to:\n\nElderly persons\nBlind or visually impaired people\nMyanmar speakers who wish to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/arabic_myanmar_quran_voices.","url":"https://huggingface.co/datasets/freococo/arabic_myanmar_quran_voices","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","audio-to-audio","automatic-speech-recognition","text-to-speech","human-annotated"],"keywords_longer_than_N":true},
	{"name":"denoised-evaluation-dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tDenoised Subset Fixed\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 500 samples organized across multiple splits and 1 subsets.\nThe dataset includes audio data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tSubsets\n\t\n\nThis dataset includes the following subsets:\n\ndenoised: 500 samples\ntest: 500 samples\n\n\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nLoad specific subset and split:\nfrom datasets import load_dataset\n\n# Load specific subset and split\ndataset = load_dataset('sujalappa/denoised-evaluation-dataset'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sujalappa/denoised-evaluation-dataset.","url":"https://huggingface.co/datasets/sujalappa/denoised-evaluation-dataset","creator_name":"sujal rajeev chondhekar","creator_url":"https://huggingface.co/sujalappa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"kasem-speech-text-parallel","keyword":"speech","description":"\n\t\n\t\t\n\t\tKasem Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 75990 parallel speech-text pairs for Kasem, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Kasem - xsm\nTask: Speech Recognition, Text-to-Speech\nSize: 75990 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/kasem-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/kasem-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Kasem"],"keywords_longer_than_N":true},
	{"name":"arabic_myanmar_quran_voices","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tüìñ Arabic-Myanmar Quran Voice Dataset\n\t\n\n\n\t\n\t\t\n\t\tüïå Overview\n\t\n\nThis dataset contains high-quality MP3 audio recordings of the entire Holy Qur‚Äôan with:\n\nArabic recitation of each verse\nFollowed immediately by its Myanmar (Burmese) translation\n\nIt is the first complete Arabic-Myanmar Quran audio interpretation of its kind publicly released in Myanmar. The goal is to make the Qur‚Äôan more accessible to:\n\nElderly persons\nBlind or visually impaired people\nMyanmar speakers who wish to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/arabic_myanmar_quran_voices.","url":"https://huggingface.co/datasets/freococo/arabic_myanmar_quran_voices","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","audio-to-audio","automatic-speech-recognition","text-to-speech","human-annotated"],"keywords_longer_than_N":true},
	{"name":"test-datasets","keyword":"automatic-speech-recognition","description":"chanchungkit/test-datasets dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/chanchungkit/test-datasets","creator_name":"Chan Chung Kit","creator_url":"https://huggingface.co/chanchungkit","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-audio","text-to-speech","translation"],"keywords_longer_than_N":true},
	{"name":"denoised-evaluation-dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDenoised Subset Fixed\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 500 samples organized across multiple splits and 1 subsets.\nThe dataset includes audio data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tSubsets\n\t\n\nThis dataset includes the following subsets:\n\ndenoised: 500 samples\ntest: 500 samples\n\n\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nLoad specific subset and split:\nfrom datasets import load_dataset\n\n# Load specific subset and split\ndataset = load_dataset('sujalappa/denoised-evaluation-dataset'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sujalappa/denoised-evaluation-dataset.","url":"https://huggingface.co/datasets/sujalappa/denoised-evaluation-dataset","creator_name":"sujal rajeev chondhekar","creator_url":"https://huggingface.co/sujalappa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"kasem-speech-text-parallel","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tKasem Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 75990 parallel speech-text pairs for Kasem, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Kasem - xsm\nTask: Speech Recognition, Text-to-Speech\nSize: 75990 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/kasem-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/kasem-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Kasem"],"keywords_longer_than_N":true},
	{"name":"GeoreviewClassification","keyword":"hate-speech-detection","description":"\n  GeoreviewClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nReview classification (5-point scale) based on Yandex Georeview dataset\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/yandex/geo-reviews-dataset-2023\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GeoreviewClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GeoreviewClassification.","url":"https://huggingface.co/datasets/mteb/GeoreviewClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"arabic_myanmar_quran_voices","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tüìñ Arabic-Myanmar Quran Voice Dataset\n\t\n\n\n\t\n\t\t\n\t\tüïå Overview\n\t\n\nThis dataset contains high-quality MP3 audio recordings of the entire Holy Qur‚Äôan with:\n\nArabic recitation of each verse\nFollowed immediately by its Myanmar (Burmese) translation\n\nIt is the first complete Arabic-Myanmar Quran audio interpretation of its kind publicly released in Myanmar. The goal is to make the Qur‚Äôan more accessible to:\n\nElderly persons\nBlind or visually impaired people\nMyanmar speakers who wish to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/arabic_myanmar_quran_voices.","url":"https://huggingface.co/datasets/freococo/arabic_myanmar_quran_voices","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","audio-to-audio","automatic-speech-recognition","text-to-speech","human-annotated"],"keywords_longer_than_N":true},
	{"name":"test-datasets","keyword":"text-to-speech","description":"chanchungkit/test-datasets dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/chanchungkit/test-datasets","creator_name":"Chan Chung Kit","creator_url":"https://huggingface.co/chanchungkit","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-audio","text-to-speech","translation"],"keywords_longer_than_N":true},
	{"name":"test-datasets","keyword":"text-to-speech","description":"chanchungkit/test-datasets dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/chanchungkit/test-datasets","creator_name":"Chan Chung Kit","creator_url":"https://huggingface.co/chanchungkit","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-audio","text-to-speech","translation"],"keywords_longer_than_N":true},
	{"name":"denoised-evaluation-dataset","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDenoised Subset Fixed\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 500 samples organized across multiple splits and 1 subsets.\nThe dataset includes audio data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tSubsets\n\t\n\nThis dataset includes the following subsets:\n\ndenoised: 500 samples\ntest: 500 samples\n\n\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nLoad specific subset and split:\nfrom datasets import load_dataset\n\n# Load specific subset and split\ndataset = load_dataset('sujalappa/denoised-evaluation-dataset'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sujalappa/denoised-evaluation-dataset.","url":"https://huggingface.co/datasets/sujalappa/denoised-evaluation-dataset","creator_name":"sujal rajeev chondhekar","creator_url":"https://huggingface.co/sujalappa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"kasem-speech-text-parallel","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tKasem Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 75990 parallel speech-text pairs for Kasem, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Kasem - xsm\nTask: Speech Recognition, Text-to-Speech\nSize: 75990 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/kasem-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/kasem-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Kasem"],"keywords_longer_than_N":true},
	{"name":"assamese_speech_corpus","keyword":"automatic-speech-recognition","description":"madhabpaul/assamese_speech_corpus dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/madhabpaul/assamese_speech_corpus","creator_name":"Madhab Paul","creator_url":"https://huggingface.co/madhabpaul","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","Assamese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"assamese_speech_corpus","keyword":"text-to-speech","description":"madhabpaul/assamese_speech_corpus dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/madhabpaul/assamese_speech_corpus","creator_name":"Madhab Paul","creator_url":"https://huggingface.co/madhabpaul","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","Assamese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"kenyan_national_parks","keyword":"text-to-speech","description":"gikebe/kenyan_national_parks dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/gikebe/kenyan_national_parks","creator_name":"Elizabeth Gikebe","creator_url":"https://huggingface.co/gikebe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","summarization","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"libritts-r-filtered-speaker-descriptions","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Annotated LibriTTS-R\n\t\n\nThis dataset is an annotated version of a filtered LibriTTS-R [1]. \nLibriTTS-R [1] is a sound quality improved version of the LibriTTS corpus which is a multi-speaker English corpus of approximately 960 hours of read English speech at 24kHz sampling rate, published in 2019. \nIn the text_description column, it provides natural language annotations on the characteristics of speakers and utterances, that have been generated using the Data-Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/libritts-r-filtered-speaker-descriptions.","url":"https://huggingface.co/datasets/parler-tts/libritts-r-filtered-speaker-descriptions","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"goodforft","keyword":"speech","description":"\n\t\n\t\t\n\t\tgoodforft\n\t\n\nThis is a merged speech dataset containing 863 audio segments from 4 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 863\nSpeakers: 4\nLanguages: en\nEmotions: angry, happy, neutral\nOriginal Datasets: 4\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/goodforft.","url":"https://huggingface.co/datasets/Codyfederer/goodforft","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"goodforft","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tgoodforft\n\t\n\nThis is a merged speech dataset containing 863 audio segments from 4 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 863\nSpeakers: 4\nLanguages: en\nEmotions: angry, happy, neutral\nOriginal Datasets: 4\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/goodforft.","url":"https://huggingface.co/datasets/Codyfederer/goodforft","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Advance","keyword":"automatic-speech-recognition","description":"Groovy-123/Advance dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Groovy-123/Advance","creator_name":"KWAME MARFO","creator_url":"https://huggingface.co/Groovy-123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"goodforft","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tgoodforft\n\t\n\nThis is a merged speech dataset containing 863 audio segments from 4 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 863\nSpeakers: 4\nLanguages: en\nEmotions: angry, happy, neutral\nOriginal Datasets: 4\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/goodforft.","url":"https://huggingface.co/datasets/Codyfederer/goodforft","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"vocalno","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tTobias Chinese TTS Dataset\n\t\n\nËøôÊòØ‰∏Ä‰∏™‰∏≠ÊñáÊñáÊú¨ËΩ¨ËØ≠Èü≥(TTS)Êï∞ÊçÆÈõÜÔºåÂåÖÂê´Á∫¶997‰∏™È´òË¥®ÈáèÁöÑ‰∏≠ÊñáÈü≥È¢ë-ÊñáÊú¨ÂØπ„ÄÇ\n\n\t\n\t\t\n\t\tÊï∞ÊçÆÈõÜ‰ø°ÊÅØ\n\t\n\n\nËØ≠Ë®Ä: ‰∏≠Êñá (Chinese)\n‰ªªÂä°: ÊñáÊú¨ËΩ¨ËØ≠Èü≥ (Text-to-Speech)\nÊ†∑Êú¨Êï∞Èáè: ~997‰∏™Èü≥È¢ë-ÊñáÊú¨ÂØπ\nÈü≥È¢ëÊ†ºÂºè: WAV, 16kHzÈááÊ†∑Áéá\nËÆ∏ÂèØËØÅ: MIT\nÂèëË®Ä‰∫∫: Âçï‰∏ÄÂèëË®Ä‰∫∫\n\n\n\t\n\t\t\n\t\tÊï∞ÊçÆÈõÜÁªìÊûÑ\n\t\n\nfrom datasets import load_dataset\n\n# Âä†ËΩΩÂÆåÊï¥Êï∞ÊçÆÈõÜ\ndataset = load_dataset(\"your_username/tobias-tts-chinese\")\n\n# Âè™Âä†ËΩΩËÆ≠ÁªÉÈõÜ\ntrain_dataset = load_dataset(\"your_username/tobias-tts-chinese\", split=\"train\")\n\n# Âè™Âä†ËΩΩÈ™åËØÅÈõÜ\nvalidation_dataset = load_dataset(\"your_username/tobias-tts-chinese\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/t0bi4s/vocalno.","url":"https://huggingface.co/datasets/t0bi4s/vocalno","creator_name":"sujiuheng","creator_url":"https://huggingface.co/t0bi4s","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Chinese","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"mabama-v1-audio","keyword":"text-to-speech","description":"ovieyra21/mabama-v1-audio dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ovieyra21/mabama-v1-audio","creator_name":"Oma Vieyra","creator_url":"https://huggingface.co/ovieyra21","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Spanish","mit","10M<n<100M","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Advance","keyword":"text-to-speech","description":"Groovy-123/Advance dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Groovy-123/Advance","creator_name":"KWAME MARFO","creator_url":"https://huggingface.co/Groovy-123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"arabic_quran_hadith14books_cmvoice17_fleurs_mediaspeech","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for quran and hadith dataset\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nArabic specialized dataset to make sure that AI is not changing our sacred scriptures in speech recognition by training and evaluating upon quran and hadith.\n\nCombining quran + magma'a el zawa'ed book of sidi Nour eldin elhaithamy author including 14 book of hadith of approximately 10,000 hadith without repititions + other existing datasets like common voice, fleurs, media speech\n\nFirst dataset to have full‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DrAliGomaa/arabic_quran_hadith14books_cmvoice17_fleurs_mediaspeech.","url":"https://huggingface.co/datasets/DrAliGomaa/arabic_quran_hadith14books_cmvoice17_fleurs_mediaspeech","creator_name":"arabic_speech","creator_url":"https://huggingface.co/DrAliGomaa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"dry-replies","keyword":"linguistics","description":"\n\t\n\t\t\n\t\tDry Replies Dataset\n\t\n\nA collection of 200+ short, neutral, and minimalistic replies commonly used in casual conversations. Perfect for chatbots, sentiment analysis, or even linguistic studies. All responses are lowercase and simple, making them easy to integrate into various projects.\n\n\t\n\t\t\n\t\tUse Cases\n\t\n\n\nChatbots: Add realistic and casual replies to conversational models.  \nSentiment Analysis: Test systems with neutral or dry responses.  \nText Generation: Incorporate concise replies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ni5arga/dry-replies.","url":"https://huggingface.co/datasets/ni5arga/dry-replies","creator_name":"Nisarga","creator_url":"https://huggingface.co/ni5arga","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","text","Text"],"keywords_longer_than_N":true},
	{"name":"all-words-in-english-with-pink-trombone","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Pink Trombone English Phonetic & Landmark Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains audio samples of English words generated by the Pink Trombone, a popular open-source vocal tract synthesizer. The primary goal of this dataset is to provide a clean, large-scale resource linking phonetic sequences to both their acoustic realization and the underlying articulatory landmarks.\nEach sample in the dataset corresponds to a word from the Oxford English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mcamara/all-words-in-english-with-pink-trombone.","url":"https://huggingface.co/datasets/mcamara/all-words-in-english-with-pink-trombone","creator_name":"Mateo C√°mara","creator_url":"https://huggingface.co/mcamara","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"SpokenPortugueseGeographicalSocialVarieties","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSpoken Portuguese - Geographical and Social Varieties\n\t\n\ndataset source: https://www.clul.ulisboa.pt\n(1995-1997 - European Commission DGXXII, Programme LINGUA/SOCRATES)\nThe project is concluded and the materials are published in CD-ROM, with the exclusive publishing support of Instituto Cam√µes, under the title Portugu√™s Falado - Documentos Aut√™nticos: Grava√ß√µes √°udio com transcri√ß√£o alinhada. Its distribution outside of Portugal is ensured by Instituto Cam√µes and in Portugal by CLUL.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TigreGotico/SpokenPortugueseGeographicalSocialVarieties.","url":"https://huggingface.co/datasets/TigreGotico/SpokenPortugueseGeographicalSocialVarieties","creator_name":"Tigre G√≥tico Lda","creator_url":"https://huggingface.co/TigreGotico","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been carefully segmented and aligned.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nautomatic-speech-recognition, audio-speaker-identification: The dataset can be used to train a model for Automatic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openslr/librispeech_asr.","url":"https://huggingface.co/datasets/openslr/librispeech_asr","creator_name":"OpenSLR","creator_url":"https://huggingface.co/openslr","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"hsb_audio_corpus","keyword":"automatic-speech-recognition","description":"This is a collection of speech recordings in Upper Sorbian. Several speakers have contributed their voice to this dataset.\nAudio files are stored in subfolders of the sig folder. The corresponding written text can be found at the same path in the trl folder.\nSubfolders are constructed as follows:\nsig/ID_of_resource/ID_of_speaker/recording_session/files.wav\n\nresp.\ntrl/ID_of_resource/ID_of_speaker/recording_session/files.trl\n\nMatching speaker IDs inside different resources indicate the same‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zalozbadev/hsb_audio_corpus.","url":"https://huggingface.co/datasets/zalozbadev/hsb_audio_corpus","creator_name":"Za≈Ço≈æba za serbski lud","creator_url":"https://huggingface.co/zalozbadev","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Upper Sorbian","cc-by-4.0","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Arabic_Audio_Deepfake","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tArAD Dataset (Arabic Audio DeepFake Dataset)\n\t\n\nDataset SummaryThis dataset contains Arabic deepfake audio samples, focusing mainly on Levantine dialect with some examples in Standard Arabic. It was created using the RVC v2 framework, fine-tuned on a custom dataset of multi-dialect Arabic speech. The goal is to simulate real-world deepfake audio attacks by generating synthetic speech from actual recordings and voice messages.\nOne of the first datasets to include real-world deepfake‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DeepFake-Audio-Rangers/Arabic_Audio_Deepfake.","url":"https://huggingface.co/datasets/DeepFake-Audio-Rangers/Arabic_Audio_Deepfake","creator_name":"DeepFake Audio Rangers","creator_url":"https://huggingface.co/DeepFake-Audio-Rangers","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","automatic-speech-recognition","Arabic","odc-by"],"keywords_longer_than_N":true},
	{"name":"EGY2K","keyword":"text-to-speech","description":"rahafvii/EGY2K dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rahafvii/EGY2K","creator_name":"xx","creator_url":"https://huggingface.co/rahafvii","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Multilingual_Speech_Dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tMultilingual Speech Dataset\n\t\n\nPaper: A Study of Multilingual End-to-End Speech Recognition for Kazakh, Russian, and English\nRepository: https://github.com/IS2AI/MultilingualASR\nDescription: This repository provides the dataset used in the paper \"A Study of Multilingual End-to-End Speech Recognition for Kazakh, Russian, and English\". The paper focuses on training a single end-to-end (E2E) ASR model for Kazakh, Russian, and English, comparing monolingual and multilingual approaches‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/Multilingual_Speech_Dataset.","url":"https://huggingface.co/datasets/issai/Multilingual_Speech_Dataset","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kazakh","Russian","English","mit"],"keywords_longer_than_N":true},
	{"name":"Multilingual_Speech_Dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tMultilingual Speech Dataset\n\t\n\nPaper: A Study of Multilingual End-to-End Speech Recognition for Kazakh, Russian, and English\nRepository: https://github.com/IS2AI/MultilingualASR\nDescription: This repository provides the dataset used in the paper \"A Study of Multilingual End-to-End Speech Recognition for Kazakh, Russian, and English\". The paper focuses on training a single end-to-end (E2E) ASR model for Kazakh, Russian, and English, comparing monolingual and multilingual approaches‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/Multilingual_Speech_Dataset.","url":"https://huggingface.co/datasets/issai/Multilingual_Speech_Dataset","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kazakh","Russian","English","mit"],"keywords_longer_than_N":true},
	{"name":"MultiMed-ST","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tMultiMed-ST: Large-scale Many-to-many Multilingual Medical Speech Translation\n\t\n\nPreprint\nKhai Le-Duc*, Tuyen Tran*,\nBach Phan Tat, Nguyen Kim Hai Bui, Quan Dang, Hung-Phong Tran, Thanh-Thuy Nguyen, Ly Nguyen, Tuan-Minh Phan, Thi Thu Phuong Tran, Chris Ngo,\nNguyen X. Khanh**, Thanh Nguyen-Tang**\n\n\n*Equal contribution\n**Equal supervision\n\n\nAbstract:\nMultilingual speech translation (ST) in the medical domain  enhances patient care by enabling efficient communication across language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/leduckhai/MultiMed-ST.","url":"https://huggingface.co/datasets/leduckhai/MultiMed-ST","creator_name":"Le Duc Khai","creator_url":"https://huggingface.co/leduckhai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","automatic-speech-recognition","Vietnamese","English","German"],"keywords_longer_than_N":true},
	{"name":"Speech-MASSIVE_vie","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tVietnamse subset of the Speech-MASSIVE dataset\n\t\n\nextracted from:\n\nhttps://huggingface.co/datasets/FBK-MT/Speech-MASSIVE\nhttps://huggingface.co/datasets/FBK-MT/Speech-MASSIVE-test\n\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/load-speechmassive.py\n","url":"https://huggingface.co/datasets/doof-ferb/Speech-MASSIVE_vie","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Speech-MASSIVE_vie","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tVietnamse subset of the Speech-MASSIVE dataset\n\t\n\nextracted from:\n\nhttps://huggingface.co/datasets/FBK-MT/Speech-MASSIVE\nhttps://huggingface.co/datasets/FBK-MT/Speech-MASSIVE-test\n\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/load-speechmassive.py\n","url":"https://huggingface.co/datasets/doof-ferb/Speech-MASSIVE_vie","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"svq","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSimple Voice Questions\n\t\n\nSimple Voice Questions (SVQ) is a set of short audio questions recorded in 26 locales across 17 languages under multiple audio conditions.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nSpeakers were presented with recording instructions specifying the recording environment and text query to be recorded.\nThey recorded using their own phones or tablets under four conditions:\n\nclean: Record in quiet environment\nbackground speech noise: Record while audio from sources like podcasts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/svq.","url":"https://huggingface.co/datasets/google/svq","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"vlsp2020_vinai_100h","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tunofficial mirror of VLSP 2020 - VinAI - ASR challenge dataset\n\t\n\nofficial announcement:\n\nti·∫øng vi·ªát: https://institute.vinbigdata.org/events/vinbigdata-chia-se-100-gio-du-lieu-tieng-noi-cho-cong-dong/\nin eglish: https://institute.vinbigdata.org/en/events/vinbigdata-shares-100-hour-data-for-the-community/\nVLSP 2020 workshop: https://vlsp.org.vn/vlsp2020\n\nofficial download: https://drive.google.com/file/d/1vUSxdORDxk-ePUt-bUVDahpoXiqKchMx/view?usp=sharing\ncontact: info@vinbigdata.org‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/vlsp2020_vinai_100h.","url":"https://huggingface.co/datasets/doof-ferb/vlsp2020_vinai_100h","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"vlsp2020_vinai_100h","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tunofficial mirror of VLSP 2020 - VinAI - ASR challenge dataset\n\t\n\nofficial announcement:\n\nti·∫øng vi·ªát: https://institute.vinbigdata.org/events/vinbigdata-chia-se-100-gio-du-lieu-tieng-noi-cho-cong-dong/\nin eglish: https://institute.vinbigdata.org/en/events/vinbigdata-shares-100-hour-data-for-the-community/\nVLSP 2020 workshop: https://vlsp.org.vn/vlsp2020\n\nofficial download: https://drive.google.com/file/d/1vUSxdORDxk-ePUt-bUVDahpoXiqKchMx/view?usp=sharing\ncontact: info@vinbigdata.org‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/vlsp2020_vinai_100h.","url":"https://huggingface.co/datasets/doof-ferb/vlsp2020_vinai_100h","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"test321","keyword":"speech","description":"\n\t\n\t\t\n\t\ttest321\n\t\n\nThis is a merged speech dataset containing 118 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 118\nSpeakers: 4\nLanguages: tr\nEmotions: happy, angry, sad, neutral\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test321.","url":"https://huggingface.co/datasets/Codyfederer/test321","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"test321","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\ttest321\n\t\n\nThis is a merged speech dataset containing 118 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 118\nSpeakers: 4\nLanguages: tr\nEmotions: happy, angry, sad, neutral\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test321.","url":"https://huggingface.co/datasets/Codyfederer/test321","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"hausa_long_voice_dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for \"hausa_long_voice_dataset\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nDataset Name: Hausa Long Voice Dataset\nDescription: This dataset contains merged Hausa language audio samples from Common Voice. Audio files from the same speaker have been concatenated to create longer audio samples with their corresponding transcriptions, designed for text-to-speech (TTS) training where longer sequences are beneficial.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nConfigs:\n\ndefault\n\nData Files:\n\nSplit: train‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mide7x/hausa_long_voice_dataset.","url":"https://huggingface.co/datasets/mide7x/hausa_long_voice_dataset","creator_name":"Olumide Adewole","creator_url":"https://huggingface.co/mide7x","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","audio-language-identification","Hausa"],"keywords_longer_than_N":true},
	{"name":"test321","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\ttest321\n\t\n\nThis is a merged speech dataset containing 118 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 118\nSpeakers: 4\nLanguages: tr\nEmotions: happy, angry, sad, neutral\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test321.","url":"https://huggingface.co/datasets/Codyfederer/test321","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"VietMDD","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tunofficial mirror of VietMMD (Mispronunciation Detection and Diagnosis)\n\t\n\nofficial announcement: https://github.com/VietMDDDataset/VietMDD\nofficial download: https://drive.google.com/drive/folders/1TjTluTxEB99QhGFTYFWb-vEdWXM-lyKJ?usp=sharing\nDOI: 10.21437/Interspeech.2023-364\n5h, 4.2k samples\npre-process: see my code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/viet-mdd.py\n\ncustom split: orphan: speech without any transcription unlike in train/validation/test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/VietMDD.","url":"https://huggingface.co/datasets/doof-ferb/VietMDD","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Vietnamese","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"ai4bharat-hi-data","keyword":"text-to-speech","description":"SachinTelecmi/ai4bharat-hi-data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/SachinTelecmi/ai4bharat-hi-data","creator_name":"Sachin Mohanty","creator_url":"https://huggingface.co/SachinTelecmi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","Hindi","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"mlc-mlsw-melspects","keyword":"speech","description":"\n\t\n\t\t\n\t\tMLCommons Multilingual Spoken Words Mel-Spectograms\n\t\n\nThis dataset contains all English words from the dataset available at MLCommons (or also available on huggingface). These audio files have been processed into Mel spectrograms for downstream usage in DCNNs or similar processes.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset description\n\t\n\nThere's a total of 6624343 samples of Mel spectograms. There are a total of 38150 different words, the cls is the index of that word in alphabetical order. With every entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/einstein8612/mlc-mlsw-melspects.","url":"https://huggingface.co/datasets/einstein8612/mlc-mlsw-melspects","creator_name":"Joey Li","creator_url":"https://huggingface.co/einstein8612","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","audio-classification","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Voice-Note-Audio","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tVoice Notes\n\t\n\nA dataset of voice notes collected by Daniel Rosehill in and around Jerusalem (mostly) in a variety of acoustic environments and in a variety of formats reflecting typical daily use with speech to text transcription apps.\nThis dataset is a subsection of a voice note training dataset that I'm curating for STT fine-tuning and entity recognition.\n\n\t\n\t\t\n\t\tAnnotation\n\t\n\nThe dataset includes rich annotations collected using Label Studio:\n\nCorrected transcripts (manually‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/danielrosehill/Voice-Note-Audio.","url":"https://huggingface.co/datasets/danielrosehill/Voice-Note-Audio","creator_name":"Daniel Rosehill","creator_url":"https://huggingface.co/danielrosehill","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"cml-tts-filtered-annotated","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Filtred and annotated CML TTS\n\t\n\nThis dataset is an annotated and filtred version of a CML-TTS [1]. \nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated.","url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","French","German","Italian","Spanish"],"keywords_longer_than_N":true},
	{"name":"last","keyword":"speech","description":"\n\t\n\t\t\n\t\tlast\n\t\n\nThis is a merged speech dataset containing 345 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 345\nSpeakers: 7\nLanguages: en\nEmotions: neutral, angry, happy, sad\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral, happy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/last.","url":"https://huggingface.co/datasets/Codyfederer/last","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"last","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tlast\n\t\n\nThis is a merged speech dataset containing 345 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 345\nSpeakers: 7\nLanguages: en\nEmotions: neutral, angry, happy, sad\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral, happy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/last.","url":"https://huggingface.co/datasets/Codyfederer/last","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"last","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tlast\n\t\n\nThis is a merged speech dataset containing 345 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 345\nSpeakers: 7\nLanguages: en\nEmotions: neutral, angry, happy, sad\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral, happy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/last.","url":"https://huggingface.co/datasets/Codyfederer/last","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"IndicTTS_Punjabi","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tPunjabi Indic TTS Dataset\n\t\n\nThis dataset is derived from the Indic TTS Database project, specifically using the Punjabi monolingual recordings from both male and female speakers. The dataset contains high-quality speech recordings with corresponding text transcriptions, making it suitable for text-to-speech (TTS) research and development.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Punjabi\nTotal Duration: ~20 hours (Male: 10 hours, Female: 10 hours)\nAudio Format: WAV\nSampling Rate: 48000Hz‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/IndicTTS_Punjabi.","url":"https://huggingface.co/datasets/SPRINGLab/IndicTTS_Punjabi","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","pb","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"muslim-names-dataset","keyword":"linguistics","description":"\n\t\n\t\t\n\t\tMuslim Names Dataset\n\t\n\nA comprehensive collection of Muslim names with meanings scraped from muslimnames.com. Contains 14,585 names with English names, Arabic names, meanings, and gender classifications.\n\n\t\n\t\t\n\t\tDataset Contents\n\t\n\nThis dataset contains ~14,585 Muslim names with the following information:\n\nEnglish name: Name in English/Latin script\nArabic name: Name in Arabic script\nMeaning: Definition and meaning of the name\nGender: Classification as male or female\n\n\n\t\n\t\t\n\t\tFiles‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/takiuddinahmed/muslim-names-dataset.","url":"https://huggingface.co/datasets/takiuddinahmed/muslim-names-dataset","creator_name":"Takiuddin Ahmed","creator_url":"https://huggingface.co/takiuddinahmed","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","Arabic","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"ToneBooksPlus","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tToneBooksPlus\n\t\n\nToneBooksPlus ‚Äî —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ Vikhrmodels/ToneBooks, –Ω–æ –±–µ–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏. –í –¥–∞—Ç–∞—Å–µ—Ç–µ 179.16 —á–∞—Å–æ–≤ –∞—É–¥–∏–æ –¥–ª—è train —Å–ø–ª–∏—Ç–∞ –∏ 9.42 —á–∞—Å–∞ –¥–ª—è validation.\n–ë–æ–ª—å—à–æ–µ —Å–ø–∞—Å–∏–±–æ its5Q –∑–∞ –ø–æ–º–æ—â—å –≤ —Å–±–æ—Ä–µ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö.\n\n\n\t\n\t\t\n\t\n\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ\n\t\n\n–î–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—É–¥–∏–æ—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ —Å–æ–±—Ä–∞–Ω—ã:\n\n–°—Å—ã–ª–∫–∞ –Ω–∞ MP3-—Ñ–∞–π–ª (audio)\n–¢–µ–∫—Å—Ç–æ–≤–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ (text)\n–ò–º—è –≥–æ–ª–æ—Å–∞ (voice_name) ‚Äî –æ–¥–Ω–æ –∏–∑ –∏–º—ë–Ω –¥–∏–∫—Ç–æ—Ä–æ–≤:\nAleksandr Kotov  \nAleksandr Zbarovskii  \nAlina Archibasova  \nDaniel Che‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneBooksPlus.","url":"https://huggingface.co/datasets/Vikhrmodels/ToneBooksPlus","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Russian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"UZ_voice","keyword":"automatic-speech-recognition","description":"Beehzod/UZ_voice dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Beehzod/UZ_voice","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"ToneBooksPlus","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tToneBooksPlus\n\t\n\nToneBooksPlus ‚Äî —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ Vikhrmodels/ToneBooks, –Ω–æ –±–µ–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏. –í –¥–∞—Ç–∞—Å–µ—Ç–µ 179.16 —á–∞—Å–æ–≤ –∞—É–¥–∏–æ –¥–ª—è train —Å–ø–ª–∏—Ç–∞ –∏ 9.42 —á–∞—Å–∞ –¥–ª—è validation.\n–ë–æ–ª—å—à–æ–µ —Å–ø–∞—Å–∏–±–æ its5Q –∑–∞ –ø–æ–º–æ—â—å –≤ —Å–±–æ—Ä–µ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö.\n\n\n\t\n\t\t\n\t\n\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ\n\t\n\n–î–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—É–¥–∏–æ—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ —Å–æ–±—Ä–∞–Ω—ã:\n\n–°—Å—ã–ª–∫–∞ –Ω–∞ MP3-—Ñ–∞–π–ª (audio)\n–¢–µ–∫—Å—Ç–æ–≤–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ (text)\n–ò–º—è –≥–æ–ª–æ—Å–∞ (voice_name) ‚Äî –æ–¥–Ω–æ –∏–∑ –∏–º—ë–Ω –¥–∏–∫—Ç–æ—Ä–æ–≤:\nAleksandr Kotov  \nAleksandr Zbarovskii  \nAlina Archibasova  \nDaniel Che‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneBooksPlus.","url":"https://huggingface.co/datasets/Vikhrmodels/ToneBooksPlus","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Russian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"test3434234","keyword":"speech","description":"\n\t\n\t\t\n\t\ttest3434234\n\t\n\nThis is a merged speech dataset containing 848 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 848\nSpeakers: 2\nLanguages: tr\nEmotions: angry, happy, neutral\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test3434234.","url":"https://huggingface.co/datasets/Codyfederer/test3434234","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ar-eg-dataset","keyword":"automatic-speech-recognition","description":"An in-progress dataset for arabic-egyptian-dialect, specifically made from transcripton of DrAliGomaa videos on youtube.\nDr Ali Gomaa is a famous Egyptian Islamic Scholar and he was the mufti of Egypt from 2003-2013\n\nLink to his youtube channel: https://www.youtube.com/@DrAliGomaa\nLink to his page on facebook: https://www.facebook.com/DrAliGomaa\n\n","url":"https://huggingface.co/datasets/DrAliGomaa/ar-eg-dataset","creator_name":"arabic_speech","creator_url":"https://huggingface.co/DrAliGomaa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"test3434234","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\ttest3434234\n\t\n\nThis is a merged speech dataset containing 848 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 848\nSpeakers: 2\nLanguages: tr\nEmotions: angry, happy, neutral\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test3434234.","url":"https://huggingface.co/datasets/Codyfederer/test3434234","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"alphanumeric-audio-dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSpeech Recognition Bias Reduction Project\n\t\n\n\n\t\n\t\t\n\t\tExecutive Summary\n\t\n\nWelcome to the Speech Recognition Bias Reduction Project. It aims to create a more inclusive and representative dataset for improving automated speech recognition systems. This project addresses the challenges faced by speakers with non-native English accents, particularly when interacting with automated voice systems that struggle to interpret alphanumeric information such as names, phone numbers, and addresses.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sakshee05/alphanumeric-audio-dataset.","url":"https://huggingface.co/datasets/sakshee05/alphanumeric-audio-dataset","creator_name":"Sakshee Patil","creator_url":"https://huggingface.co/sakshee05","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"test3434234","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\ttest3434234\n\t\n\nThis is a merged speech dataset containing 848 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 848\nSpeakers: 2\nLanguages: tr\nEmotions: angry, happy, neutral\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test3434234.","url":"https://huggingface.co/datasets/Codyfederer/test3434234","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"TikTok_MostComment_Video_Transcription_Example","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tüì≤ Example Dataset: TikTok Scraper Tool\n\t\n\nüëâ Start Scraping TikTok: TikTok Scraper Tool\n\n\t\n\t\t\n\t\t‚ú® Key Features\n\t\n\n\n‚ö° Instant Transcription ‚Äì Turn any TikTok video into an AI-ready transcript  \nüéØ Metadata ‚Äì Get the title, language description, and video hashtags  \nüîó URL-Based Access ‚Äì Just drop in a TikTok video URL to start scraping  \nüß© LLM-Ready Output ‚Äì Receive clean JSON ready for agents, RAG, or AI tools  \nüí∏ Free Tier ‚Äì Use up to 100 queries during the beta period  \nüí´ Easy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/TikTok_MostComment_Video_Transcription_Example.","url":"https://huggingface.co/datasets/Gopher-Lab/TikTok_MostComment_Video_Transcription_Example","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","feature-extraction","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"KinyaWhisperDataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tKinyarwanda Spoken Words Dataset\n\t\n\nThis dataset contains 102 short audio samples of spoken Kinyarwanda words, each labeled with its corresponding transcription. It is designed for training, evaluating, and experimenting with Automatic Speech Recognition (ASR) models in low-resource settings.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naudio/: Contains 102 .wav files (mono, 16kHz)\ntranscripts.txt: Tab-separated transcription file (e.g., 001.wav\\tmuraho)\nmanifest.jsonl: JSONL file with audio paths and text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benax-rw/KinyaWhisperDataset.","url":"https://huggingface.co/datasets/benax-rw/KinyaWhisperDataset","creator_name":"Benax Labs","creator_url":"https://huggingface.co/benax-rw","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kinyarwanda","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"opentts-lada","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tOpen Text-to-Speech voices for üá∫üá¶ Ukrainian\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { opentts-uk (Revision 32abc9c) },\n    year         = 2025,\n    url          = { https://huggingface.co/datasets/Yehor/opentts-uk },\n    doi          = { 10.57967/hf/4551 }‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/opentts-lada.","url":"https://huggingface.co/datasets/speech-uk/opentts-lada","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"emilia-yodas-english-neucodec","keyword":"speech","description":"\n\t\n\t\t\n\t\tDataset Card for NeuCodec Emilia-YODAS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe NeuCodec Emilia-YODAS dataset is an English-language dataset containing >30M audio samples (>78k hours), taken from the English-language subset of Emilia-YODAS and compressed with NeuCodec.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nimport torch\nfrom datasets import load_dataset\nfrom neucodec import NeuCodec\n\n# load dataset and model\ndataset = load_dataset(\"neuphonic/emilia-yodas-english-neucodec\", split=\"train\", streaming=True)\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neuphonic/emilia-yodas-english-neucodec.","url":"https://huggingface.co/datasets/neuphonic/emilia-yodas-english-neucodec","creator_name":"Neuphonic","creator_url":"https://huggingface.co/neuphonic","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","amphion/Emilia-YODAS","English","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"PoemSentimentClassification","keyword":"hate-speech-detection","description":"\n  PoemSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPoem Sentiment is a sentiment dataset of poem verses from Project Gutenberg.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://arxiv.org/abs/2011.02686\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"PoemSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PoemSentimentClassification.","url":"https://huggingface.co/datasets/mteb/PoemSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"PersianVox_NM","keyword":"speech","description":"\n\t\n\t\t\n\t\tPersianVox_NM\n\t\n\nPersianVox_NM is a high-quality Persian speech dataset derived from article readings by a single female speaker. This subset is sourced from Nasle Mana Magazine, a publication dedicated to producing accessible content for the visually impaired.\n\n\t\n\t\t\n\t\tüìö Dataset Summary\n\t\n\n\nLanguage: Persian (Farsi)\nSpeaker: Single female voice\nTotal Duration: 94.55 hours\nRecording Source: Articles from Nasle Mana\nDomain: Literary and informational prose\nAlignment Checked With:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saeedzou/PersianVox_NM.","url":"https://huggingface.co/datasets/saeedzou/PersianVox_NM","creator_name":"Saeedreza Zouashkiani","creator_url":"https://huggingface.co/saeedzou","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"audio-dataset-shuffled-300","keyword":"speech","description":"\n\t\n\t\t\n\t\tAudio Transcription Dataset\n\t\n\nThis dataset contains 297 audio recordings with their corresponding transcriptions for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset includes:\n\nAudio files: High-quality voice recordings (.wav format)\nTranscriptions: Accurate text transcriptions of the spoken content\nProper Audio feature type: Ready for model training (not just file paths!)\n\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal samples: 297\nAudio format: WAV files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aashish17405/audio-dataset-shuffled-300.","url":"https://huggingface.co/datasets/Aashish17405/audio-dataset-shuffled-300","creator_name":"Jaini Aashish","creator_url":"https://huggingface.co/Aashish17405","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"infore1_25hours","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tunofficial mirror of InfoRe Technology public dataset ‚Ññ1\n\t\n\nofficial announcement: https://www.facebook.com/groups/j2team.community/permalink/1010834009248719/\n25h, 14.9k samples, InfoRe paid a contractor to read text\nofficial download: magnet:?xt=urn:btih:1cbe13fb14a390c852c016a924b4a5e879d85f41&dn=25hours.zip&tr=http%3A%2F%2Foffice.socials.vn%3A8725%2Fannounce\nmirror: https://files.huylenguyen.com/datasets/infore/25hours.zip\nunzip password: BroughtToYouByInfoRe\npre-process: see‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/infore1_25hours.","url":"https://huggingface.co/datasets/doof-ferb/infore1_25hours","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"parlament_parla_v3","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for ParlamentParla v3 - Speech Corpus of Catalan Parliamentary Sessions\n\t\n\nA speech corpus composed of Catalan Parliamentary Sessions.The v3 and last version of the corpus includes both clean and other quality segments, divided into short segments (less than 30 seconds) and long segments (more than 30 seconds). The total dataset encompasses 1059h 48m 04s of speech, including 945h 51m 06s for the short segments and 113h 56m 58s for the long segments, with a total of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/parlament_parla_v3.","url":"https://huggingface.co/datasets/projecte-aina/parlament_parla_v3","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Catalan","cc-by-4.0","100K - 1M","webdataset"],"keywords_longer_than_N":true},
	{"name":"PersianVox_NM","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tPersianVox_NM\n\t\n\nPersianVox_NM is a high-quality Persian speech dataset derived from article readings by a single female speaker. This subset is sourced from Nasle Mana Magazine, a publication dedicated to producing accessible content for the visually impaired.\n\n\t\n\t\t\n\t\tüìö Dataset Summary\n\t\n\n\nLanguage: Persian (Farsi)\nSpeaker: Single female voice\nTotal Duration: 94.55 hours\nRecording Source: Articles from Nasle Mana\nDomain: Literary and informational prose\nAlignment Checked With:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saeedzou/PersianVox_NM.","url":"https://huggingface.co/datasets/saeedzou/PersianVox_NM","creator_name":"Saeedreza Zouashkiani","creator_url":"https://huggingface.co/saeedzou","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"dinner-party-corpus","keyword":"automatic-speech-recognition","description":"This repository contains a reorganized, utterance-focused version of the Dinner Party Corpus, released by Amazon, the Center for Language and Speech Processing (CLSP) and Johns Hopkins University in September 2019.\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe following description is provided in arXiv 1909.13447:\nWe present a speech data corpus that simulates a \"dinner party\" scenario taking place in an everyday home environment. The corpus was created by recording multiple groups of four Amazon employee‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjamin-paine/dinner-party-corpus.","url":"https://huggingface.co/datasets/benjamin-paine/dinner-party-corpus","creator_name":"Benjamin Paine","creator_url":"https://huggingface.co/benjamin-paine","license_name":"Community Data License Agreement Permissive 1.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-1.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","English","cdla-permissive-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"audio-dataset-shuffled-300","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tAudio Transcription Dataset\n\t\n\nThis dataset contains 297 audio recordings with their corresponding transcriptions for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset includes:\n\nAudio files: High-quality voice recordings (.wav format)\nTranscriptions: Accurate text transcriptions of the spoken content\nProper Audio feature type: Ready for model training (not just file paths!)\n\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal samples: 297\nAudio format: WAV files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aashish17405/audio-dataset-shuffled-300.","url":"https://huggingface.co/datasets/Aashish17405/audio-dataset-shuffled-300","creator_name":"Jaini Aashish","creator_url":"https://huggingface.co/Aashish17405","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"infore1_25hours","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tunofficial mirror of InfoRe Technology public dataset ‚Ññ1\n\t\n\nofficial announcement: https://www.facebook.com/groups/j2team.community/permalink/1010834009248719/\n25h, 14.9k samples, InfoRe paid a contractor to read text\nofficial download: magnet:?xt=urn:btih:1cbe13fb14a390c852c016a924b4a5e879d85f41&dn=25hours.zip&tr=http%3A%2F%2Foffice.socials.vn%3A8725%2Fannounce\nmirror: https://files.huylenguyen.com/datasets/infore/25hours.zip\nunzip password: BroughtToYouByInfoRe\npre-process: see‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/infore1_25hours.","url":"https://huggingface.co/datasets/doof-ferb/infore1_25hours","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"shrutilipi","keyword":"automatic-speech-recognition","description":"amithm3/shrutilipi dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/amithm3/shrutilipi","creator_name":"Amith M","creator_url":"https://huggingface.co/amithm3","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","Sanskrit","Bengali","Panjabi"],"keywords_longer_than_N":true},
	{"name":"InstructTTSEval","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tInstructTTSEval\n\t\n\nInstructTTSEval is a comprehensive benchmark designed to evaluate Text-to-Speech (TTS) systems' ability to follow complex natural-language style instructions. The dataset provides a hierarchical evaluation framework with three progressively challenging tasks that test both low-level acoustic control and high-level style generalization capabilities.\n\nGithub Repository: https://github.com/KexinHUANG19/InstructTTSEval\nPaper: InstructTTSEval: Benchmarking Complex‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CaasiHUANG/InstructTTSEval.","url":"https://huggingface.co/datasets/CaasiHUANG/InstructTTSEval","creator_name":"Kexin Huang","creator_url":"https://huggingface.co/CaasiHUANG","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","Chinese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"cv-22-de","keyword":"automatic-speech-recognition","description":"German split of Common Voice 22. cc0 license\n","url":"https://huggingface.co/datasets/fidoriel/cv-22-de","creator_name":"fidoriel","creator_url":"https://huggingface.co/fidoriel","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","German","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"K-BotDataset-forK-bot","keyword":"automatic-speech-recognition","description":"K3theking/K-BotDataset-forK-bot dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/K3theking/K-BotDataset-forK-bot","creator_name":"No","creator_url":"https://huggingface.co/K3theking","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","table-question-answering","text-to-speech","token-classification","automatic-speech-recognition"],"keywords_longer_than_N":true},
	{"name":"zomi_asr","keyword":"automatic-speech-recognition","description":"This is the first public Zomi language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tZomi ASR\n\t\n\nThis dataset contains audio recordings and aligned metadata in the Zomi language ‚Äî a collective ethnolinguistic identity adopted by some Kuki-Chin language-speaking communities in Myanmar and India. The term Zomi means \"Zo people\", derived from the root word Zo (ancestral identity) and mi meaning \"people.\" While originally coined to encompass all Zo-related communities, usage of the term varies regionally and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/zomi_asr.","url":"https://huggingface.co/datasets/freococo/zomi_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"zomi_asr","keyword":"automatic-speech-recognition","description":"This is the first public Zomi language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tZomi ASR\n\t\n\nThis dataset contains audio recordings and aligned metadata in the Zomi language ‚Äî a collective ethnolinguistic identity adopted by some Kuki-Chin language-speaking communities in Myanmar and India. The term Zomi means \"Zo people\", derived from the root word Zo (ancestral identity) and mi meaning \"people.\" While originally coined to encompass all Zo-related communities, usage of the term varies regionally and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/zomi_asr.","url":"https://huggingface.co/datasets/freococo/zomi_asr","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"nchlt_speech_xho","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tNCHLT Speech Corpus -- isiXhosa\n\t\n\nThis is the isiXhosa language part of the NCHLT Speech Corpus of the South African languages.\nLanguage code (ISO 639): xho\nURI: https://hdl.handle.net/20.500.12185/279\n\n\t\n\t\t\n\t\tLicence:\n\t\n\nCreative Commons Attribution 3.0 Unported License (CC BY 3.0): http://creativecommons.org/licenses/by/3.0/legalcode\n\n\t\n\t\t\n\t\tAttribution:\n\t\n\nThe Department of Arts and Culture of the government of the Republic of South Africa (DAC), Council for Scientific and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/danielshaps/nchlt_speech_xho.","url":"https://huggingface.co/datasets/danielshaps/nchlt_speech_xho","creator_name":"Daniel van Niekerk","creator_url":"https://huggingface.co/danielshaps","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Xhosa","cc-by-3.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Gemini-2.0-Flash-Kore-Voice","keyword":"text-to-speech","description":"fireblade2534/Gemini-2.0-Flash-Kore-Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/fireblade2534/Gemini-2.0-Flash-Kore-Voice","creator_name":"fireblade2534","creator_url":"https://huggingface.co/fireblade2534","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"cv-22-de","keyword":"text-to-speech","description":"German split of Common Voice 22. cc0 license\n","url":"https://huggingface.co/datasets/fidoriel/cv-22-de","creator_name":"fidoriel","creator_url":"https://huggingface.co/fidoriel","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","German","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"K-BotDataset-forK-bot","keyword":"text-to-speech","description":"K3theking/K-BotDataset-forK-bot dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/K3theking/K-BotDataset-forK-bot","creator_name":"No","creator_url":"https://huggingface.co/K3theking","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","table-question-answering","text-to-speech","token-classification","automatic-speech-recognition"],"keywords_longer_than_N":true},
	{"name":"fante_multispeaker_audio_transcribed","keyword":"speech","description":"\n\t\n\t\t\n\t\tFante Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Fante Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Fante, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial Inclusion Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/fante_multispeaker_audio_transcribed.","url":"https://huggingface.co/datasets/michsethowusu/fante_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Fanti","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"fante_multispeaker_audio_transcribed","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tFante Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Fante Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Fante, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial Inclusion Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/fante_multispeaker_audio_transcribed.","url":"https://huggingface.co/datasets/michsethowusu/fante_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Fanti","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"polish_presidential_debate","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tPolish Presidential ASR Dataset\n\t\n\nPublic domain (2025) \nSource: DEBATA PREZYDENCKA TVP | 12.05.2025\n\n\t\n\t\t\n\t\tDescription\n\t\n\nStudio-recorded utterances by 13 Polish presidential debate candidates, each providing 15 audio samples (read or spontaneous). Audio is in 16 kHz WAV format.\nThe dataset is designed for automatic speech recognition (ASR) tasks, particularly in the context of Polish language processing in political domain.\n\n\t\n\t\t\n\t\tFile Structure\n\t\n\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ audio/\n‚îÇ   ‚îî‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/directtt/polish_presidential_debate.","url":"https://huggingface.co/datasets/directtt/polish_presidential_debate","creator_name":"jendrek","creator_url":"https://huggingface.co/directtt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Polish","apache-2.0","n<1K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"linto-dataset-audio-ar-tn-augmented","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tLinTO DataSet Audio for Arabic Tunisian Augmented A collection of Tunisian dialect audio and its annotations for STT task\n\t\n\nThis is the augmented datasets used to train the Linto Tunisian dialect with code-switching STT linagora/linto-asr-ar-tn.\n\nDataset Summary\nDataset composition\nSources\nContent Types\nLanguages and Dialects\n\n\nExample use (python)\nLicense\nCitations\n\n\n\t\t\n\t\tDataset Summary\n\t\n\nThe LinTO DataSet Audio for Arabic Tunisian Augmented is a dataset that builds on LinTO‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented.","url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"toxifrench-anonymous","keyword":"hate-speech","description":"\n\t\n\t\t\n\t\tToxiFrench: Benchmarking and Enhancing Language Models via CoT Fine-Tuning for French Toxicity Detection\n\t\n\n\n‚ö†Ô∏è Content Warning\nThis project and the associated dataset contain examples of text that may be considered offensive, toxic, or otherwise disturbing. The content is presented for research purposes only.\n\n\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nDetecting toxic content using language models is crucial yet challenging. While substantial progress has been made in English, toxicity detection in French‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/phantom-researcher/toxifrench-anonymous.","url":"https://huggingface.co/datasets/phantom-researcher/toxifrench-anonymous","creator_name":"anonymous","creator_url":"https://huggingface.co/phantom-researcher","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","French","mit","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"languages_dataset","keyword":"linguistics","description":"This dataset contains a set of 8612 languages from across the world as well as data such as Glottocode, ISO-639-3 codes, names, language families etc.\nOriginal source: https://glottolog.org/glottolog/language\n","url":"https://huggingface.co/datasets/ultimate-dictionary/languages_dataset","creator_name":"Ultimate Dictionary","creator_url":"https://huggingface.co/ultimate-dictionary","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"piper-utils","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tpiper-utils\n\t\n\nPiper Binaries and voices mirror.\n\n\t\n\t\t\n\t\tReferences:\n\t\n\n\nhttps://huggingface.co/AIHeaven/piper_unofficial_voices\nhttps://huggingface.co/rhasspy/piper-voices\nhttps://github.com/rhasspy/piper\n\n","url":"https://huggingface.co/datasets/akuqt/piper-utils","creator_name":"Italo Alfaro","creator_url":"https://huggingface.co/akuqt","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"opentts-mykyta","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tOpen Text-to-Speech voices for üá∫üá¶ Ukrainian\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { opentts-uk (Revision 32abc9c) },\n    year         = 2025,\n    url          = { https://huggingface.co/datasets/Yehor/opentts-uk },\n    doi          = { 10.57967/hf/4551 }‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/opentts-mykyta.","url":"https://huggingface.co/datasets/speech-uk/opentts-mykyta","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"linto-dataset-audio-ar-tn-augmented","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tLinTO DataSet Audio for Arabic Tunisian Augmented A collection of Tunisian dialect audio and its annotations for STT task\n\t\n\nThis is the augmented datasets used to train the Linto Tunisian dialect with code-switching STT linagora/linto-asr-ar-tn.\n\nDataset Summary\nDataset composition\nSources\nContent Types\nLanguages and Dialects\n\n\nExample use (python)\nLicense\nCitations\n\n\n\t\t\n\t\tDataset Summary\n\t\n\nThe LinTO DataSet Audio for Arabic Tunisian Augmented is a dataset that builds on LinTO‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented.","url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"SBCSAE","keyword":"automatic-speech-recognition","description":"A detailed dataset description (including description, audio samples, and statistics) is provided here: https://domklement.github.io/sbcsae/\nIf you use the dataset, please, do not forget to cite our work:\n@inproceedings{maciejewski24_interspeech,\n  title     = {Evaluating the Santa Barbara Corpus: Challenges of the Breadth of Conversational Spoken Language},\n  author    = {Matthew Maciejewski and Dominik Klement and Ruizhe Huang and Matthew Wiesner and Sanjeev Khudanpur},\n  year      = {2024}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dklement/SBCSAE.","url":"https://huggingface.co/datasets/dklement/SBCSAE","creator_name":"Dominik Klement","creator_url":"https://huggingface.co/dklement","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Living-Audio-Irish","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nLiving Audio Irish speech corpus. This version is based on the Irish dataset on Kaggle.\nThe original dataset with audio in more languages is available on GitHub as part of the Idlak project.\nThe details of the Irish portion of the Living Audio dataset are as follows:\n\n\t\n\t\t\nSpeaker\nLanguage\nAccent\nGender\nTotal duration(mm:ss)\nSample rate (Hz)\n\n\n\t\t\nCLL\nIrish (ga)\nNon-native (ie)\nMan\n61:56\n48,000\n\n\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['sentence'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Living-Audio-Irish.","url":"https://huggingface.co/datasets/ymoslem/Living-Audio-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Irish","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Living-Audio-Irish","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nLiving Audio Irish speech corpus. This version is based on the Irish dataset on Kaggle.\nThe original dataset with audio in more languages is available on GitHub as part of the Idlak project.\nThe details of the Irish portion of the Living Audio dataset are as follows:\n\n\t\n\t\t\nSpeaker\nLanguage\nAccent\nGender\nTotal duration(mm:ss)\nSample rate (Hz)\n\n\n\t\t\nCLL\nIrish (ga)\nNon-native (ie)\nMan\n61:56\n48,000\n\n\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDataset({\n    features: ['sentence'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Living-Audio-Irish.","url":"https://huggingface.co/datasets/ymoslem/Living-Audio-Irish","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Irish","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ewe_bible_v2_tts","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tText-to-Speech\n\t\n\n","url":"https://huggingface.co/datasets/worldboss/ewe_bible_v2_tts","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","translation","Ewe"],"keywords_longer_than_N":true},
	{"name":"NaijaSenti","keyword":"hate-speech-detection","description":"\n  NaijaSenti\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNaijaSenti is the first large-scale human-annotated Twitter sentiment dataset for the four most widely spoken languages in Nigeria ‚Äî Hausa, Igbo, Nigerian-Pidgin, and Yor√πb√° ‚Äî consisting of around 30,000 annotated tweets per language, including a significant fraction of code-mixed tweets.\n\n\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReference\nhttps://github.com/hausanlp/NaijaSenti\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NaijaSenti.","url":"https://huggingface.co/datasets/mteb/NaijaSenti","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"ewe_bible_v2_tts","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tText-to-Speech\n\t\n\n","url":"https://huggingface.co/datasets/worldboss/ewe_bible_v2_tts","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","translation","Ewe"],"keywords_longer_than_N":true},
	{"name":"fleurs-farsi","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tFLEURS Farsi (fa_ir) - Processed Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains the Farsi (Persian, fa_ir) portion of the FLEURS (Few-shot Learning Evaluation of Universal Representations of Speech) dataset, processed into a Hugging Face datasets compatible format. FLEURS is a many-language speech dataset created by Google, designed for evaluating speech recognition systems, particularly in low-resource scenarios.\nThis version includes audio recordings and their‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MohammadGholizadeh/fleurs-farsi.","url":"https://huggingface.co/datasets/MohammadGholizadeh/fleurs-farsi","creator_name":"Mohammad Sadegh Gholizadeh","creator_url":"https://huggingface.co/MohammadGholizadeh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"rixvox-v2","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tRixVox-v2: A Swedish parliamentary speech dataset\n\t\n\nRixVox-v2 is a parliamentary speech dataset spanning nearly 23000 hours of speech. The dataset was built by matching and force aligning speeches in parliamentary protocols to media recordings of debates. Each observation contains metadata about the speaker's name, gender, district, role, party affiliation, and the date the speech was given. We include identifiers for protocols, speeches and speakers that allow linking observations in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KBLab/rixvox-v2.","url":"https://huggingface.co/datasets/KBLab/rixvox-v2","creator_name":"National Library of Sweden / KBLab","creator_url":"https://huggingface.co/KBLab","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Swedish","odc-by","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"data-kit-sub-iwslt2025-if-long-constraint","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tData for KIT‚Äôs Instruction Following Submission for IWSLT 2025\n\t\n\nThis repo contains the data used to train our model for IWSLT 2025's Instruction-Following (IF) Speech Processing track.\nIWSLT 2025's Instruction-Following (IF) Speech Processing track in the scientific domain aims to benchmark foundation models that can follow natural \nlanguage instructions‚Äîan ability well-established in textbased LLMs but still emerging in speech-based counterparts. Our approach employs an end-to-end‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maikezu/data-kit-sub-iwslt2025-if-long-constraint.","url":"https://huggingface.co/datasets/maikezu/data-kit-sub-iwslt2025-if-long-constraint","creator_name":"Maike Z√ºfle","creator_url":"https://huggingface.co/maikezu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","summarization","question-answering","translation","English"],"keywords_longer_than_N":true},
	{"name":"fleurs-farsi","keyword":"speech-recognition","description":"\n\t\n\t\t\n\t\tFLEURS Farsi (fa_ir) - Processed Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains the Farsi (Persian, fa_ir) portion of the FLEURS (Few-shot Learning Evaluation of Universal Representations of Speech) dataset, processed into a Hugging Face datasets compatible format. FLEURS is a many-language speech dataset created by Google, designed for evaluating speech recognition systems, particularly in low-resource scenarios.\nThis version includes audio recordings and their‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MohammadGholizadeh/fleurs-farsi.","url":"https://huggingface.co/datasets/MohammadGholizadeh/fleurs-farsi","creator_name":"Mohammad Sadegh Gholizadeh","creator_url":"https://huggingface.co/MohammadGholizadeh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"voxceleb","keyword":"automatic-speech-recognition","description":"This dataset includes both VoxCeleb and VoxCeleb2\n\n\t\n\t\t\n\t\tMultipart Zips\n\t\n\nAlready joined zips for convenience but these specified files are NOT part of the original datasets\nvox2_mp4_1.zip - vox2_mp4_6.zip \nvox2_aac_1.zip - vox2_aac_2.zip \n\n\t\n\t\t\n\t\tJoining Zip\n\t\n\ncat vox1_dev* > vox1_dev_wav.zip\n\ncat vox2_dev_aac* > vox2_aac.zip\n\ncat vox2_dev_mp4* > vox2_mp4.zip\n\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@article{Nagrani19,\n    author = \"Arsha Nagrani and Joon~Son Chung and Weidi Xie and Andrew‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alphaqmoi/voxceleb.","url":"https://huggingface.co/datasets/alphaqmoi/voxceleb","creator_name":"Victor Kwemoi","creator_url":"https://huggingface.co/alphaqmoi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","image-classification","video-classification","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"urdu-tts-16000Hz","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tXCollab/urdu-tts-16000Hz\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCombined Urdu Text-to-Speech dataset with 57,574 high-quality audio-text pairs.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n{\n    'index': int,           # Sample index\n    'text': str,           # Urdu text transcription  \n    'audio': {             # Audio data\n        'path': str,        # Path to audio file\n        'sampling_rate': 16000\n    },\n    'source_dataset': str  # Original dataset name\n}\n\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/XCollab/urdu-tts-16000Hz.","url":"https://huggingface.co/datasets/XCollab/urdu-tts-16000Hz","creator_name":"XCollab","creator_url":"https://huggingface.co/XCollab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Urdu","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ArVoice","keyword":"automatic-speech-recognition","description":"\n  ArVoice: A Multi-Speaker Dataset for Arabic Speech Synthesis\n\n Hawau Olamide Toyin, Rufael Marew, Humaid Alblooshi, Samar M. Magdy, Hanan Aldarmaki \n {hawau.toyin, hanan.aldarmaki}@mbzuai.ac.ae \n\n\n    ArVoice is a multi-speaker Modern Standard Arabic (MSA) speech corpus with fully diacritized transcriptions, intended  for multi-speaker speech synthesis, and can be useful for other tasks such as speech-based diacritic restoration, voice conversion, and deepfake detection.  \n      ArVoice‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/ArVoice.","url":"https://huggingface.co/datasets/MBZUAI/ArVoice","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ArVoice","keyword":"text-to-speech","description":"\n  ArVoice: A Multi-Speaker Dataset for Arabic Speech Synthesis\n\n Hawau Olamide Toyin, Rufael Marew, Humaid Alblooshi, Samar M. Magdy, Hanan Aldarmaki \n {hawau.toyin, hanan.aldarmaki}@mbzuai.ac.ae \n\n\n    ArVoice is a multi-speaker Modern Standard Arabic (MSA) speech corpus with fully diacritized transcriptions, intended  for multi-speaker speech synthesis, and can be useful for other tasks such as speech-based diacritic restoration, voice conversion, and deepfake detection.  \n      ArVoice‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/ArVoice.","url":"https://huggingface.co/datasets/MBZUAI/ArVoice","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"twi_multispeaker_audio_transcribed","keyword":"speech","description":"\n\t\n\t\t\n\t\tTwi Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Twi Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Asante Twi, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial Inclusion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi_multispeaker_audio_transcribed.","url":"https://huggingface.co/datasets/michsethowusu/twi_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Twi","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"emova-sft-speech-eval","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tEMOVA-SFT-Speech-Eval\n\t\n\n\n\n\nü§ó EMOVA-Models | ü§ó EMOVA-Datasets | ü§ó EMOVA-Demo \nüìÑ Paper | üåê Project-Page | üíª Github | üíª EMOVA-Speech-Tokenizer-Github\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-SFT-Speech-Eval is an evaluation dataset curated for omni-modal instruction tuning and emotional spoken dialogue. This dataset is created by converting existing text and visual instruction datasets via Text-to-Speech (TTS) tools. EMOVA-SFT-Speech-Eval is part of EMOVA-Datasets collection, and the training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-eval.","url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-eval","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"twi_multispeaker_audio_transcribed","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTwi Multispeaker Audio Transcribed Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Twi Multispeaker Audio Transcribed dataset is a collection of speech recordings and their transcriptions in Asante Twi, a widely spoken dialect of the Akan language in Ghana. The dataset is designed for training and evaluating automatic speech recognition (ASR) models and other natural language processing (NLP) applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: The dataset is derived from the Financial Inclusion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi_multispeaker_audio_transcribed.","url":"https://huggingface.co/datasets/michsethowusu/twi_multispeaker_audio_transcribed","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Twi","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"emova-sft-speech-eval","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tEMOVA-SFT-Speech-Eval\n\t\n\n\n\n\nü§ó EMOVA-Models | ü§ó EMOVA-Datasets | ü§ó EMOVA-Demo \nüìÑ Paper | üåê Project-Page | üíª Github | üíª EMOVA-Speech-Tokenizer-Github\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nEMOVA-SFT-Speech-Eval is an evaluation dataset curated for omni-modal instruction tuning and emotional spoken dialogue. This dataset is created by converting existing text and visual instruction datasets via Text-to-Speech (TTS) tools. EMOVA-SFT-Speech-Eval is part of EMOVA-Datasets collection, and the training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-eval.","url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-eval","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"vagla-speech-text-parallel","keyword":"speech","description":"\n\t\n\t\t\n\t\tVagla Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 48605 parallel speech-text pairs for Vagla, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Vagla - vag\nTask: Speech Recognition, Text-to-Speech\nSize: 48605 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/vagla-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/vagla-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Vagla"],"keywords_longer_than_N":true},
	{"name":"cv-corpus-1.0-en-client_id-grouped","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tcv-corpus-1.0-en-client_id-grouped\n\t\n\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nThe dataset is derived from the Common Voice dataset.\nThe original dataset is available at Common Voice Dataset.\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\nEach group is filtered to include only client IDs with a minimum of 60 samples and a maximum of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-1.0-en-client_id-grouped.","url":"https://huggingface.co/datasets/masuidrive/cv-corpus-1.0-en-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","commonvoice","English"],"keywords_longer_than_N":true},
	{"name":"vagla-speech-text-parallel","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tVagla Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 48605 parallel speech-text pairs for Vagla, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Vagla - vag\nTask: Speech Recognition, Text-to-Speech\nSize: 48605 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/vagla-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/vagla-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Vagla"],"keywords_longer_than_N":true},
	{"name":"arabic_quranic_asr","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset details\n\t\n\nThis dataset contains quran recitations of every ayats or verses. Also contains 10k unique words from quran.\n\n\t\n\t\t\n\t\tDataset Purpose\n\t\n\nThis dataset can be used to train ASR models that can be used for teaching beginners to recite quran. It can also be used for training TTS models that produces quran recitations in a way so that beginners can easily learn.\n","url":"https://huggingface.co/datasets/Sadique5/arabic_quranic_asr","creator_name":"Sadique Abdullah","creator_url":"https://huggingface.co/Sadique5","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"sauatai-ertegiler-kz-misspellings-kk-s170-len60-n6-mprob-v1","keyword":"grammar","description":"\n\t\n\t\t\n\t\tSauatAI ‚Äî Kazakh Misspelled Sentences from Ertegiler.kz\n\t\n\nSauatAI is a grammar-focused dataset built from 170 children‚Äôs stories scraped from ertegiler.kz on July 5, 2025. The dataset was designed to support Kazakh language grammar correction, error detection, and text augmentation research.\n\n\t\n\t\t\n\t\tüìå Dataset Details\n\t\n\n\ns170 ‚Äî 170 unique stories were scraped and sentence-tokenized.\nlen60 ‚Äî Only sentences with ‚â§60 characters were retained.\nn6 ‚Äî Each correct sentence has 5‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alphazhan/sauatai-ertegiler-kz-misspellings-kk-s170-len60-n6-mprob-v1.","url":"https://huggingface.co/datasets/alphazhan/sauatai-ertegiler-kz-misspellings-kk-s170-len60-n6-mprob-v1","creator_name":"Alzhan Nurgaliyev","creator_url":"https://huggingface.co/alphazhan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","Kazakh","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"vagla-speech-text-parallel","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tVagla Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 48605 parallel speech-text pairs for Vagla, a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Vagla - vag\nTask: Speech Recognition, Text-to-Speech\nSize: 48605 audio files > 1KB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/vagla-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/vagla-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Vagla"],"keywords_longer_than_N":true},
	{"name":"arabic_quranic_asr","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset details\n\t\n\nThis dataset contains quran recitations of every ayats or verses. Also contains 10k unique words from quran.\n\n\t\n\t\t\n\t\tDataset Purpose\n\t\n\nThis dataset can be used to train ASR models that can be used for teaching beginners to recite quran. It can also be used for training TTS models that produces quran recitations in a way so that beginners can easily learn.\n","url":"https://huggingface.co/datasets/Sadique5/arabic_quranic_asr","creator_name":"Sadique Abdullah","creator_url":"https://huggingface.co/Sadique5","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"listening_test","keyword":"speech","description":"\n\t\n\t\t\n\t\tListening Test Results for TTSDS2\n\t\n\nThis dataset contains all 11,000+ ratings collected for 20 synthetic speech systems for the TTSDS2 study (link coming soon).\nThe scores are MOS (Mean Opinion Score), CMOS (Comparative Mean Opinion Score) and SMOS (Speaker Similarity Mean Opinion Score).\nAll annotators included passed three attention checks throughout the survey.\n","url":"https://huggingface.co/datasets/ttsds/listening_test","creator_name":"TTS Distribution Score","creator_url":"https://huggingface.co/ttsds","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"female-LJSpeech-italian","keyword":"text-to-speech","description":"giacomoarienti/female-LJSpeech-italian dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/giacomoarienti/female-LJSpeech-italian","creator_name":"Giacomo Arienti","creator_url":"https://huggingface.co/giacomoarienti","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Italian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-15lang","keyword":"speech","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (15 Languages, Augmented)\n\t\n\nThis dataset contains augmented speech command samples in 15 languages, derived from multiple public datasets. Only commands that overlap with the Google Speech Commands (GSC) vocabulary are included, making the dataset suitable for multilingual keyword spotting tasks aligned with GSC-style classification.\nAudio samples have been augmented using standard audio techniques to improve model robustness (e.g., time-shifting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang.","url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Russian","Kazakh","Tatar","Arabic"],"keywords_longer_than_N":true},
	{"name":"test4","keyword":"speech","description":"\n\t\n\t\t\n\t\ttest4\n\t\n\nThis is a merged speech dataset containing 345 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 345\nSpeakers: 7\nLanguages: en\nEmotions: neutral, sad, angry, happy\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral, happy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test4.","url":"https://huggingface.co/datasets/Codyfederer/test4","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SpokenPortugueseGeographicalSocialVarieties_splits","keyword":"automatic-speech-recognition","description":"sentence splits from SpokenPortugueseGeographicalSocialVarieties generated via forced alignment\n","url":"https://huggingface.co/datasets/Jarbas/SpokenPortugueseGeographicalSocialVarieties_splits","creator_name":"Casimiro Ferreira","creator_url":"https://huggingface.co/Jarbas","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"test4","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\ttest4\n\t\n\nThis is a merged speech dataset containing 345 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 345\nSpeakers: 7\nLanguages: en\nEmotions: neutral, sad, angry, happy\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral, happy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test4.","url":"https://huggingface.co/datasets/Codyfederer/test4","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"test4","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\ttest4\n\t\n\nThis is a merged speech dataset containing 345 audio segments from 2 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 345\nSpeakers: 7\nLanguages: en\nEmotions: neutral, sad, angry, happy\nOriginal Datasets: 2\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral, happy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test4.","url":"https://huggingface.co/datasets/Codyfederer/test4","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"text_to_speech_dataset","keyword":"text-to-speech","description":"Kishor798/text_to_speech_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Kishor798/text_to_speech_dataset","creator_name":"Kishor thagunna","creator_url":"https://huggingface.co/Kishor798","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"kinh-phap-hoa-ke-trom-huong","keyword":"automatic-speech-recognition","description":"Normalized using https://github.com/oysterlanguage/emiliapipex\n@article{emilia,\n      title={Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation},\n      author={He, Haorui and Shang, Zengqiang and Wang, Chaoren and Li, Xuyuan and Gu, Yicheng and Hua, Hua and Liu, Liwei and Yang, Chen and Li, Jiaqi and Shi, Peiyang and Wang, Yuancheng and Chen, Kai and Zhang, Pengyuan and Wu, Zhizheng},\n      journal={arXiv},\n      volume={abs/2407.05361}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hr16/kinh-phap-hoa-ke-trom-huong.","url":"https://huggingface.co/datasets/hr16/kinh-phap-hoa-ke-trom-huong","creator_name":"Abel Greyrat","creator_url":"https://huggingface.co/hr16","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-audio","text-to-speech","automatic-speech-recognition","Vietnamese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"smartstein","keyword":"automatic-speech-recognition","description":"from datasets import load_dataset\nds = load_dataset(\"nyu-mll/glue\", \"ax\")\nfrom datasets import load_dataset\nds = load_dataset(\"nyu-mll/glue\", \"cola\")\nfrom datasets import load_dataset\nds = load_dataset(\"nyu-mll/glue\", \"mnli\")\n","url":"https://huggingface.co/datasets/jurgenpaul82/smartstein","creator_name":"westerveld","creator_url":"https://huggingface.co/jurgenpaul82","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","table-question-answering","translation","text-generation","fill-mask"],"keywords_longer_than_N":true},
	{"name":"kinh-phap-hoa-ke-trom-huong","keyword":"text-to-speech","description":"Normalized using https://github.com/oysterlanguage/emiliapipex\n@article{emilia,\n      title={Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation},\n      author={He, Haorui and Shang, Zengqiang and Wang, Chaoren and Li, Xuyuan and Gu, Yicheng and Hua, Hua and Liu, Liwei and Yang, Chen and Li, Jiaqi and Shi, Peiyang and Wang, Yuancheng and Chen, Kai and Zhang, Pengyuan and Wu, Zhizheng},\n      journal={arXiv},\n      volume={abs/2407.05361}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hr16/kinh-phap-hoa-ke-trom-huong.","url":"https://huggingface.co/datasets/hr16/kinh-phap-hoa-ke-trom-huong","creator_name":"Abel Greyrat","creator_url":"https://huggingface.co/hr16","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-audio","text-to-speech","automatic-speech-recognition","Vietnamese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"uzbek-speech-corpus","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tUzbek Speech Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Uzbek speech corpus (USC) has been developed in collaboration between ISSAI and the Image and Speech Processing Laboratory in the Department of Computer Systems of the Tashkent University of Information Technologies. The USC comprises 958 different speakers with a total of 105 hours of transcribed audio recordings. To ensure high quality, the USC has been manually checked by native speakers. The USC is primarily designed for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/murodbek/uzbek-speech-corpus.","url":"https://huggingface.co/datasets/murodbek/uzbek-speech-corpus","creator_name":"Abror Shopulatov","creator_url":"https://huggingface.co/murodbek","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"augmented_codealpaca-20k-using-together-ai-deepseek-v1","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset, named CodeAlpaca-20k, consists of examples that blend coding instructions with outputs and reasoning. Each entry includes structured fields like output, instruction, input, and cot (Chain of Thought). It is particularly designed to train and evaluate AI models that generate code and explanations based on simple programming tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tData Collection and Preparation\n\t\n\nData entries are augmented using the augment_answer function that makes API‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eagle0504/augmented_codealpaca-20k-using-together-ai-deepseek-v1.","url":"https://huggingface.co/datasets/eagle0504/augmented_codealpaca-20k-using-together-ai-deepseek-v1","creator_name":"Yiqiao Yin","creator_url":"https://huggingface.co/eagle0504","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["reinforcement-learning","text-generation","text-to-speech","English","mit"],"keywords_longer_than_N":true},
	{"name":"arabic-speech-dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tarabic-speech-dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nArabic speech dataset for TTS training with diacritized and dediacritized text variants\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset follows the LJSpeech format with 3 columns:\n\nColumn 1: Audio file identifier\nColumn 2: Original Arabic text with diacritics\nColumn 3: Processed Arabic text (mix of diacritized and dediacritized)\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (WAV format, 16kHz)\nfilename: Audio file identifier\noriginal_text:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MrEzzat/arabic-speech-dataset.","url":"https://huggingface.co/datasets/MrEzzat/arabic-speech-dataset","creator_name":"Ahmed Ezzat","creator_url":"https://huggingface.co/MrEzzat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Arabic","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"arabic-speech-dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tarabic-speech-dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nArabic speech dataset for TTS training with diacritized and dediacritized text variants\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset follows the LJSpeech format with 3 columns:\n\nColumn 1: Audio file identifier\nColumn 2: Original Arabic text with diacritics\nColumn 3: Processed Arabic text (mix of diacritized and dediacritized)\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (WAV format, 16kHz)\nfilename: Audio file identifier\noriginal_text:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MrEzzat/arabic-speech-dataset.","url":"https://huggingface.co/datasets/MrEzzat/arabic-speech-dataset","creator_name":"Ahmed Ezzat","creator_url":"https://huggingface.co/MrEzzat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Arabic","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"bam-asr-early","keyword":"automatic-speech-recognition","description":"The **Bambara-ASR-Early Audio Dataset** is a multilingual dataset containing audio samples in Bambara, accompanied by semi-expert transcriptions and French translations. \nThe dataset includes various subsets: `jeli-asr`, `oza-mali-pense`, and `rt-data-collection`. Each audio file is aligned with Bambara transcriptions or French translations, making it suitable for tasks such as automatic speech recognition (ASR) and translation. \nData sources include all publicly available collections of audio with Bambara transcriptions as of December 2024, organized for accessibility and usability.\n","url":"https://huggingface.co/datasets/RobotsMali/bam-asr-early","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","audio-language-identification","keyword-spotting"],"keywords_longer_than_N":true},
	{"name":"sada-validation-preprocessed","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDetails\n\t\n\nThis is the SADA 2022 dataset with the input_features whish are log mels and the cleaned_labels which is the tokenized version of the cleaned_text. You can directly use this as the validation dataset when training Whisper Tiny, Small, Base & Medium models, as they all use the same tokenizer. Please double check this as well from the original model repo.\nIn addtition, the following filters were applied to this data:\n\nAll audios are less than 30 seconds and greater than 0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mosama/sada-validation-preprocessed.","url":"https://huggingface.co/datasets/mosama/sada-validation-preprocessed","creator_name":"Muhammad Osama","creator_url":"https://huggingface.co/mosama","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"audiotest","keyword":"automatic-speech-recognition","description":"An audio dataset for test.\n","url":"https://huggingface.co/datasets/Andy2505/audiotest","creator_name":"Andy2505","creator_url":"https://huggingface.co/Andy2505","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"VAD_cn_audio_ds","keyword":"text-to-speech","description":"Êú¨Êï∞ÊçÆÈõÜ‰ΩøÁî®CosyvoiceÂêàÊàêÔºåËØ≠Âè•‰ΩøÁî®Qwen-PlusÂ§ßÊ®°ÂûãÁîüÊàê\n","url":"https://huggingface.co/datasets/overji/VAD_cn_audio_ds","creator_name":"overji","creator_url":"https://huggingface.co/overji","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["voice-activity-detection","text-to-speech","text-to-audio","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"arabic-speech-dataset","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tarabic-speech-dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nArabic speech dataset for TTS training with diacritized and dediacritized text variants\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset follows the LJSpeech format with 3 columns:\n\nColumn 1: Audio file identifier\nColumn 2: Original Arabic text with diacritics\nColumn 3: Processed Arabic text (mix of diacritized and dediacritized)\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (WAV format, 16kHz)\nfilename: Audio file identifier\noriginal_text:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MrEzzat/arabic-speech-dataset.","url":"https://huggingface.co/datasets/MrEzzat/arabic-speech-dataset","creator_name":"Ahmed Ezzat","creator_url":"https://huggingface.co/MrEzzat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Arabic","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"bam-asr-early","keyword":"text-to-speech","description":"The **Bambara-ASR-Early Audio Dataset** is a multilingual dataset containing audio samples in Bambara, accompanied by semi-expert transcriptions and French translations. \nThe dataset includes various subsets: `jeli-asr`, `oza-mali-pense`, and `rt-data-collection`. Each audio file is aligned with Bambara transcriptions or French translations, making it suitable for tasks such as automatic speech recognition (ASR) and translation. \nData sources include all publicly available collections of audio with Bambara transcriptions as of December 2024, organized for accessibility and usability.\n","url":"https://huggingface.co/datasets/RobotsMali/bam-asr-early","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","audio-language-identification","keyword-spotting"],"keywords_longer_than_N":true},
	{"name":"koel-benchmark","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tKoel Benchmark Suite\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Koel Benchmark Suite is a comprehensive set of evaluation datasets designed to rigorously test the real-world performance of Text-to-Speech (TTS) models for major Indian languages. The suite focuses on challenges unique to the Indian context, such as code-switching, domain-specific terminology, proper nouns, and complex numeric formats.\nThis dataset was created to help developers and researchers build more natural, accurate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NisargBhavsar25/koel-benchmark.","url":"https://huggingface.co/datasets/NisargBhavsar25/koel-benchmark","creator_name":"Nisarg Bhavsar","creator_url":"https://huggingface.co/NisargBhavsar25","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Hindi","Tamil","Telugu","Kannada"],"keywords_longer_than_N":true},
	{"name":"CommonVoices20_ro","keyword":"speech","description":"\n\t\n\t\t\n\t\tCommon Voices Corpus 20.0 (Romanian)\n\t\n\n\nCommon Voices is an open-source dataset of speech recordings created by \nMozilla to improve speech recognition technologies. \nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\n\n\n\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \nessential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro.","url":"https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro","creator_name":"Transfer Rapid","creator_url":"https://huggingface.co/TransferRapid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"toy_corpus_asr_ca","keyword":"speech","description":"This is an example of a repository with a standard data loader. The audio files are compressed in tar format. Since this repository contains very few audio files, it can be used to test certain scripts in local machines.\n","url":"https://huggingface.co/datasets/carlosdanielhernandezmena/toy_corpus_asr_ca","creator_name":"Carlos Daniel Hern√°ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Catalan","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"CommonVoices20_ro","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tCommon Voices Corpus 20.0 (Romanian)\n\t\n\n\nCommon Voices is an open-source dataset of speech recordings created by \nMozilla to improve speech recognition technologies. \nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\n\n\n\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \nessential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro.","url":"https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro","creator_name":"Transfer Rapid","creator_url":"https://huggingface.co/TransferRapid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"toy_corpus_asr_ca","keyword":"automatic-speech-recognition","description":"This is an example of a repository with a standard data loader. The audio files are compressed in tar format. Since this repository contains very few audio files, it can be used to test certain scripts in local machines.\n","url":"https://huggingface.co/datasets/carlosdanielhernandezmena/toy_corpus_asr_ca","creator_name":"Carlos Daniel Hern√°ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Catalan","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"BengaliSentimentAnalysis","keyword":"hate-speech-detection","description":"\n  BengaliSentimentAnalysis\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\ndataset contains 3307 Negative reviews and 8500 Positive reviews collected and manually annotated from Youtube Bengali drama.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\nReference\nhttps://data.mendeley.com/datasets/p6zc7krs37/4\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BengaliSentimentAnalysis.","url":"https://huggingface.co/datasets/mteb/BengaliSentimentAnalysis","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"CommonVoices20_ro","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tCommon Voices Corpus 20.0 (Romanian)\n\t\n\n\nCommon Voices is an open-source dataset of speech recordings created by \nMozilla to improve speech recognition technologies. \nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\n\n\n\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \nessential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro.","url":"https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro","creator_name":"Transfer Rapid","creator_url":"https://huggingface.co/TransferRapid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"cv-corpus-17.0-zh-TW-client_id-grouped","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tcv-corpus-17.0-zh-TW-client_id-grouped\n\t\n\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nThe dataset is derived from the Common Voice dataset.\nThe original dataset is available at Common Voice Dataset.\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\nEach group is filtered to include only client IDs with a minimum of 30 samples and a maximum‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-TW-client_id-grouped.","url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-TW-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","commonvoice","Chinese"],"keywords_longer_than_N":true},
	{"name":"google_myanmar_asr_voices","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tGoogle Myanmar ASR Dataset (WebDataset Version)\n\t\n\nThis repository provides a clean, user-friendly, and robust version of the Google Myanmar ASR Dataset, which is derived from the OpenSLR-80 Burmese Speech Corpus.\nThis version has been carefully re-processed into the WebDataset format. Each sample consists of a .wav audio file and a clean .json metadata file, packaged into sharded .tar archives. This format is highly efficient for large-scale training of ASR models.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/google_myanmar_asr_voices.","url":"https://huggingface.co/datasets/freococo/google_myanmar_asr_voices","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Burmese","cc0-1.0","1K - 10K","webdataset"],"keywords_longer_than_N":true},
	{"name":"google_myanmar_asr_voices","keyword":"speech-recognition","description":"\n\t\n\t\t\n\t\tGoogle Myanmar ASR Dataset (WebDataset Version)\n\t\n\nThis repository provides a clean, user-friendly, and robust version of the Google Myanmar ASR Dataset, which is derived from the OpenSLR-80 Burmese Speech Corpus.\nThis version has been carefully re-processed into the WebDataset format. Each sample consists of a .wav audio file and a clean .json metadata file, packaged into sharded .tar archives. This format is highly efficient for large-scale training of ASR models.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/google_myanmar_asr_voices.","url":"https://huggingface.co/datasets/freococo/google_myanmar_asr_voices","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Burmese","cc0-1.0","1K - 10K","webdataset"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part003","keyword":"speech","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 3 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 3 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part003.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part003","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"ESpeech-upvote","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tUpvote YouTube Audio Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 296 hours of processed audio segments extracted from the \"Upvote\" YouTube channel with corresponding metadata. Each audio file represents a segment from the channel's videos and content, processed at 44.1kHz sample rate.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Russian\nTask: TTS, ASR, Quality Assessment\nAudio format: MP3, 44.1kHz sample rate\nStructure: Segmented audio files with JSON metadata\nSource:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ESpeech/ESpeech-upvote.","url":"https://huggingface.co/datasets/ESpeech/ESpeech-upvote","creator_name":"Ebany Speech","creator_url":"https://huggingface.co/ESpeech","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Russian","apache-2.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part003","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 3 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 3 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part003.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part003","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"MRC-psycholinguistic-database","keyword":"linguistics","description":"\n\t\n\t\t\n\t\tMRC Psycholinguistic Database\n\t\n\nThis is the complete MRC psycholinguistic database as found on https://websites.psychology.uwa.edu.au/school/mrcdatabase/uwa_mrc.htm.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset is ideal for training and evaluating machine learning models for English word concreteness.\n\n\t\n\t\t\n\t\tAcknowledgments\n\t\n\nWe extend our heartfelt gratitude to all the authors of the original dataset.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is made available under the MIT license.\n","url":"https://huggingface.co/datasets/StephanAkkerman/MRC-psycholinguistic-database","creator_name":"Stephan Akkerman","creator_url":"https://huggingface.co/StephanAkkerman","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"ESpeech-upvote","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tUpvote YouTube Audio Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 296 hours of processed audio segments extracted from the \"Upvote\" YouTube channel with corresponding metadata. Each audio file represents a segment from the channel's videos and content, processed at 44.1kHz sample rate.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Russian\nTask: TTS, ASR, Quality Assessment\nAudio format: MP3, 44.1kHz sample rate\nStructure: Segmented audio files with JSON metadata\nSource:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ESpeech/ESpeech-upvote.","url":"https://huggingface.co/datasets/ESpeech/ESpeech-upvote","creator_name":"Ebany Speech","creator_url":"https://huggingface.co/ESpeech","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Russian","apache-2.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part003","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 3 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 3 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part003.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part003","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-jokes","keyword":"speech","description":"\n\t\n\t\t\n\t\tHailuo AI Jokes Dataset üé§\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tüéôÔ∏è Dataset Content\n\t\n\nThe dataset contains a diverse set of synthetic voice recordings generated by Hailuo AI Audio. The texts are sourced from a variety of public domain jokes and humorous anecdotes. Each audio sample is accompanied by the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes.","url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-jokes","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tHailuo AI Jokes Dataset üé§\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tüéôÔ∏è Dataset Content\n\t\n\nThe dataset contains a diverse set of synthetic voice recordings generated by Hailuo AI Audio. The texts are sourced from a variety of public domain jokes and humorous anecdotes. Each audio sample is accompanied by the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes.","url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-jokes","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tHailuo AI Jokes Dataset üé§\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tüéôÔ∏è Dataset Content\n\t\n\nThe dataset contains a diverse set of synthetic voice recordings generated by Hailuo AI Audio. The texts are sourced from a variety of public domain jokes and humorous anecdotes. Each audio sample is accompanied by the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes.","url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"hailuo-ai-jokes","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tHailuo AI Jokes Dataset üé§\n\t\n\n\n\nA curated collection of high-quality voice recordings with corresponding transcriptions and phoneme analysis. This dataset is designed for speech recognition, text-to-speech, and voice analysis tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tüéôÔ∏è Dataset Content\n\t\n\nThe dataset contains a diverse set of synthetic voice recordings generated by Hailuo AI Audio. The texts are sourced from a variety of public domain jokes and humorous anecdotes. Each audio sample is accompanied by the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes.","url":"https://huggingface.co/datasets/unlimitedbytes/hailuo-ai-jokes","creator_name":"Christian Peterson","creator_url":"https://huggingface.co/unlimitedbytes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","English","mit"],"keywords_longer_than_N":true},
	{"name":"composite_corpus_eu_v2.1","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tComposite dataset for Basque made from public available data\n\t\n\nThis dataset is composed of the following public available data:\n\n\t\n\t\t\n\t\tTrain split:\n\t\n\nThe train split is composed of the following datasets combined:\n\nmozilla-foundation/common_voice_18_0/eu: \"validated\" split removing \"test_cv\" and \"dev_cv\" split's sentences. (validated split contains official train + dev + test splits and more unique data)\ngttsehu/basque_parliament_1/eu: \"train_clean\" split removing some of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/asierhv/composite_corpus_eu_v2.1.","url":"https://huggingface.co/datasets/asierhv/composite_corpus_eu_v2.1","creator_name":"Asier Herranz","creator_url":"https://huggingface.co/asierhv","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Basque","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"MSC","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for [msc]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n1541 speech samples\n75 speech contributors\n1:38:16 hours of speech\n482 unique sentences\n1400 unique words\n553 unique syllables\n48 unique phonemes\n\nFor more detailed analysis see the python notebook provided here\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nAutomatic Speech Recognition system development, gender and age identification of speakers\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nMalayalam\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\nfile_name‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smcproject/MSC.","url":"https://huggingface.co/datasets/smcproject/MSC","creator_name":"Swathanthra Malayalam Computing","creator_url":"https://huggingface.co/smcproject","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Malayalam","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"2k_grammar_corrections","keyword":"grammar","description":"ambrosfitz/2k_grammar_corrections dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ambrosfitz/2k_grammar_corrections","creator_name":"Christopher Smith","creator_url":"https://huggingface.co/ambrosfitz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"measuring-hate-speech","keyword":"hate-speech","description":"\n\t\n\t\t\n\t\tDataset card for Measuring Hate Speech\n\t\n\nThis is a public release of the dataset described in Kennedy et al. (2020) and Sachdeva et al. (2022), consisting of 39,565 comments annotated by 7,912 annotators, for 135,556 combined rows. The primary outcome variable is the \"hate speech score\" but the 10 constituent ordinal labels (sentiment, (dis)respect, insult, humiliation, inferior status, violence, dehumanization, genocide, attack/defense, hate speech benchmark) can also be treated as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech.","url":"https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech","creator_name":"D-Lab, UC Berkeley","creator_url":"https://huggingface.co/ucberkeley-dlab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","sentiment-classification","multi-label-classification","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"measuring-hate-speech","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset card for Measuring Hate Speech\n\t\n\nThis is a public release of the dataset described in Kennedy et al. (2020) and Sachdeva et al. (2022), consisting of 39,565 comments annotated by 7,912 annotators, for 135,556 combined rows. The primary outcome variable is the \"hate speech score\" but the 10 constituent ordinal labels (sentiment, (dis)respect, insult, humiliation, inferior status, violence, dehumanization, genocide, attack/defense, hate speech benchmark) can also be treated as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech.","url":"https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech","creator_name":"D-Lab, UC Berkeley","creator_url":"https://huggingface.co/ucberkeley-dlab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","sentiment-classification","multi-label-classification","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"audiocaps-ru","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\taudiocaps-ru\n\t\n\nTranslated version of d0rj/audiocaps into Russian.\n","url":"https://huggingface.co/datasets/d0rj/audiocaps-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","translated","monolingual","d0rj/audiocaps","Russian"],"keywords_longer_than_N":true},
	{"name":"EmovDB","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tEmoV-DB\n\t\n\n\n\t\n\t\t\n\t\tSee also\n\t\n\nhttps://github.com/noetits/ICE-Talk for controllable TTS\n\n\t\n\t\t\n\t\tHow to use\n\t\n\n\n\t\n\t\t\n\t\tDownload link\n\t\n\nSorted version (recommended), new link:\nhttps://openslr.org/115/\nold link (slow download) but gives ou the folder structure needed to use \"load_emov_db()\" function: \nhttps://mega.nz/#F!KBp32apT!gLIgyWf9iQ-yqnWFUFuUHg\nNot sorted version:\nhttp://www.coe.neu.edu/Research/AClab/Speech%20Data/\n\n\t\n\t\t\n\t\n\t\n\t\tForced alignments\n\t\n\n\"It is the process of taking the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Abhinay45/EmovDB.","url":"https://huggingface.co/datasets/Abhinay45/EmovDB","creator_name":"Abhinay Poloju ","creator_url":"https://huggingface.co/Abhinay45","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","English","mit","arxiv:1806.09514","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"EmovDB","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tEmoV-DB\n\t\n\n\n\t\n\t\t\n\t\tSee also\n\t\n\nhttps://github.com/noetits/ICE-Talk for controllable TTS\n\n\t\n\t\t\n\t\tHow to use\n\t\n\n\n\t\n\t\t\n\t\tDownload link\n\t\n\nSorted version (recommended), new link:\nhttps://openslr.org/115/\nold link (slow download) but gives ou the folder structure needed to use \"load_emov_db()\" function: \nhttps://mega.nz/#F!KBp32apT!gLIgyWf9iQ-yqnWFUFuUHg\nNot sorted version:\nhttp://www.coe.neu.edu/Research/AClab/Speech%20Data/\n\n\t\n\t\t\n\t\n\t\n\t\tForced alignments\n\t\n\n\"It is the process of taking the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Abhinay45/EmovDB.","url":"https://huggingface.co/datasets/Abhinay45/EmovDB","creator_name":"Abhinay Poloju ","creator_url":"https://huggingface.co/Abhinay45","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","English","mit","arxiv:1806.09514","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"zeroth-korean","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tZeroth-Korean\n\t\n\n\n\t\n\t\t\n\t\tZeroth-Korean\n\t\n\nThe data set contains transcriebed audio data for Korean. There are 51.6 hours transcribed Korean audio for training data (22,263 utterances, 105 people, 3000 sentences) and 1.2 hours transcribed Korean audio for testing data (457 utterances, 10 people). This corpus also contains pre-trained/designed language model, lexicon and morpheme-based segmenter(morfessor).\nZeroth project introduces free Korean speech corpus and aims to make Korean‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/zeroth-korean.","url":"https://huggingface.co/datasets/Bingsu/zeroth-korean","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","monolingual","extended|kresnik/zeroth_korean","Korean"],"keywords_longer_than_N":true},
	{"name":"DIDI","keyword":"automatic-speech-recognition","description":"PeepDaSlan9/DIDI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/PeepDaSlan9/DIDI","creator_name":"Ohenenoo","creator_url":"https://huggingface.co/PeepDaSlan9","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","table-question-answering","question-answering","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr","keyword":"automatic-speech-recognition","description":"LibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\nprepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\naudiobooks from the LibriVox project, and has been carefully segmented and aligned.87","url":"https://huggingface.co/datasets/distil-whisper/librispeech_asr","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"DIDI","keyword":"text-to-speech","description":"PeepDaSlan9/DIDI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/PeepDaSlan9/DIDI","creator_name":"Ohenenoo","creator_url":"https://huggingface.co/PeepDaSlan9","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","table-question-answering","question-answering","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"swahili-speech-400hr","keyword":"automatic-speech-recognition","description":"badrex/swahili-speech-400hr dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/badrex/swahili-speech-400hr","creator_name":"Badr al-Absi","creator_url":"https://huggingface.co/badrex","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Swahili","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"librispeech_asr-token-ids","keyword":"automatic-speech-recognition","description":"LibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\nprepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\naudiobooks from the LibriVox project, and has been carefully segmented and aligned.87","url":"https://huggingface.co/datasets/distil-whisper/librispeech_asr-token-ids","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"althingi_asr","keyword":"automatic-speech-recognition","description":"Althingi Parliamentary Speech consists of approximately 542 hours of recorded speech from Althingi, the Icelandic Parliament. Speeches date from 2005-2016.","url":"https://huggingface.co/datasets/language-and-voice-lab/althingi_asr","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","machine-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"arabic_speech_corpus","keyword":"automatic-speech-recognition","description":"This Speech corpus has been developed as part of PhD work carried out by Nawar Halabi at the University of Southampton.\nThe corpus was recorded in south Levantine Arabic\n(Damascian accent) using a professional studio. Synthesized speech as an output using this corpus has produced a high quality, natural voice.\nNote that in order to limit the required storage for preparing this dataset, the audio\nis stored in the .flac format and is not converted to a float32 array. To convert, the audio\nfile to a float32 array, please make use of the `.map()` function as follows:\n\n\n```python\nimport soundfile as sf\n\ndef map_to_array(batch):\n    speech_array, _ = sf.read(batch[\"file\"])\n    batch[\"speech\"] = speech_array\n    return batch\n\ndataset = dataset.map(map_to_array, remove_columns=[\"file\"])\n```","url":"https://huggingface.co/datasets/halabi2016/arabic_speech_corpus","creator_name":"halabi2016","creator_url":"https://huggingface.co/halabi2016","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"kor_sarcasm","keyword":"sarcasm-detection","description":"\n\t\n\t\t\n\t\tDataset Card for Korean Sarcasm Detection\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Korean Sarcasm Dataset was created to detect sarcasm in text, which can significantly alter the original meaning of a sentence. 9319 tweets were collected from Twitter and labeled for sarcasm or not_sarcasm. These tweets were gathered by querying for: Ïó≠ÏÑ§, ÏïÑÎ¨¥Îßê, Ïö¥ÏàòÏ¢ãÏùÄÎÇ†, Á¨ë, Î≠êÎûò ÏïÑÎãôÎãàÎã§, Í∑∏Îü¥Î¶¨ÏóÜÎã§, Ïñ¥Í∑∏Î°ú, irony sarcastic, and sarcasm. The dataset was pre-processed by removing the keyword hashtag, urls and mentions of the user‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SpellOnYou/kor_sarcasm.","url":"https://huggingface.co/datasets/SpellOnYou/kor_sarcasm","creator_name":"SpellOnYou","creator_url":"https://huggingface.co/SpellOnYou","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"VerbaLex_voice","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tVerbaLex Voice\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThis dataset is a collection of speech from non-native English speakers. The dataset is imported from the L2-Arctic dataset.\nCurrently, the dataset only contains a few speech corpus from a few accents. Check for the list of available accent below.\nThe accents available within the dataset are represented by the standard ISO Codes for languages. For example,\nar represents Arabic accent, and zh represents Chinese accent.\n\n\t\n\t\t\n\t\n\t\n\t\tAccents available‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RitchieP/VerbaLex_voice.","url":"https://huggingface.co/datasets/RitchieP/VerbaLex_voice","creator_name":"Ritchie Poh","creator_url":"https://huggingface.co/RitchieP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"vctk","keyword":"automatic-speech-recognition","description":"The CSTR VCTK Corpus includes speech data uttered by 110 English speakers with various accents.","url":"https://huggingface.co/datasets/CSTR-Edinburgh/vctk","creator_name":"Centre for Speech Technology Research - University of Edinburgh","creator_url":"https://huggingface.co/CSTR-Edinburgh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"common_voice_16_0","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 16.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 16. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_16_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_16_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"nst","keyword":"automatic-speech-recognition","description":"This database was created by Nordic Language Technology for the development of automatic speech recognition and dictation in Swedish. In this updated version, the organization of the data have been altered to improve the usefulness of the database.\n\nIn the original version of the material, the files were organized in a specific folder structure where the folder names were meaningful. However, the file names were not meaningful, and there were also cases of files with identical names in different folders. This proved to be impractical, since users had to keep the original folder structure in order to use the data. The files have been renamed, such that the file names are unique and meaningful regardless of the folder structure. The original metadata files were in spl format. These have been converted to JSON format. The converted metadata files are also anonymized and the text encoding has been converted from ANSI to UTF-8.","url":"https://huggingface.co/datasets/KTH/nst","creator_name":"KTH","creator_url":"https://huggingface.co/KTH","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Swedish","cc0-1.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"px-corpus","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tPxCorpus : A Spoken Drug Prescription Dataset in French\n\t\n\nPxCorpus is to the best of our knowledge, the first spoken medical drug prescriptions corpus to be distributed. \nIt contains 4 hours of transcribed and annotated dialogues of drug prescriptions in \nFrench acquired through an experiment with 55 participants experts and non-experts  in drug prescriptions.\nThe automatic transcriptions were verified by human effort and aligned with \nsemantic labels to allow training of NLP models.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bastiendechamps/px-corpus.","url":"https://huggingface.co/datasets/bastiendechamps/px-corpus","creator_name":"Bastien Dechamps","creator_url":"https://huggingface.co/bastiendechamps","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","French","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"uzbekvoice-filtered","keyword":"automatic-speech-recognition","description":"This is heavy filtered version of the dataset with additional information.\nThis dataset does not contain original Mozilla Common Voice audios or texts\nWe filtered the dataset using number approaches:\n\nVAD + Noise detection. Audios which lacked voice activity and produced no sound after denoiser were removed\nReading Speed. Audios with outlier speeds (approximately 5-10%), as they didnt match natural speed or were too noisy\nAutomatic STT validation. We trained the model using subset of valid‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DavronSherbaev/uzbekvoice-filtered.","url":"https://huggingface.co/datasets/DavronSherbaev/uzbekvoice-filtered","creator_name":"Dovron Sherbaev","creator_url":"https://huggingface.co/DavronSherbaev","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"hatecheck","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nHateCheck is a suite of functional test for hate speech detection models. \nThe dataset contains 3,728 validated test cases in 29 functional tests.\n19 functional tests correspond to distinct types of hate. The other 11 functional tests cover challenging types of non-hate.\nThis allows for targeted diagnostic insights into model performance.\nIn our ACL paper, we found critical weaknesses in all commercial and academic hate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck.","url":"https://huggingface.co/datasets/Paul/hatecheck","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"vctk","keyword":"text-to-speech","description":"The CSTR VCTK Corpus includes speech data uttered by 110 English speakers with various accents.","url":"https://huggingface.co/datasets/CSTR-Edinburgh/vctk","creator_name":"Centre for Speech Technology Research - University of Edinburgh","creator_url":"https://huggingface.co/CSTR-Edinburgh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"HATS-fr","keyword":"speech","description":"\n\t\n\t\t\n\t\tüóÉÔ∏è HATS Dataset\n\t\n\nHATS (Human Assessed Transcription Side-by-Side) is a data set for French üá´üá∑ which consists of 1,000 triplets (reference, hypothesis A, hypothesis B) and 7,150 human choice annotated by 143 subjects ü´Ç Their objective was to select, given a textual reference, which of two erroneous hypotheses is the best.\n\n\n\n\n\nCurated by: Thibault Ba√±eras-Roux, Richard Dufour, Jane Wottawa, Mickael Rouvier, Teva Merlin\nFunded by: Agence Nationale de la Recherche - DIETS project‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thibault-baneras-roux/HATS-fr.","url":"https://huggingface.co/datasets/thibault-baneras-roux/HATS-fr","creator_name":"Thibault Ba√±eras-Roux","creator_url":"https://huggingface.co/thibault-baneras-roux","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["French","mit","1K - 10K","text","Text"],"keywords_longer_than_N":true},
	{"name":"openslr63","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSLR63: Crowdsourced high-quality Malayalam multi-speaker speech data set\n\t\n\nThis data set contains transcribed high-quality audio of Malayalam sentences recorded by volunteers. The data set consists of wave files, and a TSV file (line_index.tsv). The file line_index.tsv contains a anonymized FileID and the transcription of audio in the file.\nThe data set has been manually quality checked, but there might still be errors.\nPlease report any issues in the following issue tracker on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vrclc/openslr63.","url":"https://huggingface.co/datasets/vrclc/openslr63","creator_name":"Virtual Resource Centre for Language Computing (Digital University Kerala)","creator_url":"https://huggingface.co/vrclc","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Malayalam","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"openslr63","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tSLR63: Crowdsourced high-quality Malayalam multi-speaker speech data set\n\t\n\nThis data set contains transcribed high-quality audio of Malayalam sentences recorded by volunteers. The data set consists of wave files, and a TSV file (line_index.tsv). The file line_index.tsv contains a anonymized FileID and the transcription of audio in the file.\nThe data set has been manually quality checked, but there might still be errors.\nPlease report any issues in the following issue tracker on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vrclc/openslr63.","url":"https://huggingface.co/datasets/vrclc/openslr63","creator_name":"Virtual Resource Centre for Language Computing (Digital University Kerala)","creator_url":"https://huggingface.co/vrclc","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Malayalam","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"vistaar_small_asr_eval","keyword":"speech","description":"\n\t\n\t\t\n\t\tVistaar Small ASR Eval\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Vistaar Small ASR Eval dataset is a multilingual automatic speech recognition evaluation dataset containing 9,486 audio samples across 12 Indian languages. This dataset represents a subset of the larger Vistaar dataset published by AI4Bharat, designed specifically for evaluating ASR model performance on diverse Indian language speech data. A smaller evaluation dataset was created for the use-cases where a quick benchmarking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AdityK2409/vistaar_small_asr_eval.","url":"https://huggingface.co/datasets/AdityK2409/vistaar_small_asr_eval","creator_name":"Aditya Kapoor","creator_url":"https://huggingface.co/AdityK2409","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"latvian-text","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tLatvian text dataset\n\t\n\nData set of latvian language texts. Intended for use in AI tool development, like speech recognition or spellcheckers\n\n\t\n\t\t\n\t\tData sources used\n\t\n\n\nLatvian Wikisource articles - https://wikisource.org/wiki/Category:Latvian\nLiterary works of Rainis - https://repository.clarin.lv/repository/xmlui/handle/20.500.12574/41\nLatvian Wikipedia articles - https://huggingface.co/datasets/joelito/EU_Wikipedias\nEuropean Parliament Proceedings Parallel Corpus -‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RaivisDejus/latvian-text.","url":"https://huggingface.co/datasets/RaivisDejus/latvian-text","creator_name":"Raivis Dejus","creator_url":"https://huggingface.co/RaivisDejus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","extended|tilde_model"],"keywords_longer_than_N":true},
	{"name":"vistaar_small_asr_eval","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tVistaar Small ASR Eval\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Vistaar Small ASR Eval dataset is a multilingual automatic speech recognition evaluation dataset containing 9,486 audio samples across 12 Indian languages. This dataset represents a subset of the larger Vistaar dataset published by AI4Bharat, designed specifically for evaluating ASR model performance on diverse Indian language speech data. A smaller evaluation dataset was created for the use-cases where a quick benchmarking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AdityK2409/vistaar_small_asr_eval.","url":"https://huggingface.co/datasets/AdityK2409/vistaar_small_asr_eval","creator_name":"Aditya Kapoor","creator_url":"https://huggingface.co/AdityK2409","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"jalandhary_asr","keyword":"automatic-speech-recognition","description":"Jalandhary dataset is created using whisper model for STT and TTS. Some audios are ommited due to issues while trimming them. If there are some isues \nin the dataset or audio not matching the text you can start a discussion or ping me to correcting it. \n","url":"https://huggingface.co/datasets/mirfan899/jalandhary_asr","creator_name":"Muhammad Irfan","creator_url":"https://huggingface.co/mirfan899","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Urdu","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"TuPy-Dataset","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tPortuguese Hate Speech Dataset (TuPy)\n\t\n\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) \nand natural language processing (NLP) techniques. TuPy is comprised of 10,000 (ten thousand) unpublished, annotated, and anonymized documents collected \non Twitter (currently known as X) in 2023. \nThis repository is organized as follows:\nroot.\n    ‚îú‚îÄ‚îÄ binary     : binary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Silly-Machine/TuPy-Dataset.","url":"https://huggingface.co/datasets/Silly-Machine/TuPy-Dataset","creator_name":"Silly-Machine","creator_url":"https://huggingface.co/Silly-Machine","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","crowdsourced","Brazilian-Portuguese","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"audiocaps","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\taudiocaps\n\t\n\nHuggingFace mirror of official data repo.\n","url":"https://huggingface.co/datasets/d0rj/audiocaps","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","monolingual","original","English","mit"],"keywords_longer_than_N":true},
	{"name":"vistaar_small_asr_eval","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tVistaar Small ASR Eval\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Vistaar Small ASR Eval dataset is a multilingual automatic speech recognition evaluation dataset containing 9,486 audio samples across 12 Indian languages. This dataset represents a subset of the larger Vistaar dataset published by AI4Bharat, designed specifically for evaluating ASR model performance on diverse Indian language speech data. A smaller evaluation dataset was created for the use-cases where a quick benchmarking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AdityK2409/vistaar_small_asr_eval.","url":"https://huggingface.co/datasets/AdityK2409/vistaar_small_asr_eval","creator_name":"Aditya Kapoor","creator_url":"https://huggingface.co/AdityK2409","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"jalandhary_asr","keyword":"text-to-speech","description":"Jalandhary dataset is created using whisper model for STT and TTS. Some audios are ommited due to issues while trimming them. If there are some isues \nin the dataset or audio not matching the text you can start a discussion or ping me to correcting it. \n","url":"https://huggingface.co/datasets/mirfan899/jalandhary_asr","creator_name":"Muhammad Irfan","creator_url":"https://huggingface.co/mirfan899","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Urdu","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"xtreme_s","keyword":"automatic-speech-recognition","description":"XTREME-S covers four task families: speech recognition, classification, speech-to-text translation and retrieval. Covering 102\nlanguages from 10+ language families, 3 different domains and 4\ntask families, XTREME-S aims to simplify multilingual speech\nrepresentation evaluation, as well as catalyze research in ‚Äúuniversal‚Äù speech representation learning.","url":"https://huggingface.co/datasets/google/xtreme_s","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"xtreme_s","keyword":"speech-recognition","description":"XTREME-S covers four task families: speech recognition, classification, speech-to-text translation and retrieval. Covering 102\nlanguages from 10+ language families, 3 different domains and 4\ntask families, XTREME-S aims to simplify multilingual speech\nrepresentation evaluation, as well as catalyze research in ‚Äúuniversal‚Äù speech representation learning.","url":"https://huggingface.co/datasets/google/xtreme_s","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Umamusume-voice-text-pairs","keyword":"automatic-speech-recognition","description":"Plachta/Umamusume-voice-text-pairs dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Plachta/Umamusume-voice-text-pairs","creator_name":"ElderFrog","creator_url":"https://huggingface.co/Plachta","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"multilingual-gec","keyword":"grammar","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Grammar Error Correction\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset can be used to train a transformer model (we used T5) to correct grammar errors in simple sentences written in English, Spanish, French, or German. \nThis dataset was developed as a component for the Squidigies platform.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nGrammar Error Correction: By appending the prefix fix grammar: to the prrompt.\nLanguage Detection: By appending the prefix:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/juancavallotti/multilingual-gec.","url":"https://huggingface.co/datasets/juancavallotti/multilingual-gec","creator_name":"Juan Alberto Lopez Cavallotti","creator_url":"https://huggingface.co/juancavallotti","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Spanish","French","German"],"keywords_longer_than_N":true},
	{"name":"news-ro-offense","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-News-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive message detection with manually \nannotated comment from a local Romanian news website (stiri de cluj) into five classes:\n\nnon-offensive\ntargeted insults\nracist\nhomophobic\nsexist\n\nResulting in 4052 annotated messages\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example of 'train' looks as follows.\n{\n  'comment_id': 5‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/news-ro-offense.","url":"https://huggingface.co/datasets/readerbench/news-ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"news-ro-offense","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-News-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive message detection with manually \nannotated comment from a local Romanian news website (stiri de cluj) into five classes:\n\nnon-offensive\ntargeted insults\nracist\nhomophobic\nsexist\n\nResulting in 4052 annotated messages\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example of 'train' looks as follows.\n{\n  'comment_id': 5‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/news-ro-offense.","url":"https://huggingface.co/datasets/readerbench/news-ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-arabic","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-arabic.","url":"https://huggingface.co/datasets/Paul/hatecheck-arabic","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Umamusume-voice-text-pairs","keyword":"text-to-speech","description":"Plachta/Umamusume-voice-text-pairs dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Plachta/Umamusume-voice-text-pairs","creator_name":"ElderFrog","creator_url":"https://huggingface.co/Plachta","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"nb_samtale","keyword":"speech","description":"NB Samtale is a speech corpus made by the Language Bank at the National Library of Norway.\nThe corpus contains orthographically transcribed speech from podcasts and recordings of live events at the National Library.\nThe corpus is intended as an open source dataset for Automatic Speech Recognition (ASR) development,\nand is specifically aimed at improving ASR systems‚Äô handle on conversational speech.","url":"https://huggingface.co/datasets/Sprakbanken/nb_samtale","creator_name":"Nasjonalbiblioteket Spr√•kbanken","creator_url":"https://huggingface.co/Sprakbanken","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Norwegian Bokm√•l","Norwegian Nynorsk","Norwegian","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"nb_samtale","keyword":"automatic-speech-recognition","description":"NB Samtale is a speech corpus made by the Language Bank at the National Library of Norway.\nThe corpus contains orthographically transcribed speech from podcasts and recordings of live events at the National Library.\nThe corpus is intended as an open source dataset for Automatic Speech Recognition (ASR) development,\nand is specifically aimed at improving ASR systems‚Äô handle on conversational speech.","url":"https://huggingface.co/datasets/Sprakbanken/nb_samtale","creator_name":"Nasjonalbiblioteket Spr√•kbanken","creator_url":"https://huggingface.co/Sprakbanken","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Norwegian Bokm√•l","Norwegian Nynorsk","Norwegian","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"banc-trawsgrifiadau-bangor","keyword":"automatic-speech-recognition","description":"Huggingface Dataset version of Banc Trawsgrifiadau Bangor","url":"https://huggingface.co/datasets/prvInSpace/banc-trawsgrifiadau-bangor","creator_name":"Preben Vangberg","creator_url":"https://huggingface.co/prvInSpace","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Welsh","cc0-1.0","10K - 100K","Audio"],"keywords_longer_than_N":true},
	{"name":"or_in_dataset","keyword":"automatic-speech-recognition","description":"Ranjit/or_in_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Ranjit/or_in_dataset","creator_name":"Ranjit Patro","creator_url":"https://huggingface.co/Ranjit","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Oriya","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"isizulu-asr-1.1-speed","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tisiZulu Speech Recognition Augmented Dataset - 1.1 Speed\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains augmented speech recordings and transcriptions for isiZulu, one of South Africa's official languages.\nThe dataset has been optimized for use with OpenAI's Whisper ASR models.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nNumber of samples: 699\nLanguage: isiZulu (Zul)\nAudio format: WAV, 16kHz, mono, 16-bit\nMaximum duration: 30 seconds (truncated for Whisper compatibility)\nTranscription‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zionia/isizulu-asr-1.1-speed.","url":"https://huggingface.co/datasets/zionia/isizulu-asr-1.1-speed","creator_name":"Zion van Wyk","creator_url":"https://huggingface.co/zionia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Zulu","Xhosa","Southern Ndebele","Pedi"],"keywords_longer_than_N":true},
	{"name":"hatecheck-french","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-french.","url":"https://huggingface.co/datasets/Paul/hatecheck-french","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"vivechan-spritual-text-dataset-v2","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tVivechan - Spiritual Text Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe Vivechan - Spiritual Text Dataset is an open and public collection of textual data extracted from significant spiritual texts, curated to support discussions, inquiries, doubts, and Q&A sessions within the realm of spirituality. This dataset provides valuable content from the following revered sources:\n\nShrimad Bhagwat Mahapurana\nShripad Shri Vallabha Charitramrutam\nShiv Mahapurana Sankshipt\nValmiki Ramayan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/om-ashish-soni/vivechan-spritual-text-dataset-v2.","url":"https://huggingface.co/datasets/om-ashish-soni/vivechan-spritual-text-dataset-v2","creator_name":"Om Ashishkumar Soni","creator_url":"https://huggingface.co/om-ashish-soni","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-to-speech","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"infore2_audiobooks","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tunofficial mirror of InfoRe Technology public dataset ‚Ññ2\n\t\n\nofficial announcement: https://www.facebook.com/groups/j2team.community/permalink/1010834009248719/\n415h, 315k samples, vietnamese audiobooks of chinese w«îxi√° Ê≠¶‰ø† & xiƒÅnxi√° ‰ªô‰ø†\nb·ªô d·ªØ li·ªáu b√≥c ra t·ª´ YouTube ƒë·ªçc truy·ªán v√µ hi·ªáp & ti√™n hi·ªáp, √°p d·ª•ng kƒ© thu·∫≠t ƒë·ªëi chi·∫øu vƒÉn b·∫£n ƒë·ªÉ d√°n nh√£n t·ª± ƒë·ªông\nofficial download:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/infore2_audiobooks.","url":"https://huggingface.co/datasets/doof-ferb/infore2_audiobooks","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"openstt","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tOpen Speech-to-Text corpus for üá∫üá¶ Ukrainian\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset has transcriptions with other metadata for the VOA Ukrainian dataset (398h) and YODAS2 (400h).\n","url":"https://huggingface.co/datasets/speech-uk/openstt","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Ukrainian","cc-by-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"baneks-speech","keyword":"automatic-speech-recognition","description":"This dataset contains speech generated for anecdotes from the [baneks dataset](https://huggingface.co/datasets/zeio/baneks)","url":"https://huggingface.co/datasets/zeio/baneks-speech","creator_name":"zeionara","creator_url":"https://huggingface.co/zeio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","crowdsourced","original","machine-generated"],"keywords_longer_than_N":true},
	{"name":"commonvoice_benchmark_catalan_accents","keyword":"automatic-speech-recognition","description":"A new presentation of the corpus Catalan Common Voice v17.0 - metadata annotated version with the splits redefined to benchmark ASR models with various Catalan accent","url":"https://huggingface.co/datasets/projecte-aina/commonvoice_benchmark_catalan_accents","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","audio-to-audio","audio-language-identification","expert-generated"],"keywords_longer_than_N":true},
	{"name":"auto-pale","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset card for pale\n\t\n\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nThis dataset contains league of legends champions' quotes parsed from fandom.\nSee dataset usage example at google colab.\nThe dataset is available in the following configurations:\n\nvanilla - all data pulled from the website without significant modifications apart from the web page structure parsing;\nquotes - truncated version of the corpus, which does't contain sound effects;\nannotated - an extended version of the full configuration‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zeio/auto-pale.","url":"https://huggingface.co/datasets/zeio/auto-pale","creator_name":"zeionara","creator_url":"https://huggingface.co/zeio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","automatic-speech-recognition","crowdsourced","English"],"keywords_longer_than_N":true},
	{"name":"infore2_audiobooks","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tunofficial mirror of InfoRe Technology public dataset ‚Ññ2\n\t\n\nofficial announcement: https://www.facebook.com/groups/j2team.community/permalink/1010834009248719/\n415h, 315k samples, vietnamese audiobooks of chinese w«îxi√° Ê≠¶‰ø† & xiƒÅnxi√° ‰ªô‰ø†\nb·ªô d·ªØ li·ªáu b√≥c ra t·ª´ YouTube ƒë·ªçc truy·ªán v√µ hi·ªáp & ti√™n hi·ªáp, √°p d·ª•ng kƒ© thu·∫≠t ƒë·ªëi chi·∫øu vƒÉn b·∫£n ƒë·ªÉ d√°n nh√£n t·ª± ƒë·ªông\nofficial download:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/infore2_audiobooks.","url":"https://huggingface.co/datasets/doof-ferb/infore2_audiobooks","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"baneks-speech","keyword":"text-to-speech","description":"This dataset contains speech generated for anecdotes from the [baneks dataset](https://huggingface.co/datasets/zeio/baneks)","url":"https://huggingface.co/datasets/zeio/baneks-speech","creator_name":"zeionara","creator_url":"https://huggingface.co/zeio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","crowdsourced","original","machine-generated"],"keywords_longer_than_N":true},
	{"name":"dv-presidential-speech","keyword":"speech","description":"Dhivehi Presidential Speech is a Dhivehi speech dataset created from data extracted and \nprocessed by [Sofwath](https://github.com/Sofwath) as part of a collection of Dhivehi \ndatasets found [here](https://github.com/Sofwath/DhivehiDatasets).\n\nThe dataset contains around 2.5 hrs (1 GB) of speech collected from Maldives President's Office\nconsisting of 7 speeches given by President Yaameen Abdhul Gayyoom.","url":"https://huggingface.co/datasets/dash8x/dv-presidential-speech","creator_name":"Arushad Ahmed","creator_url":"https://huggingface.co/dash8x","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Divehi","apache-2.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"dv-presidential-speech","keyword":"automatic-speech-recognition","description":"Dhivehi Presidential Speech is a Dhivehi speech dataset created from data extracted and \nprocessed by [Sofwath](https://github.com/Sofwath) as part of a collection of Dhivehi \ndatasets found [here](https://github.com/Sofwath/DhivehiDatasets).\n\nThe dataset contains around 2.5 hrs (1 GB) of speech collected from Maldives President's Office\nconsisting of 7 speeches given by President Yaameen Abdhul Gayyoom.","url":"https://huggingface.co/datasets/dash8x/dv-presidential-speech","creator_name":"Arushad Ahmed","creator_url":"https://huggingface.co/dash8x","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Divehi","apache-2.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"pile-detoxify","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for pile-pii-scrubadub\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains text from The Pile, annotated based on the toxicity of each sentence.\nEach document (row in the dataset) is segmented into sentences, and each sentence is given a score: the toxicity predicted by the Detoxify.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThis dataset is taken from The Pile, which is English text.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tomekkorbak/pile-detoxify.","url":"https://huggingface.co/datasets/tomekkorbak/pile-detoxify","creator_name":"Tomek Korbak","creator_url":"https://huggingface.co/tomekkorbak","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","other","acceptability-classification","hate-speech-detection","text-scoring"],"keywords_longer_than_N":true},
	{"name":"dv-presidential-speech","keyword":"text-to-speech","description":"Dhivehi Presidential Speech is a Dhivehi speech dataset created from data extracted and \nprocessed by [Sofwath](https://github.com/Sofwath) as part of a collection of Dhivehi \ndatasets found [here](https://github.com/Sofwath/DhivehiDatasets).\n\nThe dataset contains around 2.5 hrs (1 GB) of speech collected from Maldives President's Office\nconsisting of 7 speeches given by President Yaameen Abdhul Gayyoom.","url":"https://huggingface.co/datasets/dash8x/dv-presidential-speech","creator_name":"Arushad Ahmed","creator_url":"https://huggingface.co/dash8x","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Divehi","apache-2.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"rir-noise","keyword":"automatic-speech-recognition","description":"nabbra/rir-noise dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/nabbra/rir-noise","creator_name":"Nabbra","creator_url":"https://huggingface.co/nabbra","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"AlbanianSpeech","keyword":"text-to-speech","description":"Yakidev/AlbanianSpeech dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Yakidev/AlbanianSpeech","creator_name":"Trust Oriakhi","creator_url":"https://huggingface.co/Yakidev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Albanian","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"cmu-arctic-xvectors","keyword":"text-to-speech","description":"The CMU ARCTIC dataset without needing to run remote code, so it is compatible with datasets >= 4.0.0.\n","url":"https://huggingface.co/datasets/regisss/cmu-arctic-xvectors","creator_name":"R√©gis Pierrard","creator_url":"https://huggingface.co/regisss","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MyspeechASR","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for librispeech_asr\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been carefully segmented and aligned.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nautomatic-speech-recognition, audio-speaker-identification: The dataset can be used to train a model for Automatic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sidd2899/MyspeechASR.","url":"https://huggingface.co/datasets/Sidd2899/MyspeechASR","creator_name":"Siddhant Kadam","creator_url":"https://huggingface.co/Sidd2899","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"audio_letters_eo","keyword":"automatic-speech-recognition","description":"Audio files sampled at 48000Hz of an American male pronouncing the names of the Esperanto letters in three ways. Retroflex-r and trilled-r are included.\n","url":"https://huggingface.co/datasets/xekri/audio_letters_eo","creator_name":"Xekri Dragon","creator_url":"https://huggingface.co/xekri","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Esperanto","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"isixhosa-asr","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tisiXhosa Speech Recognition Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains speech recordings and transcriptions for isiXhosa, one of South Africa's official languages.\nThe dataset has been optimized for use with OpenAI's Whisper ASR models.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nNumber of samples: 789\nLanguage: isiXhosa (Xho)\nAudio format: WAV, 16kHz, mono, 16-bit\nMaximum duration: 30 seconds (truncated for Whisper compatibility)\nTranscription format: Cleaned text (lowercase‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zionia/isixhosa-asr.","url":"https://huggingface.co/datasets/zionia/isixhosa-asr","creator_name":"Zion van Wyk","creator_url":"https://huggingface.co/zionia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Zulu","Xhosa","Southern Ndebele","Pedi"],"keywords_longer_than_N":true},
	{"name":"isizulu-asr","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tisiZulu Speech Recognition Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains speech recordings and transcriptions for isiZulu, one of South Africa's official languages.\nThe dataset has been optimized for use with OpenAI's Whisper ASR models.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nNumber of samples: 699\nLanguage: isiZulu (Zul)\nAudio format: WAV, 16kHz, mono, 16-bit\nMaximum duration: 30 seconds (truncated for Whisper compatibility)\nTranscription format: Cleaned text (lowercase, no‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zionia/isizulu-asr.","url":"https://huggingface.co/datasets/zionia/isizulu-asr","creator_name":"Zion van Wyk","creator_url":"https://huggingface.co/zionia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Zulu","Xhosa","Southern Ndebele","Pedi"],"keywords_longer_than_N":true},
	{"name":"genshin_ch_10npc","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for \"genshin_ch_10npc\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/xmj2002/genshin_ch_10npc","creator_name":"xmj","creator_url":"https://huggingface.co/xmj2002","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Chinese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"twi-trigrams-speech-text-parallel","keyword":"speech","description":"\n\t\n\t\t\n\t\tTwi Trigrams Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 166156 parallel speech-text pairs for Twi, a language spoken primarily in Ghana. The dataset consists of audio recordings of trigram segments (3-word sequences) paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi - twi\nTask: Speech Recognition, Text-to-Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-trigrams-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/twi-trigrams-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"mucs","keyword":"speech","description":"\n\t\n\t\t\n\t\tMucs\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3,843 samples organized across multiple splits.\nThe dataset includes audio data.\n\n\t\n\t\t\n\t\tSplits\n\t\n\n\ntrain: 3,074 samples\ntest: 769 samples\n\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset was created using StreamableDatasetManager on 2025-10-16T12:45:15.159031.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThe dataset includes the following columns:\n\nid: Int64 data\ntext: String data\nlabel: Int64 data\naudio: Audio data (16kHz sampling rate)\nmd5_audio:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AdityK2409/mucs.","url":"https://huggingface.co/datasets/AdityK2409/mucs","creator_name":"Aditya Kapoor","creator_url":"https://huggingface.co/AdityK2409","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"twi-trigrams-speech-text-parallel","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTwi Trigrams Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 166156 parallel speech-text pairs for Twi, a language spoken primarily in Ghana. The dataset consists of audio recordings of trigram segments (3-word sequences) paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi - twi\nTask: Speech Recognition, Text-to-Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-trigrams-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/twi-trigrams-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"mucs","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tMucs\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3,843 samples organized across multiple splits.\nThe dataset includes audio data.\n\n\t\n\t\t\n\t\tSplits\n\t\n\n\ntrain: 3,074 samples\ntest: 769 samples\n\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset was created using StreamableDatasetManager on 2025-10-16T12:45:15.159031.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThe dataset includes the following columns:\n\nid: Int64 data\ntext: String data\nlabel: Int64 data\naudio: Audio data (16kHz sampling rate)\nmd5_audio:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AdityK2409/mucs.","url":"https://huggingface.co/datasets/AdityK2409/mucs","creator_name":"Aditya Kapoor","creator_url":"https://huggingface.co/AdityK2409","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"twi-trigrams-speech-text-parallel","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tTwi Trigrams Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 166156 parallel speech-text pairs for Twi, a language spoken primarily in Ghana. The dataset consists of audio recordings of trigram segments (3-word sequences) paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi - twi\nTask: Speech Recognition, Text-to-Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-trigrams-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/twi-trigrams-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"mucs","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tMucs\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3,843 samples organized across multiple splits.\nThe dataset includes audio data.\n\n\t\n\t\t\n\t\tSplits\n\t\n\n\ntrain: 3,074 samples\ntest: 769 samples\n\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset was created using StreamableDatasetManager on 2025-10-16T12:45:15.159031.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThe dataset includes the following columns:\n\nid: Int64 data\ntext: String data\nlabel: Int64 data\naudio: Audio data (16kHz sampling rate)\nmd5_audio:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AdityK2409/mucs.","url":"https://huggingface.co/datasets/AdityK2409/mucs","creator_name":"Aditya Kapoor","creator_url":"https://huggingface.co/AdityK2409","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"pawol-la-pale","keyword":"speech","description":"\n\t\n\t\t\n\t\tAudio Dataset\n\t\n\nThis dataset contains audio segments with transcriptions for speech recognition and text-to-speech tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\ndataset.json: Complete dataset in JSON format\ntrain.jsonl: Dataset in JSONL format for use with Hugging Face datasets library\ndataset_info.json: Metadata about the dataset structure\n\nEach entry contains:\n\nfile: Original filename\naudio: Audio data with sampling rate\ntranscription: Text transcription\nduration: Audio duration in seconds\n\n","url":"https://huggingface.co/datasets/jsbeaudry/pawol-la-pale","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"pawol-la-pale","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tAudio Dataset\n\t\n\nThis dataset contains audio segments with transcriptions for speech recognition and text-to-speech tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\ndataset.json: Complete dataset in JSON format\ntrain.jsonl: Dataset in JSONL format for use with Hugging Face datasets library\ndataset_info.json: Metadata about the dataset structure\n\nEach entry contains:\n\nfile: Original filename\naudio: Audio data with sampling rate\ntranscription: Text transcription\nduration: Audio duration in seconds\n\n","url":"https://huggingface.co/datasets/jsbeaudry/pawol-la-pale","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"nota","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Nota\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis data was created by the public institution Nota, which is part of the Danish Ministry of Culture. Nota has a library audiobooks and audiomagazines for people with reading or sight disabilities. Nota also produces a number of audiobooks and audiomagazines themselves.  \nThe dataset consists of audio and associated transcriptions from Nota's audiomagazines \"Inspiration\" and \"Radio/TV\". All files related to one reading of one edition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/nota.","url":"https://huggingface.co/datasets/alexandrainst/nota","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Danish","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"czech_parliament_plenary_hearings","keyword":"automatic-speech-recognition","description":"jkot/czech_parliament_plenary_hearings dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/jkot/czech_parliament_plenary_hearings","creator_name":"Josef Kotoun","creator_url":"https://huggingface.co/jkot","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Czech","cc-by-4.0","10B<n<100B","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"mls_eng_10k","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls_eng_10k.","url":"https://huggingface.co/datasets/parler-tts/mls_eng_10k","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"pawol-la-pale","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tAudio Dataset\n\t\n\nThis dataset contains audio segments with transcriptions for speech recognition and text-to-speech tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\ndataset.json: Complete dataset in JSON format\ntrain.jsonl: Dataset in JSONL format for use with Hugging Face datasets library\ndataset_info.json: Metadata about the dataset structure\n\nEach entry contains:\n\nfile: Original filename\naudio: Audio data with sampling rate\ntranscription: Text transcription\nduration: Audio duration in seconds\n\n","url":"https://huggingface.co/datasets/jsbeaudry/pawol-la-pale","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"nota","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Nota\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis data was created by the public institution Nota, which is part of the Danish Ministry of Culture. Nota has a library audiobooks and audiomagazines for people with reading or sight disabilities. Nota also produces a number of audiobooks and audiomagazines themselves.  \nThe dataset consists of audio and associated transcriptions from Nota's audiomagazines \"Inspiration\" and \"Radio/TV\". All files related to one reading of one edition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/nota.","url":"https://huggingface.co/datasets/alexandrainst/nota","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Danish","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"mls_eng_10k","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls_eng_10k.","url":"https://huggingface.co/datasets/parler-tts/mls_eng_10k","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mls-eng-10k-tags_tagged_10k_generated","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of 10K hours of English MLS\n\t\n\nThis dataset consists in annotations of a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls-eng-10k-tags_tagged_10k_generated.","url":"https://huggingface.co/datasets/parler-tts/mls-eng-10k-tags_tagged_10k_generated","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mls-eng-10k-tags_tagged_10k_generated","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of 10K hours of English MLS\n\t\n\nThis dataset consists in annotations of a 10K hours subset of English version of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls-eng-10k-tags_tagged_10k_generated.","url":"https://huggingface.co/datasets/parler-tts/mls-eng-10k-tags_tagged_10k_generated","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"vistaar_small_asr_eval","keyword":"speech","description":"\n\t\n\t\t\n\t\tVistaar Small ASR Eval\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Vistaar Small ASR Eval dataset is a multilingual automatic speech recognition evaluation dataset containing 9,486 audio samples across 12 Indian languages. This dataset represents a subset of the larger Vistaar dataset published by AI4Bharat, designed specifically for evaluating ASR model performance on diverse Indian language speech data. A smaller evaluation dataset was created for the use-cases where a quick benchmarking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ekacare/vistaar_small_asr_eval.","url":"https://huggingface.co/datasets/ekacare/vistaar_small_asr_eval","creator_name":"Eka Care","creator_url":"https://huggingface.co/ekacare","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"vistaar_small_asr_eval","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tVistaar Small ASR Eval\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Vistaar Small ASR Eval dataset is a multilingual automatic speech recognition evaluation dataset containing 9,486 audio samples across 12 Indian languages. This dataset represents a subset of the larger Vistaar dataset published by AI4Bharat, designed specifically for evaluating ASR model performance on diverse Indian language speech data. A smaller evaluation dataset was created for the use-cases where a quick benchmarking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ekacare/vistaar_small_asr_eval.","url":"https://huggingface.co/datasets/ekacare/vistaar_small_asr_eval","creator_name":"Eka Care","creator_url":"https://huggingface.co/ekacare","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"vistaar_small_asr_eval","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tVistaar Small ASR Eval\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Vistaar Small ASR Eval dataset is a multilingual automatic speech recognition evaluation dataset containing 9,486 audio samples across 12 Indian languages. This dataset represents a subset of the larger Vistaar dataset published by AI4Bharat, designed specifically for evaluating ASR model performance on diverse Indian language speech data. A smaller evaluation dataset was created for the use-cases where a quick benchmarking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ekacare/vistaar_small_asr_eval.","url":"https://huggingface.co/datasets/ekacare/vistaar_small_asr_eval","creator_name":"Eka Care","creator_url":"https://huggingface.co/ekacare","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"synthetic-multilingual-speaker-diarization","keyword":"speech","description":"\n\t\n\t\t\n\t\tMultilingual Speaker Diarization Dataset\n\t\n\nThis dataset contains synthetic multilingual speaker diarization data with Hindi, English, and Punjabi audio samples.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n‚îú‚îÄ‚îÄ audio/           # WAV audio files (16kHz) - 627 files\n‚îú‚îÄ‚îÄ csv/            # Individual CSV annotations - 627 files\n‚îú‚îÄ‚îÄ rttm/           # RTTM format files for diarization - 627 files\n‚îú‚îÄ‚îÄ all_samples_combined.csv  # Complete dataset annotations\n‚îî‚îÄ‚îÄ all_samples_combined.rttm # Complete RTTM‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/noty7gian/synthetic-multilingual-speaker-diarization.","url":"https://huggingface.co/datasets/noty7gian/synthetic-multilingual-speaker-diarization","creator_name":"Saksham Bansal","creator_url":"https://huggingface.co/noty7gian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","Hindi","English","Panjabi"],"keywords_longer_than_N":true},
	{"name":"mile_dataset","keyword":"automatic-speech-recognition","description":"IISc-MILE Tamil ASR Corpus contains transcribed speech corpus for training ASR systems for Tamil language. It contains ~150 hours of read speech data collected from 531 speakers in a noise-free recording environment with high quality USB microphones.","url":"https://huggingface.co/datasets/parambharat/mile_dataset","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"synthetic-multilingual-speaker-diarization","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tMultilingual Speaker Diarization Dataset\n\t\n\nThis dataset contains synthetic multilingual speaker diarization data with Hindi, English, and Punjabi audio samples.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n‚îú‚îÄ‚îÄ audio/           # WAV audio files (16kHz) - 627 files\n‚îú‚îÄ‚îÄ csv/            # Individual CSV annotations - 627 files\n‚îú‚îÄ‚îÄ rttm/           # RTTM format files for diarization - 627 files\n‚îú‚îÄ‚îÄ all_samples_combined.csv  # Complete dataset annotations\n‚îî‚îÄ‚îÄ all_samples_combined.rttm # Complete RTTM‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/noty7gian/synthetic-multilingual-speaker-diarization.","url":"https://huggingface.co/datasets/noty7gian/synthetic-multilingual-speaker-diarization","creator_name":"Saksham Bansal","creator_url":"https://huggingface.co/noty7gian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","Hindi","English","Panjabi"],"keywords_longer_than_N":true},
	{"name":"kannada_asr_corpus","keyword":"automatic-speech-recognition","description":"The corpus contains roughly 360 hours of audio and transcripts in Kannada language. The transcripts have beed de-duplicated using exact match deduplication.","url":"https://huggingface.co/datasets/parambharat/kannada_asr_corpus","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","extended|openslr"],"keywords_longer_than_N":true},
	{"name":"sharif_emotional_speech_dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSharif Emotional Speech Dataset (ShEMO)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset includes 3000 semi-natural utterances, equivalent to 3 hours and 25 minutes of speech data extracted from online Persian radio plays. The ShEMO covers speech samples of 87 native-Persian speakers for five basic emotions including anger, fear, happiness, sadness and surprise, as well as neutral state. Twelve annotators label the underlying emotional state of utterances and majority voting is used to decide‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pariajm/sharif_emotional_speech_dataset.","url":"https://huggingface.co/datasets/pariajm/sharif_emotional_speech_dataset","creator_name":"Paria Jamshid Lou","creator_url":"https://huggingface.co/pariajm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","expert-generated","monolingual","radio-plays"],"keywords_longer_than_N":true},
	{"name":"audio_vreme","keyword":"automatic-speech-recognition","description":"iulik-pisik/audio_vreme dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/iulik-pisik/audio_vreme","creator_name":"Iulia Udrea","creator_url":"https://huggingface.co/iulik-pisik","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Romanian","apache-2.0","üá∫üá∏ Region: US","climate"],"keywords_longer_than_N":false},
	{"name":"test-esp","keyword":"speech","description":"\n\t\n\t\t\n\t\tMulti-Domain Spanish Speech Dataset\n\t\n\nThis dataset contains 1 audio recordings with corresponding text transcriptions across multiple languages and domains.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA comprehensive collection of audio files paired with text transcriptions, featuring both synthetic and natural speech across various domains. Suitable for automatic speech recognition (ASR), text-to-speech (TTS), and domain-specific speech processing tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jsbeaudry/test-esp.","url":"https://huggingface.co/datasets/jsbeaudry/test-esp","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Spanish","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"test-esp","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tMulti-Domain Spanish Speech Dataset\n\t\n\nThis dataset contains 1 audio recordings with corresponding text transcriptions across multiple languages and domains.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA comprehensive collection of audio files paired with text transcriptions, featuring both synthetic and natural speech across various domains. Suitable for automatic speech recognition (ASR), text-to-speech (TTS), and domain-specific speech processing tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jsbeaudry/test-esp.","url":"https://huggingface.co/datasets/jsbeaudry/test-esp","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Spanish","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"quantized-librispeech-train-360","keyword":"automatic-speech-recognition","description":"theblackcat102/quantized-librispeech-train-360 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/theblackcat102/quantized-librispeech-train-360","creator_name":"theblackcat102","creator_url":"https://huggingface.co/theblackcat102","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"voxpopuli-timestamped","keyword":"automatic-speech-recognition","description":"A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation.","url":"https://huggingface.co/datasets/distil-whisper/voxpopuli-timestamped","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc0-1.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Cylonix_ASR_dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tKoddaDuck/Cylonix_ASR_dataset\n\t\n\n","url":"https://huggingface.co/datasets/KoddaDuck/Cylonix_ASR_dataset","creator_name":"Haodong Huang","creator_url":"https://huggingface.co/KoddaDuck","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"nota","keyword":"automatic-speech-recognition","description":"Nota lyd- og tekstdata\nDatas√¶ttet indeholder b√•de tekst- og taledata fra udvalgte dele af Nota's lydbogsbiblotek. Datas√¶ttet best√•r af \nover 500 timers opl√¶sninger og medf√∏lgende transkriptioner p√• dansk. Al lyddata er i .wav-format, mens tekstdata \ner i .txt-format.\n\nI data indg√•r indl√¶sninger af Notas eget blad \"Inspiration\" og \"Radio/TV\", som er udgivet i perioden 2007 til 2022.\nNota krediteres for arbejdet med at strukturere data, s√•ledes at tekst og lyd stemmer overens.\n\nNota er en institution under Kulturministeriet, der g√∏r trykte tekster tilg√¶ngelige i digitale formater til personer \nmed synshandicap og l√¶sevanskeligheder, fx via produktion af lydb√∏ger og opl√¶sning af aviser, magasiner, mv.","url":"https://huggingface.co/datasets/arpelarpe/nota","creator_name":"Rasmus Arpe Fogh Egeb√¶k","creator_url":"https://huggingface.co/arpelarpe","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","Danish","cc0-1.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"test-esp","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tMulti-Domain Spanish Speech Dataset\n\t\n\nThis dataset contains 1 audio recordings with corresponding text transcriptions across multiple languages and domains.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA comprehensive collection of audio files paired with text transcriptions, featuring both synthetic and natural speech across various domains. Suitable for automatic speech recognition (ASR), text-to-speech (TTS), and domain-specific speech processing tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jsbeaudry/test-esp.","url":"https://huggingface.co/datasets/jsbeaudry/test-esp","creator_name":"Jean Sauvenel Beaudry","creator_url":"https://huggingface.co/jsbeaudry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Spanish","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"TikTok_MostComment_Video_Transcription_Example","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tüì≤ Example Dataset: TikTok Scraper Tool\n\t\n\nüëâ Start Scraping TikTok: TikTok Scraper Tool\n\n\t\n\t\t\n\t\t‚ú® Key Features\n\t\n\n\n‚ö° Instant Transcription ‚Äì Turn any TikTok video into an AI-ready transcript  \nüéØ Metadata ‚Äì Get the title, language description, and video hashtags  \nüîó URL-Based Access ‚Äì Just drop in a TikTok video URL to start scraping  \nüß© LLM-Ready Output ‚Äì Receive clean JSON ready for agents, RAG, or AI tools  \nüí∏ Free Tier ‚Äì Use up to 100 queries during the beta period  \nüí´ Easy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/TikTok_MostComment_Video_Transcription_Example.","url":"https://huggingface.co/datasets/Gopher-Lab/TikTok_MostComment_Video_Transcription_Example","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","feature-extraction","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"tr-combined","keyword":"speech","description":"\n\t\n\t\t\n\t\tTr_combined\n\t\n\nThis is a merged speech dataset containing 221531 audio segments from 894 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 221531\nSpeakers: 2158\nLanguages: tr\nEmotions: happy, angry, neutral, sad\nOriginal Datasets: 894\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nlanguage:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/tr-combined.","url":"https://huggingface.co/datasets/Codyfederer/tr-combined","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"tr-combined","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTr_combined\n\t\n\nThis is a merged speech dataset containing 221531 audio segments from 894 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 221531\nSpeakers: 2158\nLanguages: tr\nEmotions: happy, angry, neutral, sad\nOriginal Datasets: 894\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nlanguage:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/tr-combined.","url":"https://huggingface.co/datasets/Codyfederer/tr-combined","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"ami-sdm-timestamped","keyword":"automatic-speech-recognition","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\nnon-native speakers. \\n","url":"https://huggingface.co/datasets/distil-whisper/ami-sdm-timestamped","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"tr-combined","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tTr_combined\n\t\n\nThis is a merged speech dataset containing 221531 audio segments from 894 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 221531\nSpeakers: 2158\nLanguages: tr\nEmotions: happy, angry, neutral, sad\nOriginal Datasets: 894\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nlanguage:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/tr-combined.","url":"https://huggingface.co/datasets/Codyfederer/tr-combined","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"atco2_only_augmented","keyword":"automatic-speech-recognition","description":"luigisaetta/atco2_only_augmented dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/luigisaetta/atco2_only_augmented","creator_name":"LuigiSaetta","creator_url":"https://huggingface.co/luigisaetta","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"SqCLIRIL","keyword":"speech","description":"\n\t\n\t\t\n\t\tüó£Ô∏è SqCLIRIL: Spoken Query Benchmark for Cross-Lingual IR in Indian Languages\n\t\n\nSqCLIRIL is a Spoken Query Benchmark designed to evaluate cross-lingual information retrieval (CLIR) systems using both spoken and text queries.It covers five Indian languages ‚Äî Hindi, Gujarati, Bengali, Kannada, and English ‚Äî with diverse speech samples from male and female speakers to capture natural variability in pronunciation and acoustic conditions.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìò Dataset Summary\n\t\n\n\n\t\n\t\t\nFeature‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/irlab-daiict/SqCLIRIL.","url":"https://huggingface.co/datasets/irlab-daiict/SqCLIRIL","creator_name":"IRLAB","creator_url":"https://huggingface.co/irlab-daiict","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-retrieval","Hindi","Gujarati","Bengali"],"keywords_longer_than_N":true},
	{"name":"SqCLIRIL","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tüó£Ô∏è SqCLIRIL: Spoken Query Benchmark for Cross-Lingual IR in Indian Languages\n\t\n\nSqCLIRIL is a Spoken Query Benchmark designed to evaluate cross-lingual information retrieval (CLIR) systems using both spoken and text queries.It covers five Indian languages ‚Äî Hindi, Gujarati, Bengali, Kannada, and English ‚Äî with diverse speech samples from male and female speakers to capture natural variability in pronunciation and acoustic conditions.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìò Dataset Summary\n\t\n\n\n\t\n\t\t\nFeature‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/irlab-daiict/SqCLIRIL.","url":"https://huggingface.co/datasets/irlab-daiict/SqCLIRIL","creator_name":"IRLAB","creator_url":"https://huggingface.co/irlab-daiict","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-retrieval","Hindi","Gujarati","Bengali"],"keywords_longer_than_N":true},
	{"name":"ro-fb-offense","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-FB-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFB-RO-Offense corpus, an offensive speech dataset containing 4,455 user-generated comments from Facebook live broadcasts available in Romanian\nThe annotation follows the hierarchical tagset proposed in the Germeval 2018 Dataset. \nThe following Classes are available:\n\nOTHER: Non-Offensive Language\nOFFENSIVE:\nPROFANITY\nINSULT\nABUSE\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-fb-offense.","url":"https://huggingface.co/datasets/readerbench/ro-fb-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ro-fb-offense","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-FB-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFB-RO-Offense corpus, an offensive speech dataset containing 4,455 user-generated comments from Facebook live broadcasts available in Romanian\nThe annotation follows the hierarchical tagset proposed in the Germeval 2018 Dataset. \nThe following Classes are available:\n\nOTHER: Non-Offensive Language\nOFFENSIVE:\nPROFANITY\nINSULT\nABUSE\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-fb-offense.","url":"https://huggingface.co/datasets/readerbench/ro-fb-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"peoples_speech-dirty","keyword":"automatic-speech-recognition","description":"The People's Speech is a free-to-download 30,000-hour and growing supervised \nconversational English speech recognition dataset licensed for academic and \ncommercial usage under CC-BY-SA (with a CC-BY subset).","url":"https://huggingface.co/datasets/distil-whisper/peoples_speech-dirty","creator_name":"Whisper Distillation","creator_url":"https://huggingface.co/distil-whisper","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"WolBanking77","keyword":"automatic-speech-recognition","description":"Intent classification models have made a lot of progress in recent years. However, previous studies primarily focus on high-resource languages datasets, which results in a gap for low-resource languages and for regions with a high rate of illiterate people where languages are more spoken than read or written. This is the case in Senegal, for example, where Wolof is spoken by around 90% of the population, with an illiteracy rate of 42% for the country. Wolof is actually spoken by more than 10‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/karim155/WolBanking77.","url":"https://huggingface.co/datasets/karim155/WolBanking77","creator_name":"Abdou Karim KANDJI","creator_url":"https://huggingface.co/karim155","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","automatic-speech-recognition","translation","Wolof","French"],"keywords_longer_than_N":true},
	{"name":"work","keyword":"speech","description":"\n\t\n\t\t\n\t\tFine-tuned XLSR-53 large model for speech recognition in Japanese\n\t\n\nFine-tuned facebook/wav2vec2-large-xlsr-53 on Japanese using the train and validation splits of Common Voice 6.1, CSS10 and JSUT.\nWhen using this model, make sure that your speech input is sampled at 16kHz.\nThis model has been fine-tuned thanks to the GPU credits generously given by the OVHcloud :)\nThe script used for training can be found here: https://github.com/jonatasgrosman/wav2vec2-sprint\n\t\n\t\t\n\t\tUsage\n\t\n\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gustav114514/work.","url":"https://huggingface.co/datasets/Gustav114514/work","creator_name":"Ryohei Kasai","creator_url":"https://huggingface.co/Gustav114514","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Japanese","apache-2.0","Audio","üá∫üá∏ Region: US","audio"],"keywords_longer_than_N":true},
	{"name":"work","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tFine-tuned XLSR-53 large model for speech recognition in Japanese\n\t\n\nFine-tuned facebook/wav2vec2-large-xlsr-53 on Japanese using the train and validation splits of Common Voice 6.1, CSS10 and JSUT.\nWhen using this model, make sure that your speech input is sampled at 16kHz.\nThis model has been fine-tuned thanks to the GPU credits generously given by the OVHcloud :)\nThe script used for training can be found here: https://github.com/jonatasgrosman/wav2vec2-sprint\n\t\n\t\t\n\t\tUsage\n\t\n\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gustav114514/work.","url":"https://huggingface.co/datasets/Gustav114514/work","creator_name":"Ryohei Kasai","creator_url":"https://huggingface.co/Gustav114514","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Japanese","apache-2.0","Audio","üá∫üá∏ Region: US","audio"],"keywords_longer_than_N":true},
	{"name":"librispeech-alignments","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Librispeech Alignments\n\t\n\nLibrispeech with alignments generated by the Montreal Forced Aligner. The original alignments in TextGrid format can be found here\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLibrispeech is a corpus of read English speech, designed for training and evaluating automatic speech recognition (ASR) systems. The dataset contains 1000 hours of 16kHz read English speech derived from audiobooks.\nThe Montreal Forced Aligner (MFA) was used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gilkeyio/librispeech-alignments.","url":"https://huggingface.co/datasets/gilkeyio/librispeech-alignments","creator_name":"Kim Gilkey","creator_url":"https://huggingface.co/gilkeyio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"tamil_asr_corpus","keyword":"automatic-speech-recognition","description":"The corpus contains roughly 1000 hours of audio and trasncripts in Tamil language. The transcripts have beedn de-duplicated using exact match deduplication.","url":"https://huggingface.co/datasets/parambharat/tamil_asr_corpus","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"CommonPhoneDataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tDataset Card for Common Phone\n\t\n\nThis corpus aims to provide a basis for Machine Learning (ML) researchers and enthusiasts to train and test their models against a wide variety of speakers, hardware/software ecosystems and acoustic conditions to improve generalization and availability of ML in real-world speech applications.\nThe current version of Common Phone comprises 116,5 hours of speech samples, collected from 11.246 speakers in 6 languages.\nCommon Phone has been used as the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pklumpp/CommonPhoneDataset.","url":"https://huggingface.co/datasets/pklumpp/CommonPhoneDataset","creator_name":"Philipp Klumpp","creator_url":"https://huggingface.co/pklumpp","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","German","French","Italian"],"keywords_longer_than_N":true},
	{"name":"KikuyuASR_trainingdataset","keyword":"automatic-speech-recognition","description":"This dataset is obtained as part of AIEP prject by Digital Green and Karya from the extension workers, lead farmers and farmers.\nProcess of collection of data:\nSelected users were given the option of doing a task and getting paid for it.\nThe users were supposed to record the sentence as it appeared on the screen.\nThe audio file thus obtained was validated matched with the sentences to fine tune the model.\nAlso available are the python script that helps in processing and splitting the data into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DigiGreen/KikuyuASR_trainingdataset.","url":"https://huggingface.co/datasets/DigiGreen/KikuyuASR_trainingdataset","creator_name":"Digital Green","creator_url":"https://huggingface.co/DigiGreen","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kikuyu","apache-2.0","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"nchlt_speech_sot","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tNCHLT Speech Corpus -- Sesotho\n\t\n\nThis is the Sesotho language part of the NCHLT Speech Corpus of the South African languages.\nLanguage code (ISO 639): sot\nURI: https://hdl.handle.net/20.500.12185/278\n\n\t\n\t\t\n\t\tLicence:\n\t\n\nCreative Commons Attribution 3.0 Unported License (CC BY 3.0): http://creativecommons.org/licenses/by/3.0/legalcode\n\n\t\n\t\t\n\t\tAttribution:\n\t\n\nThe Department of Arts and Culture of the government of the Republic of South Africa (DAC), Council for Scientific and Industrial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/danielshaps/nchlt_speech_sot.","url":"https://huggingface.co/datasets/danielshaps/nchlt_speech_sot","creator_name":"Daniel van Niekerk","creator_url":"https://huggingface.co/danielshaps","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Southern Sotho","cc-by-3.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"CommonPhoneDataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Common Phone\n\t\n\nThis corpus aims to provide a basis for Machine Learning (ML) researchers and enthusiasts to train and test their models against a wide variety of speakers, hardware/software ecosystems and acoustic conditions to improve generalization and availability of ML in real-world speech applications.\nThe current version of Common Phone comprises 116,5 hours of speech samples, collected from 11.246 speakers in 6 languages.\nCommon Phone has been used as the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pklumpp/CommonPhoneDataset.","url":"https://huggingface.co/datasets/pklumpp/CommonPhoneDataset","creator_name":"Philipp Klumpp","creator_url":"https://huggingface.co/pklumpp","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","German","French","Italian"],"keywords_longer_than_N":true},
	{"name":"babelbox_voice","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Babelbox Voice\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis database was created by Nordic Language Technology for the development of automatic speech recognition and dictation in Swedish. \nIt is redistributed as a Hugging Face dataset for convienience.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nSwedish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/babelbox/babelbox_voice.","url":"https://huggingface.co/datasets/babelbox/babelbox_voice","creator_name":"BabelBox","creator_url":"https://huggingface.co/babelbox","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","Swedish"],"keywords_longer_than_N":true},
	{"name":"voxpopolo_2","keyword":"automatic-speech-recognition","description":"A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation.","url":"https://huggingface.co/datasets/mcapozi/voxpopolo_2","creator_name":"Matteo Capozi","creator_url":"https://huggingface.co/mcapozi","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","multilingual","English","German","French"],"keywords_longer_than_N":true},
	{"name":"speech-pa","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for \"speech-pa\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/aipanjab/speech-pa","creator_name":"AI Panjab","creator_url":"https://huggingface.co/aipanjab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Panjabi","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"korean-voice-emotion-dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tKorean Voice Emotion Dataset\n\t\n\n*This dataset contains high-quality (‚ÄúA-grade‚Äù) data. It has been carefully curated, cleaned, and verified to ensure accuracy, completeness, and consistency, making it suitable for high-stakes or production-grade model training.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset comprises high-quality Korean speech recordings designed for training and evaluating Speech Emotion Recognition (SER) models. The dataset contains voice samples expressing four distinct‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/korean-voice-emotion-dataset.","url":"https://huggingface.co/datasets/Kratos-AI/korean-voice-emotion-dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Korean","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Fleurs-Kn","keyword":"automatic-speech-recognition","description":"This is a filtered version of the Fleurs dataset only containing samples of Kannada language.\nThe dataset contains total of 2283 training, 368 validation and 838 test samples.\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'id': 1053,\n 'num_samples': 226560,\n 'path': '/home/ravi.naik/.cache/huggingface/datasets/downloads/extracted/e7c8b501d4e6892673b6dc291d42de48e7987b0d2aa6471066a671f686224ed1/10000267636955490843.wav',\n 'audio': {'path': 'train/10000267636955490843.wav',\n  'array': array([ 0.        ,  0.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kannada-LLM-Labs/Fleurs-Kn.","url":"https://huggingface.co/datasets/Kannada-LLM-Labs/Fleurs-Kn","creator_name":"Kannada LLM Labs","creator_url":"https://huggingface.co/Kannada-LLM-Labs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Vulpisfoglia","keyword":"text-to-speech","description":"None1145/Vulpisfoglia dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/None1145/Vulpisfoglia","creator_name":"None","creator_url":"https://huggingface.co/None1145","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","Italian"],"keywords_longer_than_N":true},
	{"name":"vais1000","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tunofficial mirror of VAIS-1000\n\t\n\nofficial announcement: https://vais.vn/vi/tai-ve/hts_for_vietnamese (dead)\nmirror: https://github.com/undertheseanlp/text_to_speech/tree/run/data/vais1000/raw\nsmall only 1h40min audio - 1 speaker (female northern accent) - 1k samples\npre-process: none\nneed to do: check misspelling, restore foreign words phonetised to vietnamese\nusage with HuggingFace:\n# pip install -q \"datasets[audio]\"\nfrom datasets import load_dataset\nfrom torch.utils.data import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/vais1000.","url":"https://huggingface.co/datasets/doof-ferb/vais1000","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"TTS_eval_datasets","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tTTS evaluation datasets\n\t\n\nThis repository contains three testsets for zero-shot TTS models:\n\ndialog_testset: Chinese and English testsets for spoken dialogue generation models, introduced in paper ZipVoice-Dialog.\nlibrispeech_pc_testset: English testset for zero-shot TTS models, introduced in paper F5-TTS.\nseedtts_testset: Chinese and English testsets for zero-shot TTS models, introduced in paper Seed-TTS.\n\n","url":"https://huggingface.co/datasets/k2-fsa/TTS_eval_datasets","creator_name":"k2-fsa","creator_url":"https://huggingface.co/k2-fsa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Chinese","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"vais1000","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tunofficial mirror of VAIS-1000\n\t\n\nofficial announcement: https://vais.vn/vi/tai-ve/hts_for_vietnamese (dead)\nmirror: https://github.com/undertheseanlp/text_to_speech/tree/run/data/vais1000/raw\nsmall only 1h40min audio - 1 speaker (female northern accent) - 1k samples\npre-process: none\nneed to do: check misspelling, restore foreign words phonetised to vietnamese\nusage with HuggingFace:\n# pip install -q \"datasets[audio]\"\nfrom datasets import load_dataset\nfrom torch.utils.data import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/vais1000.","url":"https://huggingface.co/datasets/doof-ferb/vais1000","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"twi-words-speech-text-parallel","keyword":"speech","description":"\n\t\n\t\t\n\t\tTwi Words Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 413463 parallel speech-text pairs for Twi (Akan), a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi (Akan) - tw\nTask: Speech Recognition, Text-to-Speech\nSize: 413463 audio files >‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-words-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/twi-words-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"twi-words-speech-text-parallel","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTwi Words Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 413463 parallel speech-text pairs for Twi (Akan), a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi (Akan) - tw\nTask: Speech Recognition, Text-to-Speech\nSize: 413463 audio files >‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-words-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/twi-words-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"Tuda-De","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tOpen speech data for German speech recognition\n\t\n\nLanguage Technology, Universit√§t Hamburg, Germany\nhttps://www.inf.uni-hamburg.de/en/inst/ab/lt (formerly TU-Darmstadt)\nhttps://www.lt.tu-darmstadt.de\nTelecooperation labs, TU-Darmstadt, Germany\nhttps://www.tk.informatik.tu-darmstadt.de\n\n\t\n\t\t\n\t\n\t\n\t\tGeneral information\n\t\n\n\nThe speech data was collected in a controlled environment (same room, same microphone distances, etc. )\nDistance between speakers and the microphones is about 1 meter‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/uhhlt/Tuda-De.","url":"https://huggingface.co/datasets/uhhlt/Tuda-De","creator_name":"LT Group at UHH","creator_url":"https://huggingface.co/uhhlt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"twi-words-speech-text-parallel","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tTwi Words Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 413463 parallel speech-text pairs for Twi (Akan), a language spoken primarily in Ghana. The dataset consists of audio recordings paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Twi (Akan) - tw\nTask: Speech Recognition, Text-to-Speech\nSize: 413463 audio files >‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-words-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/twi-words-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Twi"],"keywords_longer_than_N":true},
	{"name":"raw_1hr_myanmar_asr_audio","keyword":"speech","description":"\n\t\n\t\t\n\t\tüá≤üá≤ Raw 1-Hour Burmese ASR Audio Dataset\n\t\n\nA 1-hour dataset of Burmese (Myanmar language) spoken audio clips with transcripts, curated from official public-service media broadcasts by PVTV Myanmar ‚Äî the media voice of Myanmar‚Äôs National Unity Government (NUG).\nThis dataset is intended for automatic speech recognition (ASR) and Burmese speech-processing research.\n‚û°Ô∏è Author: freococo‚û°Ô∏è License: MIT‚û°Ô∏è Language: Burmese (my)\n\n\n\t\n\t\t\n\t\n\t\n\t\tüì¶ Dataset Summary\n\t\n\n\nDuration: ~1 hour\nChunks:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/raw_1hr_myanmar_asr_audio.","url":"https://huggingface.co/datasets/freococo/raw_1hr_myanmar_asr_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Burmese","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"raw_1hr_myanmar_asr_audio","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tüá≤üá≤ Raw 1-Hour Burmese ASR Audio Dataset\n\t\n\nA 1-hour dataset of Burmese (Myanmar language) spoken audio clips with transcripts, curated from official public-service media broadcasts by PVTV Myanmar ‚Äî the media voice of Myanmar‚Äôs National Unity Government (NUG).\nThis dataset is intended for automatic speech recognition (ASR) and Burmese speech-processing research.\n‚û°Ô∏è Author: freococo‚û°Ô∏è License: MIT‚û°Ô∏è Language: Burmese (my)\n\n\n\t\n\t\t\n\t\n\t\n\t\tüì¶ Dataset Summary\n\t\n\n\nDuration: ~1 hour\nChunks:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/raw_1hr_myanmar_asr_audio.","url":"https://huggingface.co/datasets/freococo/raw_1hr_myanmar_asr_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Burmese","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Ben-Tucker","keyword":"speech","description":"\n\t\n\t\t\n\t\tAudio Dataset for ASR\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio recordings with corresponding transcriptions for Automatic Speech Recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal samples: 2144\nTrain samples: 1715\nValidation samples: 429\nAudio format: WAV, 16kHz, mono\nLanguage: Indonesian (adjust as needed)\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n{\n    'id': str,\n    'audio': Audio(sampling_rate=16000),\n    'text': str,\n    'text_cleaned': str\n}\n\n\n\t\n\t\t\n\t\tUsage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ngademin/Ben-Tucker.","url":"https://huggingface.co/datasets/ngademin/Ben-Tucker","creator_name":"Fajar M","creator_url":"https://huggingface.co/ngademin","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Indonesian","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Ben-Tucker","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tAudio Dataset for ASR\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio recordings with corresponding transcriptions for Automatic Speech Recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal samples: 2144\nTrain samples: 1715\nValidation samples: 429\nAudio format: WAV, 16kHz, mono\nLanguage: Indonesian (adjust as needed)\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n{\n    'id': str,\n    'audio': Audio(sampling_rate=16000),\n    'text': str,\n    'text_cleaned': str\n}\n\n\n\t\n\t\t\n\t\tUsage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ngademin/Ben-Tucker.","url":"https://huggingface.co/datasets/ngademin/Ben-Tucker","creator_name":"Fajar M","creator_url":"https://huggingface.co/ngademin","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Indonesian","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MasriSpeech-1K","keyword":"speech","description":"\n\t\n\t\t\n\t\tüó£Ô∏è NigMasriSpeech: Egyptian Arabic Speech Dataset (1K Samples)\n\t\n\n\n\n\n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüåç Overview\n\t\n\nNigMasriSpeech is a compact Egyptian Arabic speech dataset, designed for Automatic Speech Recognition (ASR) and other speech processing tasks. This dataset contains 1,000 professionally annotated audio samples totaling over 10 hours of natural Egyptian Arabic speech.\nüí° Key Features:\n\nHigh-quality 16kHz speech recordings\nNatural conversational Egyptian Arabic\nCompact size for quick‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NightPrince/MasriSpeech-1K.","url":"https://huggingface.co/datasets/NightPrince/MasriSpeech-1K","creator_name":"Yahya Muhammad Alnwsany","creator_url":"https://huggingface.co/NightPrince","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","any-to-any","Egyptian Arabic","Arabic"],"keywords_longer_than_N":true},
	{"name":"MasriSpeech-1K","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tüó£Ô∏è NigMasriSpeech: Egyptian Arabic Speech Dataset (1K Samples)\n\t\n\n\n\n\n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüåç Overview\n\t\n\nNigMasriSpeech is a compact Egyptian Arabic speech dataset, designed for Automatic Speech Recognition (ASR) and other speech processing tasks. This dataset contains 1,000 professionally annotated audio samples totaling over 10 hours of natural Egyptian Arabic speech.\nüí° Key Features:\n\nHigh-quality 16kHz speech recordings\nNatural conversational Egyptian Arabic\nCompact size for quick‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NightPrince/MasriSpeech-1K.","url":"https://huggingface.co/datasets/NightPrince/MasriSpeech-1K","creator_name":"Yahya Muhammad Alnwsany","creator_url":"https://huggingface.co/NightPrince","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","any-to-any","Egyptian Arabic","Arabic"],"keywords_longer_than_N":true},
	{"name":"MasriSpeech-1K","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tüó£Ô∏è NigMasriSpeech: Egyptian Arabic Speech Dataset (1K Samples)\n\t\n\n\n\n\n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüåç Overview\n\t\n\nNigMasriSpeech is a compact Egyptian Arabic speech dataset, designed for Automatic Speech Recognition (ASR) and other speech processing tasks. This dataset contains 1,000 professionally annotated audio samples totaling over 10 hours of natural Egyptian Arabic speech.\nüí° Key Features:\n\nHigh-quality 16kHz speech recordings\nNatural conversational Egyptian Arabic\nCompact size for quick‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NightPrince/MasriSpeech-1K.","url":"https://huggingface.co/datasets/NightPrince/MasriSpeech-1K","creator_name":"Yahya Muhammad Alnwsany","creator_url":"https://huggingface.co/NightPrince","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","any-to-any","Egyptian Arabic","Arabic"],"keywords_longer_than_N":true},
	{"name":"RomanianReviewsSentiment","keyword":"hate-speech-detection","description":"\n  RomanianReviewsSentiment\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLaRoSeDa (A Large Romanian Sentiment Data Set) contains 15,000 reviews written in Romanian\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReferencehttps://arxiv.org/abs/2101.04197\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"RomanianReviewsSentiment\")\nevaluator = mteb.MTEB([task])\n\nmodel‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RomanianReviewsSentiment.","url":"https://huggingface.co/datasets/mteb/RomanianReviewsSentiment","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"libritts_p_dataset_20250821_095157","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tContribution\n\t\n\nThis dataset is a processed version of the original LibriTTS-P dataset, optimized for use on the Hugging Face platform. I've uploaded this version to make it more accessible to the community. All credit for the original data goes to the creators of LibriTTS-P.\n\n\t\n\t\t\n\t\tOriginal LibriTTS-P Dataset\n\t\n\nhttps://github.com/line/LibriTTS-P\n\n\t\n\t\t\n\t\tOriginal LibriTTS-P Dataset Citation\n\t\n\n@inproceedings{librittsp,\n    authors={Masaya Kawamura, Ryuichi Yamamoto, Yuma Shirahata‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tictap11/libritts_p_dataset_20250821_095157.","url":"https://huggingface.co/datasets/tictap11/libritts_p_dataset_20250821_095157","creator_name":"Mingwan Song","creator_url":"https://huggingface.co/tictap11","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","cc-by-4.0","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"ScreenTalk-XS","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tüé¨ ScreenTalk-XS: Sample Speech Dataset from Screen Content üñ•Ô∏è\n\t\n\n  \n\n\t\n\t\t\n\t\n\t\n\t\tüì¢ What is ScreenTalk-XS?\n\t\n\nScreenTalk-XS is a high-quality transcribed speech dataset containing 10k speech samples from diverse screen content.It is designed for automatic speech recognition (ASR), natural language processing (NLP), and conversational AI research.  \n‚úÖ This dataset is freely available for research and educational use.üîπ If you need a larger dataset with more diverse speech samples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Itbanque/ScreenTalk-XS.","url":"https://huggingface.co/datasets/Itbanque/ScreenTalk-XS","creator_name":"Itbanque","creator_url":"https://huggingface.co/Itbanque","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"luvila-kikongo-grammar","keyword":"grammar","description":"Svngoku/luvila-kikongo-grammar dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Svngoku/luvila-kikongo-grammar","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Kongo","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"SyntacticAgreement","keyword":"linguistics","description":"\n\t\n\t\t\n\t\tSyntacticAgreement\n\t\n\nThis dataset provides manually curated syntactic agreement test suites for four morphologically rich languages: Italian, Spanish, Portuguese, and Russian.It is designed to evaluate the ability of neural language models to capture hierarchical syntactic dependencies, with a focus on agreement phenomena that go beyond English subject‚Äìverb agreement.\nThis dataset is designed for targeted syntactic evaluation, which does not fit standard supervised NLP tasks. For this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/albalbalba/SyntacticAgreement.","url":"https://huggingface.co/datasets/albalbalba/SyntacticAgreement","creator_name":"alba taboas","creator_url":"https://huggingface.co/albalbalba","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["other","expert-generated","Spanish","Italian","Portuguese"],"keywords_longer_than_N":true},
	{"name":"nchlt_speech_zul","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tNCHLT Speech Corpus -- isiZulu\n\t\n\nThis is the isiZulu language part of the NCHLT Speech Corpus of the South African languages.\nLanguage code (ISO 639): zul\nURI: https://hdl.handle.net/20.500.12185/275\n\n\t\n\t\t\n\t\tLicence:\n\t\n\nCreative Commons Attribution 3.0 Unported License (CC BY 3.0): http://creativecommons.org/licenses/by/3.0/legalcode\n\n\t\n\t\t\n\t\tAttribution:\n\t\n\nThe Department of Arts and Culture of the government of the Republic of South Africa (DAC), Council for Scientific and Industrial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/danielshaps/nchlt_speech_zul.","url":"https://huggingface.co/datasets/danielshaps/nchlt_speech_zul","creator_name":"Daniel van Niekerk","creator_url":"https://huggingface.co/danielshaps","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Zulu","cc-by-3.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"qirimtatar-tts","keyword":"text-to-speech","description":" \n\n\n\t\n\t\t\n\t\tOpen Source Crimean Tatar Text-to-Speech datasets\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tVoices\n\t\n\n\n\t\n\t\t\n\t\tMale\n\t\n\n\n\t\n\t\t\n\t\tAbibullah\n\t\n\n\nQuality: high\nDuration: 2h + 50m\nAudio formats: OPUS\nFrequency: 48000 Hz\n\n\n\t\n\t\t\n\t\tArslan\n\t\n\n\nQuality: high\nDuration: 40m + 40m\nAudio formats: OPUS\nFrequency: 48000 Hz\n\n\n\t\n\t\t\n\t\tFemale\n\t\n\n\n\t\n\t\t\n\t\tSevil\n\t\n\n\nQuality:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Yehor/qirimtatar-tts.","url":"https://huggingface.co/datasets/Yehor/qirimtatar-tts","creator_name":"Smoliakov","creator_url":"https://huggingface.co/Yehor","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Crimean Tatar","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"urdu-tts-fast","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tXCollab/urdu-tts-fast\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCombined Urdu Text-to-Speech dataset with 10,534 high-quality audio-text pairs.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n{\n    'index': int,           # Sample index\n    'text': str,           # Urdu text transcription  \n    'audio': {             # Audio data\n        'path': str,        # Path to audio file\n        'sampling_rate': 16000\n    },\n    'source_dataset': str  # Original dataset name\n}\n\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/XCollab/urdu-tts-fast.","url":"https://huggingface.co/datasets/XCollab/urdu-tts-fast","creator_name":"XCollab","creator_url":"https://huggingface.co/XCollab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Urdu","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"emilia-yodas","keyword":"speech","description":"A mirror of the Emilia-YODAS dataset. Only includes the YODAS subset from the original dataset.\nhttps://huggingface.co/datasets/amphion/Emilia-Dataset\n","url":"https://huggingface.co/datasets/TTS-AGI/emilia-yodas","creator_name":"TTS AGI","creator_url":"https://huggingface.co/TTS-AGI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","German","French"],"keywords_longer_than_N":true},
	{"name":"hyvoxpopuli","keyword":"speech","description":"\n\t\n\t\t\n\t\tHyVoxPopuli Dataset\n\t\n\nThe HyVoxPopuli dataset is the Armenian language subset of the Facebook VoxPopuli dataset. The name \"HyVoxPopuli\" comes from combining \"hy\" (the ISO 639-1 language code for Armenian) with \"VoxPopuli\" (the original dataset name). It is a high-quality collection of Armenian speech recordings with expert-validated transcriptions, carefully extracted and processed from the original VoxPopuli dataset (https://github.com/facebookresearch/voxpopuli).\nThis dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Edmon02/hyvoxpopuli.","url":"https://huggingface.co/datasets/Edmon02/hyvoxpopuli","creator_name":"Edmon Sahakyan","creator_url":"https://huggingface.co/Edmon02","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Armenian","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"emilia-yodas","keyword":"automatic-speech-recognition","description":"A mirror of the Emilia-YODAS dataset. Only includes the YODAS subset from the original dataset.\nhttps://huggingface.co/datasets/amphion/Emilia-Dataset\n","url":"https://huggingface.co/datasets/TTS-AGI/emilia-yodas","creator_name":"TTS AGI","creator_url":"https://huggingface.co/TTS-AGI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","German","French"],"keywords_longer_than_N":true},
	{"name":"hyvoxpopuli","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tHyVoxPopuli Dataset\n\t\n\nThe HyVoxPopuli dataset is the Armenian language subset of the Facebook VoxPopuli dataset. The name \"HyVoxPopuli\" comes from combining \"hy\" (the ISO 639-1 language code for Armenian) with \"VoxPopuli\" (the original dataset name). It is a high-quality collection of Armenian speech recordings with expert-validated transcriptions, carefully extracted and processed from the original VoxPopuli dataset (https://github.com/facebookresearch/voxpopuli).\nThis dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Edmon02/hyvoxpopuli.","url":"https://huggingface.co/datasets/Edmon02/hyvoxpopuli","creator_name":"Edmon Sahakyan","creator_url":"https://huggingface.co/Edmon02","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Armenian","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"emilia-yodas","keyword":"text-to-speech","description":"A mirror of the Emilia-YODAS dataset. Only includes the YODAS subset from the original dataset.\nhttps://huggingface.co/datasets/amphion/Emilia-Dataset\n","url":"https://huggingface.co/datasets/TTS-AGI/emilia-yodas","creator_name":"TTS AGI","creator_url":"https://huggingface.co/TTS-AGI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","German","French"],"keywords_longer_than_N":true},
	{"name":"eka_filtered_data","keyword":"speech","description":"\n\t\n\t\t\n\t\tEka Medical Asr Sample Noise Eval Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 62 samples organized across multiple splits and 31 subsets.\nThe dataset includes audio data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tSubsets\n\t\n\nThis dataset includes the following subsets:\n\noriginal: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-10: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-20: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-30: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-40: 2 samples\ntest:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sujalappa/eka_filtered_data.","url":"https://huggingface.co/datasets/sujalappa/eka_filtered_data","creator_name":"sujal rajeev chondhekar","creator_url":"https://huggingface.co/sujalappa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"eka_filtered_data","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tEka Medical Asr Sample Noise Eval Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 62 samples organized across multiple splits and 31 subsets.\nThe dataset includes audio data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tSubsets\n\t\n\nThis dataset includes the following subsets:\n\noriginal: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-10: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-20: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-30: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-40: 2 samples\ntest:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sujalappa/eka_filtered_data.","url":"https://huggingface.co/datasets/sujalappa/eka_filtered_data","creator_name":"sujal rajeev chondhekar","creator_url":"https://huggingface.co/sujalappa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"synthetic-speaker-diarization-dataset-fa-large-3000","keyword":"automatic-speech-recognition","description":"uncleMehrzad/synthetic-speaker-diarization-dataset-fa-large-3000 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/uncleMehrzad/synthetic-speaker-diarization-dataset-fa-large-3000","creator_name":"Amirreza Mehrzadian","creator_url":"https://huggingface.co/uncleMehrzad","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","Persian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"latam-xix","keyword":"hate-speech-detection","description":"Flaglab/latam-xix dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Flaglab/latam-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-retrieval","text-classification","slot-filling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"eka_filtered_data","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tEka Medical Asr Sample Noise Eval Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 62 samples organized across multiple splits and 31 subsets.\nThe dataset includes audio data.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tSubsets\n\t\n\nThis dataset includes the following subsets:\n\noriginal: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-10: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-20: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-30: 2 samples\ntest: 2 samples\n\n\nnoisy-bg-snr-40: 2 samples\ntest:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sujalappa/eka_filtered_data.","url":"https://huggingface.co/datasets/sujalappa/eka_filtered_data","creator_name":"sujal rajeev chondhekar","creator_url":"https://huggingface.co/sujalappa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"drill-instructor","keyword":"text-to-speech","description":"AodenT/drill-instructor dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/AodenT/drill-instructor","creator_name":"Aoden Teo Masa Toshi","creator_url":"https://huggingface.co/AodenT","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","English","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"singaporean_district_noise","keyword":"speech","description":"\n\t\n\t\t\n\t\tSingaporean district with noise\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSingaporean district speech dataset with controlled noise augmentation for ASR training\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: EN\nTask: Automatic Speech Recognition  \nTotal Samples: 2,288\nAudio Sample Rate: 16kHz\nBase Dataset: Custom dataset\nProcessing: Noise-augmented\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (16kHz WAV format)\ntext: Transcription text\nnoise_type: Type of background noise‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise.","url":"https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise","creator_name":"DANG VAN THUC","creator_url":"https://huggingface.co/thucdangvan020999","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"singaporean_district_noise","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSingaporean district with noise\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSingaporean district speech dataset with controlled noise augmentation for ASR training\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: EN\nTask: Automatic Speech Recognition  \nTotal Samples: 2,288\nAudio Sample Rate: 16kHz\nBase Dataset: Custom dataset\nProcessing: Noise-augmented\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (16kHz WAV format)\ntext: Transcription text\nnoise_type: Type of background noise‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise.","url":"https://huggingface.co/datasets/thucdangvan020999/singaporean_district_noise","creator_name":"DANG VAN THUC","creator_url":"https://huggingface.co/thucdangvan020999","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"common_voice_17_0_eu","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tCommon Voice 17.0 - Euskera with Audio Features\n\t\n\nThis dataset contains the Euskera (Basque) subset of the Mozilla Common Voice 17.0 dataset. It includes audio clips and corresponding transcriptions, prepared with audio features readily available for use with libraries like Hugging Face datasets. For the preparation of this dataset, the following notebook was used: Preparar_dataset_euskera.ipynb\nSource:\nThe original data is from the Mozilla Common Voice 17.0 dataset.\nLanguage:\nEuskera‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mikelalda/common_voice_17_0_eu.","url":"https://huggingface.co/datasets/mikelalda/common_voice_17_0_eu","creator_name":"Mikel  Aldalur","creator_url":"https://huggingface.co/mikelalda","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["cc0-1.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"TurkishVoiceDataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cubukcum/TurkishVoiceDataset.","url":"https://huggingface.co/datasets/cubukcum/TurkishVoiceDataset","creator_name":"Mehmet","creator_url":"https://huggingface.co/cubukcum","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","text-to-speech","Turkish","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"TurkishVoiceDataset","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cubukcum/TurkishVoiceDataset.","url":"https://huggingface.co/datasets/cubukcum/TurkishVoiceDataset","creator_name":"Mehmet","creator_url":"https://huggingface.co/cubukcum","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","text-to-speech","Turkish","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"HomoRich-G2P-Persian","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tHomoRich: A Persian Homograph Dataset for G2P Conversion\n\t\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nHomoRich is the first large-scale, sentence-level Persian homograph dataset designed for grapheme-to-phoneme (G2P) conversion tasks. It addresses the scarcity of balanced, contextually annotated homograph data for low-resource languages. The dataset was created using a semi-automated pipeline combining human expertise and LLM-generated samples, as described in the paper:\"Fast, Not Fancy: Rethinking G2P‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahtaFetrat/HomoRich-G2P-Persian.","url":"https://huggingface.co/datasets/MahtaFetrat/HomoRich-G2P-Persian","creator_name":"Mahta Fetrat","creator_url":"https://huggingface.co/MahtaFetrat","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-to-speech","Persian","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"IndicTTS_Tamil","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tTamil Indic TTS Dataset\n\t\n\nThis dataset is derived from the Indic TTS Database project, specifically using the Tamil monolingual recordings from both male and female speakers. The dataset contains high-quality speech recordings with corresponding text transcriptions, making it suitable for text-to-speech (TTS) research and development.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Tamil\nTotal Duration: ~20.33 hours (Male: 10.3 hours, Female: 10.03 hours)\nAudio Format: WAV\nSampling Rate:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/IndicTTS_Tamil.","url":"https://huggingface.co/datasets/SPRINGLab/IndicTTS_Tamil","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Tamil","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mls-eng-128kb","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for English MLS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the English version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ntt123/mls-eng-128kb.","url":"https://huggingface.co/datasets/ntt123/mls-eng-128kb","creator_name":"Th√¥ng Nguy·ªÖn","creator_url":"https://huggingface.co/ntt123","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"MMedFD","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tMMedFD: A Real-World Healthcare Benchmark for Multi-Turn Full-Duplex Automatic Speech Recognition\n\t\n\n\n\t\n\t\t\n\t\tüìÑ Preprint: MMedFD ‚Äî For the complete benchmark construction pipeline, evaluation methodology, dataset specifications, and additional implementation details, please refer to the preprint.\n\t\n\n\n\t\n\t\t\n\t\t‚ö†Ô∏èData Availability\n\t\n\nFull access requires internal approval and a research-only data use agreement. \nüö´ Non-Commercial Use\nThis dataset is provided for non-commercial research and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HanselZz/MMedFD.","url":"https://huggingface.co/datasets/HanselZz/MMedFD","creator_name":"Hongzhao Chen","creator_url":"https://huggingface.co/HanselZz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mls-eng-128kb","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for English MLS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the English version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ntt123/mls-eng-128kb.","url":"https://huggingface.co/datasets/ntt123/mls-eng-128kb","creator_name":"Th√¥ng Nguy·ªÖn","creator_url":"https://huggingface.co/ntt123","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"CommonVoice-SpeechRE-audio","keyword":"speech","description":"\n\t\n\t\t\n\t\tCommonVoice-SpeechRE-audio\n\t\n\nThis repository provides the audio part of the CommonVoice-SpeechRE dataset, a benchmark for Speech Relation Extraction (SpeechRE), presented in the paper CommonVoice-SpeechRE and RPG-MoGe: Advancing Speech Relation Extraction with a New Dataset and Multi-Order Generative Framework.\nIt contains 19,583 speech samples derived from Common Voice 17.0.\nAll audio files are downsampled to 16kHz for consistency with common speech processing pipelines.\nüëâ The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kobe8-24/CommonVoice-SpeechRE-audio.","url":"https://huggingface.co/datasets/kobe8-24/CommonVoice-SpeechRE-audio","creator_name":"Jinzhong Ning","creator_url":"https://huggingface.co/kobe8-24","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["English","cc-by-4.0","Audio","arxiv:2509.08438","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"podcasts_tashkent_dialect_youtube_uzbek_speech_dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTashkent dialect focused podcasts youtube uzbek speech\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio clips and their corresponding transcriptions in the Uzbek language with mostly tashkent dialects. The data was collected from publicly available podcast videos on YouTube. It is designed for training and evaluating Automatic Speech Recognition (ASR) models.\nMost of the content comes from the Jahongir Latipov interviews and Bu podcast (respect authors) YouTube videos. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/islomov/podcasts_tashkent_dialect_youtube_uzbek_speech_dataset.","url":"https://huggingface.co/datasets/islomov/podcasts_tashkent_dialect_youtube_uzbek_speech_dataset","creator_name":"Sardor Islomov","creator_url":"https://huggingface.co/islomov","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"French_Grammar_Explanations","keyword":"grammar","description":"\nThis dataset contains 1500+ French grammar explanations. It's the one I used to train my finetuned LLM called FrenchLlama-3.2-1B-Instruct.\nYou can use this dataset for your own training purposes & find the aforementioned model on my HuggingFace profile.\n","url":"https://huggingface.co/datasets/Sufi2425/French_Grammar_Explanations","creator_name":"Sufian \"CreativeAlloy\"","creator_url":"https://huggingface.co/Sufi2425","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"English-Tamazight-Dictionnary-2007","keyword":"linguistics","description":"\n\t\n\t\t\n\t\tTamazight-English Dictionary 2007\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains cleaned and structured data extracted from the Tamazight-English Dictionary 2007 book, converted into machine-readable TSV files for linguistic research, language learning, and NLP applications.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset provides comprehensive bilingual resources for Tamazight (Central Atlas Tamazight/Berber) and English, including:\n\nBidirectional translation pairs (English‚ÜîTamazight)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Abdeljalil-Ounaceur/English-Tamazight-Dictionnary-2007.","url":"https://huggingface.co/datasets/Abdeljalil-Ounaceur/English-Tamazight-Dictionnary-2007","creator_name":"Abdeljalil  Ounaceur","creator_url":"https://huggingface.co/Abdeljalil-Ounaceur","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-classification","multilingual","original","English"],"keywords_longer_than_N":true},
	{"name":"LJSpeech-1.1-48kHz","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tLJSpeech-1.1 High-Resolution Dataset (48,000 Hz)\n\t\n\nThis dataset was created using the method described in HiFi-SR: A Unified Generative Transformer-Convolutional Adversarial Network for High-Fidelity Speech Super-Resolution and is part of ClearerVoice-Studio: Bridging Advanced Speech Processing Research and Practical Deployment (Github).\nThe LJSpeech-1.1 dataset, widely recognized for its utility in text-to-speech (TTS) and other speech processing tasks, has now been enhanced through‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alibabasglab/LJSpeech-1.1-48kHz.","url":"https://huggingface.co/datasets/alibabasglab/LJSpeech-1.1-48kHz","creator_name":"Alibaba_Speech_Lab_SG","creator_url":"https://huggingface.co/alibabasglab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"tr123","keyword":"speech","description":"\n\t\n\t\t\n\t\ttr123\n\t\n\nThis is a merged speech dataset containing 11930 audio segments from 24 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 11930\nSpeakers: 69\nLanguages: tr\nEmotions: sad, neutral, happy, angry\nOriginal Datasets: 24\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/tr123.","url":"https://huggingface.co/datasets/Codyfederer/tr123","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"tr123","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\ttr123\n\t\n\nThis is a merged speech dataset containing 11930 audio segments from 24 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 11930\nSpeakers: 69\nLanguages: tr\nEmotions: sad, neutral, happy, angry\nOriginal Datasets: 24\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/tr123.","url":"https://huggingface.co/datasets/Codyfederer/tr123","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"voice-of-america","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tVoice of America for  üá∫üá¶ Ukrainian\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\nDuration: 390.99 hours\n\nmean: 4.315471\nstd: 3.63682\nmin: 0.2995625\n25%: 1.82\n50%: 3.42\n75%: 5.628\nmax: 29.98\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { opentts-uk (Revision 32abc9c) },\n    year‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/voice-of-america.","url":"https://huggingface.co/datasets/speech-uk/voice-of-america","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Ukrainian","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"tr123","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\ttr123\n\t\n\nThis is a merged speech dataset containing 11930 audio segments from 24 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 11930\nSpeakers: 69\nLanguages: tr\nEmotions: sad, neutral, happy, angry\nOriginal Datasets: 24\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/tr123.","url":"https://huggingface.co/datasets/Codyfederer/tr123","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"khmer-speech-dataset-fixed","keyword":"speech","description":"\n\t\n\t\t\n\t\tKhmer Speech Dataset\n\t\n\nKhmer speech dataset with transcriptions for automatic speech recognition.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nLanguage: Khmer (km)\nTask: Automatic Speech Recognition\nFormat: Audio files with text transcriptions\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"mrrtmob/khmer-speech-dataset-fixed\")\n\n# Access a sample\nsample = dataset[0]\naudio_array = sample[\"audio\"][\"array\"]\ntranscription = sample[\"text\"]\nsampling_rate =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mrrtmob/khmer-speech-dataset-fixed.","url":"https://huggingface.co/datasets/mrrtmob/khmer-speech-dataset-fixed","creator_name":"Vanna Mork","creator_url":"https://huggingface.co/mrrtmob","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Khmer","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MasriSpeech","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tüó£Ô∏è MasriSpeech: Egyptian Arabic Speech Dataset\n\t\n\nA large-scale, high-quality Egyptian Arabic speech dataset for Automatic Speech Recognition (ASR), curated and released by Yahya Muhammad Alnwsany. MasriSpeech is designed to empower research and development in Arabic ASR, dialect modeling, and linguistic studies.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüåü Mission & Vision\n\t\n\nMasriSpeech aims to:\n\nAdvance the state of Egyptian Arabic ASR and dialectal NLP.\nEnable researchers, developers, and students to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NightPrince/MasriSpeech.","url":"https://huggingface.co/datasets/NightPrince/MasriSpeech","creator_name":"Yahya Muhammad Alnwsany","creator_url":"https://huggingface.co/NightPrince","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"khmer-speech-dataset-fixed","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tKhmer Speech Dataset\n\t\n\nKhmer speech dataset with transcriptions for automatic speech recognition.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nLanguage: Khmer (km)\nTask: Automatic Speech Recognition\nFormat: Audio files with text transcriptions\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"mrrtmob/khmer-speech-dataset-fixed\")\n\n# Access a sample\nsample = dataset[0]\naudio_array = sample[\"audio\"][\"array\"]\ntranscription = sample[\"text\"]\nsampling_rate =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mrrtmob/khmer-speech-dataset-fixed.","url":"https://huggingface.co/datasets/mrrtmob/khmer-speech-dataset-fixed","creator_name":"Vanna Mork","creator_url":"https://huggingface.co/mrrtmob","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Khmer","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"amazon_polarity","keyword":"hate-speech-detection","description":"\n  AmazonPolarityClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAmazon Polarity Classification Dataset.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://huggingface.co/datasets/amazon_polarity\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AmazonPolarityClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_polarity.","url":"https://huggingface.co/datasets/mteb/amazon_polarity","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"MasriSpeech","keyword":"speech-recognition","description":"\n\t\n\t\t\n\t\tüó£Ô∏è MasriSpeech: Egyptian Arabic Speech Dataset\n\t\n\nA large-scale, high-quality Egyptian Arabic speech dataset for Automatic Speech Recognition (ASR), curated and released by Yahya Muhammad Alnwsany. MasriSpeech is designed to empower research and development in Arabic ASR, dialect modeling, and linguistic studies.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüåü Mission & Vision\n\t\n\nMasriSpeech aims to:\n\nAdvance the state of Egyptian Arabic ASR and dialectal NLP.\nEnable researchers, developers, and students to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NightPrince/MasriSpeech.","url":"https://huggingface.co/datasets/NightPrince/MasriSpeech","creator_name":"Yahya Muhammad Alnwsany","creator_url":"https://huggingface.co/NightPrince","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"MasriSpeech","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tüó£Ô∏è MasriSpeech: Egyptian Arabic Speech Dataset\n\t\n\nA large-scale, high-quality Egyptian Arabic speech dataset for Automatic Speech Recognition (ASR), curated and released by Yahya Muhammad Alnwsany. MasriSpeech is designed to empower research and development in Arabic ASR, dialect modeling, and linguistic studies.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüåü Mission & Vision\n\t\n\nMasriSpeech aims to:\n\nAdvance the state of Egyptian Arabic ASR and dialectal NLP.\nEnable researchers, developers, and students to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NightPrince/MasriSpeech.","url":"https://huggingface.co/datasets/NightPrince/MasriSpeech","creator_name":"Yahya Muhammad Alnwsany","creator_url":"https://huggingface.co/NightPrince","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"marathi-language-audio","keyword":"speech","description":"\n\t\n\t\t\n\t\tMarathi Language Audio Dataset\n\t\n\nText spoken by all participants:\n\"‡§ï‡•É‡§§‡•ç‡§∞‡§ø‡§Æ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§§‡•ç‡§§‡§æ (AI) ‡§ù‡§™‡§æ‡§ü‡•ç‡§Ø‡§æ‡§®‡•á ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§π‡•ã‡§§ ‡§Ü‡§π‡•á, ‡§ú‡•Ä ‡§¶‡•à‡§®‡§Ç‡§¶‡§ø‡§® ‡§ú‡•Ä‡§µ‡§®‡§æ‡§≤‡§æ ‡§¨‡§¶‡§≤‡§§ ‡§Ü‡§π‡•á. ‡§§‡§ø‡§ö‡•á ‡§®‡§µ‡§æ‡§ö‡§æ‡§∞ ‡§∂‡§ø‡§ï‡•ç‡§∑‡§£, ‡§Ü‡§∞‡•ã‡§ó‡•ç‡§Ø‡§∏‡•á‡§µ‡§æ ‡§Ü‡§£‡§ø ‡§ï‡§æ‡§Æ‡§æ‡§≤‡§æ ‡§∏‡•Å‡§ß‡§æ‡§∞‡§§ ‡§Ü‡§π‡•á‡§§, ‡§ú‡•ç‡§Ø‡§æ‡§Æ‡•Å‡§≥‡•á ‡§®‡§µ‡•Ä‡§® ‡§∏‡§Ç‡§ß‡•Ä ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§π‡•ã‡§§ ‡§Ü‡§π‡•á‡§§‡•§\"\nThe dataset supports training and evaluation of models in:\n\nAutomatic Speech Recognition (ASR)\nEmotional tone classification\nVoice synthesis and generation\nEmotion-aware conversational agents\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntended Uses\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t‚úÖ Direct Use‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/marathi-language-audio.","url":"https://huggingface.co/datasets/Kratos-AI/marathi-language-audio","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","cc-by-4.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"Luminous","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kskip/Luminous.","url":"https://huggingface.co/datasets/Kskip/Luminous","creator_name":"William Kyle Skipper","creator_url":"https://huggingface.co/Kskip","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","summarization","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"surah_ikhlas_qalqala","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSurah Ikhlas Qalqala Errors\n\t\n\nThis dataset is a modified version of the Surah Ikhlas dataset, containing recordings for assessing Qalqala Tajweed rule detection.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\naudio: 16kHz resampled mono audio recordings\nverse: Verse number (1/2/3/4)\nqalqala_ahad_v1: Qalqala for letter ÿØ in word ÿ£ÿ≠ÿØ\nqalqala_samad: Qalqala for letter ÿØ in word ÿßŸÑÿµŸÖÿØ\nqalqala_yalid: Qalqala for letter ÿØ in word ŸäŸÑÿØ \nqalqala_yulad: Qalqala for letter ÿØ in word ŸäŸàŸÑÿØ\nqalqala_ahad_v4: Qalqala‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hetchyy/surah_ikhlas_qalqala.","url":"https://huggingface.co/datasets/hetchyy/surah_ikhlas_qalqala","creator_name":"Ahmed Ibrahim","creator_url":"https://huggingface.co/hetchyy","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"distilled-yodas-spanish","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for distilled-yodas-spanish\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n[!WARNING]\nRepository under construction\nWe are in the process of uploading the audio files.\nSorry for the inconvenience.\n\nDistilled YODAS Spanish is a high-quality subset of the Spanish portion of the YouTube-Oriented Dataset for Audio and Speech (YODAS).\nWhile the full YODAS corpus contains over 37,000 hours of Spanish speech across 43 million files, this dataset provides a distilled version of approximately 8‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BSC-LT/distilled-yodas-spanish.","url":"https://huggingface.co/datasets/BSC-LT/distilled-yodas-spanish","creator_name":"Language Technologies Laboratory @ Barcelona Supercomputing Center","creator_url":"https://huggingface.co/BSC-LT","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","cc-by-3.0","1M<n<10M","üá™üá∫ Region: EU"],"keywords_longer_than_N":true},
	{"name":"common-voice-20-mn-normalized","keyword":"speech","description":"\n\t\n\t\t\n\t\tCommon Voice 20.0 Mongolian Dataset\n\t\n\nThis dataset is a subset of Mozilla's Common Voice project, containing Mongolian speech data. It's part of Common Voice 20.0 release.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio clips in .mp3 format\nTranscriptions for each audio clip\nTrain/test/dev splits\nAdditional metadata including speaker demographics\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset can be used for:\n\nSpeech Recognition\nVoice Analysis\nLinguistic Research\nSpeech Processing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/warmestman/common-voice-20-mn-normalized.","url":"https://huggingface.co/datasets/warmestman/common-voice-20-mn-normalized","creator_name":"Ankhbayasgalan Davaadorj","creator_url":"https://huggingface.co/warmestman","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Mongolian","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"common-voice-20-mn-normalized","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tCommon Voice 20.0 Mongolian Dataset\n\t\n\nThis dataset is a subset of Mozilla's Common Voice project, containing Mongolian speech data. It's part of Common Voice 20.0 release.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio clips in .mp3 format\nTranscriptions for each audio clip\nTrain/test/dev splits\nAdditional metadata including speaker demographics\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset can be used for:\n\nSpeech Recognition\nVoice Analysis\nLinguistic Research\nSpeech Processing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/warmestman/common-voice-20-mn-normalized.","url":"https://huggingface.co/datasets/warmestman/common-voice-20-mn-normalized","creator_name":"Ankhbayasgalan Davaadorj","creator_url":"https://huggingface.co/warmestman","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Mongolian","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ro-offense","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive language detection with manually \nannotated offensive labels from a local Romanian sports news website (gsp.ro):\nResulting in 12,445 annotated messages\n\n\t\n\t\n\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/upb-nlp/ro-offense.","url":"https://huggingface.co/datasets/upb-nlp/ro-offense","creator_name":"POLITEHNICA Bucharest NLP Group","creator_url":"https://huggingface.co/upb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ro-offense","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive language detection with manually \nannotated offensive labels from a local Romanian sports news website (gsp.ro):\nResulting in 12,445 annotated messages\n\n\t\n\t\n\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/upb-nlp/ro-offense.","url":"https://huggingface.co/datasets/upb-nlp/ro-offense","creator_name":"POLITEHNICA Bucharest NLP Group","creator_url":"https://huggingface.co/upb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"swahili-speech","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tSwahili Speech-to-Text Dataset\n\t\n\nThis dataset contains paired audio and text data for training and evaluating speech-to-text models in Swahili. The audio files have been processed to remove silence, converted to 44.1kHz mono FLAC format, and are paired with corresponding transcriptions.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naudio_*.flac: Audio files in FLAC format, named by their corresponding text corpus ID.\nmetadata.jsonl: JSON Lines file with metadata for each audio-text pair. Each line is a JSON‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stem-content-ai-project/swahili-speech.","url":"https://huggingface.co/datasets/stem-content-ai-project/swahili-speech","creator_name":"Harnessing AI Project","creator_url":"https://huggingface.co/stem-content-ai-project","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Swahili","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"audio-dataset-300","keyword":"speech","description":"\n\t\n\t\t\n\t\tAudio Transcription Dataset\n\t\n\nThis dataset contains 297 audio recordings with their corresponding transcriptions for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset includes:\n\nAudio files: High-quality voice recordings (.wav format)\nTranscriptions: Accurate text transcriptions of the spoken content\nProper Audio feature type: Ready for model training (not just file paths!)\n\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal samples: 297\nAudio format: WAV files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aashish17405/audio-dataset-300.","url":"https://huggingface.co/datasets/Aashish17405/audio-dataset-300","creator_name":"Jaini Aashish","creator_url":"https://huggingface.co/Aashish17405","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"audio-dataset-300","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tAudio Transcription Dataset\n\t\n\nThis dataset contains 297 audio recordings with their corresponding transcriptions for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset includes:\n\nAudio files: High-quality voice recordings (.wav format)\nTranscriptions: Accurate text transcriptions of the spoken content\nProper Audio feature type: Ready for model training (not just file paths!)\n\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal samples: 297\nAudio format: WAV files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aashish17405/audio-dataset-300.","url":"https://huggingface.co/datasets/Aashish17405/audio-dataset-300","creator_name":"Jaini Aashish","creator_url":"https://huggingface.co/Aashish17405","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"ruslan_sova_ai","keyword":"text-to-speech","description":"This is a saved ruslan dataset from SOVA AI\n","url":"https://huggingface.co/datasets/intexcp/ruslan_sova_ai","creator_name":"Ivan Shivalov","creator_url":"https://huggingface.co/intexcp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"tts-crh-sevil","keyword":"text-to-speech","description":" \n\n\n\t\n\t\t\n\t\tOpen Source Crimean Tatar Text-to-Speech datasets\n\t\n\nThis is subset of Sevil voice with train/test splits.\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\nQuality: high\nDuration: 2h29m\nFrequency: 48 kHz\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { qirimtatar-tts (Revision c2ceec6) }‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/tts-crh-sevil.","url":"https://huggingface.co/datasets/speech-uk/tts-crh-sevil","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Crimean Tatar","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"text-to-speech-phonemized-sentences","keyword":"text-to-speech","description":"Phonemized version of https://huggingface.co/datasets/speech-uk/text-to-speech-sentences with some additional fields.\n","url":"https://huggingface.co/datasets/speech-uk/text-to-speech-phonemized-sentences","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"mabama-v6","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset mabama-v6\n\t\n\nDataset de audio para entrenar modelos de s√≠ntesis de voz (TTS) en espa√±ol.\n\n\t\n\t\t\n\t\tDescripci√≥n\n\t\n\n\nContenido: Audios en espa√±ol con sus transcripciones textuales.\nHablante: mabama (voz √∫nica).\nDuraci√≥n total: X horas (ajusta este valor).\nTasa de muestreo: 22.05 kHz (o la que uses).\n\n\n\t\n\t\t\n\t\tEstructura\n\t\n\n","url":"https://huggingface.co/datasets/gitgato/mabama-v6","creator_name":"Git Porter","creator_url":"https://huggingface.co/gitgato","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Spanish","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"elevenlabs_multilingual_v2-technical-speech","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tElevenLabs Multilingual V2 Technical Speech Dataset\n\t\n\nThis dataset contains automatically generated technical phrases in three domains, converted to speech using the ElevenLabs Multilingual V2 model with Adam voice.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset includes audio samples of technical phrases across three categories:\n\nMachine Learning (ML)\nScience\nTechnology\n\nEach entry contains:\n\nAudio file in MP3 format (22050Hz)\nSource text\nText length\nCategory label\n\n\n\t\n\t\t\n\t\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WpythonW/elevenlabs_multilingual_v2-technical-speech.","url":"https://huggingface.co/datasets/WpythonW/elevenlabs_multilingual_v2-technical-speech","creator_name":"Andrew","creator_url":"https://huggingface.co/WpythonW","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Clapping_Sound_Dataset","keyword":"automatic-speech-recognition","description":"zahidpichen/Clapping_Sound_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zahidpichen/Clapping_Sound_Dataset","creator_name":"ninjagamer","creator_url":"https://huggingface.co/zahidpichen","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"emilia-en-snac","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tStats (EN)\n\t\n\nEmilia: 46,349 hours\nEmilia-YODAS: 87,258 hours\nTotal: 133,607 hours\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThe Emilia subset is licensed under CC BY-NC 4.0.\nThe Emilia-YODAS subset is licensed under CC BY 4.0.\n\n\t\n\t\t\n\t\tReference\n\t\n\n@inproceedings{emilialarge,\n    author={He, Haorui and Shang, Zengqiang and Wang, Chaoren and Li, Xuyuan and Gu, Yicheng and Hua, Hua and Liu, Liwei and Yang, Chen and Li, Jiaqi and Shi, Peiyang and Wang, Yuancheng and Chen, Kai and Zhang, Pengyuan and Wu‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nytopop/emilia-en-snac.","url":"https://huggingface.co/datasets/nytopop/emilia-en-snac","creator_name":"Eric Izoita","creator_url":"https://huggingface.co/nytopop","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","cc-by-4.0","100M - 1B"],"keywords_longer_than_N":true},
	{"name":"emilia-en-snac","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tStats (EN)\n\t\n\nEmilia: 46,349 hours\nEmilia-YODAS: 87,258 hours\nTotal: 133,607 hours\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThe Emilia subset is licensed under CC BY-NC 4.0.\nThe Emilia-YODAS subset is licensed under CC BY 4.0.\n\n\t\n\t\t\n\t\tReference\n\t\n\n@inproceedings{emilialarge,\n    author={He, Haorui and Shang, Zengqiang and Wang, Chaoren and Li, Xuyuan and Gu, Yicheng and Hua, Hua and Liu, Liwei and Yang, Chen and Li, Jiaqi and Shi, Peiyang and Wang, Yuancheng and Chen, Kai and Zhang, Pengyuan and Wu‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nytopop/emilia-en-snac.","url":"https://huggingface.co/datasets/nytopop/emilia-en-snac","creator_name":"Eric Izoita","creator_url":"https://huggingface.co/nytopop","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","cc-by-4.0","100M - 1B"],"keywords_longer_than_N":true},
	{"name":"language-metric-data","keyword":"linguistics","description":"# This dataset contains the entire content of three files loaded as a single example:\n# - `languages_list.pkl`: A pickled list of language strings.\n# - `average_distances_matrix.npy`: A NumPy matrix converted to a list of lists of floats.\n# - `distances_matrices.pkl`: A pickled dict of dicts of NumPy matrices.  \n#    It is converted into a list of records where each record corresponds to a dataset with a nested list of models and their associated distance matrices.\n#","url":"https://huggingface.co/datasets/mshamrai/language-metric-data","creator_name":"Maksym Shamrai","creator_url":"https://huggingface.co/mshamrai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","mit","arxiv:2508.11676","üá∫üá∏ Region: US","multilingual"],"keywords_longer_than_N":true},
	{"name":"Gemini-2.0-Flash-Fenrir-Voice","keyword":"text-to-speech","description":"fireblade2534/Gemini-2.0-Flash-Fenrir-Voice dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/fireblade2534/Gemini-2.0-Flash-Fenrir-Voice","creator_name":"fireblade2534","creator_url":"https://huggingface.co/fireblade2534","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"swahili-tts-dataset","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tSwahili TTS Dataset\n\t\n\nThis dataset contains 10 Swahili audio clips with corresponding transcripts, used to train a Text-to-Speech (TTS) model using Coqui TTS.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nwavs/: Contains WAV audio files (One.wav to Ten.wav).\nmetadata.csv: Contains the following columns:\nfile_name: Name of the audio file.\naudio_path: Path to the audio file.\ntranscript: Swahili transcript of the audio.\nduration: Duration of the audio in seconds.\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\nThis dataset can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jacksonwambali/swahili-tts-dataset.","url":"https://huggingface.co/datasets/jacksonwambali/swahili-tts-dataset","creator_name":"Jackson Wambali","creator_url":"https://huggingface.co/jacksonwambali","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Swahili","cc-by-4.0","Audio","üá∫üá∏ Region: US","audio"],"keywords_longer_than_N":true},
	{"name":"tts_ahmet_deniz_tur","keyword":"speech-recognition","description":"\n\t\n\t\t\n\t\tMerhaba Arkada≈ülar üöÄ\n\t\n\n\n\t\n\t\t\n\t\tT√ºr√ße TTS √ºzerinde olu≈üturduƒüum veri seti bu ≈üekildedir.\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tAmacƒ±m TTS ( Text-To-Speech) √ºzerine a√ßƒ±k kaynak modellerin T√ºrk√ße performansƒ±nƒ± iyile≈ütirmek ve daha kaliteli √ßƒ±ktƒ±lar vermesini saƒülamaktƒ±r. Bunun i√ßin √ße≈üitli kaynaklardan elde ettiƒüim videolarƒ± doƒüru formata getirip eƒüitime hazƒ±r bir veri seti olu≈üturdum,\n\t\n\n\n\t\n\t\n\t\n\t\tBu veri setinin olu≈üturmakta ki amacƒ±m ticari bir gaye deƒüil, ara≈ütƒ±rma alanƒ±nda √ßalƒ±≈üan ki≈üilere fayda‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/omersaidd/tts_ahmet_deniz_tur.","url":"https://huggingface.co/datasets/omersaidd/tts_ahmet_deniz_tur","creator_name":"√ñmer Said Yilmaz","creator_url":"https://huggingface.co/omersaidd","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Turkish","mit","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"tts_ahmet_deniz_tur","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tMerhaba Arkada≈ülar üöÄ\n\t\n\n\n\t\n\t\t\n\t\tT√ºr√ße TTS √ºzerinde olu≈üturduƒüum veri seti bu ≈üekildedir.\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tAmacƒ±m TTS ( Text-To-Speech) √ºzerine a√ßƒ±k kaynak modellerin T√ºrk√ße performansƒ±nƒ± iyile≈ütirmek ve daha kaliteli √ßƒ±ktƒ±lar vermesini saƒülamaktƒ±r. Bunun i√ßin √ße≈üitli kaynaklardan elde ettiƒüim videolarƒ± doƒüru formata getirip eƒüitime hazƒ±r bir veri seti olu≈üturdum,\n\t\n\n\n\t\n\t\n\t\n\t\tBu veri setinin olu≈üturmakta ki amacƒ±m ticari bir gaye deƒüil, ara≈ütƒ±rma alanƒ±nda √ßalƒ±≈üan ki≈üilere fayda‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/omersaidd/tts_ahmet_deniz_tur.","url":"https://huggingface.co/datasets/omersaidd/tts_ahmet_deniz_tur","creator_name":"√ñmer Said Yilmaz","creator_url":"https://huggingface.co/omersaidd","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Turkish","mit","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Theresa","keyword":"text-to-speech","description":"None1145/Theresa dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/None1145/Theresa","creator_name":"None","creator_url":"https://huggingface.co/None1145","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-generation","Chinese","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"mrtv_news_voices","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tüó£Ô∏è Overview\n\t\n\nMRTV Voices is a large-scale Burmese speech dataset built from publicly available news broadcasts and programs aired on Myanma Radio and Television (MRTV) ‚Äî the official state-run media channel of Myanmar.\n\nüéôÔ∏è It contains over 130,000 short audio clips (‚âà117 hours) with aligned transcripts derived from auto-generated subtitles.\n\nThis dataset captures:\n\nFormal Burmese used in government bulletins and official reports  \nClear pronunciation, enunciation, and pacing ‚Äî‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/mrtv_news_voices.","url":"https://huggingface.co/datasets/freococo/mrtv_news_voices","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","Burmese","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"mrtv_news_voices","keyword":"speech","description":"\n\t\n\t\t\n\t\tüó£Ô∏è Overview\n\t\n\nMRTV Voices is a large-scale Burmese speech dataset built from publicly available news broadcasts and programs aired on Myanma Radio and Television (MRTV) ‚Äî the official state-run media channel of Myanmar.\n\nüéôÔ∏è It contains over 130,000 short audio clips (‚âà117 hours) with aligned transcripts derived from auto-generated subtitles.\n\nThis dataset captures:\n\nFormal Burmese used in government bulletins and official reports  \nClear pronunciation, enunciation, and pacing ‚Äî‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/mrtv_news_voices.","url":"https://huggingface.co/datasets/freococo/mrtv_news_voices","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","Burmese","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"talromur3_without_emotions","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis corpus is an emotion-less version of Talromur3_with_prompts. talromur_3_without_emotions is a prompt-labelled corpus that can be used for fine-tuning models, such as ParlerTTS.The corpus consists of approximately 15,000 utterances, spoken by 7 named speakers in 6 different emotions (see more info here).\nThe dataset is an expanded version of Talromur-3: an Icelandic emotional speech corpus.We have added natural-language descriptions of utterance-level pitch, speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/atlithor/talromur3_without_emotions.","url":"https://huggingface.co/datasets/atlithor/talromur3_without_emotions","creator_name":"Atli","creator_url":"https://huggingface.co/atlithor","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Icelandic","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"audio_data_russian_annotated","keyword":"speech","description":"\n\t\n\t\t\n\t\tDataset Audio Russian Annotated\n\t\n\nThis is a dataset with Russian annotated audio data, split into train for tasks like text-to-speech, speech recognition, and speaker identification.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\ntext: Audio transcription (string).\nspeaker_name: Speaker identifier (string).\naudio: Audio file.\nutterance_pitch_mean: The average pitch of the speech utterance (float64).\nutterance_pitch_std: The standard deviation of pitch, representing variability in intonation (float64)\nsnr:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kijjjj/audio_data_russian_annotated.","url":"https://huggingface.co/datasets/kijjjj/audio_data_russian_annotated","creator_name":"fgfd","creator_url":"https://huggingface.co/kijjjj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Preprocessed-MS-IL-POST-Data","keyword":"parts-of-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tOut-of-Scope Use\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data\n\t\n\n\n\n\n\t\n\t\t\n\t\tData Collection‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/musfiqdehan/Preprocessed-MS-IL-POST-Data.","url":"https://huggingface.co/datasets/musfiqdehan/Preprocessed-MS-IL-POST-Data","creator_name":"Md. Musfiqur Rahaman","creator_url":"https://huggingface.co/musfiqdehan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","Bengali","English","mit"],"keywords_longer_than_N":true},
	{"name":"audio_data_russian_annotated","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Audio Russian Annotated\n\t\n\nThis is a dataset with Russian annotated audio data, split into train for tasks like text-to-speech, speech recognition, and speaker identification.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\ntext: Audio transcription (string).\nspeaker_name: Speaker identifier (string).\naudio: Audio file.\nutterance_pitch_mean: The average pitch of the speech utterance (float64).\nutterance_pitch_std: The standard deviation of pitch, representing variability in intonation (float64)\nsnr:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kijjjj/audio_data_russian_annotated.","url":"https://huggingface.co/datasets/kijjjj/audio_data_russian_annotated","creator_name":"fgfd","creator_url":"https://huggingface.co/kijjjj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"conrad-lynk-voice-pack-enhanced","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tConrad Lynk Voice Pack (Enhanced)\n\t\n\nA high-quality voice dataset featuring Conrad Lynk, an AI assistant for real estate professionals. This enhanced version includes speaker identification and detailed audio metadata.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal Files: 144 audio samples\nSpeaker: Conrad Lynk (AI assistant)\nFormat: WAV audio with text transcripts\nLanguage: English\nDomain: Real estate conversations\nSample Rate: 48 kHz\nChannels: Mono\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach row contains:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BlandAIOrg/conrad-lynk-voice-pack-enhanced.","url":"https://huggingface.co/datasets/BlandAIOrg/conrad-lynk-voice-pack-enhanced","creator_name":"Bland AI","creator_url":"https://huggingface.co/BlandAIOrg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"testtrdataset-1","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTestTRDataset_1\n\t\n\nThis is a merged speech dataset containing 11930 audio segments from 24 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 11930\nSpeakers: 69\nLanguages: tr\nEmotions: angry, happy, neutral, sad\nOriginal Datasets: 24\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/testtrdataset-1.","url":"https://huggingface.co/datasets/Codyfederer/testtrdataset-1","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"PhonemeFakeV2","keyword":"speech","description":"\n\t\n\t\t\n\t\tPhonemeFake -  A Phonetic Deepfake Dataset\n\t\n\n\n\nWe introduce PhonemeFake, a DF attack that manipulates critical speech segments using language reasoning, significantly reducing human perception and SoTA\nmodel accuracies.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nWe provide example spoof audio in the viewers tab along with the transcription of the bonafide sample, the manipulated transcription and the audio timings for a small set of the data.\nThe dataset is split into three subsets. The spoof samples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/phonemefake/PhonemeFakeV2.","url":"https://huggingface.co/datasets/phonemefake/PhonemeFakeV2","creator_name":"PhonemeFake Dataset","creator_url":"https://huggingface.co/phonemefake","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"testtrdataset-1","keyword":"speech","description":"\n\t\n\t\t\n\t\tTestTRDataset_1\n\t\n\nThis is a merged speech dataset containing 11930 audio segments from 24 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 11930\nSpeakers: 69\nLanguages: tr\nEmotions: angry, happy, neutral, sad\nOriginal Datasets: 24\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/testtrdataset-1.","url":"https://huggingface.co/datasets/Codyfederer/testtrdataset-1","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"conrad-lynk-voice-pack-enhanced","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tConrad Lynk Voice Pack (Enhanced)\n\t\n\nA high-quality voice dataset featuring Conrad Lynk, an AI assistant for real estate professionals. This enhanced version includes speaker identification and detailed audio metadata.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal Files: 144 audio samples\nSpeaker: Conrad Lynk (AI assistant)\nFormat: WAV audio with text transcripts\nLanguage: English\nDomain: Real estate conversations\nSample Rate: 48 kHz\nChannels: Mono\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach row contains:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BlandAIOrg/conrad-lynk-voice-pack-enhanced.","url":"https://huggingface.co/datasets/BlandAIOrg/conrad-lynk-voice-pack-enhanced","creator_name":"Bland AI","creator_url":"https://huggingface.co/BlandAIOrg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"testtrdataset-1","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tTestTRDataset_1\n\t\n\nThis is a merged speech dataset containing 11930 audio segments from 24 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 11930\nSpeakers: 69\nLanguages: tr\nEmotions: angry, happy, neutral, sad\nOriginal Datasets: 24\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/testtrdataset-1.","url":"https://huggingface.co/datasets/Codyfederer/testtrdataset-1","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"Corinth_dataset","keyword":"text-to-speech","description":"OlameMend/Corinth_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/OlameMend/Corinth_dataset","creator_name":"leo","creator_url":"https://huggingface.co/OlameMend","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","cc-by-4.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"ro-offense-news","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-News-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive message detection with manually \nannotated comment from a local Romanian news website (stiri de cluj) into five classes:\n\nnon-offensive\ntargeted insults\nracist\nhomophobic\nsexist\n\nResulting in 4052 annotated messages\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example of 'train' looks as follows.\n{\n  'comment_id': 5‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/upb-nlp/ro-offense-news.","url":"https://huggingface.co/datasets/upb-nlp/ro-offense-news","creator_name":"POLITEHNICA Bucharest NLP Group","creator_url":"https://huggingface.co/upb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ro-offense-news","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-News-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive message detection with manually \nannotated comment from a local Romanian news website (stiri de cluj) into five classes:\n\nnon-offensive\ntargeted insults\nracist\nhomophobic\nsexist\n\nResulting in 4052 annotated messages\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example of 'train' looks as follows.\n{\n  'comment_id': 5‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/upb-nlp/ro-offense-news.","url":"https://huggingface.co/datasets/upb-nlp/ro-offense-news","creator_name":"POLITEHNICA Bucharest NLP Group","creator_url":"https://huggingface.co/upb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Obama-Sample-Dataset","keyword":"speech","description":"\n\n\t\n\t\t\n\t\tObama Voice Sample Dataset for RVC Training\n\t\n\nA curated dataset of Barack Obama's voice samples, specifically prepared for training Demo RVC (Retrieval-based Voice Conversion) model on ModelsLab.\n\n\t\n\t\t\n\t\tDataset Specifications\n\t\n\n\nTotal Duration: 25+ minutes\nAudio Format: WAV\nSampling Rate: 24 kHz\nContent Type: Clean speech samples from speeches and addresses\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset is designed for training RVC (Retrieval-based Voice Conversion) models. The minimum recommended‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ModelsLab/Obama-Sample-Dataset.","url":"https://huggingface.co/datasets/ModelsLab/Obama-Sample-Dataset","creator_name":"ModelsLab","creator_url":"https://huggingface.co/ModelsLab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"TikTok_Hottest_Video_Transcript_Example","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tüì≤ Example Dataset: TikTok Scraper Tool\n\t\n\nüëâ Start Scraping TikTok: TikTok Scraper Tool\n\n\n\t\n\t\t\n\t\t‚ú® Key Features\n\t\n\n\n‚ö° Instant Transcription ‚Äì Turn any TikTok video into an AI-ready transcript  \nüéØ Metadata ‚Äì Get the title, language description, and video hashtags  \nüîó URL-Based Access ‚Äì Just drop in a TikTok video URL to start scraping  \nüß© LLM-Ready Output ‚Äì Receive clean JSON ready for agents, RAG, or AI tools  \nüí∏ Free Tier ‚Äì Use up to 100 queries during the beta period  \nüí´ Easy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/TikTok_Hottest_Video_Transcript_Example.","url":"https://huggingface.co/datasets/Gopher-Lab/TikTok_Hottest_Video_Transcript_Example","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"uzlib","keyword":"linguistics","description":"\n\t\n\t\t\n\t\tUzbek Linguistic Benchmark (UzLiB)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nUzLiB (Uzbek Linguistic Benchmark) is the first comprehensive multiple-choice question benchmark designed to evaluate the linguistic understanding and capabilities of Large Language Models (LLMs) in the Uzbek language. It assesses how well models grasp correct Uzbek forms, usage, meanings, and contextual nuances.\nFor more detailed background on the motivation, creation process, and initial findings, please refer to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tahrirchi/uzlib.","url":"https://huggingface.co/datasets/tahrirchi/uzlib","creator_name":"Tahrirchi","creator_url":"https://huggingface.co/tahrirchi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Uzbek","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"tts-crh-arslan","keyword":"text-to-speech","description":" \n\n\n\t\n\t\t\n\t\tOpen Source Crimean Tatar Text-to-Speech datasets\n\t\n\nThis is subset of Arslan voice with train/test splits.\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\nQuality: high\nDuration: 1h20m\nFrequency: 48 kHz\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { qirimtatar-tts (Revision c2ceec6) }‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/tts-crh-arslan.","url":"https://huggingface.co/datasets/speech-uk/tts-crh-arslan","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Crimean Tatar","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"prueba_parquet","keyword":"automatic-speech-recognition","description":"This is an example of a repository with parquet files only.\n","url":"https://huggingface.co/datasets/carlosdanielhernandezmena/prueba_parquet","creator_name":"Carlos Daniel Hern√°ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"opentts-tetiana","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tOpen Text-to-Speech voices for üá∫üá¶ Ukrainian\n\t\n\n\n\t\n\t\t\n\t\tCommunity\n\t\n\n\nDiscord: https://bit.ly/discord-uds\nSpeech Recognition: https://t.me/speech_recognition_uk\nSpeech Synthesis: https://t.me/speech_synthesis_uk\n\n\n\t\n\t\t\n\t\tCite this work\n\t\n\n@misc {smoliakov_2025,\n    author       = { {Smoliakov} },\n    title        = { opentts-uk (Revision 32abc9c) },\n    year         = 2025,\n    url          = { https://huggingface.co/datasets/Yehor/opentts-uk },\n    doi          = { 10.57967/hf/4551 }‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/speech-uk/opentts-tetiana.","url":"https://huggingface.co/datasets/speech-uk/opentts-tetiana","creator_name":"Speech-UK initiative","creator_url":"https://huggingface.co/speech-uk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Ukrainian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"police-scanner-audio","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tPolice Scanner Audio Dataset\n\t\n\nA comprehensive collection of police and emergency services radio communications from multiple US cities, captured from publicly available scanner feeds.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset contains 103,660 audio recordings totaling 357GB of police scanner audio from 6 different cities across the United States. The recordings span multiple months of continuous monitoring and represent real-world emergency services communications.\n\n\t\n\t\t\n\t\tScanner‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trentmkelly/police-scanner-audio.","url":"https://huggingface.co/datasets/trentmkelly/police-scanner-audio","creator_name":"Trent Kelly","creator_url":"https://huggingface.co/trentmkelly","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","cc-by-3.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"cetuc","keyword":"automatic-speech-recognition","description":"falabrasil/cetuc dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/falabrasil/cetuc","creator_name":"Grupo FalaBrasil","creator_url":"https://huggingface.co/falabrasil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","100K - 1M","webdataset"],"keywords_longer_than_N":true},
	{"name":"CEDRClassification","keyword":"hate-speech-detection","description":"\n  CEDRClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClassification of sentences by emotions, labeled into 5 categories (joy, sadness, surprise, fear, and anger).\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Social, Blog, Written\n\nReference\nhttps://www.sciencedirect.com/science/article/pii/S1877050921013247\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/CEDRClassification.","url":"https://huggingface.co/datasets/mteb/CEDRClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","sentiment-analysis","sentiment-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"kokoro-82M-voices","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tKokoro-82M Voices\n\t\n\nThis dataset contains all the voices available in hexgrad/Kokoro-82M.\nThis dataset provides the voices in 3 different formats.\n\nIndividual voices embeddings in different JSON file\nSingle JSON which contains all the voices in a JSON object.\nParquet format for usage via datasets\nThe voices name is the same as the .pth file names shown below.\n\nvoices = [\n    \"af\",\n    \"af_bella\",\n    \"af_nicole\",\n    \"af_sarah\",\n    \"af_sky\",\n    \"am_adam\",\n    \"am_michael\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ecyht2/kokoro-82M-voices.","url":"https://huggingface.co/datasets/ecyht2/kokoro-82M-voices","creator_name":"Tan Hong Kai","creator_url":"https://huggingface.co/ecyht2","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"BibleMMS_vie","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tVietnamse subset of the BibleMMS dataset\n\t\n\nextracted from: https://huggingface.co/datasets/Flux9665/BibleMMS\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/load-biblemms.py\n","url":"https://huggingface.co/datasets/doof-ferb/BibleMMS_vie","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"BibleMMS_vie","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tVietnamse subset of the BibleMMS dataset\n\t\n\nextracted from: https://huggingface.co/datasets/Flux9665/BibleMMS\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/load-biblemms.py\n","url":"https://huggingface.co/datasets/doof-ferb/BibleMMS_vie","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"speech-recognition","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"chichewa-trigrams-speech-text-parallel","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tChichewa Trigrams Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 132549 parallel speech-text pairs for Chichewa, a language spoken primarily in Malawi. The dataset consists of audio recordings of trigram segments (3-word sequences) paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Chichewa - ny\nTask: Speech Recognition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/chichewa-trigrams-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/chichewa-trigrams-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Chichewa"],"keywords_longer_than_N":true},
	{"name":"ljs-mos-120","keyword":"speech","description":"\n\t\n\t\t\n\t\tLJS-MOS-120: Human MOS Ratings for 120 Samples of the LJ Speech Dataset\n\t\n\nLJS-MOS-120 provides Mean Opinion Score (MOS) ratings for 120 text-to-speech (TTS) samples based on the LJ Speech dataset. Each sample was rated by human annotators for intelligibility and naturalness across four experimental TTS conditions. The dataset follows the Tidy data format, with one row per rating per dimension.\nRatings were collected via Amazon Mechanical Turk (MTurk) in 2022. Each entry includes the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stefantaubert/ljs-mos-120.","url":"https://huggingface.co/datasets/stefantaubert/ljs-mos-120","creator_name":"Stefan Taubert","creator_url":"https://huggingface.co/stefantaubert","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"chichewa-trigrams-speech-text-parallel","keyword":"speech","description":"\n\t\n\t\t\n\t\tChichewa Trigrams Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 132549 parallel speech-text pairs for Chichewa, a language spoken primarily in Malawi. The dataset consists of audio recordings of trigram segments (3-word sequences) paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Chichewa - ny\nTask: Speech Recognition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/chichewa-trigrams-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/chichewa-trigrams-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Chichewa"],"keywords_longer_than_N":true},
	{"name":"ro-offense-sequences","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Teodora-Andreea Ion\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive sequence detection with manually \nannotated offensive sequences from a local Romanian sports news website (gsp.ro):\nResulting in 4800 annotated messages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/upb-nlp/ro-offense-sequences.","url":"https://huggingface.co/datasets/upb-nlp/ro-offense-sequences","creator_name":"POLITEHNICA Bucharest NLP Group","creator_url":"https://huggingface.co/upb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ro-offense-sequences","keyword":"hate-speech-detection","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Teodora-Andreea Ion\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive sequence detection with manually \nannotated offensive sequences from a local Romanian sports news website (gsp.ro):\nResulting in 4800 annotated messages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/upb-nlp/ro-offense-sequences.","url":"https://huggingface.co/datasets/upb-nlp/ro-offense-sequences","creator_name":"POLITEHNICA Bucharest NLP Group","creator_url":"https://huggingface.co/upb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ljs-mos-120","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tLJS-MOS-120: Human MOS Ratings for 120 Samples of the LJ Speech Dataset\n\t\n\nLJS-MOS-120 provides Mean Opinion Score (MOS) ratings for 120 text-to-speech (TTS) samples based on the LJ Speech dataset. Each sample was rated by human annotators for intelligibility and naturalness across four experimental TTS conditions. The dataset follows the Tidy data format, with one row per rating per dimension.\nRatings were collected via Amazon Mechanical Turk (MTurk) in 2022. Each entry includes the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stefantaubert/ljs-mos-120.","url":"https://huggingface.co/datasets/stefantaubert/ljs-mos-120","creator_name":"Stefan Taubert","creator_url":"https://huggingface.co/stefantaubert","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"ljs-mos-120","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tLJS-MOS-120: Human MOS Ratings for 120 Samples of the LJ Speech Dataset\n\t\n\nLJS-MOS-120 provides Mean Opinion Score (MOS) ratings for 120 text-to-speech (TTS) samples based on the LJ Speech dataset. Each sample was rated by human annotators for intelligibility and naturalness across four experimental TTS conditions. The dataset follows the Tidy data format, with one row per rating per dimension.\nRatings were collected via Amazon Mechanical Turk (MTurk) in 2022. Each entry includes the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stefantaubert/ljs-mos-120.","url":"https://huggingface.co/datasets/stefantaubert/ljs-mos-120","creator_name":"Stefan Taubert","creator_url":"https://huggingface.co/stefantaubert","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","mit","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Rosmontis","keyword":"text-to-speech","description":"None1145/Rosmontis dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/None1145/Rosmontis","creator_name":"None","creator_url":"https://huggingface.co/None1145","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","Chinese","Japanese","Korean"],"keywords_longer_than_N":true},
	{"name":"chichewa-trigrams-speech-text-parallel","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tChichewa Trigrams Speech-Text Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 132549 parallel speech-text pairs for Chichewa, a language spoken primarily in Malawi. The dataset consists of audio recordings of trigram segments (3-word sequences) paired with their corresponding text transcriptions, making it suitable for automatic speech recognition (ASR) and text-to-speech (TTS) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Chichewa - ny\nTask: Speech Recognition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/chichewa-trigrams-speech-text-parallel.","url":"https://huggingface.co/datasets/michsethowusu/chichewa-trigrams-speech-text-parallel","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Chichewa"],"keywords_longer_than_N":true},
	{"name":"urdu-language-audiodataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tUrdu Language Audio Dataset\n\t\n\nText spoken by all participants:\nŸÖÿµŸÜŸàÿπ€å ÿ∞€ÅÿßŸÜÿ™ (AI) ÿ™€åÿ≤€å ÿ≥€í ÿ™ÿ±ŸÇ€å ⁄©ÿ± ÿ±€Å€å €Å€íÿå ÿ¨Ÿà ÿ±Ÿàÿ≤ŸÖÿ±€Å ⁄©€å ÿ≤ŸÜÿØ⁄Ø€å ⁄©Ÿà ÿ®ÿØŸÑ ÿ±€Å€å €Å€í€î ÿßÿ≥ ⁄©€å ÿßÿÆÿ™ÿ±ÿßÿπÿßÿ™ ÿ™ÿπŸÑ€åŸÖÿå ÿµÿ≠ÿ™ ⁄©€å ÿØ€å⁄©⁄æ ÿ®⁄æÿßŸÑ ÿßŸàÿ± ⁄©ÿßŸÖ ⁄©Ÿà ÿ®€Åÿ™ÿ± ÿ®ŸÜÿß ÿ±€Å€å €Å€å⁄∫ÿå ŸÜÿ¶€í ŸÖŸàÿßŸÇÿπ Ÿæ€åÿØÿß ⁄©ÿ± ÿ±€Å€å €Å€å⁄∫€î\nThe dataset supports training and evaluation of models in:\n\nAutomatic Speech Recognition (ASR)\nEmotional tone classification\nVoice synthesis and generation\nEmotion-aware conversational agents\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntended Uses\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t‚úÖ Direct Use‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/urdu-language-audiodataset.","url":"https://huggingface.co/datasets/Kratos-AI/urdu-language-audiodataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Urdu","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"grammar_sq_0.1","keyword":"grammar","description":"\n\t\n\t\t\n\t\tPhysics and Math Problems Dataset\n\t\n\nThis repository contains a dataset of 5,623 enteries of different Albanian linguistics to improve Albanian queries further by introducing Albanian language rules and literature. The dataset is designed to support various NLP tasks and educational applications.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal Rows: 5,623\nLanguage: Albanian\nTopics:\nemrat: gjinia (mashkullore, fem√´rore, asnjan√´se), numri (nj√´j√´s, shum√´s), format dialektore: 29\nemrat: format e‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LTS-VVE/grammar_sq_0.1.","url":"https://huggingface.co/datasets/LTS-VVE/grammar_sq_0.1","creator_name":"LTS","creator_url":"https://huggingface.co/LTS-VVE","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Albanian","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"tts-test2","keyword":"text-to-speech","description":"deniskaanalpay/tts-test2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/deniskaanalpay/tts-test2","creator_name":"denis kaan alpay","creator_url":"https://huggingface.co/deniskaanalpay","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Turkish","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"ikk_bible_JHNandMRK_chapter1_to_10","keyword":"speech","description":"\n\t\n\t\t\n\t\tikk_bible_JHNandMRK_chapter1_to_10 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDisclaimer\n\t\n\nThis dataset is not fully setup, you will encounter errors while trying to load the data.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Ikaaudio dataset comprises segments from the first 10 chapters of the Ika translation of the New Testament. It contains verse-level audio segments, manually verified to include only high-quality segments were the transcription sufficiently matches the audio. The MMS_FA MMS‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ogbi/ikk_bible_JHNandMRK_chapter1_to_10.","url":"https://huggingface.co/datasets/ogbi/ikk_bible_JHNandMRK_chapter1_to_10","creator_name":"Daniel Ogbuigwe","creator_url":"https://huggingface.co/ogbi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Ika","apache-2.0","Audio","üá∫üá∏ Region: US","audio"],"keywords_longer_than_N":true},
	{"name":"sarcasm-statements-90","keyword":"sarcasm-detection","description":"\n\t\n\t\t\n\t\tDataset Name : 90 Labelled Sarcasm Statements Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 70 short English-language text statements, each manually labeled as either sarcastic (True) or non-sarcastic (False). The goal is to help researchers and developers train and evaluate models for sarcasm detection, especially in low-resource or few-shot settings.\nThe dataset captures a mix of:\n\nDry sarcasm\n\nIronic praise\n\nOverstated negativity or positivity\n\nContext-independent‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/elvanalabs/sarcasm-statements-90.","url":"https://huggingface.co/datasets/elvanalabs/sarcasm-statements-90","creator_name":"Calypse AI","creator_url":"https://huggingface.co/elvanalabs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"ToneBooks","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tToneBooks\n\t\n\nToneBooks ‚Äî –±–æ–ª—å—à–æ–π —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∞—É–¥–∏–æ–∫–Ω–∏–≥ —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π –∏–Ω—Ç–æ–Ω–∞—Ü–∏–π, —Ç–µ–º–±—Ä–∞ –∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≥–æ–ª–æ—Å–∞. –í –¥–∞—Ç–∞—Å–µ—Ç–µ 179.16 —á–∞—Å–æ–≤ –∞—É–¥–∏–æ –¥–ª—è train —Å–ø–ª–∏—Ç–∞ –∏ 9.42 —á–∞—Å–∞ –¥–ª—è validation.\n–ë–æ–ª—å—à–æ–µ —Å–ø–∞—Å–∏–±–æ its5Q –∑–∞ –ø–æ–º–æ—â—å –≤ —Å–±–æ—Ä–µ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö.\n\n\n\t\n\t\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ\n\t\n\n–î–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—É–¥–∏–æ—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ —Å–æ–±—Ä–∞–Ω—ã:\n\n–¢–µ–∫—Å—Ç–æ–≤–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ (text)\n–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–Ω—Ç–æ–Ω–∞—Ü–∏–∏ –∏ —ç–º–æ—Ü–∏–π (text_description), —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º:\nAccent/Affect  \nVoice Affect‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneBooks.","url":"https://huggingface.co/datasets/Vikhrmodels/ToneBooks","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Russian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"soreva","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tSOREVA\n\t\n\nSOREVA (Small Out-of-domain Resource for Various African languages) is a multilingual speech dataset designed for the evaluation of text-to-speech (TTS) and speech representation models in low-resource African languages.\nComming from Goethe Institut intiative of collecting 150 samples(Audio and transcription) for about 49 africain languages and dialectes\nThis dataset specifically targets out-of-domain generalization, addressing the lack of evaluation sets for languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OlameMend/soreva.","url":"https://huggingface.co/datasets/OlameMend/soreva","creator_name":"leo","creator_url":"https://huggingface.co/OlameMend","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Afrikaans","Tuki","Basa (Cameroon)"],"keywords_longer_than_N":true},
	{"name":"GLOBE","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tUpdated\n\t\n\n\n\t\n\t\t\n\t\tYou can use the V3 version, which includes more data, detailed speech quality annotations, and the original Common Voice IDs.\n\t\n\n\n\t\n\t\t\n\t\tAlternatively, you can use the V2 version to avoid the abnormal voice volume issue in this version.\n\t\n\n\n\t\n\t\t\n\t\tGlobe\n\t\n\nThe full paper can be accessed here: arXiv\nAn online demo can be accessed here: Github\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nThis paper introduces GLOBE, a high-quality English corpus with worldwide accents, specifically designed to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MushanW/GLOBE.","url":"https://huggingface.co/datasets/MushanW/GLOBE","creator_name":"MushanW","creator_url":"https://huggingface.co/MushanW","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-audio","automatic-speech-recognition","audio-to-audio","audio-classification","mozilla-foundation/common_voice_14_0"],"keywords_longer_than_N":true},
	{"name":"TV-24kHz-Neutral","keyword":"speech","description":"\n\t\n\t\t\n\t\tThorsten-Voice TV-24kHz-Neutral Dataset\n\t\n\nThis dataset is a resampled version of the \"TV-2022.10-Neutral\" configuration from the original Thorsten-Voice TV-44kHz-Full dataset, converted from 44.1kHz to 24kHz sampling rate.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Thorsten-Voice dataset contains German speech recordings by Thorsten M√ºller, suitable for text-to-speech (TTS) training and other speech synthesis tasks.\n\n\t\n\t\t\n\t\tChanges from Original\n\t\n\n\nSample Rate: Converted from 44.1kHz to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Thorsten-Voice/TV-24kHz-Neutral.","url":"https://huggingface.co/datasets/Thorsten-Voice/TV-24kHz-Neutral","creator_name":"Thorsten M√ºller","creator_url":"https://huggingface.co/Thorsten-Voice","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["German","cc-by-4.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"ToneBooks","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tToneBooks\n\t\n\nToneBooks ‚Äî –±–æ–ª—å—à–æ–π —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∞—É–¥–∏–æ–∫–Ω–∏–≥ —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π –∏–Ω—Ç–æ–Ω–∞—Ü–∏–π, —Ç–µ–º–±—Ä–∞ –∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≥–æ–ª–æ—Å–∞. –í –¥–∞—Ç–∞—Å–µ—Ç–µ 179.16 —á–∞—Å–æ–≤ –∞—É–¥–∏–æ –¥–ª—è train —Å–ø–ª–∏—Ç–∞ –∏ 9.42 —á–∞—Å–∞ –¥–ª—è validation.\n–ë–æ–ª—å—à–æ–µ —Å–ø–∞—Å–∏–±–æ its5Q –∑–∞ –ø–æ–º–æ—â—å –≤ —Å–±–æ—Ä–µ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö.\n\n\n\t\n\t\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ\n\t\n\n–î–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—É–¥–∏–æ—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ —Å–æ–±—Ä–∞–Ω—ã:\n\n–¢–µ–∫—Å—Ç–æ–≤–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ (text)\n–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–Ω—Ç–æ–Ω–∞—Ü–∏–∏ –∏ —ç–º–æ—Ü–∏–π (text_description), —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º:\nAccent/Affect  \nVoice Affect‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneBooks.","url":"https://huggingface.co/datasets/Vikhrmodels/ToneBooks","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Russian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"soreva","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tSOREVA\n\t\n\nSOREVA (Small Out-of-domain Resource for Various African languages) is a multilingual speech dataset designed for the evaluation of text-to-speech (TTS) and speech representation models in low-resource African languages.\nComming from Goethe Institut intiative of collecting 150 samples(Audio and transcription) for about 49 africain languages and dialectes\nThis dataset specifically targets out-of-domain generalization, addressing the lack of evaluation sets for languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OlameMend/soreva.","url":"https://huggingface.co/datasets/OlameMend/soreva","creator_name":"leo","creator_url":"https://huggingface.co/OlameMend","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Afrikaans","Tuki","Basa (Cameroon)"],"keywords_longer_than_N":true},
	{"name":"css10-ja-ljspeech","keyword":"speech","description":"\n\t\n\t\t\n\t\tCSS100-LJSpeech (Japanese / Meian)\n\t\n\ncss100-ljspeech „ÅØ„ÄÅPark et al. „ÅåÂÖ¨Èñã„Åó„Åü CSS10 Êó•Êú¨Ë™û„Ç≥„Éº„Éë„ÇπÔºàÊòéÊöóÔºâ„Çí„ÄÅLJ Speech ‰∫íÊèõ„Éï„Ç©„Éº„Éû„ÉÉ„Éà (id|text & wavs/*.wav) „Å∏Â§âÊèõ„Åó„ÅüÊ¥æÁîü„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ\n\n\t\n\t\t\n\t\t„Éá„Éº„ÇøÊ¶ÇË¶Å\n\t\n\n\n\t\n\t\t\nÈ†ÖÁõÆ\nÂÄ§\n\n\n\t\t\nË©±ËÄÖ\n1 (ekzemplaro)\n\n\nÈü≥Â£∞Êï∞\n6,841\n\n\nÂêàË®àÊôÇÈñì\nÁ¥Ñ 15 ÊôÇÈñì\n\n\n„Çµ„É≥„Éó„É™„É≥„Ç∞„É¨„Éº„Éà\n22,050 Hz\n\n\n„ÉÜ„Ç≠„Çπ„ÉàË®ÄË™û\nÊó•Êú¨Ë™û\n\n\n„Éï„Ç©„Éº„Éû„ÉÉ„Éà\n``id\n\n\n\t\n\n\n\t\n\t\t\n\t\t„Éï„Ç°„Ç§„É´ÊßãÊàê\n\t\n\ncss100-ljspeech/\n‚îú‚îÄ‚îÄ metadata.csv   # 2 Âàó (id|text)\n‚îî‚îÄ‚îÄ wavs/\n    ‚îú‚îÄ‚îÄ meian_0000.wav\n    ‚îú‚îÄ‚îÄ meian_0001.wav\n    ‚îî‚îÄ‚îÄ ...\n\n\n\t\n\t\t\n\t\t‰ΩøÁî®‰æã (ü§ó Datasets)\n\t\n\nfrom datasets import load_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/css10-ja-ljspeech.","url":"https://huggingface.co/datasets/ayousanz/css10-ja-ljspeech","creator_name":"yousan","creator_url":"https://huggingface.co/ayousanz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Japanese","apache-2.0","Audio","üá∫üá∏ Region: US","audio"],"keywords_longer_than_N":true},
	{"name":"Easy-Turn-Trainset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tEasy Turn: Integrating Acoustic and Linguistic Modalities for Robust Turn-Taking in Full-Duplex Spoken Dialogue Systems\n\t\n\n\n  Guojian Li1, Chengyou Wang1, Hongfei Xue1, \n  Shuiyuan Wang1, Dehui Gao1, Zihan Zhang2, \n  Yuke Lin2, Wenjie Li2, Longshuai Xiao2, \n  Zhonghua Fu1,‚ïÄ, Lei Xie1,‚ïÄ\n\n\n\n  1 Audio, Speech and Language Processing Group (ASLP@NPU), Northwestern Polytechnical University \n  2 Huawei Technologies, China \n\n\n\n\n\n\t\n\t\t\nüé§ Demo Page\nü§ñ Easy Turn Model\nüìë Paper\nüåê Huggingface‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ASLP-lab/Easy-Turn-Trainset.","url":"https://huggingface.co/datasets/ASLP-lab/Easy-Turn-Trainset","creator_name":"ASLP-lab","creator_url":"https://huggingface.co/ASLP-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Easy-Turn-Trainset","keyword":"speech","description":"\n\t\n\t\t\n\t\tEasy Turn: Integrating Acoustic and Linguistic Modalities for Robust Turn-Taking in Full-Duplex Spoken Dialogue Systems\n\t\n\n\n  Guojian Li1, Chengyou Wang1, Hongfei Xue1, \n  Shuiyuan Wang1, Dehui Gao1, Zihan Zhang2, \n  Yuke Lin2, Wenjie Li2, Longshuai Xiao2, \n  Zhonghua Fu1,‚ïÄ, Lei Xie1,‚ïÄ\n\n\n\n  1 Audio, Speech and Language Processing Group (ASLP@NPU), Northwestern Polytechnical University \n  2 Huawei Technologies, China \n\n\n\n\n\n\t\n\t\t\nüé§ Demo Page\nü§ñ Easy Turn Model\nüìë Paper\nüåê Huggingface‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ASLP-lab/Easy-Turn-Trainset.","url":"https://huggingface.co/datasets/ASLP-lab/Easy-Turn-Trainset","creator_name":"ASLP-lab","creator_url":"https://huggingface.co/ASLP-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"3hr_myanmar_asr_raw_audio","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tüìö 3-Hour Burmese Speech Dataset from FOEIM Academy (ASR-ready)\n\t\n\nThis is a curated ~3-hour dataset of Burmese-language audio-transcript pairs derived from the official public-service educational media of FOEIM Academy, a civic platform affiliated with FOEIM.ORG.\nIt is structured for fine-grained automatic speech recognition (ASR) training and testing.All data is aligned from timestamped subtitle files (.srt) and segmented into high-quality .mp3 mono files with aligned transcripts.\n‚û°Ô∏è‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/3hr_myanmar_asr_raw_audio.","url":"https://huggingface.co/datasets/freococo/3hr_myanmar_asr_raw_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","mit"],"keywords_longer_than_N":true},
	{"name":"EchoX-Dialougues","keyword":"automatic-speech-recognition","description":"\n\n  EchoX-Dialogues: Training Data for EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs\n\n\n\n\n  üêà‚Äç‚¨õ Github¬†ÔΩú¬†üìÉ Paper¬†ÔΩú¬†üöÄ Space¬†\n\n\n  üß† EchoX-8B¬†ÔΩú¬†üß† EchoX-3B¬†ÔΩú¬†üì¶ EchoX-Dialogues-Plus¬†\n\n\nEchoX-Dialogues provides the primary speech dialogue data used to train EchoX, restricted to S2T (speech ‚Üí text) in this repository.\nAll input speech is synthetic; text is derived from public sources with multi-stage cleaning and rewriting. Most turns include asr /‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/EchoX-Dialougues.","url":"https://huggingface.co/datasets/FreedomIntelligence/EchoX-Dialougues","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","question-answering","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"mls-eng-speaker-descriptions","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of English MLS\n\t\n\nThis dataset consists in annotations of the English subset of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours for other languages.\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls-eng-speaker-descriptions.","url":"https://huggingface.co/datasets/parler-tts/mls-eng-speaker-descriptions","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"3hr_myanmar_asr_raw_audio","keyword":"speech","description":"\n\t\n\t\t\n\t\tüìö 3-Hour Burmese Speech Dataset from FOEIM Academy (ASR-ready)\n\t\n\nThis is a curated ~3-hour dataset of Burmese-language audio-transcript pairs derived from the official public-service educational media of FOEIM Academy, a civic platform affiliated with FOEIM.ORG.\nIt is structured for fine-grained automatic speech recognition (ASR) training and testing.All data is aligned from timestamped subtitle files (.srt) and segmented into high-quality .mp3 mono files with aligned transcripts.\n‚û°Ô∏è‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/3hr_myanmar_asr_raw_audio.","url":"https://huggingface.co/datasets/freococo/3hr_myanmar_asr_raw_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","mit"],"keywords_longer_than_N":true},
	{"name":"EchoX-Dialougues","keyword":"speech","description":"\n\n  EchoX-Dialogues: Training Data for EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs\n\n\n\n\n  üêà‚Äç‚¨õ Github¬†ÔΩú¬†üìÉ Paper¬†ÔΩú¬†üöÄ Space¬†\n\n\n  üß† EchoX-8B¬†ÔΩú¬†üß† EchoX-3B¬†ÔΩú¬†üì¶ EchoX-Dialogues-Plus¬†\n\n\nEchoX-Dialogues provides the primary speech dialogue data used to train EchoX, restricted to S2T (speech ‚Üí text) in this repository.\nAll input speech is synthetic; text is derived from public sources with multi-stage cleaning and rewriting. Most turns include asr /‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/EchoX-Dialougues.","url":"https://huggingface.co/datasets/FreedomIntelligence/EchoX-Dialougues","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","question-answering","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"EchoX-Dialougues","keyword":"text-to-speech","description":"\n\n  EchoX-Dialogues: Training Data for EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs\n\n\n\n\n  üêà‚Äç‚¨õ Github¬†ÔΩú¬†üìÉ Paper¬†ÔΩú¬†üöÄ Space¬†\n\n\n  üß† EchoX-8B¬†ÔΩú¬†üß† EchoX-3B¬†ÔΩú¬†üì¶ EchoX-Dialogues-Plus¬†\n\n\nEchoX-Dialogues provides the primary speech dialogue data used to train EchoX, restricted to S2T (speech ‚Üí text) in this repository.\nAll input speech is synthetic; text is derived from public sources with multi-stage cleaning and rewriting. Most turns include asr /‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/EchoX-Dialougues.","url":"https://huggingface.co/datasets/FreedomIntelligence/EchoX-Dialougues","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","question-answering","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"malay-tts-tags","keyword":"text-to-speech","description":"doublesizebed/malay-tts-tags dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/doublesizebed/malay-tts-tags","creator_name":"chong","creator_url":"https://huggingface.co/doublesizebed","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Malay","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"mls-eng-speaker-descriptions","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of English MLS\n\t\n\nThis dataset consists in annotations of the English subset of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours for other languages.\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parler-tts/mls-eng-speaker-descriptions.","url":"https://huggingface.co/datasets/parler-tts/mls-eng-speaker-descriptions","creator_name":"Parler TTS","creator_url":"https://huggingface.co/parler-tts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part005","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 5 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 5 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part005.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part005","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"cv17_es_other_automatically_verified","keyword":"automatic-speech-recognition","description":"Split called -other- of the Spanish Common Voice v17.0 that was automatically verified\nusing various ASR system.","url":"https://huggingface.co/datasets/projecte-aina/cv17_es_other_automatically_verified","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","mozilla-foundation/common_voice_17_0"],"keywords_longer_than_N":true},
	{"name":"test5","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\ttest5\n\t\n\nThis is a merged speech dataset containing 1806 audio segments from 8 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 1806\nSpeakers: 47\nLanguages: en\nEmotions: happy, neutral, sad, angry\nOriginal Datasets: 8\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test5.","url":"https://huggingface.co/datasets/Codyfederer/test5","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part005","keyword":"speech","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 5 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 5 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part005.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part005","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"test5","keyword":"speech","description":"\n\t\n\t\t\n\t\ttest5\n\t\n\nThis is a merged speech dataset containing 1806 audio segments from 8 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 1806\nSpeakers: 47\nLanguages: en\nEmotions: happy, neutral, sad, angry\nOriginal Datasets: 8\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test5.","url":"https://huggingface.co/datasets/Codyfederer/test5","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"twi-speech-text-parallel-synthetic-1m-part005","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tTwi Speech-Text Parallel Dataset - Part 5 of 5\n\t\n\n\n\t\n\t\t\n\t\tüéâ The Largest Speech Dataset for Twi Language\n\t\n\nThis dataset contains part 5 of the largest speech dataset for the Twi language, featuring 1 million speech-to-text pairs split across 5 parts (approximately 200,000 samples each). This represents a groundbreaking resource for Twi (Akan), a language spoken primarily in Ghana.\n\n\t\n\t\t\n\t\tüöÄ Breaking the Low-Resource Language Barrier\n\t\n\nThis publication demonstrates that African‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part005.","url":"https://huggingface.co/datasets/michsethowusu/twi-speech-text-parallel-synthetic-1m-part005","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","keyword-spotting","monolingual","Akan"],"keywords_longer_than_N":true},
	{"name":"test5","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\ttest5\n\t\n\nThis is a merged speech dataset containing 1806 audio segments from 8 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 1806\nSpeakers: 47\nLanguages: en\nEmotions: happy, neutral, sad, angry\nOriginal Datasets: 8\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, 16kHz sampling rate)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion (neutral‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/test5.","url":"https://huggingface.co/datasets/Codyfederer/test5","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"vocsim","keyword":"speech","description":"\n\t\n\t\t\n\t\tVocSim: A Training-Free Benchmark for Content Identity in Single-Source Audio Embeddings\n\t\n\n\n\n\nVocSim evaluates how well neural audio embeddings generalize for zero-shot audio similarity. It tests recognizing fine-grained acoustic similarity without specific similarity training.\n\n\n\t\n\t\n\t\n\t\tKey Features\n\t\n\n\nDiverse Sources: Human speech (phones, words, utterances), birdsong, otter calls, environmental sounds.Varied Conditions: Spans clean to noisy recordings, short (<100ms) to long‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anonymous-submission000/vocsim.","url":"https://huggingface.co/datasets/anonymous-submission000/vocsim","creator_name":"Anonymous","creator_url":"https://huggingface.co/anonymous-submission000","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["cc-by-4.0","100K - 1M","parquet","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"speechocean762","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tspeechocean762: A non-native English corpus for pronunciation scoring task\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nPronunciation scoring is a crucial technology in computer-assisted language learning (CALL) systems. The pronunciation quality scores might be given at phoneme-level, word-level, and sentence-level for a typical pronunciation scoring task.\nThis corpus aims to provide a free public dataset for the pronunciation scoring task.\nKey features:\n\nIt is available for free download for both‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mispeech/speechocean762.","url":"https://huggingface.co/datasets/mispeech/speechocean762","creator_name":"Xiaomi Dasheng Team","creator_url":"https://huggingface.co/mispeech","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Thai-understanding","keyword":"speech","description":"\n\t\n\t\t\n\t\tThai-Understanding: Thai-SUP & XLSR-Thai\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThai-Understanding is an open-source repository that provides a solution for speech understanding in the Thai language. This repository includes:\n\nThai-SUP: The first open-source Thai speech understanding dataset, which includes over 1,000 hours of data across three tasks: Intent Classification (IC), Named Entity Recognition (NER), and Speech Rephrasing (SR).\nXLSR-Thai: The first large-scale self-supervised learning (SSL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mcshao/Thai-understanding.","url":"https://huggingface.co/datasets/mcshao/Thai-understanding","creator_name":"shaomingchen","creator_url":"https://huggingface.co/mcshao","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Thai","apache-2.0","100K - 1M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"lapsbm2","keyword":"automatic-speech-recognition","description":"falabrasil/lapsbm2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/falabrasil/lapsbm2","creator_name":"Grupo FalaBrasil","creator_url":"https://huggingface.co/falabrasil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","Portuguese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"dubs","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tStudio Dub Recordings\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nStudio Dub Recordings is a speech dataset consisting of high-quality studio recordings of dubbed audio in Tatar language. The dataset features professional voice actors performing various scripted dialogues, intended primarily for speech and text-to-speech (TTS) research in Tatar.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nParts:The dataset contains two main configurations:\n\naudiobooks: Contains the original audiobooks recordings.\n\nData Fields:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yasalma/dubs.","url":"https://huggingface.co/datasets/yasalma/dubs","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"dubs","keyword":"speech","description":"\n\t\n\t\t\n\t\tStudio Dub Recordings\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nStudio Dub Recordings is a speech dataset consisting of high-quality studio recordings of dubbed audio in Tatar language. The dataset features professional voice actors performing various scripted dialogues, intended primarily for speech and text-to-speech (TTS) research in Tatar.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nParts:The dataset contains two main configurations:\n\naudiobooks: Contains the original audiobooks recordings.\n\nData Fields:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yasalma/dubs.","url":"https://huggingface.co/datasets/yasalma/dubs","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"dubs","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tStudio Dub Recordings\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nStudio Dub Recordings is a speech dataset consisting of high-quality studio recordings of dubbed audio in Tatar language. The dataset features professional voice actors performing various scripted dialogues, intended primarily for speech and text-to-speech (TTS) research in Tatar.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nParts:The dataset contains two main configurations:\n\naudiobooks: Contains the original audiobooks recordings.\n\nData Fields:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yasalma/dubs.","url":"https://huggingface.co/datasets/yasalma/dubs","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","audio-to-audio","Tatar","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"LSVSC","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tunofficial mirror of LSVSC dataset (novel large-scale Vietnamese speech corpus)\n\t\n\nofficial announcement: https://www.mdpi.com/2079-9292/13/5/977\nofficial download: https://drive.google.com/drive/folders/1tiPKaIOC7bt6isv5qFqf61O_2jFK8ZOI\n100h, 57k samples\npre-process: see my code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/clean-lsvsc.py\nneed to do: check misspelling, restore foreign words phonetised to vietnamese\nusage with HuggingFace:\n# pip install -q‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/LSVSC.","url":"https://huggingface.co/datasets/doof-ferb/LSVSC","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"common_voice_19_0_zh-TW","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tCommon Voice Corpus 19.0 Chinese (Taiwan)\n\t\n\nThe test set is the same as the original test set, while validated_without_test includes all validated examples except those with sentence IDs that appear in the test set.\n\nvalidated_without_test has about 50,000 examples in total, equivalent to approximately 44 hours, and is intended for use as the training set.\ntest has about 5,000 examples, which is approximately 5 hours.\n\n","url":"https://huggingface.co/datasets/JacobLinCool/common_voice_19_0_zh-TW","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"rohingya_asr_audio","keyword":"automatic-speech-recognition","description":"This is the first public Rohingya language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains broadcast audio recordings from the Voice of America (VOA) Rohingya Service. Each file represents a daily news segment, typically 30 minutes in length, automatically segmented into chunks of 5‚Äì15 seconds for use in self-supervised ASR, pretraining, language identification, and more.\nThe content was aired publicly as part of VOA‚Äôs Rohingya-language radio program and is therefore‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/rohingya_asr_audio.","url":"https://huggingface.co/datasets/freococo/rohingya_asr_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Public Domain Dedication & License","license_url":"https://scancode-licensedb.aboutcode.org/pddl-1.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"trfttest1","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\ttrfttest1\n\t\n\nThis is a merged speech dataset containing 1258 audio segments from 3 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 1258\nSpeakers: 12\nLanguages: tr\nEmotions: neutral, angry, happy\nOriginal Datasets: 3\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/trfttest1.","url":"https://huggingface.co/datasets/Codyfederer/trfttest1","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"rohingya_asr_audio","keyword":"speech","description":"This is the first public Rohingya language ASR dataset in AI history.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains broadcast audio recordings from the Voice of America (VOA) Rohingya Service. Each file represents a daily news segment, typically 30 minutes in length, automatically segmented into chunks of 5‚Äì15 seconds for use in self-supervised ASR, pretraining, language identification, and more.\nThe content was aired publicly as part of VOA‚Äôs Rohingya-language radio program and is therefore‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/rohingya_asr_audio.","url":"https://huggingface.co/datasets/freococo/rohingya_asr_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Public Domain Dedication & License","license_url":"https://scancode-licensedb.aboutcode.org/pddl-1.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","found","original"],"keywords_longer_than_N":true},
	{"name":"trfttest1","keyword":"speech","description":"\n\t\n\t\t\n\t\ttrfttest1\n\t\n\nThis is a merged speech dataset containing 1258 audio segments from 3 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 1258\nSpeakers: 12\nLanguages: tr\nEmotions: neutral, angry, happy\nOriginal Datasets: 3\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/trfttest1.","url":"https://huggingface.co/datasets/Codyfederer/trfttest1","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"LSVSC","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tunofficial mirror of LSVSC dataset (novel large-scale Vietnamese speech corpus)\n\t\n\nofficial announcement: https://www.mdpi.com/2079-9292/13/5/977\nofficial download: https://drive.google.com/drive/folders/1tiPKaIOC7bt6isv5qFqf61O_2jFK8ZOI\n100h, 57k samples\npre-process: see my code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/clean-lsvsc.py\nneed to do: check misspelling, restore foreign words phonetised to vietnamese\nusage with HuggingFace:\n# pip install -q‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/LSVSC.","url":"https://huggingface.co/datasets/doof-ferb/LSVSC","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"trfttest1","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\ttrfttest1\n\t\n\nThis is a merged speech dataset containing 1258 audio segments from 3 source datasets.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nTotal Segments: 1258\nSpeakers: 12\nLanguages: tr\nEmotions: neutral, angry, happy\nOriginal Datasets: 3\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\naudio: Audio file (WAV format, original sampling rate preserved)\ntext: Transcription of the audio\nspeaker_id: Unique speaker identifier (made unique across all merged datasets)\nemotion: Detected emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Codyfederer/trfttest1.","url":"https://huggingface.co/datasets/Codyfederer/trfttest1","creator_name":"Hakan Kozaklƒ±","creator_url":"https://huggingface.co/Codyfederer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Turkish","cc-by-4.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"mabama-data","keyword":"automatic-speech-recognition","description":"aztro/mabama-data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/aztro/mabama-data","creator_name":"Jose Omar Vieyra","creator_url":"https://huggingface.co/aztro","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Spanish","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"wpp_pav_transcrito_openai","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tüé§ Transcri√ß√µes WhatsApp - OpenAI GPT-4o Transcribe\n\t\n\nEste dataset cont√©m transcri√ß√µes de mensagens de √°udio do WhatsApp geradas usando OpenAI GPT-4o Transcribe.\n\n\t\n\t\t\n\t\tüìã Descri√ß√£o\n\t\n\n\nOrigem: Mensagens de √°udio do WhatsApp em portugu√™s brasileiro\nModelo: OpenAI GPT-4o Transcribe\nPre√ßo: $6.00/1M tokens\nTotal de amostras: 198\nFormato de √°udio: WAV (16kHz)\nIdioma: Portugu√™s brasileiro\n\nModelo Whisper de alta precis√£o da OpenAI para transcri√ß√£o de √°udio.\n\n\t\n\t\t\n\t\n\t\n\t\tüìä Estat√≠sticas‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_openai.","url":"https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_openai","creator_name":"Bernardo Aires","creator_url":"https://huggingface.co/BernardoAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Lappland-the-Decadenza","keyword":"text-to-speech","description":"None1145/Lappland-the-Decadenza dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/None1145/Lappland-the-Decadenza","creator_name":"None","creator_url":"https://huggingface.co/None1145","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","Italian"],"keywords_longer_than_N":true},
	{"name":"bengali-language-audio","keyword":"speech","description":"\n\t\n\t\t\n\t\tBengali Language Audio Dataset\n\t\n\nText spoken by all participants:\n\"‡¶ï‡ßÉ‡¶§‡ßç‡¶∞‡¶ø‡¶Æ ‡¶¨‡ßÅ‡¶¶‡ßç‡¶ß‡¶ø‡¶Æ‡¶§‡ßç‡¶§‡¶æ (AI) ‡¶¶‡ßç‡¶∞‡ßÅ‡¶§ ‡¶¨‡¶ø‡¶ï‡¶∂‡¶ø‡¶§ ‡¶π‡¶ö‡ßç‡¶õ‡ßá, ‡¶¶‡ßà‡¶®‡¶®‡ßç‡¶¶‡¶ø‡¶® ‡¶ú‡ßÄ‡¶¨‡¶®‡¶ï‡ßá ‡¶∞‡ßÇ‡¶™‡¶æ‡¶®‡ßç‡¶§‡¶∞‡¶ø‡¶§ ‡¶ï‡¶∞‡¶õ‡ßá‡•§ ‡¶è‡¶∞ ‡¶â‡¶¶‡ßç‡¶≠‡¶æ‡¶¨‡¶® ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ, ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø‡¶∏‡ßá‡¶¨‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶ï‡¶æ‡¶ú‡¶ï‡ßá ‡¶â‡¶®‡ßç‡¶®‡¶§ ‡¶ï‡¶∞‡¶õ‡ßá, ‡¶®‡¶§‡ßÅ‡¶® ‡¶∏‡¶Æ‡ßç‡¶≠‡¶æ‡¶¨‡¶®‡¶æ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶õ‡ßá‡•§\"\nThe dataset supports training and evaluation of models in:\n\nAutomatic Speech Recognition (ASR)\nEmotional tone classification\nVoice synthesis and generation\nEmotion-aware conversational agents\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntended Uses\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t‚úÖ Direct Use\n\t\n\n\nTraining‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/bengali-language-audio.","url":"https://huggingface.co/datasets/Kratos-AI/bengali-language-audio","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","cc-by-4.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"KoGEM","keyword":"grammar","description":"\n\t\n\t\t\n\t\tDataset Card for KoGEM\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nKoGEM is a benchmark designed to assess Korean linguistic competence in both large language models (LLMs) and humans through 1.5k multiple-choice questions covering five main linguistic categories with 16 subcategories. Refer to the [not yet](not yet) for more details.\n\n\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\n# pip install -q datasets\nfrom datasets import load_dataset\ndataset = load_dataset(\"Poppo/KoGEM\")[\"test\"]\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Poppo/KoGEM.","url":"https://huggingface.co/datasets/Poppo/KoGEM","creator_name":"SungHo Kim","creator_url":"https://huggingface.co/Poppo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","Korean","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"VietMed_labeled","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tunofficial mirror of VietMed (Vietnamese speech data in medical domain) labeled set\n\t\n\nofficial announcement: https://arxiv.org/abs/2404.05659\nofficial download: https://huggingface.co/datasets/leduckhai/VietMed\nthis repo contains the labeled set: 9.2k samples\ni also gather the metadata: see info.csv\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/vietmed-labeled.py\nneed to do: check misspelling, restore foreign words phonetised to vietnamese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/VietMed_labeled.","url":"https://huggingface.co/datasets/doof-ferb/VietMed_labeled","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"mls-annotated","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of non English MLS\n\t\n\nThis dataset consists in annotations of a the Non English subset of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours for other languages.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/mls-annotated.","url":"https://huggingface.co/datasets/PHBJT/mls-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","French","German","Dutch","Portuguese"],"keywords_longer_than_N":true},
	{"name":"VietMed_labeled","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tunofficial mirror of VietMed (Vietnamese speech data in medical domain) labeled set\n\t\n\nofficial announcement: https://arxiv.org/abs/2404.05659\nofficial download: https://huggingface.co/datasets/leduckhai/VietMed\nthis repo contains the labeled set: 9.2k samples\ni also gather the metadata: see info.csv\nmy extraction code: https://github.com/phineas-pta/fine-tune-whisper-vi/blob/main/misc/vietmed-labeled.py\nneed to do: check misspelling, restore foreign words phonetised to vietnamese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/doof-ferb/VietMed_labeled.","url":"https://huggingface.co/datasets/doof-ferb/VietMed_labeled","creator_name":"Phan Tu·∫•n Anh","creator_url":"https://huggingface.co/doof-ferb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MultiMed-TSS","keyword":"automatic-speech-recognition","description":"SehwanMoon/MultiMed-TSS dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/SehwanMoon/MultiMed-TSS","creator_name":"Sehwan Moon","creator_url":"https://huggingface.co/SehwanMoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","German","French","Chinese"],"keywords_longer_than_N":true},
	{"name":"stock_market_asx_audio","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Stock Market ASX Audio\n\t\n\nContains audios for every listed company on the Australian Stock Exchange (ASX). The dataset contains 2329 audio files of people saying the name of the company.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nsentence_id (string): An id for the sentence used for the recording.\nvoice_id (string): An id for which client (voice) made the recording.\naudio (dict): A dictionary containing the path to the downloaded audio file.\nsentence (string): The sentence the user was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sdeering/stock_market_asx_audio.","url":"https://huggingface.co/datasets/sdeering/stock_market_asx_audio","creator_name":"Sam","creator_url":"https://huggingface.co/sdeering","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","sdeering","google translate","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"multi-hatecheck","keyword":"hate-speech-detection","description":"\n  MultiHateClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHate speech detection dataset with binary\n                       (hateful vs non-hateful) labels. Includes 25+ distinct types of hate\n                       and challenging non-hate, and 11 languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nConstructed, Written\n\n\nReference\nhttps://aclanthology.org/2022.woah-1.15/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/multi-hatecheck.","url":"https://huggingface.co/datasets/mteb/multi-hatecheck","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"MovieReviewSentimentClassification","keyword":"hate-speech-detection","description":"\n  MovieReviewSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Allocin√© dataset is a French-language dataset for sentiment analysis that contains movie reviews produced by the online community of the Allocin√©.fr website.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\nDomains\nReviews, Written\n\n\nReference\nhttps://github.com/TheophileBlard/french-sentiment-analysis-with-bert\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MovieReviewSentimentClassification.","url":"https://huggingface.co/datasets/mteb/MovieReviewSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"makise-kurisu-vn-voicelines","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tMakise Kurisu VN dialogue\n\t\n\nTranscribed using Whisper Large-V2 from this video.\nClips were separated via pydub, so some text may be incorrect. I have not cleaned it up at all. \nIntended for TTS model training. \nI do not own any of the content. \n","url":"https://huggingface.co/datasets/zhonglongbao/makise-kurisu-vn-voicelines","creator_name":"zhonglongbao","creator_url":"https://huggingface.co/zhonglongbao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Japanese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"ContextASR-Bench","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tContextASR-Bench: A Massive Contextual Speech Recognition Benchmark\n\t\n\n\n\n\n\nAutomatic Speech Recognition (ASR) has been extensively investigated, yet prior benchmarks have largely focused on assessing the acoustic robustness of ASR models, leaving evaluations of their linguistic capabilities relatively underexplored. This largely stems from the limited parameter sizes and training corpora of conventional ASR models, leaving them with insufficient world knowledge, which is crucial for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MrSupW/ContextASR-Bench.","url":"https://huggingface.co/datasets/MrSupW/ContextASR-Bench","creator_name":"He Wang","creator_url":"https://huggingface.co/MrSupW","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ContextASR-Bench","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tContextASR-Bench: A Massive Contextual Speech Recognition Benchmark\n\t\n\n\n\n\n\nAutomatic Speech Recognition (ASR) has been extensively investigated, yet prior benchmarks have largely focused on assessing the acoustic robustness of ASR models, leaving evaluations of their linguistic capabilities relatively underexplored. This largely stems from the limited parameter sizes and training corpora of conventional ASR models, leaving them with insufficient world knowledge, which is crucial for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MrSupW/ContextASR-Bench.","url":"https://huggingface.co/datasets/MrSupW/ContextASR-Bench","creator_name":"He Wang","creator_url":"https://huggingface.co/MrSupW","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"cml-tts-filtered","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tDataset Card for Filtred and CML-TTS\n\t\n\nThis dataset is a filtred version of a CML-TTS [1]. \nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered.","url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","French","German","Dutch","Polish"],"keywords_longer_than_N":true},
	{"name":"ToneSlavic","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tToneSlavic\n\t\n\nToneSlavic ‚Äî —ç—Ç–æ –¥–∞—Ç–∞—Å–µ—Ç, —Å–æ–±—Ä–∞–Ω–Ω—ã–π –∏–∑ —Ä—É—Å—Å–∫–∏—Ö, –±–µ–ª–æ—Ä—É—Å—Å–∫–∏—Ö –∏ —É–∫—Ä–∞–∏–Ω—Å–∫–∏—Ö —Å–ø–ª–∏—Ç–æ–≤ –¥–∞—Ç–∞—Å–µ—Ç–∞ Common Voice Corpus 21.0. –í –≤—ã–±–æ—Ä–∫—É –≤–æ—à–ª–∏ —Ç–æ–ª—å–∫–æ —Ñ—Ä–∞–∑—ã –∏–∑ —Ñ–∞–π–ª–æ–≤ validated.tsv.\n\n\n\t\n\t\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ\n\t\n\n–î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—Ç—Å—è:\n\n–°—Å—ã–ª–∫–∞ –Ω–∞ MP3-—Ñ–∞–π–ª (audio)\n–¢–µ–∫—Å—Ç–æ–≤–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ (text)\n–Ø–∑—ã–∫ –ø—Ä–∏–º–µ—Ä–∞ (locale)\n\n\nru ‚Äî —Ä—É—Å—Å–∫–∏–π  \nbe ‚Äî –±–µ–ª–æ—Ä—É—Å—Å–∫–∏–π  \nuk ‚Äî —É–∫—Ä–∞–∏–Ω—Å–∫–∏–π\n\n–í –¥–∞—Ç–∞—Å–µ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —Å–ø–ª–∏—Ç–∞–º –∏ —è–∑—ã–∫–∞–º:\n\nTrain (1 475 164 —Å—Ç—Ä–æ–∫, 1 968.22 —á–∞—Å–æ–≤ –∞—É–¥–∏–æ):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneSlavic.","url":"https://huggingface.co/datasets/Vikhrmodels/ToneSlavic","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Russian","Belarusian","Ukrainian"],"keywords_longer_than_N":true},
	{"name":"Multi-Talker-SD","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Card for Multi-Talker-SD\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMulti-Talker-SD is a large-scale bilingual (English‚ÄìMandarin) multi-speaker meeting dataset designed to support research on speaker diarization and meeting transcription.  \n\nSize: 1,000 simulated meetings  \nParticipants per meeting: 10‚Äì30 speakers  \nAverage duration: ~20 minutes per meeting, up to one hour  \nLanguages: English, Mandarin (code-switching possible)  \nAudio characteristics: realistic speaker overlap‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yihao005/Multi-Talker-SD.","url":"https://huggingface.co/datasets/yihao005/Multi-Talker-SD","creator_name":"wu","creator_url":"https://huggingface.co/yihao005","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","Chinese","apache-2.0","Audio"],"keywords_longer_than_N":true},
	{"name":"sTinyStories","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tsTinyStories\n\t\n\nA spoken version of TinyStories Synthesized with LJ voice using FastSpeech2.\nThe dataset was synthesized to boost the training of Speech Language Models as detailed in the paper \"Slamming: Training a Speech Language Model on One GPU in a Day\".\nIt was first suggested by Cuervo et. al 2024.\nWe refer you to the SlamKit codebase to see how you can train a SpeechLM with this dataset.\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets importload_dataset\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slprl/sTinyStories.","url":"https://huggingface.co/datasets/slprl/sTinyStories","creator_name":"SLP-RL HUJI","creator_url":"https://huggingface.co/slprl","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","mit"],"keywords_longer_than_N":true},
	{"name":"uzbek_speech_data","keyword":"automatic-speech-recognition","description":"Beehzod/uzbek_speech_data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Beehzod/uzbek_speech_data","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"BigAudioDataset","keyword":"speech-recognition","description":"\n\t\n\t\t\n\t\tAstraMindAI/BigAudioDataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAstraMindAI/BigAudioDataset is a large-scale, multilingual dataset designed for a wide range of audio and speech processing tasks. It comprises a diverse collection of audio clips, including both spoken voice and music, making it a valuable resource for training and evaluating models for automatic speech recognition (ASR), text-to-speech (TTS), audio classification, and more.\nThe voice data is aggregated from well-known‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AstraMindAI/BigAudioDataset.","url":"https://huggingface.co/datasets/AstraMindAI/BigAudioDataset","creator_name":"AstraMindAI","creator_url":"https://huggingface.co/AstraMindAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","English","Italian","French","German"],"keywords_longer_than_N":true},
	{"name":"ToneSlavic","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tToneSlavic\n\t\n\nToneSlavic ‚Äî —ç—Ç–æ –¥–∞—Ç–∞—Å–µ—Ç, —Å–æ–±—Ä–∞–Ω–Ω—ã–π –∏–∑ —Ä—É—Å—Å–∫–∏—Ö, –±–µ–ª–æ—Ä—É—Å—Å–∫–∏—Ö –∏ —É–∫—Ä–∞–∏–Ω—Å–∫–∏—Ö —Å–ø–ª–∏—Ç–æ–≤ –¥–∞—Ç–∞—Å–µ—Ç–∞ Common Voice Corpus 21.0. –í –≤—ã–±–æ—Ä–∫—É –≤–æ—à–ª–∏ —Ç–æ–ª—å–∫–æ —Ñ—Ä–∞–∑—ã –∏–∑ —Ñ–∞–π–ª–æ–≤ validated.tsv.\n\n\n\t\n\t\t\n\t\t–û–ø–∏—Å–∞–Ω–∏–µ\n\t\n\n–î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—Ç—Å—è:\n\n–°—Å—ã–ª–∫–∞ –Ω–∞ MP3-—Ñ–∞–π–ª (audio)\n–¢–µ–∫—Å—Ç–æ–≤–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ (text)\n–Ø–∑—ã–∫ –ø—Ä–∏–º–µ—Ä–∞ (locale)\n\n\nru ‚Äî —Ä—É—Å—Å–∫–∏–π  \nbe ‚Äî –±–µ–ª–æ—Ä—É—Å—Å–∫–∏–π  \nuk ‚Äî —É–∫—Ä–∞–∏–Ω—Å–∫–∏–π\n\n–í –¥–∞—Ç–∞—Å–µ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —Å–ø–ª–∏—Ç–∞–º –∏ —è–∑—ã–∫–∞–º:\n\nTrain (1 475 164 —Å—Ç—Ä–æ–∫, 1 968.22 —á–∞—Å–æ–≤ –∞—É–¥–∏–æ):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/ToneSlavic.","url":"https://huggingface.co/datasets/Vikhrmodels/ToneSlavic","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Russian","Belarusian","Ukrainian"],"keywords_longer_than_N":true},
	{"name":"sTinyStories","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tsTinyStories\n\t\n\nA spoken version of TinyStories Synthesized with LJ voice using FastSpeech2.\nThe dataset was synthesized to boost the training of Speech Language Models as detailed in the paper \"Slamming: Training a Speech Language Model on One GPU in a Day\".\nIt was first suggested by Cuervo et. al 2024.\nWe refer you to the SlamKit codebase to see how you can train a SpeechLM with this dataset.\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets importload_dataset\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slprl/sTinyStories.","url":"https://huggingface.co/datasets/slprl/sTinyStories","creator_name":"SLP-RL HUJI","creator_url":"https://huggingface.co/slprl","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","mit"],"keywords_longer_than_N":true},
	{"name":"BigAudioDataset","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tAstraMindAI/BigAudioDataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAstraMindAI/BigAudioDataset is a large-scale, multilingual dataset designed for a wide range of audio and speech processing tasks. It comprises a diverse collection of audio clips, including both spoken voice and music, making it a valuable resource for training and evaluating models for automatic speech recognition (ASR), text-to-speech (TTS), audio classification, and more.\nThe voice data is aggregated from well-known‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AstraMindAI/BigAudioDataset.","url":"https://huggingface.co/datasets/AstraMindAI/BigAudioDataset","creator_name":"AstraMindAI","creator_url":"https://huggingface.co/AstraMindAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","English","Italian","French","German"],"keywords_longer_than_N":true},
	{"name":"russian_librispeech","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tRussian LibriSpeech (RuLS)\n\t\n\nIdentifier: SLR96 from openslr.org\nSummary: This dataset is based on LibriVox audiobooks\nCategory: Speech\nLicense: The dataset is Public Domain in the USA.\nAbout this resource:\nRussian LibriSpeech (RuLS) dataset is based on LibriVox's public domain audio books (see BOOKS.TXT for the list of included books) and contains about 98 hours of audio data.\n","url":"https://huggingface.co/datasets/istupakov/russian_librispeech","creator_name":"Ilya Stupakov","creator_url":"https://huggingface.co/istupakov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Russian","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"acl-6060","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tACL 60/60\n\t\n\n\n\t\n\t\t\n\t\tDataset details\n\t\n\nACL 60/60 evaluation sets for multilingual translation of ACL 2022 technical presentations into 10 target languages.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@inproceedings{salesky-etal-2023-evaluating,\n    title = \"Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology\",\n    author = \"Salesky, Elizabeth  and\n      Darwish, Kareem  and\n      Al-Badrashiny, Mohamed  and\n      Diab, Mona  and\n      Niehues, Jan\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/acl-6060.","url":"https://huggingface.co/datasets/ymoslem/acl-6060","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","automatic-speech-recognition","English","Arabic","German"],"keywords_longer_than_N":true},
	{"name":"russian_librispeech","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tRussian LibriSpeech (RuLS)\n\t\n\nIdentifier: SLR96 from openslr.org\nSummary: This dataset is based on LibriVox audiobooks\nCategory: Speech\nLicense: The dataset is Public Domain in the USA.\nAbout this resource:\nRussian LibriSpeech (RuLS) dataset is based on LibriVox's public domain audio books (see BOOKS.TXT for the list of included books) and contains about 98 hours of audio data.\n","url":"https://huggingface.co/datasets/istupakov/russian_librispeech","creator_name":"Ilya Stupakov","creator_url":"https://huggingface.co/istupakov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Russian","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"9000hours_voa_burmese_audio","keyword":"speech","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nVOA Burmese radio news archive covering Morning (·Äî·Ä∂·Äî·ÄÄ·Ä∫ ·ÅÖ:·ÅÉ·ÅÄ ‚Äì ·ÅÜ:·ÅÉ·ÅÄ) and Evening (·Ää·Äï·Ä≠·ÄØ·ÄÑ·Ä∫·Ä∏ ·Åâ:·ÅÄ·ÅÄ ‚Äì ·ÅÅ·ÅÄ:·ÅÄ·ÅÄ) programmes for every calendar day from 2012-09-16 ‚Üí 2025-06-09.\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nHours / rows\n9 159\n\n\nFiles per day\n2 (morning, evening)\n\n\nTypical file size\n15 ‚Äì 50 MB\n\n\nLicence\nPublic-domain (VOA staff recordings, U.S. 17 U.S.C. ¬ß 105)\n\n\n\t\n\nThis dataset upgrades Burmese from low-resource to mid-resource status for speech research, enabling self-supervised‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/9000hours_voa_burmese_audio.","url":"https://huggingface.co/datasets/freococo/9000hours_voa_burmese_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Public Domain Dedication & License","license_url":"https://scancode-licensedb.aboutcode.org/pddl-1.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","pddl"],"keywords_longer_than_N":true},
	{"name":"9000hours_voa_burmese_audio","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nVOA Burmese radio news archive covering Morning (·Äî·Ä∂·Äî·ÄÄ·Ä∫ ·ÅÖ:·ÅÉ·ÅÄ ‚Äì ·ÅÜ:·ÅÉ·ÅÄ) and Evening (·Ää·Äï·Ä≠·ÄØ·ÄÑ·Ä∫·Ä∏ ·Åâ:·ÅÄ·ÅÄ ‚Äì ·ÅÅ·ÅÄ:·ÅÄ·ÅÄ) programmes for every calendar day from 2012-09-16 ‚Üí 2025-06-09.\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nHours / rows\n9 159\n\n\nFiles per day\n2 (morning, evening)\n\n\nTypical file size\n15 ‚Äì 50 MB\n\n\nLicence\nPublic-domain (VOA staff recordings, U.S. 17 U.S.C. ¬ß 105)\n\n\n\t\n\nThis dataset upgrades Burmese from low-resource to mid-resource status for speech research, enabling self-supervised‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/9000hours_voa_burmese_audio.","url":"https://huggingface.co/datasets/freococo/9000hours_voa_burmese_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Public Domain Dedication & License","license_url":"https://scancode-licensedb.aboutcode.org/pddl-1.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-to-audio","audio-classification","Burmese","pddl"],"keywords_longer_than_N":true},
	{"name":"audio_recordings","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tAudio Recordings\n\t\n\nThese are some personal and open source audio recordings. Feel free to use.\n","url":"https://huggingface.co/datasets/da2ce7/audio_recordings","creator_name":"Cam","creator_url":"https://huggingface.co/da2ce7","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","audio-text-to-text","any-to-any","text-to-speech","English"],"keywords_longer_than_N":true},
	{"name":"wpp_pav_transcrito_gemini","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tüé§ Transcri√ß√µes WhatsApp - Google Gemini 2.0 Flash\n\t\n\nEste dataset cont√©m transcri√ß√µes de mensagens de √°udio do WhatsApp geradas usando Google Gemini 2.0 Flash.\n\n\t\n\t\t\n\t\tüìã Descri√ß√£o\n\t\n\n\nOrigem: Mensagens de √°udio do WhatsApp em portugu√™s brasileiro\nModelo: Google Gemini 2.0 Flash\nPre√ßo: $0.075/1M tokens\nTotal de amostras: 198\nFormato de √°udio: WAV (16kHz)\nIdioma: Portugu√™s brasileiro\n\nModelo de IA multimodal avan√ßado da Google com capacidades de an√°lise contextual de √°udio.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_gemini.","url":"https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_gemini","creator_name":"Bernardo Aires","creator_url":"https://huggingface.co/BernardoAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"YouTube-Cantonese","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tCantonese Audio Dataset from YouTube\n\t\n\nThis dataset contains Cantonese audio segments and creator uploaded transcripts (likely higher quality) extracted from various YouTube channels, along with corresponding transcript metadata. The data is intended for training automatic speech recognition (ASR) models.\n\n\t\n\t\t\n\t\tData Source and Processing\n\t\n\nThe data was obtained through the following process:\n\nDownload: Audio (.m4a) and available Cantonese subtitles (.srt for zh-TW, zh-HK, zh-Hant)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OrcinusOrca/YouTube-Cantonese.","url":"https://huggingface.co/datasets/OrcinusOrca/YouTube-Cantonese","creator_name":"Orca","creator_url":"https://huggingface.co/OrcinusOrca","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","Yue Chinese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"be-sidon-restored-sample-100","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tbe-sidon-restored-sample-100\n\t\n\n–ù–∞–±–æ—Ä –ø—Ä—ã–∫–ª–∞–¥–∞—û –±–µ–ª–∞—Ä—É—Å–∫–∞–π –º–æ–≤—ã –∑ Common Voice (validated), –∞–ø—Ä–∞—Ü–∞–≤–∞–Ω—ã –º–∞–¥—ç–ª–ª—é –∞–¥–Ω–∞—û–ª–µ–Ω–Ω—è (denoise).\n\n\t\n\t\t\n\t\t–§–∞–π–ª—ã\n\t\n\n\naudio/original/ ‚Äî –∞—Ä—ã–≥—ñ–Ω–∞–ª—å–Ω—ã—è –∫–ª—ñ–ø—ã (—è–∫ —É Common Voice).\naudio/restored/ ‚Äî –∞–¥–Ω–æ—û–ª–µ–Ω—ã—è WAV (48 –∫–ì—Ü).\nmetadata.csv ‚Äî –ø–∞–ª–µ—Ç–∫—ñ: audio, original_audio, sentence, speaker.\n\n–î–∞—Ç–∞ —Å—Ç–≤–∞—Ä—ç–Ω–Ω—è: 2025-09-25.\n","url":"https://huggingface.co/datasets/archivartaunik/be-sidon-restored-sample-100","creator_name":"vartaunik","creator_url":"https://huggingface.co/archivartaunik","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","common_voice","Belarusian","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"fptu-vovinam-dataset","keyword":"speech","description":"\n\t\n\t\t\n\t\tFPTU Vovinam Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Vietnamese audio recordings with corresponding text transcriptions, specifically focused on Vovinam martial arts terminology and instruction. This dataset is created by FPT University for research and educational purposes in the field of Vietnamese speech recognition and natural language processing.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nAudio Files: High-quality audio recordings in AAC format (uploaded as raw data)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/minhtien2405/fptu-vovinam-dataset.","url":"https://huggingface.co/datasets/minhtien2405/fptu-vovinam-dataset","creator_name":"Pham Minh Tien","creator_url":"https://huggingface.co/minhtien2405","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"fptu-vovinam-dataset","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tFPTU Vovinam Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Vietnamese audio recordings with corresponding text transcriptions, specifically focused on Vovinam martial arts terminology and instruction. This dataset is created by FPT University for research and educational purposes in the field of Vietnamese speech recognition and natural language processing.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nAudio Files: High-quality audio recordings in AAC format (uploaded as raw data)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/minhtien2405/fptu-vovinam-dataset.","url":"https://huggingface.co/datasets/minhtien2405/fptu-vovinam-dataset","creator_name":"Pham Minh Tien","creator_url":"https://huggingface.co/minhtien2405","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"fptu-vovinam-dataset","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tFPTU Vovinam Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Vietnamese audio recordings with corresponding text transcriptions, specifically focused on Vovinam martial arts terminology and instruction. This dataset is created by FPT University for research and educational purposes in the field of Vietnamese speech recognition and natural language processing.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nAudio Files: High-quality audio recordings in AAC format (uploaded as raw data)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/minhtien2405/fptu-vovinam-dataset.","url":"https://huggingface.co/datasets/minhtien2405/fptu-vovinam-dataset","creator_name":"Pham Minh Tien","creator_url":"https://huggingface.co/minhtien2405","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Vietnamese","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"myanmar-speech-dataset-google-fleurs","keyword":"automatic-speech-recognition","description":"Please visit to the GitHub repository for other Myanmar Langauge datasets.\n\n\t\n\t\t\n\t\tMyanmar Speech Dataset (Google Fleurs)\n\t\n\nThis dataset consists exclusively of Myanmar speech recordings, extracted from the larger multilingual Google Fleurs dataset.\nFor the complete multilingual dataset and additional information, please visit the original dataset repository \nof Google Fleurs HuggingFace page.\n\n\t\n\t\t\n\t\tOriginal Source\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-google-fleurs.","url":"https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-google-fleurs","creator_name":"Chuu Htet Naing","creator_url":"https://huggingface.co/chuuhtetnaing","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Burmese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"myanmar-speech-dataset-google-fleurs","keyword":"speech-recognition","description":"Please visit to the GitHub repository for other Myanmar Langauge datasets.\n\n\t\n\t\t\n\t\tMyanmar Speech Dataset (Google Fleurs)\n\t\n\nThis dataset consists exclusively of Myanmar speech recordings, extracted from the larger multilingual Google Fleurs dataset.\nFor the complete multilingual dataset and additional information, please visit the original dataset repository \nof Google Fleurs HuggingFace page.\n\n\t\n\t\t\n\t\tOriginal Source\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-google-fleurs.","url":"https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-google-fleurs","creator_name":"Chuu Htet Naing","creator_url":"https://huggingface.co/chuuhtetnaing","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Burmese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"myanmar-speech-dataset-google-fleurs","keyword":"text-to-speech","description":"Please visit to the GitHub repository for other Myanmar Langauge datasets.\n\n\t\n\t\t\n\t\tMyanmar Speech Dataset (Google Fleurs)\n\t\n\nThis dataset consists exclusively of Myanmar speech recordings, extracted from the larger multilingual Google Fleurs dataset.\nFor the complete multilingual dataset and additional information, please visit the original dataset repository \nof Google Fleurs HuggingFace page.\n\n\t\n\t\t\n\t\tOriginal Source\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-google-fleurs.","url":"https://huggingface.co/datasets/chuuhtetnaing/myanmar-speech-dataset-google-fleurs","creator_name":"Chuu Htet Naing","creator_url":"https://huggingface.co/chuuhtetnaing","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Burmese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_ru","keyword":"speech","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\n–ù–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö validated.tsv –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ down_votes = 0\n\n\t\n\t\t\n\t\tüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n\t\n\n\n\t\n\t\t\n\t\t–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Å–ø–ª–∏—Ç–∞–º\n\t\n\n\n\t\n\t\t\n\t\tüîπ –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –Ω–∞–±–æ—Ä (train)\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–º–ø–ª–æ–≤\n93,531\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n132.25 —á–∞—Å–æ–≤ (476,089.70 —Å–µ–∫—É–Ω–¥)\n\n\n–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–º–ø–ª–∞\n5.09 —Å–µ–∫—É–Ω–¥\n\n\n\t\n\n\n\t\n\t\t\n\t\tüîπ –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä (validate)\n\t\n\n\n\t\n\t\t\n–ú–µ—Ç—Ä–∏–∫–∞\n–ó–Ω–∞—á–µ–Ω–∏–µ\n\n\n\t\t\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–º–ø–ª–æ–≤\n38,836\n\n\n–û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n55.21‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sh1man/common_voice_21_ru.","url":"https://huggingface.co/datasets/Sh1man/common_voice_21_ru","creator_name":"dd","creator_url":"https://huggingface.co/Sh1man","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","Russian","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"dsb_audio_corpus","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tAcknowledgements\n\t\n\n\nThanks to all speakers that contributed to this dataset!\nThanks to \"Ludowe Nak≈Çadnistwo Domowina\" and \"Rƒõƒçny Centrum WITAJ\" for donation of their recordings!\n\n","url":"https://huggingface.co/datasets/Serbski-institut/dsb_audio_corpus","creator_name":"Serbski institut z.t. / Sorbisches Institut e.V.","creator_url":"https://huggingface.co/Serbski-institut","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Lower Sorbian","cc-by-4.0","10K - 100K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"zoengjyutgaai","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tÂºµÊÇ¶Ê•∑Ë¨õÂè§Ë™ûÈü≥Êï∏ÊìöÈõÜ\n\t\n\nEnglish\nÂë¢ÂÄã‰øÇÂºµÊÇ¶Ê•∑Ë¨õ„Ää‰∏âÂúãÊºîÁæ©„Äã„ÄÅ„ÄäÊ∞¥Êª∏ÂÇ≥„Äã„ÄÅ„ÄäËµ∞ÈÄ≤ÊØõÊæ§Êù±ÁöÑÊúÄÂæåÊ≠≤Êúà„Äã„ÄÅ„ÄäÈπøÈºéË®ò„ÄãË™ûÈü≥Êï∏ÊìöÈõÜ„ÄÇÂºµÊÇ¶Ê•∑‰øÇÂª£Â∑ûÊúÄÂá∫ÂêçÂòÖË¨õÂè§‰Ω¨ / Á≤µË™ûË™¨Êõ∏Ëóù‰∫∫„ÄÇ‰Ω¢Âæû‰∏ä‰∏ñÁ¥Ä‰∏ÉÂçÅÂπ¥‰ª£ÈñãÂßãÂ∞±Âñ∫Âª£Êù±ÂêÑÂÄãÊî∂Èü≥ÈõªÂè∞Â∫¶Ë¨õÂè§Ôºå‰Ω¢ÊääËÅ≤‰øÇÂ•ΩÂ§öÂª£Â∑û‰∫∫ÂòÖÂÖ±ÂêåÂõûÊÜ∂„ÄÇÊú¨Êï∏ÊìöÈõÜÊî∂ÈõÜÂòÖ‰øÇ‰Ω¢ÊúÄÁü•ÂêçÂòÖÂõõÈÉ®‰ΩúÂìÅ„ÄÇ\nÊï∏ÊìöÈõÜÁî®ÈÄîÔºö\n\nTTSÔºàË™ûÈü≥ÂêàÊàêÔºâË®ìÁ∑¥ÈõÜ\nASRÔºàË™ûÈü≥Ë≠òÂà•ÔºâË®ìÁ∑¥ÈõÜÊàñÊ∏¨Ë©¶ÈõÜ\nÂêÑÁ®ÆË™ûË®ÄÂ≠∏„ÄÅÊñáÂ≠∏Á†îÁ©∂\nÁõ¥Êé•ËÅΩÂöüÊ¨£Ë≥ûËóùË°ìÔºÅ\n\nTTS ÊïàÊûúÊºîÁ§∫Ôºöhttps://huggingface.co/spaces/laubonghaudoi/zoengjyutgaai_tts\n\n\t\n\t\t\n\t\n\t\n\t\tË™¨Êòé\n\t\n\n\nÊâÄÊúâÊñáÊú¨ÈÉΩÊ†πÊìö https://jyutping.org/blog/typo/ Âêå https://jyutping.org/blog/particles/ Ë¶èÁØÑÁî®Â≠ó„ÄÇ\nÊâÄÊúâÊñáÊú¨ÈÉΩ‰ΩøÁî®ÂÖ®ËßíÊ®ôÈªûÔºåÂÜáÂçäËßíÊ®ôÈªû„ÄÇ\nÊâÄÊúâÊñáÊú¨ÈÉΩÁî®Êº¢Â≠óËΩâÂØ´ÔºåÁÑ°ÈòøÊãâ‰ºØÊï∏Â≠óÁÑ°Ëã±ÊñáÂ≠óÊØç\nÊâÄÊúâÈü≥È†ªÊ∫êÈÉΩÂ≠òÊîæÂñ∫/sourceÔºåÁÇ∫Êñπ‰æøÁõ¥Êé•Áî®‰ΩúË®ìÁ∑¥Êï∏ÊìöÔºåÂàáÂàÜÂæåÂòÖÈü≥È†ªÈÉΩÊîæÂñ∫ opus/\nÊâÄÊúâ opus Èü≥È†ªÁöÜÁÇ∫ 48000‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CanCLID/zoengjyutgaai.","url":"https://huggingface.co/datasets/CanCLID/zoengjyutgaai","creator_name":"Á≤µË™ûË®àÁÆóË™ûË®ÄÂ≠∏Âü∫Á§éÂª∫Ë®≠ÁµÑ (CanCLID)","creator_url":"https://huggingface.co/CanCLID","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-generation","feature-extraction","audio-to-audio"],"keywords_longer_than_N":true},
	{"name":"kachin_asr_audio","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the first public Kachin language ASR dataset in history.\nKachin ASR Audio is a collection of speech data in the Kachin (Jinghpaw) language, sourced entirely from publicly available PVTV (People‚Äôs Voice Television) broadcasts. The dataset includes narration, interviews, and spoken reports intended to support the development of automatic speech recognition (ASR) systems for rare-resource indigenous languages in Myanmar.\nEach audio file is paired with metadata‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/kachin_asr_audio.","url":"https://huggingface.co/datasets/freococo/kachin_asr_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","manual","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"kachin_asr_audio","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the first public Kachin language ASR dataset in history.\nKachin ASR Audio is a collection of speech data in the Kachin (Jinghpaw) language, sourced entirely from publicly available PVTV (People‚Äôs Voice Television) broadcasts. The dataset includes narration, interviews, and spoken reports intended to support the development of automatic speech recognition (ASR) systems for rare-resource indigenous languages in Myanmar.\nEach audio file is paired with metadata‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/kachin_asr_audio.","url":"https://huggingface.co/datasets/freococo/kachin_asr_audio","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","manual","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"LccSentimentClassification","keyword":"hate-speech-detection","description":"\n  LccSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe leipzig corpora collection, annotated for sentiment\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Web, Written\n\n\nReference\nhttps://github.com/fnielsen/lcc-sentiment\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"LccSentimentClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LccSentimentClassification.","url":"https://huggingface.co/datasets/mteb/LccSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"zoengjyutgaai","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tÂºµÊÇ¶Ê•∑Ë¨õÂè§Ë™ûÈü≥Êï∏ÊìöÈõÜ\n\t\n\nEnglish\nÂë¢ÂÄã‰øÇÂºµÊÇ¶Ê•∑Ë¨õ„Ää‰∏âÂúãÊºîÁæ©„Äã„ÄÅ„ÄäÊ∞¥Êª∏ÂÇ≥„Äã„ÄÅ„ÄäËµ∞ÈÄ≤ÊØõÊæ§Êù±ÁöÑÊúÄÂæåÊ≠≤Êúà„Äã„ÄÅ„ÄäÈπøÈºéË®ò„ÄãË™ûÈü≥Êï∏ÊìöÈõÜ„ÄÇÂºµÊÇ¶Ê•∑‰øÇÂª£Â∑ûÊúÄÂá∫ÂêçÂòÖË¨õÂè§‰Ω¨ / Á≤µË™ûË™¨Êõ∏Ëóù‰∫∫„ÄÇ‰Ω¢Âæû‰∏ä‰∏ñÁ¥Ä‰∏ÉÂçÅÂπ¥‰ª£ÈñãÂßãÂ∞±Âñ∫Âª£Êù±ÂêÑÂÄãÊî∂Èü≥ÈõªÂè∞Â∫¶Ë¨õÂè§Ôºå‰Ω¢ÊääËÅ≤‰øÇÂ•ΩÂ§öÂª£Â∑û‰∫∫ÂòÖÂÖ±ÂêåÂõûÊÜ∂„ÄÇÊú¨Êï∏ÊìöÈõÜÊî∂ÈõÜÂòÖ‰øÇ‰Ω¢ÊúÄÁü•ÂêçÂòÖÂõõÈÉ®‰ΩúÂìÅ„ÄÇ\nÊï∏ÊìöÈõÜÁî®ÈÄîÔºö\n\nTTSÔºàË™ûÈü≥ÂêàÊàêÔºâË®ìÁ∑¥ÈõÜ\nASRÔºàË™ûÈü≥Ë≠òÂà•ÔºâË®ìÁ∑¥ÈõÜÊàñÊ∏¨Ë©¶ÈõÜ\nÂêÑÁ®ÆË™ûË®ÄÂ≠∏„ÄÅÊñáÂ≠∏Á†îÁ©∂\nÁõ¥Êé•ËÅΩÂöüÊ¨£Ë≥ûËóùË°ìÔºÅ\n\nTTS ÊïàÊûúÊºîÁ§∫Ôºöhttps://huggingface.co/spaces/laubonghaudoi/zoengjyutgaai_tts\n\n\t\n\t\t\n\t\n\t\n\t\tË™¨Êòé\n\t\n\n\nÊâÄÊúâÊñáÊú¨ÈÉΩÊ†πÊìö https://jyutping.org/blog/typo/ Âêå https://jyutping.org/blog/particles/ Ë¶èÁØÑÁî®Â≠ó„ÄÇ\nÊâÄÊúâÊñáÊú¨ÈÉΩ‰ΩøÁî®ÂÖ®ËßíÊ®ôÈªûÔºåÂÜáÂçäËßíÊ®ôÈªû„ÄÇ\nÊâÄÊúâÊñáÊú¨ÈÉΩÁî®Êº¢Â≠óËΩâÂØ´ÔºåÁÑ°ÈòøÊãâ‰ºØÊï∏Â≠óÁÑ°Ëã±ÊñáÂ≠óÊØç\nÊâÄÊúâÈü≥È†ªÊ∫êÈÉΩÂ≠òÊîæÂñ∫/sourceÔºåÁÇ∫Êñπ‰æøÁõ¥Êé•Áî®‰ΩúË®ìÁ∑¥Êï∏ÊìöÔºåÂàáÂàÜÂæåÂòÖÈü≥È†ªÈÉΩÊîæÂñ∫ opus/\nÊâÄÊúâ opus Èü≥È†ªÁöÜÁÇ∫ 48000‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CanCLID/zoengjyutgaai.","url":"https://huggingface.co/datasets/CanCLID/zoengjyutgaai","creator_name":"Á≤µË™ûË®àÁÆóË™ûË®ÄÂ≠∏Âü∫Á§éÂª∫Ë®≠ÁµÑ (CanCLID)","creator_url":"https://huggingface.co/CanCLID","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-generation","feature-extraction","audio-to-audio"],"keywords_longer_than_N":true},
	{"name":"MultiMed","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tMultiMed: Multilingual Medical Speech Recognition via Attention Encoder Decoder\n\t\n\nACL 2025\nKhai Le-Duc, Phuc Phan, Tan-Hanh Pham, Bach Phan Tat,\n\nMinh-Huong Ngo, Chris Ngo, Thanh Nguyen-Tang, Truong-Son Hy\n\n\nPlease press ‚≠ê button and/or cite papers if you feel helpful.\n\n\n  \n\n\n\nAbstract:\nMultilingual automatic speech recognition (ASR) in the medical domain serves as a foundational task for various downstream applications such as speech translation, spoken language understanding, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/leduckhai/MultiMed.","url":"https://huggingface.co/datasets/leduckhai/MultiMed","creator_name":"Le Duc Khai","creator_url":"https://huggingface.co/leduckhai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Vietnamese","English","German","French"],"keywords_longer_than_N":true},
	{"name":"ESpeech-tuchniyzhab","keyword":"automatic-speech-recognition","description":"\n\t\n\t\t\n\t\tTuchniy Zhab YouTube Audio Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 306 hours of processed audio segments extracted from the \"Tuchniy Zhab\" YouTube channel with corresponding metadata. Each audio file represents a segment from the channel's videos and content, processed at 44.1kHz sample rate.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Russian\nTask: TTS, ASR, Quality Assessment\nAudio format: MP3, 44.1kHz sample rate\nStructure: Segmented audio files with JSON metadata‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ESpeech/ESpeech-tuchniyzhab.","url":"https://huggingface.co/datasets/ESpeech/ESpeech-tuchniyzhab","creator_name":"Ebany Speech","creator_url":"https://huggingface.co/ESpeech","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Russian","apache-2.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"libritts-r-mimi","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tLibriTTS-R Mimi encoding\n\t\n\nThis dataset converts all audio in the dev.clean, test.clean, train.100 and train.360 splits of the LibriTTS-R dataset from waveforms to tokens in Kyutai's Mimi neural codec.\nThese tokens are intended as targets for DualAR audio models, but also allow you to simply download all audio in ~50-100x less space, if you're comfortable decoding later on with rustymimi or Transformers.\nThis does NOT contain the original audio, please use the regular LibriTTS-R for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jkeisling/libritts-r-mimi.","url":"https://huggingface.co/datasets/jkeisling/libritts-r-mimi","creator_name":"Jacob Keisling","creator_url":"https://huggingface.co/jkeisling","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"ESpeech-tuchniyzhab","keyword":"text-to-speech","description":"\n\t\n\t\t\n\t\tTuchniy Zhab YouTube Audio Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 306 hours of processed audio segments extracted from the \"Tuchniy Zhab\" YouTube channel with corresponding metadata. Each audio file represents a segment from the channel's videos and content, processed at 44.1kHz sample rate.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Russian\nTask: TTS, ASR, Quality Assessment\nAudio format: MP3, 44.1kHz sample rate\nStructure: Segmented audio files with JSON metadata‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ESpeech/ESpeech-tuchniyzhab.","url":"https://huggingface.co/datasets/ESpeech/ESpeech-tuchniyzhab","creator_name":"Ebany Speech","creator_url":"https://huggingface.co/ESpeech","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Russian","apache-2.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"lleisiau-arfor","keyword":"automatic-speech-recognition","description":"See below for English\n\n\t\n\t\t\n\t\tLleisiau ARFOR\n\t\n\nCafodd y set ddata hon ei chreu gan Cymen fel rhan o brosiect a ariannwyd gan ARFOR ar y cyd √¢‚Äôr Uned Technolegau Iaith ym Mhrifysgol Bangor.‚ÄØ‚ÄØ \nNod y prosiect oedd casglu llawer iawn o ddata llafar Cymraeg o ansawdd uchel, ynghyd √¢‚Äôu trawsgrifiadau cyfatebol, gan ganolbwyntio‚Äôn benodol ar iaith anffurfiol, sgyrsiol a digymell o ardal Arfor. Bydd y set ddata sy‚Äôn deillio ohoni wedyn yn cael ei defnyddio i wella technoleg adnabod llais yng Nghymru‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cymen-arfor/lleisiau-arfor.","url":"https://huggingface.co/datasets/cymen-arfor/lleisiau-arfor","creator_name":"Prosiect Arfor Cymen","creator_url":"https://huggingface.co/cymen-arfor","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Welsh","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"multiCHILDES","keyword":"linguistics","description":"\n\t\n\t\t\n\t\tmultiCHILDES: Multilingual Child-Directed Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains child-directed speech from 19 languages, extracted from the CHILDES corpus. The text has been cleaned and is designed for text generation tasks, particularly in studying early language acquisition.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: CHILDES corpus\nLanguages: 19 languages\nText Type: Child-directed speech\nTask: Text Generation, Language Modeling\nData Processing: The dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IParraMartin/multiCHILDES.","url":"https://huggingface.co/datasets/IParraMartin/multiCHILDES","creator_name":"I√±igo Parra","creator_url":"https://huggingface.co/IParraMartin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Basque","Spanish","Portuguese"],"keywords_longer_than_N":true}
]
;
