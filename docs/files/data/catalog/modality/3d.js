const data_for_modality_3d = 
[
	{"name":"4dgs","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Langelaw/4dgs","creator_name":"ZHANG CHI","creator_url":"https://huggingface.co/Langelaw","description":"Langelaw/4dgs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"UrbanSyn","keyword":"depth-estimation","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UrbanSyn/UrbanSyn","creator_name":"Administrator","creator_url":"https://huggingface.co/UrbanSyn","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUrbanSyn Dataset\\n\\t\\n\\nUrbanSyn is an open synthetic dataset featuring photorealistic driving scenes. It contains ground-truth annotations for semantic segmentation, scene depth, panoptic instance segmentation, and 2-D bounding boxes. Website https://urbansyn.org\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nUrbanSyn is a diverse, compact, and photorealistic dataset that provides more than 7.5k synthetic annotated images. It was born to address the synth-to-real domain gap, contributing to unprecedented… See the full description on the dataset page: https://huggingface.co/datasets/UrbanSyn/UrbanSyn.","first_N":5,"first_N_keywords":["object-detection","image-segmentation","depth-estimation","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"kryptik","keyword":"depth-estimation","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Samuel-Martineau/kryptik","creator_name":"Samuel Martineau","creator_url":"https://huggingface.co/Samuel-Martineau","description":"Samuel-Martineau/kryptik dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["robotics","depth-estimation","object-detection","gpl-3.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"splats","keyword":"3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kedardes/splats","creator_name":"Kedar Pizza","creator_url":"https://huggingface.co/kedardes","description":"kedardes/splats dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"lerf_ovs","keyword":"3d","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Qmh/lerf_ovs","creator_name":"Minghan Qin","creator_url":"https://huggingface.co/Qmh","description":"Qmh/lerf_ovs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["bsd-2-clause","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"us-in-the-wild","keyword":"image-to-3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rishitdagli/us-in-the-wild","creator_name":"Rishit Dagli","creator_url":"https://huggingface.co/rishitdagli","description":"We collect the data following a standardized protocol using a hand-held ultrasound device (Butterfly iQ+ by Butterfly Network Inc., Burlington, MA, USA). We capture video and mid-sagittal images, including the suprapatellar longitudinal view of the suprapatellar recess of the knee. Using this, we capture 10 unique casual sweeps at 30 FPS on multiple unique subjects around the human knee with at least 85 frames in each sweep. All sweeps in this dataset have been captured by the authors on… See the full description on the dataset page: https://huggingface.co/datasets/rishitdagli/us-in-the-wild.","first_N":5,"first_N_keywords":["image-to-3d","apache-2.0","1K<n<10K","Image","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"PhysDreamer","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/YunjinZhang/PhysDreamer","creator_name":"Tianyuan Zhang","creator_url":"https://huggingface.co/YunjinZhang","description":"This dataset contains datas, and pretrained models in paper PhysDreamer: Physics-Based Interaction with 3D Objects via Video Generation. [website] \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nphysics_dreamer.zip contains images, camera poses and optimized 3D Gaussians for four scenes: alocasia, carnation, telephone and hat. \\nmodels.zip contains optimized models (velocity fields and material fields) for four scenes: alocasia, carnation, telephone and hat. \\n","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"DART","keyword":"image-to-3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Yuliang/DART","creator_name":"Yuliang Xiu","creator_url":"https://huggingface.co/Yuliang","description":"\\n\\n  DART: Articulated Hand Model with Diverse Accessories and Rich Textures\\n  \\n    Daiheng Gao*\\n    ·\\n    Yuliang Xiu*\\n    ·\\n    Kailin Li*\\n    ·\\n    Lixin Yang*\\n    \\n    Feng Wang\\n    ·\\n    Peng Zhang\\n    ·\\n    Bang Zhang\\n    ·\\n    Cewu Lu\\n   ·\\n    Ping Tan\\n  \\n  NeurIPS 2022 (Datasets and Benchmarks Track)\\n  \\n  \\n    \\n      \\n    \\n    \\n      \\n    \\n    \\n      \\n    \\n    \\n    \\n    \\n    \\n  \\n    \\n  \\n  \\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUpdate\\n\\t\\n\\n\\n[2022.10.07] DART's raw textures+accessories are released at RAW… See the full description on the dataset page: https://huggingface.co/datasets/Yuliang/DART.","first_N":5,"first_N_keywords":["image-to-3d","English","mit","100K<n<1M","Image"],"keywords_longer_than_N":true},
	{"name":"3d-arena","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dylanebert/3d-arena","creator_name":"Dylan Ebert","creator_url":"https://huggingface.co/dylanebert","description":"For more information, visit the 3D Arena Space.\\nInputs are sourced from iso3D.\\n","first_N":5,"first_N_keywords":["mit","1K - 10K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"3d-arena","keyword":"image-to-3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dylanebert/3d-arena","creator_name":"Dylan Ebert","creator_url":"https://huggingface.co/dylanebert","description":"For more information, visit the 3D Arena Space.\\nInputs are sourced from iso3D.\\n","first_N":5,"first_N_keywords":["mit","1K - 10K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"SoleilScan","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MakiAi/SoleilScan","creator_name":"Sunwood.ai.labs","creator_url":"https://huggingface.co/MakiAi","description":"\\n\\nこのリポジトリは、高機能フォトグラメトリーソフト「RealityCapture 1.4」を使用して、クライミングジムのソレイユの壁をスキャンしたプロジェクトのデータを含んでいます。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tプロジェクトの目的\\n\\t\\n\\n\\nソレイユのクライミングウォールを高精度で3Dスキャンする\\nRealityCapture 1.4の性能を実際のプロジェクトで検証する\\nスキャンデータを使って、クライミングウォールの分析や可視化を行う\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t使用したソフトウェアとハードウェア\\n\\t\\n\\n\\nRealityCapture 1.4\\niphone14 pro\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tデータ\\n\\t\\n\\n\\nこのリポジトリには以下のデータが含まれています：\\n\\n高解像度の写真（RAW形式とJPEG形式）\\nRealityCapture 1.4で処理された3Dモデル（OBJ形式とFBX形式）\\nテクスチャ画像\\nプロジェクトファイル\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t今後の展望\\n\\t\\n\\n\\n3Dモデルを使ったクライミングルートの分析\\nVRやARでのクライミングウォールの可視化\\n3Dプリントによる模型の作成… See the full description on the dataset page: https://huggingface.co/datasets/MakiAi/SoleilScan.","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"HiRISE-DTMs","keyword":"depth-estimation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Diffins/HiRISE-DTMs","creator_name":"Diffins Solutions","creator_url":"https://huggingface.co/Diffins","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHiRISE Digital Terrain Models\\n\\t\\n\\nHiRISE DTMs are digital terrain models created for the surface of Mars. These DTMs are generated using stereo-matching techniques on two satellite images taken from different angles as part of the High-Resolution Imaging Science Experiment (HiRISE) project.\\nThis dataset consists of stereo pairs and their respective digital terrain models. More detailed descriptions about the generation of the digital terrain models are included in [1]. This dataset… See the full description on the dataset page: https://huggingface.co/datasets/Diffins/HiRISE-DTMs.","first_N":5,"first_N_keywords":["depth-estimation","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"bilarf_data","keyword":"3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yuehao/bilarf_data","creator_name":"Yuehao Wang","creator_url":"https://huggingface.co/Yuehao","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBilaRF Dataset\\n\\t\\n\\nProject Page | Arxiv | Code\\nThis dataset contains our own captured nighttime scenes, synthetic data generated from RawNeRF dataset, and editing samples.\\nTo use the data, please go to 'Files and versions' and download 'bilarf_data.zip'.\\nThe dataset follows the file structure of NeRF LLFF data (forward-facing scenes).\\nIn addition, editing samples are stored in the 'edits/' directory. The filename of each editing is formatted in 'editX_color_split-name_index.png'… See the full description on the dataset page: https://huggingface.co/datasets/Yuehao/bilarf_data.","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","imagefolder","Image","3D"],"keywords_longer_than_N":true},
	{"name":"bilarf_data","keyword":"3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yuehao/bilarf_data","creator_name":"Yuehao Wang","creator_url":"https://huggingface.co/Yuehao","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBilaRF Dataset\\n\\t\\n\\nProject Page | Arxiv | Code\\nThis dataset contains our own captured nighttime scenes, synthetic data generated from RawNeRF dataset, and editing samples.\\nTo use the data, please go to 'Files and versions' and download 'bilarf_data.zip'.\\nThe dataset follows the file structure of NeRF LLFF data (forward-facing scenes).\\nIn addition, editing samples are stored in the 'edits/' directory. The filename of each editing is formatted in 'editX_color_split-name_index.png'… See the full description on the dataset page: https://huggingface.co/datasets/Yuehao/bilarf_data.","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","imagefolder","Image","3D"],"keywords_longer_than_N":true},
	{"name":"3DCoMPaT200","keyword":"3d","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CoMPaT/3DCoMPaT200","creator_name":"CoMPaT","creator_url":"https://huggingface.co/CoMPaT","description":"\\n\\t\\n\\t\\t\\n\\t\\t3DCoMPaT200 Dataset\\n\\t\\n\\nThe 3DCoMPaT200 dataset is a comprehensive collection of 3D objects with compositional part annotations. This repository contains various formats and versions of the dataset organized for different use cases.\\n\\n\\t\\n\\t\\t\\n\\t\\t📁 Directory Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t2D Folder\\n\\t\\n\\nContains train, validation, and test data in tar format for 10 compositions:\\n\\nTraining set\\nValidation set\\nTest set\\n\\nEach file contains 2D representations of the objects with their corresponding… See the full description on the dataset page: https://huggingface.co/datasets/CoMPaT/3DCoMPaT200.","first_N":5,"first_N_keywords":["cc-by-4.0","1M - 10M","webdataset","3D","Image"],"keywords_longer_than_N":true},
	{"name":"XLD-Baidu","keyword":"3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lifuguan/XLD-Baidu","creator_name":"leoli","creator_url":"https://huggingface.co/lifuguan","description":"lifuguan/XLD-Baidu dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"HUVER","keyword":"image-to-3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/raiselab/HUVER","creator_name":"RAISE Lab","creator_url":"https://huggingface.co/raiselab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for HUVER\\n\\t\\n\\n\\n\\nThe dataset is comprised of a 6,051 unique UAV configurations, where each configuration is described by multiple data for-\\nmats, including a grammar string, an RGB image, and an GLB file.\\nComplementing these representation modalities, we also provide a configuration-based description, i.e., a text descriptor describing the features of each UAV using natural language\\n\\nCurated by: Abhiram Karri, Gary Stump, Christopher McComb, Binyang Song\\n\\nLanguage(s)… See the full description on the dataset page: https://huggingface.co/datasets/raiselab/HUVER.","first_N":5,"first_N_keywords":["image-to-text","image-to-3d","image-feature-extraction","text-to-3d","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"HUVER","keyword":"text-to-3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/raiselab/HUVER","creator_name":"RAISE Lab","creator_url":"https://huggingface.co/raiselab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for HUVER\\n\\t\\n\\n\\n\\nThe dataset is comprised of a 6,051 unique UAV configurations, where each configuration is described by multiple data for-\\nmats, including a grammar string, an RGB image, and an GLB file.\\nComplementing these representation modalities, we also provide a configuration-based description, i.e., a text descriptor describing the features of each UAV using natural language\\n\\nCurated by: Abhiram Karri, Gary Stump, Christopher McComb, Binyang Song\\n\\nLanguage(s)… See the full description on the dataset page: https://huggingface.co/datasets/raiselab/HUVER.","first_N":5,"first_N_keywords":["image-to-text","image-to-3d","image-feature-extraction","text-to-3d","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"HUVER","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/raiselab/HUVER","creator_name":"RAISE Lab","creator_url":"https://huggingface.co/raiselab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for HUVER\\n\\t\\n\\n\\n\\nThe dataset is comprised of a 6,051 unique UAV configurations, where each configuration is described by multiple data for-\\nmats, including a grammar string, an RGB image, and an GLB file.\\nComplementing these representation modalities, we also provide a configuration-based description, i.e., a text descriptor describing the features of each UAV using natural language\\n\\nCurated by: Abhiram Karri, Gary Stump, Christopher McComb, Binyang Song\\n\\nLanguage(s)… See the full description on the dataset page: https://huggingface.co/datasets/raiselab/HUVER.","first_N":5,"first_N_keywords":["image-to-text","image-to-3d","image-feature-extraction","text-to-3d","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"GameIR","keyword":"image-to-3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LLLebin/GameIR","creator_name":"Lebin Zhou","creator_url":"https://huggingface.co/LLLebin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGameIR\\n\\t\\n\\nImage restoration techniques such as super-resolution and image synthesis are used in products like NVIDIA's DLSS but are less understood by the public when applied to gaming. This is due to a shortage of relevant ground-truth training data for gaming, which differs from typical content with its distinct, sharp low-resolution images.\\nIn this case, we develop GameIR, a large-scale high-quality computer-synthesized ground-truth dataset to fill in the blanks, targeting at 2… See the full description on the dataset page: https://huggingface.co/datasets/LLLebin/GameIR.","first_N":5,"first_N_keywords":["image-to-image","image-to-3d","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"simple-chairs","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/andyye/simple-chairs","creator_name":"andyye","creator_url":"https://huggingface.co/andyye","description":"andyye/simple-chairs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","3D","Text"],"keywords_longer_than_N":true},
	{"name":"GSO-SAD","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SEU-WYL/GSO-SAD","creator_name":"yulin wang","creator_url":"https://huggingface.co/SEU-WYL","description":"\\n\\t\\n\\t\\t\\n\\t\\tGoogle Scanned Objects (GSO) Symmetry Axis Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1. Dataset Description\\n\\t\\n\\nThis dataset is an extension of the Google Scanned Objects (GSO) dataset, enriched with symmetry axis annotations for each object. It is designed to assist in pose estimation tasks by providing explicit symmetry information for objects with both geometric and texture symmetries.\\n\\n\\t\\n\\t\\t\\n\\t\\tKey Features:\\n\\t\\n\\nObjects: 3D scanned models of various objects from the GSO dataset.\\nSymmetry Annotations: Each… See the full description on the dataset page: https://huggingface.co/datasets/SEU-WYL/GSO-SAD.","first_N":5,"first_N_keywords":["mit","3D","Image","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"DSRSTO-dataset","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SEU-WYL/DSRSTO-dataset","creator_name":"yulin wang","creator_url":"https://huggingface.co/SEU-WYL","description":"\\n\\t\\n\\t\\t\\n\\t\\tDSRSTO-dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1. Dataset Description\\n\\t\\n\\nThe DSRSTO-dataset is a specialized dataset designed to support research on 3D object symmetry. It includes annotations for seven distinct types of symmetries and is composed of 3D models created using 3D CAD software, making it a valuable resource for tasks such as pose estimation, object recognition, and symmetry-based 3D model analysis.\\n\\n\\t\\n\\t\\t\\n\\t\\tKey Features:\\n\\t\\n\\nLearning Resource: This dataset serves as an excellent learning… See the full description on the dataset page: https://huggingface.co/datasets/SEU-WYL/DSRSTO-dataset.","first_N":5,"first_N_keywords":["mit","< 1K","json","3D","Text"],"keywords_longer_than_N":true},
	{"name":"tripoexamples","keyword":"3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Avmromanov/tripoexamples","creator_name":"Andrey Romanov","creator_url":"https://huggingface.co/Avmromanov","description":"Avmromanov/tripoexamples dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"pbflbm-part-orientation","keyword":"3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sebius/pbflbm-part-orientation","creator_name":"Sebastian Wenger","creator_url":"https://huggingface.co/sebius","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe following directory structure is consistent across all datasets. Each geometry is assigned an unique identifier: {dataset_name}_00000000 where {dataset_name} is the name of the dataset and 00000000 is an 8-digit number starting from zero.\\nEach dataset has two main folders: info and stl. The info folder contains metadata about each geometry in JSON format, including geometric parameters, random rotation applied to the geometry, reverse transformation (label) in… See the full description on the dataset page: https://huggingface.co/datasets/sebius/pbflbm-part-orientation.","first_N":5,"first_N_keywords":["apache-2.0","3D","doi:10.57967/hf/4458","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"FreeSplatterStatic","keyword":"3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bluestyle97/FreeSplatterStatic","creator_name":"Jiale Xu","creator_url":"https://huggingface.co/bluestyle97","description":"bluestyle97/FreeSplatterStatic dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"BlinkSim_ExampleAssets","keyword":"3d","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BlinkVision/BlinkSim_ExampleAssets","creator_name":"BlinkVision","creator_url":"https://huggingface.co/BlinkVision","description":"The github repo of the simulator: https://github.com/zju3dv/blink_sim\\nThe github repo of the benchmark: https://github.com/eugenelyj/blinkvision_benchmark\\nThe benchmark website: https://zju3dv.github.io/blinkvision\\n","first_N":5,"first_N_keywords":["cc-by-sa-4.0","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"Industrialrobotics","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/introvoyz041/Industrialrobotics","creator_name":"Bri Parales","creator_url":"https://huggingface.co/introvoyz041","description":"introvoyz041/Industrialrobotics dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","3D","Image","Text"],"keywords_longer_than_N":true},
	{"name":"Printer","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/introvoyz041/Printer","creator_name":"Bri Parales","creator_url":"https://huggingface.co/introvoyz041","description":"introvoyz041/Printer dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","text","3D","Text"],"keywords_longer_than_N":true},
	{"name":"Hirthjoint","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/introvoyz041/Hirthjoint","creator_name":"Bri Parales","creator_url":"https://huggingface.co/introvoyz041","description":"introvoyz041/Hirthjoint dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"Prusaslicer","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/introvoyz041/Prusaslicer","creator_name":"Bri Parales","creator_url":"https://huggingface.co/introvoyz041","description":"introvoyz041/Prusaslicer dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","text","3D","Image"],"keywords_longer_than_N":true},
	{"name":"TactileDreamFusion","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Ruihan28/TactileDreamFusion","creator_name":"Ruihan Gao","creator_url":"https://huggingface.co/Ruihan28","description":"Ruihan28/TactileDreamFusion dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"Minecraft-Depth-Images","keyword":"depth-estimation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JulianBvW/Minecraft-Depth-Images","creator_name":"Julian BvW","creator_url":"https://huggingface.co/JulianBvW","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tD4MCDataset\\n\\t\\n\\nDataset created to train the Depth4MC model.\\nImages and depth label are of size 480x854.\\nRead more information on the GitHub page: https://github.com/JulianBvW/Depth4MC\\n\\n","first_N":5,"first_N_keywords":["depth-estimation","apache-2.0","10K - 100K","webdataset","Image"],"keywords_longer_than_N":true},
	{"name":"RelitLRM_Web","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/YunjinZhang/RelitLRM_Web","creator_name":"Tianyuan Zhang","creator_url":"https://huggingface.co/YunjinZhang","description":"YunjinZhang/RelitLRM_Web dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"OpenMind","keyword":"3d","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AnonRes/OpenMind","creator_name":"AnonResearcher","creator_url":"https://huggingface.co/AnonRes","description":"\\n\\t\\n\\t\\t\\n\\t\\tThe OpenMind Dataset: A large-scale Head-And-Neck 3D MRI Dataset for self-supervised learning\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nThe OpenMind Dataset is a large-scale 3D MRI dataset of the head and neck region featuring 114k MRI Images. Its purpose is to provide access of large amounts of 3D medical imaging data to accelerate the development of self-supervised learning methods for 3D medical imaging. This data was pooled from exactly 800 datasets from the OpenNeuro platform and provides 23… See the full description on the dataset page: https://huggingface.co/datasets/AnonRes/OpenMind.","first_N":5,"first_N_keywords":["image-feature-extraction","cc-by-4.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"OpenMind","keyword":"3d","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AnonRes/OpenMind","creator_name":"AnonResearcher","creator_url":"https://huggingface.co/AnonRes","description":"\\n\\t\\n\\t\\t\\n\\t\\tThe OpenMind Dataset: A large-scale Head-And-Neck 3D MRI Dataset for self-supervised learning\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nThe OpenMind Dataset is a large-scale 3D MRI dataset of the head and neck region featuring 114k MRI Images. Its purpose is to provide access of large amounts of 3D medical imaging data to accelerate the development of self-supervised learning methods for 3D medical imaging. This data was pooled from exactly 800 datasets from the OpenNeuro platform and provides 23… See the full description on the dataset page: https://huggingface.co/datasets/AnonRes/OpenMind.","first_N":5,"first_N_keywords":["image-feature-extraction","cc-by-4.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"nerfbaselines-supplementary","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nerfbaselines/nerfbaselines-supplementary","creator_name":"NerfBaselines","creator_url":"https://huggingface.co/nerfbaselines","description":"nerfbaselines/nerfbaselines-supplementary dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","3D","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"nfa-inspection-synth","keyword":"3d","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/research-centre-rez/nfa-inspection-synth","creator_name":"Research Centre Řež","creator_url":"https://huggingface.co/research-centre-rez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNuclear Fuel Assembly (NFA) Inspection Videos\\n\\t\\n\\nThis repository contains inspection data from three nuclear fuel assemblies (NFAs) of varying ages and deformation levels. Each assembly is inspected on all six hexagonal faces, with corresponding videos and supplementary data files provided for each face.\\nDataset Contents. \\nThis dataset was generated by a simulator described in the publication Simulating Nuclear Fuel Inspections: Enhancing Reliability through Synthetic Data.\\nEach… See the full description on the dataset page: https://huggingface.co/datasets/research-centre-rez/nfa-inspection-synth.","first_N":5,"first_N_keywords":["gpl-3.0","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"Diffusion4RobustDepth","keyword":"depth-estimation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fabiotosi92/Diffusion4RobustDepth","creator_name":"Fabio Tosi","creator_url":"https://huggingface.co/fabiotosi92","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDiffusion4RobustDepth\\n\\t\\n\\nThis repository contains the generated dataset and trained network weights used in the paper \\\"Diffusion Models for Monocular Depth Estimation: Overcoming Challenging Conditions\\\" (ECCV 2024).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset is organized into three main categories:\\n\\ndriving/: Contains autonomous driving datasets with challenging images.\\nToM/: Contains the Transparent and Mirrored (ToM) objects dataset.\\nweights/: Contains the weights of models… See the full description on the dataset page: https://huggingface.co/datasets/fabiotosi92/Diffusion4RobustDepth.","first_N":5,"first_N_keywords":["depth-estimation","mit","100K - 1M","webdataset","Image"],"keywords_longer_than_N":true},
	{"name":"BlendNet","keyword":"3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/BlendNet","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\t📚 BlendNet\\n\\t\\n\\nThe dataset contains $12k$ samples. To balance cost savings with data quality and scale, we manually annotated $2k$ samples and used GPT-4o to annotate the remaining $10k$ samples.\\nFor more details, please visit our GitHub repository or refer to our arXiv paper.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📖 Citation\\n\\t\\n\\n@misc{du2024blenderllmtraininglargelanguage,\\n      title={BlenderLLM: Training Large Language Models for Computer-Aided Design with Self-improvement}, \\n      author={Yuhao Du and… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/BlendNet.","first_N":5,"first_N_keywords":["text2text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"3D-NEXRAD","keyword":"3d","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ziyeeee/3D-NEXRAD","creator_name":"Ziye Wang","creator_url":"https://huggingface.co/Ziyeeee","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for 3D-NEXRAD\\n\\t\\n\\n\\n\\n3D gridded radar reflectivity data collected from the U.S.NEXRAD WSR-88D radar network. \\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\nThe 3D-NEXRDA dataset comprises 3D radar observations of severe storm events across the United States, with each event captured at different geographic locations. \\nThe dataset provides high-resolution insights into storm dynamics with high temporal and spatial resolution.\\n\\nTemporal Coverage:\\n\\nTime Span: 2020.01.01 - 2022.12.31… See the full description on the dataset page: https://huggingface.co/datasets/Ziyeeee/3D-NEXRAD.","first_N":5,"first_N_keywords":["cc-by-4.0","🇺🇸 Region: US","3D","Radar","Prediction"],"keywords_longer_than_N":false},
	{"name":"DurLAR_S","keyword":"depth-estimation","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/l1997i/DurLAR_S","creator_name":"Li Li","creator_url":"https://huggingface.co/l1997i","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tDurLAR: A High-Fidelity 128-Channel LiDAR Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tNews\\n\\t\\n\\n\\n[2024/12/05] We provide the intrinsic parameters of our OS1-128 LiDAR [download].\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSensor placement\\n\\t\\n\\n\\nLiDAR: Ouster OS1-128 LiDAR sensor with 128 channels vertical resolution\\n\\nStereo Camera: Carnegie Robotics MultiSense S21 stereo camera with grayscale, colour, and IR enhanced imagers, 2048x1088 @ 2MP resolution\\n\\nGNSS/INS: OxTS RT3000v3 global navigation satellite and inertial navigation system, supporting… See the full description on the dataset page: https://huggingface.co/datasets/l1997i/DurLAR_S.","first_N":5,"first_N_keywords":["depth-estimation","English","cc-by-4.0","10K - 100K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"RoboTwin_asset","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ZanxinChen/RoboTwin_asset","creator_name":"ZanxinChen","creator_url":"https://huggingface.co/ZanxinChen","description":"ZanxinChen/RoboTwin_asset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"Coil100-Augmented","keyword":"image-to-3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dappu97/Coil100-Augmented","creator_name":"Jacopo Dapueto","creator_url":"https://huggingface.co/dappu97","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThis dataset derives from Coil100. \\nThere are more than 1,1M images of 100 objects. Each object was turned on a turnable through 360 degrees to vary object pose with respect to a fixed color camera. Images of the objects were taken at pose intervals of 5 degrees. This corresponds to 72 poses per object. \\nIn addition to the original dataset, planar rotation (9 angles) and  18 scaling factors have been applied so that there are no dependencies between factors.\\nObjects… See the full description on the dataset page: https://huggingface.co/datasets/dappu97/Coil100-Augmented.","first_N":5,"first_N_keywords":["image-feature-extraction","image-classification","image-to-3d","image-segmentation","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"fida","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ttVeelo/fida","creator_name":"Hossein Ghazanfari","creator_url":"https://huggingface.co/ttVeelo","description":"ttVeelo/fida dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"3DComicScene","keyword":"3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Asianfleet/3DComicScene","creator_name":"WonderComicJourney","creator_url":"https://huggingface.co/Asianfleet","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t漫画 3D 场景数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t整体结构\\n\\t\\n\\n\\nArchitecture: 包含建筑相关的文件，细分为不同类型的建筑（如中国古代建筑、现代建筑、外国建筑等），并且每种建筑类型下又有室内、室外、材料、网格等子目录。\\n\\nCharacters: 包含各种角色的文件，分为动物（如水生动物、鸟类、哺乳动物、爬行动物）、幻想角色和人类（男性、女性）等。\\n\\nMisc: 包含各种杂项内容，分为抽象、幻想、历史和科幻等类别。\\n\\nNature: 包含自然相关的文件，细分为风景、植物、岩石、树木和水体（如湖泊、海洋、河流）等。\\n\\nObjects: 包含各种物体的文件，分为衣物、电子产品、家具、厨房用具、工具和武器（冷兵器和火器）等。\\n\\nTextures: 包含不同材质的纹理文件，如陶瓷、布料、玻璃、金属、塑料、石材和木材等。\\n\\nVehicles: 包含各种交通工具的文件，分为自行车、汽车、飞机、船只和火车等。\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据存储标准\\n\\t\\n\\n每一个类别文件夹都包含若干子文件夹，最后一级子文件夹中有三个数据文件夹：\\n\\nimages… See the full description on the dataset page: https://huggingface.co/datasets/Asianfleet/3DComicScene.","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"nyu_depth_v2","keyword":"depth-estimation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sayakpaul/nyu_depth_v2","creator_name":"Sayak Paul","creator_url":"https://huggingface.co/sayakpaul","description":"The NYU-Depth V2 data set is comprised of video sequences from a variety of indoor scenes as recorded by both the RGB and Depth cameras from the Microsoft Kinect.","first_N":5,"first_N_keywords":["depth-estimation","monolingual","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"nyu_depth_v2","keyword":"depth-estimation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sayakpaul/nyu_depth_v2","creator_name":"Sayak Paul","creator_url":"https://huggingface.co/sayakpaul","description":"The NYU-Depth V2 data set is comprised of video sequences from a variety of indoor scenes as recorded by both the RGB and Depth cameras from the Microsoft Kinect.","first_N":5,"first_N_keywords":["depth-estimation","monolingual","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Military-Aircraft-Detection","keyword":"depth-estimation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Illia56/Military-Aircraft-Detection","creator_name":"Illia Liudogovskyi","creator_url":"https://huggingface.co/Illia56","description":"Dataset for object detection of military aircraft\\nbounding box in PASCAL VOC format (xmin, ymin, xmax, ymax)\\n43 aircraft types\\n(A-10, A-400M, AG-600, AV-8B, B-1, B-2, B-52 Be-200, C-130, C-17, C-2, C-5, E-2, E-7, EF-2000, F-117, F-14, F-15, F-16, F/A-18, F-22, F-35, F-4, J-20, JAS-39, MQ-9, Mig-31, Mirage2000, P-3(CP-140), RQ-4, Rafale, SR-71(may contain A-12), Su-34, Su-57, Tornado, Tu-160, Tu-95(Tu-142), U-2, US-2(US-1A Kai), V-22, Vulcan, XB-70, YF-23)\\nPlease let me know if you find wrong… See the full description on the dataset page: https://huggingface.co/datasets/Illia56/Military-Aircraft-Detection.","first_N":5,"first_N_keywords":["object-detection","zero-shot-classification","zero-shot-image-classification","depth-estimation","image-classification"],"keywords_longer_than_N":true},
	{"name":"COIL-100","keyword":"image-to-3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Voxel51/COIL-100","creator_name":"Voxel51","creator_url":"https://huggingface.co/Voxel51","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for COIL-100\\n\\t\\n\\n\\nThis is a FiftyOne dataset with 7200 samples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInstallation\\n\\t\\n\\nIf you haven't already, install FiftyOne:\\npip install -U fiftyone\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport fiftyone as fo\\nimport fiftyone.utils.huggingface as fouh\\n\\n# Load the dataset\\n# Note: other available arguments include 'max_samples', etc\\ndataset = fouh.load_from_hub(\\\"Voxel51/COIL-100\\\")\\n\\n# Launch the App\\nsession = fo.launch_app(dataset)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details… See the full description on the dataset page: https://huggingface.co/datasets/Voxel51/COIL-100.","first_N":5,"first_N_keywords":["image-feature-extraction","image-to-3d","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Diffusion4D","keyword":"text-to-3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hw-liang/Diffusion4D","creator_name":"Hanwen Liang","creator_url":"https://huggingface.co/hw-liang","description":"\\n\\t\\n\\t\\t\\n\\t\\tDiffusion4D: Fast Spatial-temporal Consistent 4D Generation via Video Diffusion Models\\n\\t\\n\\n[Project Page] | [Arxiv] | [Code]\\n\\n\\t\\n\\t\\t\\n\\t\\tNews\\n\\t\\n\\n\\n2024.6.28:  Released rendered data from curated objaverse-xl.\\n2024.6.4:  Released rendered data from curated objaverse-1.0, including orbital videos of dynamic 3D, orbital videos of static 3D, and monocular videos from front view.\\n2024.5.27: Released metadata for objects!\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nWe collect a large-scale, high-quality dynamic… See the full description on the dataset page: https://huggingface.co/datasets/hw-liang/Diffusion4D.","first_N":5,"first_N_keywords":["text-to-3d","image-to-3d","English","apache-2.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"Diffusion4D","keyword":"image-to-3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hw-liang/Diffusion4D","creator_name":"Hanwen Liang","creator_url":"https://huggingface.co/hw-liang","description":"\\n\\t\\n\\t\\t\\n\\t\\tDiffusion4D: Fast Spatial-temporal Consistent 4D Generation via Video Diffusion Models\\n\\t\\n\\n[Project Page] | [Arxiv] | [Code]\\n\\n\\t\\n\\t\\t\\n\\t\\tNews\\n\\t\\n\\n\\n2024.6.28:  Released rendered data from curated objaverse-xl.\\n2024.6.4:  Released rendered data from curated objaverse-1.0, including orbital videos of dynamic 3D, orbital videos of static 3D, and monocular videos from front view.\\n2024.5.27: Released metadata for objects!\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nWe collect a large-scale, high-quality dynamic… See the full description on the dataset page: https://huggingface.co/datasets/hw-liang/Diffusion4D.","first_N":5,"first_N_keywords":["text-to-3d","image-to-3d","English","apache-2.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"Diffusion4D","keyword":"3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hw-liang/Diffusion4D","creator_name":"Hanwen Liang","creator_url":"https://huggingface.co/hw-liang","description":"\\n\\t\\n\\t\\t\\n\\t\\tDiffusion4D: Fast Spatial-temporal Consistent 4D Generation via Video Diffusion Models\\n\\t\\n\\n[Project Page] | [Arxiv] | [Code]\\n\\n\\t\\n\\t\\t\\n\\t\\tNews\\n\\t\\n\\n\\n2024.6.28:  Released rendered data from curated objaverse-xl.\\n2024.6.4:  Released rendered data from curated objaverse-1.0, including orbital videos of dynamic 3D, orbital videos of static 3D, and monocular videos from front view.\\n2024.5.27: Released metadata for objects!\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nWe collect a large-scale, high-quality dynamic… See the full description on the dataset page: https://huggingface.co/datasets/hw-liang/Diffusion4D.","first_N":5,"first_N_keywords":["text-to-3d","image-to-3d","English","apache-2.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"Diffusion4D","keyword":"3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hw-liang/Diffusion4D","creator_name":"Hanwen Liang","creator_url":"https://huggingface.co/hw-liang","description":"\\n\\t\\n\\t\\t\\n\\t\\tDiffusion4D: Fast Spatial-temporal Consistent 4D Generation via Video Diffusion Models\\n\\t\\n\\n[Project Page] | [Arxiv] | [Code]\\n\\n\\t\\n\\t\\t\\n\\t\\tNews\\n\\t\\n\\n\\n2024.6.28:  Released rendered data from curated objaverse-xl.\\n2024.6.4:  Released rendered data from curated objaverse-1.0, including orbital videos of dynamic 3D, orbital videos of static 3D, and monocular videos from front view.\\n2024.5.27: Released metadata for objects!\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nWe collect a large-scale, high-quality dynamic… See the full description on the dataset page: https://huggingface.co/datasets/hw-liang/Diffusion4D.","first_N":5,"first_N_keywords":["text-to-3d","image-to-3d","English","apache-2.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"living-room-passes","keyword":"depth-estimation","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nfiniteai/living-room-passes","creator_name":"Nfinite","creator_url":"https://huggingface.co/Nfiniteai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tnfinite-living-room-passes\\n\\t\\n\\nVersion of the release: 1.0.0-alphaRelease date: 2024/06/17\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe nfinite-living-room-passes dataset is a dataset of images from 3D models for objects usually found in the living room space. 500 products are available, across 10500 images.  \\nEach product has been rendered photo-realistically from a 3D model and is also available as a series of images depicting its normal map, its depth map, and some other information.Those… See the full description on the dataset page: https://huggingface.co/datasets/Nfiniteai/living-room-passes.","first_N":5,"first_N_keywords":["depth-estimation","image-classification","image-segmentation","text-to-image","image-to-text"],"keywords_longer_than_N":true},
	{"name":"3DRewardDB","keyword":"text-to-3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yejunliang23/3DRewardDB","creator_name":"yejunliang","creator_url":"https://huggingface.co/yejunliang23","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t3DRewardDB\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n3DRewardDB is a diverse 3D dataset suitable for training and testing models aligned with human preferences. \\nTo build the 3DRewardDB, We select 2530 prompts from cap3d, each corresponding to 4-10 3D assets generated using ashawkey/mvdream-sd2.1-diffusers.\\nNotice: The complete dataset will be used for commercial purposes, so we have only open-sourced 1000 of the 2530 prompts.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n# 3DRewardDB\\n./\\n├── data\\n│… See the full description on the dataset page: https://huggingface.co/datasets/yejunliang23/3DRewardDB.","first_N":5,"first_N_keywords":["text-to-3d","English","apache-2.0","Image","arxiv:2403.14613"],"keywords_longer_than_N":true},
	{"name":"omages_ABO","keyword":"text-to-3d","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/3dlg-hcvc/omages_ABO","creator_name":"3D Language & Human-Centric Visual Computing","creator_url":"https://huggingface.co/3dlg-hcvc","description":"This repo hosts the processed data of the ABO dataset for the paper An Object is Worth 64x64 Pixels: Generating 3D Object via Image Diffusion.\\nPlease refer to the project homepage, arxiv page and github repo for more details.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset details\\n\\t\\n\\nWe first download the .glb ABO shapes, then we turn the .glb files into 1024x1024x12 object images using Blender 4.0. We set the maximum number of patches to 64 and set the margin to be 2%. The 1024 resolution data is in the data/ folder… See the full description on the dataset page: https://huggingface.co/datasets/3dlg-hcvc/omages_ABO.","first_N":5,"first_N_keywords":["text-to-3d","cc-by-4.0","Image","arxiv:2408.03178","arxiv:2110.06199"],"keywords_longer_than_N":true},
	{"name":"panorama_hdr_dataset","keyword":"image-to-3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gokaygokay/panorama_hdr_dataset","creator_name":"gokay aydogan","creator_url":"https://huggingface.co/gokaygokay","description":"Panorama HDR images from https://hdri-haven.com/\\nCaptions are from Florence-2-large\\n","first_N":5,"first_N_keywords":["image-to-3d","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"3D-PC","keyword":"3d","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/3D-PC/3D-PC","creator_name":"3D-PC","creator_url":"https://huggingface.co/3D-PC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nVisual perspective taking (VPT), the ability to accurately perceive and reason about the perspectives of others, is an essential feature of human intelligence. \\nDeep neural networks (DNNs) may be a good candidate for modeling VPT and its computational demands in light of a growing number of reports indicating that DNNs gain the ability to analyze 3D scenes after training on large static-image datasets.\\nWe developed the 3D perception challenge (3D-PC) for comparing 3D… See the full description on the dataset page: https://huggingface.co/datasets/3D-PC/3D-PC.","first_N":5,"first_N_keywords":["image-classification","cc-by-4.0","10K - 100K","parquet","3D"],"keywords_longer_than_N":true},
	{"name":"DiffusionGS","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CaiYuanhao/DiffusionGS","creator_name":"Yuanhao Cai","creator_url":"https://huggingface.co/CaiYuanhao","description":"CaiYuanhao/DiffusionGS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","3D","Image","Video"],"keywords_longer_than_N":true},
	{"name":"CamVid-30K","keyword":"image-to-3d","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yuyang-z/CamVid-30K","creator_name":"Yuyang","creator_url":"https://huggingface.co/Yuyang-z","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCamVid-30K\\n\\t\\n\\n\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThis is the CamVid-30K dataset introduced in our paper, \\\"GenXD: Generating Any 3D and 4D Scenes.\\\" CamVid-30K is the first open-sourced, large-scale 4D dataset, designed to support various dynamic 3D tasks. It includes videos sourced from VIPSeg, OpenVid-1M, and WebVid-10M, with camera annotations curated using our data curation pipeline.  \\nProject: https://gen-x-d.github.io/\\nPaper: https://arxiv.org/pdf/2411.02319\\nCode:… See the full description on the dataset page: https://huggingface.co/datasets/Yuyang-z/CamVid-30K.","first_N":5,"first_N_keywords":["image-to-3d","English","cc-by-4.0","10K<n<100K","3D"],"keywords_longer_than_N":true},
	{"name":"CamVid-30K","keyword":"3d","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yuyang-z/CamVid-30K","creator_name":"Yuyang","creator_url":"https://huggingface.co/Yuyang-z","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCamVid-30K\\n\\t\\n\\n\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThis is the CamVid-30K dataset introduced in our paper, \\\"GenXD: Generating Any 3D and 4D Scenes.\\\" CamVid-30K is the first open-sourced, large-scale 4D dataset, designed to support various dynamic 3D tasks. It includes videos sourced from VIPSeg, OpenVid-1M, and WebVid-10M, with camera annotations curated using our data curation pipeline.  \\nProject: https://gen-x-d.github.io/\\nPaper: https://arxiv.org/pdf/2411.02319\\nCode:… See the full description on the dataset page: https://huggingface.co/datasets/Yuyang-z/CamVid-30K.","first_N":5,"first_N_keywords":["image-to-3d","English","cc-by-4.0","10K<n<100K","3D"],"keywords_longer_than_N":true},
	{"name":"CamVid-30K","keyword":"3d","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yuyang-z/CamVid-30K","creator_name":"Yuyang","creator_url":"https://huggingface.co/Yuyang-z","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCamVid-30K\\n\\t\\n\\n\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThis is the CamVid-30K dataset introduced in our paper, \\\"GenXD: Generating Any 3D and 4D Scenes.\\\" CamVid-30K is the first open-sourced, large-scale 4D dataset, designed to support various dynamic 3D tasks. It includes videos sourced from VIPSeg, OpenVid-1M, and WebVid-10M, with camera annotations curated using our data curation pipeline.  \\nProject: https://gen-x-d.github.io/\\nPaper: https://arxiv.org/pdf/2411.02319\\nCode:… See the full description on the dataset page: https://huggingface.co/datasets/Yuyang-z/CamVid-30K.","first_N":5,"first_N_keywords":["image-to-3d","English","cc-by-4.0","10K<n<100K","3D"],"keywords_longer_than_N":true},
	{"name":"csvps","keyword":"depth-estimation","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/khwstolle/csvps","creator_name":"Kurt H.W. Stolle","creator_url":"https://huggingface.co/khwstolle","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCityscapes VPS\\n\\t\\n\\nThis dataset is derived from the videos in the validation split of the Cityscapes[^1] dataset.\\nIt aggregates the images and metadata from Cityscapes[^1], Cityscapes-VPS[^2] and Cityscapes-DVPS[^3] into a single structured format. \\nThis comprehensive derivative was created out of the need for a batteries-included variant of the dataset for academic purposes.\\nSpecifically, joining samples from the individual datasets in their original structure (each is organized… See the full description on the dataset page: https://huggingface.co/datasets/khwstolle/csvps.","first_N":5,"first_N_keywords":["depth-estimation","image-segmentation","video-classification","object-detection","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"CADBench","keyword":"3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/CADBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📚 CADBench\\n\\t\\n\\nCADBench is a comprehensive benchmark to evaluate the ability of LLMs to generate CAD scripts. It contains 500 simulated data samples and 200 data samples collected from online forums.\\nFor more details, please visit our GitHub repository or refer to our arXiv paper.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📖 Citation\\n\\t\\n\\n@misc{du2024blenderllmtraininglargelanguage,\\n      title={BlenderLLM: Training Large Language Models for Computer-Aided Design with Self-improvement}, \\n      author={Yuhao Du… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/CADBench.","first_N":5,"first_N_keywords":["text2text-generation","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"TRELLIS-500K","keyword":"image-to-3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JeffreyXiang/TRELLIS-500K","creator_name":"Jianfeng Xiang","creator_url":"https://huggingface.co/JeffreyXiang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTRELLIS-500K\\n\\t\\n\\nTRELLIS-500K is a dataset of 500K 3D assets curated from Objaverse(XL), ABO, 3D-FUTURE, HSSD, and Toys4k, filtered based on aesthetic scores.\\nThis dataset serves for 3D generation tasks.\\nIt was introduced in the paper Structured 3D Latents for Scalable and Versatile 3D Generation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\nThe following table summarizes the dataset's filtering and composition:\\nNOTE: Some of the 3D assets lack text captions. Please filter out such assets if… See the full description on the dataset page: https://huggingface.co/datasets/JeffreyXiang/TRELLIS-500K.","first_N":5,"first_N_keywords":["image-to-3d","text-to-3d","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"TRELLIS-500K","keyword":"text-to-3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JeffreyXiang/TRELLIS-500K","creator_name":"Jianfeng Xiang","creator_url":"https://huggingface.co/JeffreyXiang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTRELLIS-500K\\n\\t\\n\\nTRELLIS-500K is a dataset of 500K 3D assets curated from Objaverse(XL), ABO, 3D-FUTURE, HSSD, and Toys4k, filtered based on aesthetic scores.\\nThis dataset serves for 3D generation tasks.\\nIt was introduced in the paper Structured 3D Latents for Scalable and Versatile 3D Generation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\nThe following table summarizes the dataset's filtering and composition:\\nNOTE: Some of the 3D assets lack text captions. Please filter out such assets if… See the full description on the dataset page: https://huggingface.co/datasets/JeffreyXiang/TRELLIS-500K.","first_N":5,"first_N_keywords":["image-to-3d","text-to-3d","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"EmbodiedEval","keyword":"3d","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EmbodiedEval/EmbodiedEval","creator_name":"EmbodiedEval","creator_url":"https://huggingface.co/EmbodiedEval","description":"This repository contains the dataset of the paper EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents.\\nGithub repository: https://github.com/thunlp/EmbodiedEval\\nProject Page: https://embodiedeval.github.io/\\n","first_N":5,"first_N_keywords":["robotics","video-text-to-text","English","cc0-1.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Dora-bench-256","keyword":"3d","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aruichen/Dora-bench-256","creator_name":"aruichen","creator_url":"https://huggingface.co/aruichen","description":"aruichen/Dora-bench-256 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","3D","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"diode-subset-train","keyword":"depth-estimation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sayakpaul/diode-subset-train","creator_name":"Sayak Paul","creator_url":"https://huggingface.co/sayakpaul","description":"DIODE dataset: https://diode-dataset.org/\\nCode to prepare the archive: TBA\\n","first_N":5,"first_N_keywords":["mit","🇺🇸 Region: US","depth-estimation"],"keywords_longer_than_N":false},
	{"name":"test","keyword":"depth-estimation","license":"Boost Software License 1.0","license_url":"https://choosealicense.com/licenses/bsl-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pengxiang01/test","creator_name":"wang","creator_url":"https://huggingface.co/pengxiang01","description":"aasdfsdf\\n","first_N":5,"first_N_keywords":["tabular-to-text","table-to-text","multiple-choice","text-retrieval","time-series-forecasting"],"keywords_longer_than_N":true},
	{"name":"Cars_I_like","keyword":"depth-estimation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Basilisk181297/Cars_I_like","creator_name":"Basil Minhaj","creator_url":"https://huggingface.co/Basilisk181297","description":"Basilisk181297/Cars_I_like dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["image-classification","image-to-text","depth-estimation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Military-Aircraft-Recognition-dataset","keyword":"depth-estimation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Alex5666/Military-Aircraft-Recognition-dataset","creator_name":"Gracio","creator_url":"https://huggingface.co/Alex5666","description":"This is a remote sensing image Military Aircraft Recognition dataset that include 3842 images, 20 types, and 22341 instances annotated with horizontal bounding boxes and oriented bounding boxes.\\n","first_N":5,"first_N_keywords":["image-classification","image-segmentation","image-to-text","image-to-image","object-detection"],"keywords_longer_than_N":true},
	{"name":"Forest_Depth_Estimation_by_Frost_Head","keyword":"depth-estimation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/frosthead/Forest_Depth_Estimation_by_Frost_Head","creator_name":"Ayush Sharma","creator_url":"https://huggingface.co/frosthead","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tForest Depth Estimation by Frost Head\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Frost Head Forest Depth Estimation Dataset is a comprehensive collection of synthetic forest images generated using Unreal Engine 5. This dataset is specifically designed for advanced forest depth estimation research and related applications in the field of computer vision and environmental analysis.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Construction\\n\\t\\n\\nThe Frost Head Forest Depth Estimation Dataset is constructed using advanced… See the full description on the dataset page: https://huggingface.co/datasets/frosthead/Forest_Depth_Estimation_by_Frost_Head.","first_N":5,"first_N_keywords":["image-to-image","depth-estimation","apache-2.0","1K<n<10K","Image"],"keywords_longer_than_N":true},
	{"name":"gafoart","keyword":"3d","license":"PostgreSQL License","license_url":"https://choosealicense.com/licenses/postgresql/","language":"en","dataset_url":"https://huggingface.co/datasets/gafoart/gafoart","creator_name":"Cesar Rodriguez","creator_url":"https://huggingface.co/gafoart","description":"gafoart/gafoart dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["postgresql","< 1K","3D","Image","Video"],"keywords_longer_than_N":true},
	{"name":"Bottle","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Venkatakrishnan-Ramesh/Bottle","creator_name":"Venkatakrishnan R","creator_url":"https://huggingface.co/Venkatakrishnan-Ramesh","description":"Venkatakrishnan-Ramesh/Bottle dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","1K - 10K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"psegs-ios-lidar-ext","keyword":"3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PSegs/psegs-ios-lidar-ext","creator_name":"Perception Segments","creator_url":"https://huggingface.co/PSegs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPSegs iOS Lidar Extension\\n\\t\\n\\n\\nThis project contains data captured using Lidar-equipped iPhone(s)\\nfor use as an extension with the \\nPSegs project.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure\\n\\t\\n\\n\\nthreeDScannerApp_data - This is test data captured\\n  using the 3D Scanner App for iOS.\\nps_external_test_fixtures - These are fixtures\\n  created using the data in this repo and code in \\n  PSegs.  They are hosted here and \\n  provided to power PSegs unit tests.\\n\\n","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"DungeonAssistant","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gyrojeff/DungeonAssistant","creator_name":"Haoyun Qin","creator_url":"https://huggingface.co/gyrojeff","description":"Check https://github.com/JeffersonQin/DungeonAssistant for details.\\n","first_N":5,"first_N_keywords":["mit","3D","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"mydata","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TheHenk/mydata","creator_name":"Henrik Ljungberg","creator_url":"https://huggingface.co/TheHenk","description":"TheHenk/mydata dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"realhouse","keyword":"3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FutureMa/realhouse","creator_name":"MaShijian","creator_url":"https://huggingface.co/FutureMa","description":"FutureMa/realhouse dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"ycb-fixed-meshes","keyword":"3d","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ll4ma-lab/ycb-fixed-meshes","creator_name":"Utah Learning Lab for Manipulation Autonomy","creator_url":"https://huggingface.co/ll4ma-lab","description":"This folder has updated versions of the YCB meshes. All updates are in google_16k folders for each object.\\nThe following updated are available:\\nnontextured_proc.stl: These are simplified meshes with the normals fixed recommended to be used as collision models. (Note: The normal fixes has to be done manually so not all meshes are verfied, feel free to update them using meshlab, blender, etc).\\nnontextured_binvox.bt: These file are voxelised representation of the meshes (resolution up to 1mm).… See the full description on the dataset page: https://huggingface.co/datasets/ll4ma-lab/ycb-fixed-meshes.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"RSL_Maran","keyword":"depth-estimation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ae5115242430e13/RSL_Maran","creator_name":"R.s.L Maran","creator_url":"https://huggingface.co/ae5115242430e13","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/ae5115242430e13/RSL_Maran.","first_N":5,"first_N_keywords":["token-classification","table-question-answering","question-answering","text-classification","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Diycncmachinemetaldrawing","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/introvoyz041/Diycncmachinemetaldrawing","creator_name":"Bri Parales","creator_url":"https://huggingface.co/introvoyz041","description":"introvoyz041/Diycncmachinemetaldrawing dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"gaussian_splatting","keyword":"3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Voxel51/gaussian_splatting","creator_name":"Voxel51","creator_url":"https://huggingface.co/Voxel51","description":"\\n\\t\\n\\t\\t\\n\\t\\tGaussian Splats Dataset\\n\\t\\n\\n3D Gaussian Splatting for Real-Time Radiance Field Rendering  \\nDataset Author: Paula RamosCreated Using: 3D Gaussian Splatting PaperCode Repository: GitHub - graphdeco-inria/gaussian-splatting \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset consists of Gaussian Splats representations of different real-world scenes, created using the official 3D Gaussian Splatting method. Each scene folder contains:\\nA reference image representing the scene.\\nA PLY file stored in a… See the full description on the dataset page: https://huggingface.co/datasets/Voxel51/gaussian_splatting.","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","imagefolder","3D"],"keywords_longer_than_N":true},
	{"name":"OpenSpaces","keyword":"depth-estimation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/remyxai/OpenSpaces","creator_name":"Remyx AI","creator_url":"https://huggingface.co/remyxai","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenSpaces\\n\\t\\n\\nThe OpenSpaces dataset is created using VQASynth to synthesize spatialVQA data using images from the first 30K rows \\nof the localized narratives split of the cauldron.\\nCompared to the related dataset used to train SpaceLLaVA, \\nthe OpenSpaces emphasizes greater diversity in the image distribution instead of focusing on warehouse scenes.\\nThe following chart shows the distribution of images over tags labeled by CLIP embedding similarity:\\n\\nThe OpenSpaces dataset also… See the full description on the dataset page: https://huggingface.co/datasets/remyxai/OpenSpaces.","first_N":5,"first_N_keywords":["visual-question-answering","depth-estimation","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"InstantSplat","keyword":"image-to-3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kairunwen/InstantSplat","creator_name":"Kairun Wen","creator_url":"https://huggingface.co/kairunwen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInstantSplat: Sparse-view SfM-free Gaussian Splatting in Seconds\\n\\t\\n\\n[Project Page]  |  [Arxiv]  |  [Video]  |  [Code]  |  [HF Demo]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis repository contains two large-scale datasets: Tanks and Temples and MVimgNet.\\n\\nTanks and Temples: This dataset includes five outdoor scenes and three indoor scenes, namely Barn, Family, Francis, Horse, Ignatius, Church, Ballroom, and Museum.\\nMVimgNet: This dataset comprises seven outdoor scenes, covering a variety of scene… See the full description on the dataset page: https://huggingface.co/datasets/kairunwen/InstantSplat.","first_N":5,"first_N_keywords":["image-to-3d","English","apache-2.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"InstantSplat","keyword":"3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kairunwen/InstantSplat","creator_name":"Kairun Wen","creator_url":"https://huggingface.co/kairunwen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInstantSplat: Sparse-view SfM-free Gaussian Splatting in Seconds\\n\\t\\n\\n[Project Page]  |  [Arxiv]  |  [Video]  |  [Code]  |  [HF Demo]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis repository contains two large-scale datasets: Tanks and Temples and MVimgNet.\\n\\nTanks and Temples: This dataset includes five outdoor scenes and three indoor scenes, namely Barn, Family, Francis, Horse, Ignatius, Church, Ballroom, and Museum.\\nMVimgNet: This dataset comprises seven outdoor scenes, covering a variety of scene… See the full description on the dataset page: https://huggingface.co/datasets/kairunwen/InstantSplat.","first_N":5,"first_N_keywords":["image-to-3d","English","apache-2.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"InstantSplat","keyword":"3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kairunwen/InstantSplat","creator_name":"Kairun Wen","creator_url":"https://huggingface.co/kairunwen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInstantSplat: Sparse-view SfM-free Gaussian Splatting in Seconds\\n\\t\\n\\n[Project Page]  |  [Arxiv]  |  [Video]  |  [Code]  |  [HF Demo]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis repository contains two large-scale datasets: Tanks and Temples and MVimgNet.\\n\\nTanks and Temples: This dataset includes five outdoor scenes and three indoor scenes, namely Barn, Family, Francis, Horse, Ignatius, Church, Ballroom, and Museum.\\nMVimgNet: This dataset comprises seven outdoor scenes, covering a variety of scene… See the full description on the dataset page: https://huggingface.co/datasets/kairunwen/InstantSplat.","first_N":5,"first_N_keywords":["image-to-3d","English","apache-2.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"3d-prompt","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Miguelpef/3d-prompt","creator_name":"Miguel","creator_url":"https://huggingface.co/Miguelpef","description":"Miguelpef/3d-prompt dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Spanish","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"3d-prompt","keyword":"3d","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Miguelpef/3d-prompt","creator_name":"Miguel","creator_url":"https://huggingface.co/Miguelpef","description":"Miguelpef/3d-prompt dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Spanish","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"ObjaverseSyntheticEditable","keyword":"3d","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EmbodiedEval/ObjaverseSyntheticEditable","creator_name":"EmbodiedEval","creator_url":"https://huggingface.co/EmbodiedEval","description":"EmbodiedEval/ObjaverseSyntheticEditable dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"depth-estimation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate… See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"text-to-3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate… See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"image-to-3d","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate… See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true}
]
;
