const data_for_modality_3d = 
[
	{"name":"URDF","keyword":"3d","description":"\n\t\n\t\t\n\t\t3D Model URDF Dataset\n\t\n\nThis is a URDF dataset of 3D models, with both textured and untextured versions, designed to support research in robotics simulation, grasping, and physics simulation.\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset consists of two parts, totaling 500 models:\n\n235 Textured URDF Models: This part includes detailed texture maps, suitable for scenarios requiring high-fidelity rendering.\n265 Untextured URDF Models: This part focuses on the physical and geometricâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Behavision/URDF.","url":"https://huggingface.co/datasets/Behavision/URDF","creator_name":"Behavision","creator_url":"https://huggingface.co/Behavision","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"Objaverse-Rand6View","keyword":"3d","description":"\n\t\n\t\t\n\t\tObjaverse-Rand6View\n\t\n\nGithub | Project Page | Paper\n\n\t\n\t\t\n\t\t1. Dataset Introduction\n\t\n\nTL;DR: This dataset contains multi-view images that are rendered from a high-quality subset of Objaverse, used in MV-Adapter.\nFeatures:\n\nOrthographic or perspective views (random)\n1024x1024 resolution\nRGB, Depth, Normal, Camera\n\n\n\t\n\t\t\n\t\n\t\n\t\t2. Data Extraction\n\t\n\nsudo apt-get install git-lfs\ngit lfs install\ngit clone https://huggingface.co/datasets/huanngzh/Objaverse-Rand6View\ncatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/huanngzh/Objaverse-Rand6View.","url":"https://huggingface.co/datasets/huanngzh/Objaverse-Rand6View","creator_name":"zehuan-huang","creator_url":"https://huggingface.co/huanngzh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","image-to-3d","text-to-image","image-to-image","English"],"keywords_longer_than_N":true},
	{"name":"Objaverse-Rand6View","keyword":"3d","description":"\n\t\n\t\t\n\t\tObjaverse-Rand6View\n\t\n\nGithub | Project Page | Paper\n\n\t\n\t\t\n\t\t1. Dataset Introduction\n\t\n\nTL;DR: This dataset contains multi-view images that are rendered from a high-quality subset of Objaverse, used in MV-Adapter.\nFeatures:\n\nOrthographic or perspective views (random)\n1024x1024 resolution\nRGB, Depth, Normal, Camera\n\n\n\t\n\t\t\n\t\n\t\n\t\t2. Data Extraction\n\t\n\nsudo apt-get install git-lfs\ngit lfs install\ngit clone https://huggingface.co/datasets/huanngzh/Objaverse-Rand6View\ncatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/huanngzh/Objaverse-Rand6View.","url":"https://huggingface.co/datasets/huanngzh/Objaverse-Rand6View","creator_name":"zehuan-huang","creator_url":"https://huggingface.co/huanngzh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","image-to-3d","text-to-image","image-to-image","English"],"keywords_longer_than_N":true},
	{"name":"Objaverse-Rand6View","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tObjaverse-Rand6View\n\t\n\nGithub | Project Page | Paper\n\n\t\n\t\t\n\t\t1. Dataset Introduction\n\t\n\nTL;DR: This dataset contains multi-view images that are rendered from a high-quality subset of Objaverse, used in MV-Adapter.\nFeatures:\n\nOrthographic or perspective views (random)\n1024x1024 resolution\nRGB, Depth, Normal, Camera\n\n\n\t\n\t\t\n\t\n\t\n\t\t2. Data Extraction\n\t\n\nsudo apt-get install git-lfs\ngit lfs install\ngit clone https://huggingface.co/datasets/huanngzh/Objaverse-Rand6View\ncatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/huanngzh/Objaverse-Rand6View.","url":"https://huggingface.co/datasets/huanngzh/Objaverse-Rand6View","creator_name":"zehuan-huang","creator_url":"https://huggingface.co/huanngzh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","image-to-3d","text-to-image","image-to-image","English"],"keywords_longer_than_N":true},
	{"name":"Objaverse-Rand6View","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tObjaverse-Rand6View\n\t\n\nGithub | Project Page | Paper\n\n\t\n\t\t\n\t\t1. Dataset Introduction\n\t\n\nTL;DR: This dataset contains multi-view images that are rendered from a high-quality subset of Objaverse, used in MV-Adapter.\nFeatures:\n\nOrthographic or perspective views (random)\n1024x1024 resolution\nRGB, Depth, Normal, Camera\n\n\n\t\n\t\t\n\t\n\t\n\t\t2. Data Extraction\n\t\n\nsudo apt-get install git-lfs\ngit lfs install\ngit clone https://huggingface.co/datasets/huanngzh/Objaverse-Rand6View\ncatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/huanngzh/Objaverse-Rand6View.","url":"https://huggingface.co/datasets/huanngzh/Objaverse-Rand6View","creator_name":"zehuan-huang","creator_url":"https://huggingface.co/huanngzh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","image-to-3d","text-to-image","image-to-image","English"],"keywords_longer_than_N":true},
	{"name":"Diffusion4D","keyword":"3d","description":"\n\t\n\t\t\n\t\tDiffusion4D: Fast Spatial-temporal Consistent 4D Generation via Video Diffusion Models\n\t\n\n[Project Page] | [Arxiv] | [Code]\n\n\t\n\t\t\n\t\tNews\n\t\n\n\n2024.6.28:  Released rendered data from curated objaverse-xl.\n2024.6.4:  Released rendered data from curated objaverse-1.0, including orbital videos of dynamic 3D, orbital videos of static 3D, and monocular videos from front view.\n2024.5.27: Released metadata for objects!\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nWe collect a large-scale, high-quality dynamicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hw-liang/Diffusion4D.","url":"https://huggingface.co/datasets/hw-liang/Diffusion4D","creator_name":"Hanwen Liang","creator_url":"https://huggingface.co/hw-liang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","image-to-3d","English","apache-2.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"Diffusion4D","keyword":"3d","description":"\n\t\n\t\t\n\t\tDiffusion4D: Fast Spatial-temporal Consistent 4D Generation via Video Diffusion Models\n\t\n\n[Project Page] | [Arxiv] | [Code]\n\n\t\n\t\t\n\t\tNews\n\t\n\n\n2024.6.28:  Released rendered data from curated objaverse-xl.\n2024.6.4:  Released rendered data from curated objaverse-1.0, including orbital videos of dynamic 3D, orbital videos of static 3D, and monocular videos from front view.\n2024.5.27: Released metadata for objects!\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nWe collect a large-scale, high-quality dynamicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hw-liang/Diffusion4D.","url":"https://huggingface.co/datasets/hw-liang/Diffusion4D","creator_name":"Hanwen Liang","creator_url":"https://huggingface.co/hw-liang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","image-to-3d","English","apache-2.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"Diffusion4D","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tDiffusion4D: Fast Spatial-temporal Consistent 4D Generation via Video Diffusion Models\n\t\n\n[Project Page] | [Arxiv] | [Code]\n\n\t\n\t\t\n\t\tNews\n\t\n\n\n2024.6.28:  Released rendered data from curated objaverse-xl.\n2024.6.4:  Released rendered data from curated objaverse-1.0, including orbital videos of dynamic 3D, orbital videos of static 3D, and monocular videos from front view.\n2024.5.27: Released metadata for objects!\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nWe collect a large-scale, high-quality dynamicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hw-liang/Diffusion4D.","url":"https://huggingface.co/datasets/hw-liang/Diffusion4D","creator_name":"Hanwen Liang","creator_url":"https://huggingface.co/hw-liang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","image-to-3d","English","apache-2.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"Diffusion4D","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tDiffusion4D: Fast Spatial-temporal Consistent 4D Generation via Video Diffusion Models\n\t\n\n[Project Page] | [Arxiv] | [Code]\n\n\t\n\t\t\n\t\tNews\n\t\n\n\n2024.6.28:  Released rendered data from curated objaverse-xl.\n2024.6.4:  Released rendered data from curated objaverse-1.0, including orbital videos of dynamic 3D, orbital videos of static 3D, and monocular videos from front view.\n2024.5.27: Released metadata for objects!\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nWe collect a large-scale, high-quality dynamicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hw-liang/Diffusion4D.","url":"https://huggingface.co/datasets/hw-liang/Diffusion4D","creator_name":"Hanwen Liang","creator_url":"https://huggingface.co/hw-liang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","image-to-3d","English","apache-2.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"OpenMind","keyword":"3d","description":"\n\t\n\t\t\n\t\tThe OpenMind Dataset: A large-scale Head-And-Neck 3D MRI Dataset for self-supervised learning\n\t\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe OpenMind Dataset is a large-scale 3D MRI dataset of the head and neck region featuring 114k MRI Images. Its purpose is to provide access of large amounts of 3D medical imaging data to accelerate the development of self-supervised learning methods for 3D medical imaging. This data was pooled from exactly 800 datasets from the OpenNeuro platform and provides 23â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AnonRes/OpenMind.","url":"https://huggingface.co/datasets/AnonRes/OpenMind","creator_name":"AnonResearcher","creator_url":"https://huggingface.co/AnonRes","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["image-feature-extraction","cc-by-4.0","3D","Image","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"OpenMind","keyword":"3d","description":"\n\t\n\t\t\n\t\tThe OpenMind Dataset: A large-scale Head-And-Neck 3D MRI Dataset for self-supervised learning\n\t\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe OpenMind Dataset is a large-scale 3D MRI dataset of the head and neck region featuring 114k MRI Images. Its purpose is to provide access of large amounts of 3D medical imaging data to accelerate the development of self-supervised learning methods for 3D medical imaging. This data was pooled from exactly 800 datasets from the OpenNeuro platform and provides 23â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AnonRes/OpenMind.","url":"https://huggingface.co/datasets/AnonRes/OpenMind","creator_name":"AnonResearcher","creator_url":"https://huggingface.co/AnonRes","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["image-feature-extraction","cc-by-4.0","3D","Image","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"DA-2-Evaluation","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tDA2: Depth Anything in Any Direction\n\t\n\n\n\n\n\nDA2 predicts dense, scale-invariant distance from a single 360Â° panorama in an end-to-end manner, with remarkable geometric fidelity and strong zero-shot generalization.\n\n\t\n\t\t\n\t\tðŸŽ® Usage\n\t\n\nPlease see here.\n\n\t\n\t\t\n\t\tðŸŽ“ Citation\n\t\n\nIf you find these datasets useful, please consider citing ðŸŒ¹:\n@article{li2025depth,\n  title={DA $\\^{} 2$: Depth Anything in Any Direction},\n  author={Li, Haodong and Zheng, Wangguangdong and He, Jing and Liu, Yuhaoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/haodongli/DA-2-Evaluation.","url":"https://huggingface.co/datasets/haodongli/DA-2-Evaluation","creator_name":"Haodong Li","creator_url":"https://huggingface.co/haodongli","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","apache-2.0","1K - 10K","webdataset","Image"],"keywords_longer_than_N":true},
	{"name":"DA-2-Evaluation","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tDA2: Depth Anything in Any Direction\n\t\n\n\n\n\n\nDA2 predicts dense, scale-invariant distance from a single 360Â° panorama in an end-to-end manner, with remarkable geometric fidelity and strong zero-shot generalization.\n\n\t\n\t\t\n\t\tðŸŽ® Usage\n\t\n\nPlease see here.\n\n\t\n\t\t\n\t\tðŸŽ“ Citation\n\t\n\nIf you find these datasets useful, please consider citing ðŸŒ¹:\n@article{li2025depth,\n  title={DA $\\^{} 2$: Depth Anything in Any Direction},\n  author={Li, Haodong and Zheng, Wangguangdong and He, Jing and Liu, Yuhaoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/haodongli/DA-2-Evaluation.","url":"https://huggingface.co/datasets/haodongli/DA-2-Evaluation","creator_name":"Haodong Li","creator_url":"https://huggingface.co/haodongli","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","apache-2.0","1K - 10K","webdataset","Image"],"keywords_longer_than_N":true},
	{"name":"diffusionNet","keyword":"3d","description":"Silly98/diffusionNet dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Silly98/diffusionNet","creator_name":"Navin Shrivatsan Rajasekaran","creator_url":"https://huggingface.co/Silly98","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","text","3D","Text"],"keywords_longer_than_N":true},
	{"name":"SkyScenes","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tSkyScenes: A Synthetic Dataset for Aerial Scene Understanding\n\t\n\nSahil Khose*, Anisha Pal*, Aayushi Agarwal*, Deepanshi*, Judy Hoffman, Prithvijit Chattopadhyay\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nReal-world aerial scene understanding is limited by a lack of datasets that contain densely annotated images curated under a diverse set of conditions. \nDue to inherent challenges in obtaining such images in controlled real-world settings,\nwe present SkyScenes, a synthetic dataset of denselyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hoffman-lab/SkyScenes.","url":"https://huggingface.co/datasets/hoffman-lab/SkyScenes","creator_name":"Hoffman Lab","creator_url":"https://huggingface.co/hoffman-lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["object-detection","depth-estimation","image-segmentation","English","mit"],"keywords_longer_than_N":true},
	{"name":"RefRef_additional","keyword":"image-to-3d","description":"RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects\n\n\n  Yue Yin Â· \n  Enze Tao Â· \n  Weijian Deng Â· \n  Dylan Campbell\n\n\n\n  \n    \n  \n  \n  \n  \n  \n\t\n\t\t\n\t\tAbout\n\t\n\nThis repository provides additional data for the RefRef dataset.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{yin2025refrefsyntheticdatasetbenchmark,\n      title={RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects}, \n      author={Yue Yin and Enze Tao and Weijian Deng andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yinyue27/RefRef_additional.","url":"https://huggingface.co/datasets/yinyue27/RefRef_additional","creator_name":"yue's organization","creator_url":"https://huggingface.co/yinyue27","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","English","apache-2.0","10K<n<100K","Image"],"keywords_longer_than_N":true},
	{"name":"4DNeX-10M","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\t4DNeX-10M Dataset\n\t\n\nðŸ“„ Paper â€‚|â€‚ ðŸš€ Project Page â€‚|â€‚ ðŸ’» GitHub\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\n4DNeX-10M is a large-scale hybrid dataset introduced in the paper \"4DNeX: Feed-Forward 4D Generative Modeling Made Easy\". \nThe dataset aggregates monocular videos from diverse sources, including both static and dynamic scenes, accompanied by high-quality pseudo 4D annotations generated using state-of-the-art 3D and 4D reconstruction methods. The dataset enables joint modeling of RGB appearance andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/3DTopia/4DNeX-10M.","url":"https://huggingface.co/datasets/3DTopia/4DNeX-10M","creator_name":"3DTopia","creator_url":"https://huggingface.co/3DTopia","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","apache-2.0","n>1T","arxiv:2508.13154","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"AnimPortrait3D_gallery","keyword":"3d","description":"\n\t\n\t\t\n\t\tAnimPortrait3D Results Gallery\n\t\n\nThis gallery showcases the results of AnimPortrait3D.  \nðŸ”¹ For interactive visualization, visit our GitHub page.  \n\n\t\n\t\t\n\t\tPreview Images\n\t\n\nPreview images are available in the preview folder within this project.  \n\n\t\n\t\t\n\t\tFile Structure\n\t\n\nEach result is stored in a ZIP archive named after the face ID, containing the following files:  \nface_id.zip\nâ”‚\nâ”œâ”€â”€ fitted_params.pkl   # Fitted SMPL-X parameters  \nâ”‚\nâ”œâ”€â”€ point_cloud.ply     # The generated avatarâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/onethousand/AnimPortrait3D_gallery.","url":"https://huggingface.co/datasets/onethousand/AnimPortrait3D_gallery","creator_name":"Yiqian Wu","creator_url":"https://huggingface.co/onethousand","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","mit","< 1K","imagefolder","3D"],"keywords_longer_than_N":true},
	{"name":"SSR-3DFRONT","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tSSR-3DFRONT: Structured Scene Representation for 3D Indoor Scenes\n\t\n\nThis dataset provides a processed version of the 3D-FRONT dataset with structured scene representations for text-driven 3D indoor scene synthesis and editing.\nMor information about ReSpace: http://respace.mnbucher.com\nFor detailed usage instructions, training details, and examples, see the associated repository: https://github.com/GradientSpaces/respace\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nSSR-3DFRONT contains 13,055â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gradient-spaces/SSR-3DFRONT.","url":"https://huggingface.co/datasets/gradient-spaces/SSR-3DFRONT","creator_name":"Gradient Spaces Research Group","creator_url":"https://huggingface.co/gradient-spaces","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","robotics","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"AnimPortrait3D_gallery","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tAnimPortrait3D Results Gallery\n\t\n\nThis gallery showcases the results of AnimPortrait3D.  \nðŸ”¹ For interactive visualization, visit our GitHub page.  \n\n\t\n\t\t\n\t\tPreview Images\n\t\n\nPreview images are available in the preview folder within this project.  \n\n\t\n\t\t\n\t\tFile Structure\n\t\n\nEach result is stored in a ZIP archive named after the face ID, containing the following files:  \nface_id.zip\nâ”‚\nâ”œâ”€â”€ fitted_params.pkl   # Fitted SMPL-X parameters  \nâ”‚\nâ”œâ”€â”€ point_cloud.ply     # The generated avatarâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/onethousand/AnimPortrait3D_gallery.","url":"https://huggingface.co/datasets/onethousand/AnimPortrait3D_gallery","creator_name":"Yiqian Wu","creator_url":"https://huggingface.co/onethousand","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","mit","< 1K","imagefolder","3D"],"keywords_longer_than_N":true},
	{"name":"EmbodiedGenData","keyword":"3d","description":"HorizonRobotics/EmbodiedGenData dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/HorizonRobotics/EmbodiedGenData","creator_name":"HorizonRobotics","creator_url":"https://huggingface.co/HorizonRobotics","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"RSL_Maran","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ae5115242430e13/RSL_Maran.","url":"https://huggingface.co/datasets/ae5115242430e13/RSL_Maran","creator_name":"R.s.L Maran","creator_url":"https://huggingface.co/ae5115242430e13","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","table-question-answering","question-answering","text-classification","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"CADBench","keyword":"3d","description":"\n\t\n\t\t\n\t\tðŸ“š CADBench\n\t\n\nCADBench is a comprehensive benchmark to evaluate the ability of LLMs to generate CAD scripts. It contains 500 simulated data samples and 200 data samples collected from online forums.\nFor more details, please visit our GitHub repository or refer to our arXiv paper.\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“– Citation\n\t\n\n@misc{du2024blenderllmtraininglargelanguage,\n      title={BlenderLLM: Training Large Language Models for Computer-Aided Design with Self-improvement}, \n      author={Yuhao Du andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/CADBench.","url":"https://huggingface.co/datasets/FreedomIntelligence/CADBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"tinybasic","keyword":"3d","description":"introvoyz041/tinybasic dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/introvoyz041/tinybasic","creator_name":"Bri Parales","creator_url":"https://huggingface.co/introvoyz041","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","text","3D","Image"],"keywords_longer_than_N":true},
	{"name":"HouseLayout3D","keyword":"3d","description":"\n\t\n\t\t\n\t\tHouseLayout3D: A Benchmark Dataset for 3D Layout Estimation in the Wild\n\t\n\nHouseLayout3D is a challenging benchmark dataset for 3D layout estimation in large-scale, multi-floor buildings. It is built upon real-world building scans from Matterport3D, and provides detailed annotations of structural elements across up to five floors and forty rooms per building. The dataset is designed to support research in scene understanding, indoor mapping, and robotics applications that requireâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bieriv/HouseLayout3D.","url":"https://huggingface.co/datasets/bieriv/HouseLayout3D","creator_name":"Valentin Bieri","creator_url":"https://huggingface.co/bieriv","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","10K - 100K","3D","Text","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"OpenGameArt-CC0","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-CC0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the Creative Commons 0 (CC0) license, making them effectively public domain works. The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC0.","url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-CC0","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-CC0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the Creative Commons 0 (CC0) license, making them effectively public domain works. The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC0.","url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"tripoexamples","keyword":"3d","description":"Avmromanov/tripoexamples dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Avmromanov/tripoexamples","creator_name":"Andrey Romanov","creator_url":"https://huggingface.co/Avmromanov","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"CamVid-30K","keyword":"3d","description":"\n\t\n\t\t\n\t\n\t\n\t\tCamVid-30K\n\t\n\n\n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tSummary\n\t\n\nThis is the CamVid-30K dataset introduced in our paper, \"GenXD: Generating Any 3D and 4D Scenes.\" CamVid-30K is the first open-sourced, large-scale 4D dataset, designed to support various dynamic 3D tasks. It includes videos sourced from VIPSeg, OpenVid-1M, and WebVid-10M, with camera annotations curated using our data curation pipeline.  \nProject: https://gen-x-d.github.io/\nPaper: https://arxiv.org/pdf/2411.02319\nCode:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yuyang-z/CamVid-30K.","url":"https://huggingface.co/datasets/Yuyang-z/CamVid-30K","creator_name":"Yuyang","creator_url":"https://huggingface.co/Yuyang-z","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","English","cc-by-4.0","10K<n<100K","3D"],"keywords_longer_than_N":true},
	{"name":"CamVid-30K","keyword":"3d","description":"\n\t\n\t\t\n\t\n\t\n\t\tCamVid-30K\n\t\n\n\n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tSummary\n\t\n\nThis is the CamVid-30K dataset introduced in our paper, \"GenXD: Generating Any 3D and 4D Scenes.\" CamVid-30K is the first open-sourced, large-scale 4D dataset, designed to support various dynamic 3D tasks. It includes videos sourced from VIPSeg, OpenVid-1M, and WebVid-10M, with camera annotations curated using our data curation pipeline.  \nProject: https://gen-x-d.github.io/\nPaper: https://arxiv.org/pdf/2411.02319\nCode:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yuyang-z/CamVid-30K.","url":"https://huggingface.co/datasets/Yuyang-z/CamVid-30K","creator_name":"Yuyang","creator_url":"https://huggingface.co/Yuyang-z","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","English","cc-by-4.0","10K<n<100K","3D"],"keywords_longer_than_N":true},
	{"name":"CamVid-30K","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\n\t\n\t\tCamVid-30K\n\t\n\n\n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tSummary\n\t\n\nThis is the CamVid-30K dataset introduced in our paper, \"GenXD: Generating Any 3D and 4D Scenes.\" CamVid-30K is the first open-sourced, large-scale 4D dataset, designed to support various dynamic 3D tasks. It includes videos sourced from VIPSeg, OpenVid-1M, and WebVid-10M, with camera annotations curated using our data curation pipeline.  \nProject: https://gen-x-d.github.io/\nPaper: https://arxiv.org/pdf/2411.02319\nCode:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yuyang-z/CamVid-30K.","url":"https://huggingface.co/datasets/Yuyang-z/CamVid-30K","creator_name":"Yuyang","creator_url":"https://huggingface.co/Yuyang-z","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","English","cc-by-4.0","10K<n<100K","3D"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"depth-estimation","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"image-to-3d","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"text-to-3d","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"PixelArt_Multiview","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tMultiview PixelArt\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nContains sets of images representing a full 360Â° turnaround of characters, animals and objects in pixel art.\nEach row contains 9 images from all angles.\nCamera Data can be downloaded \n\nExamples\n\n\t\n\t\t\nInput (f1)\nf2\nf3\nf4\n\n\n\n\t\t\n\n\n\n\n\n\nf5\nf6\nf7\nf8\nf9\n\n\n\n\n\n\n\n\n\t\n\n\n\t\n\t\t\nInput (f1)\nf2\nf3\nf4\n\n\n\n\t\t\n\n\n\n\n\n\nf5\nf6\nf7\nf8\nf9\n\n\n\n\n\n\n\n\n\t\n\n\n\t\n\t\t\nInput (f1)\nf2\nf3\nf4\n\n\n\n\t\t\n\n\n\n\n\nf5\nf6\nf7\nf8\nf9\n\n\n\n\n\n\n\n\n\n\t\n\n\n\t\n\t\t\nInput (f1)\nf2\nf3\nf4\n\n\n\n\t\t\n\n\n\n\n\n\n\nf5\nf6\nf7\nf8\nf9â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Scaryplasmon96/PixelArt_Multiview.","url":"https://huggingface.co/datasets/Scaryplasmon96/PixelArt_Multiview","creator_name":"Andrea Cicero","creator_url":"https://huggingface.co/Scaryplasmon96","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-image","image-to-3d","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Minecraft-Depth-Images","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tD4MCDataset\n\t\n\nDataset created to train the Depth4MC model.\nImages and depth label are of size 480x854.\nRead more information on the GitHub page: https://github.com/JulianBvW/Depth4MC\n\n","url":"https://huggingface.co/datasets/JulianBvW/Minecraft-Depth-Images","creator_name":"Julian BvW","creator_url":"https://huggingface.co/JulianBvW","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","apache-2.0","10K - 100K","webdataset","Image"],"keywords_longer_than_N":true},
	{"name":"DurLAR","keyword":"depth-estimation","description":"\n\n\t\n\t\t\n\t\tDurLAR: A High-Fidelity 128-Channel LiDAR Dataset\n\t\n\n\n\t\n\t\t\n\t\tNews\n\t\n\n\n[2025/03/16] We provide the dataset download link hosted on Hugging Face, along with the corresponding new download script.\n[2025/03/16] We provide an exemplar dataset (600 frames), which is now available for direct preview on the webpage, displaying dataset image-based topics (image_00, image_01, reflectivity, ambient).\n[2024/12/05] We provide the intrinsic parameters of our OS1-128 LiDAR [download].â€¦ See the full description on the dataset page: https://huggingface.co/datasets/l1997i/DurLAR.","url":"https://huggingface.co/datasets/l1997i/DurLAR","creator_name":"Li Li","creator_url":"https://huggingface.co/l1997i","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["depth-estimation","English","cc-by-4.0","1M<n<10M","arxiv:2406.10068"],"keywords_longer_than_N":true},
	{"name":"microgen3D","keyword":"3d","description":"\n\t\n\t\t\n\t\tmicrogen3D\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nmicrogen3D is a dataset of 3D voxelized microstructures designed for training, evaluation, and benchmarking of generative modelsâ€”especially Conditional Latent Diffusion Models (LDMs). It includes both synthetic (Cahnâ€“Hilliard) and experimental microstructures with multiple phases (2 to 3). The voxel grids range from 64Â³ up to 128Ã—128Ã—64.\nThe dataset consists of three microstructure types:\n\nExperimental microstructures\n2-phase Cahnâ€“Hilliardâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BGLab/microgen3D.","url":"https://huggingface.co/datasets/BGLab/microgen3D","creator_name":"Baskar Group","creator_url":"https://huggingface.co/BGLab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","3D","arxiv:2503.10711","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"microgen3D","keyword":"3d","description":"\n\t\n\t\t\n\t\tmicrogen3D\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nmicrogen3D is a dataset of 3D voxelized microstructures designed for training, evaluation, and benchmarking of generative modelsâ€”especially Conditional Latent Diffusion Models (LDMs). It includes both synthetic (Cahnâ€“Hilliard) and experimental microstructures with multiple phases (2 to 3). The voxel grids range from 64Â³ up to 128Ã—128Ã—64.\nThe dataset consists of three microstructure types:\n\nExperimental microstructures\n2-phase Cahnâ€“Hilliardâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BGLab/microgen3D.","url":"https://huggingface.co/datasets/BGLab/microgen3D","creator_name":"Baskar Group","creator_url":"https://huggingface.co/BGLab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","3D","arxiv:2503.10711","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"RoboTwin_Challenge_Round2","keyword":"3d","description":"ZanxinChen/RoboTwin_Challenge_Round2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ZanxinChen/RoboTwin_Challenge_Round2","creator_name":"ZanxinChen","creator_url":"https://huggingface.co/ZanxinChen","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","1K - 10K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"assets","keyword":"3d","description":"Genesis-Intelligence/assets dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Genesis-Intelligence/assets","creator_name":"Genesis AI","creator_url":"https://huggingface.co/Genesis-Intelligence","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"3D-PC","keyword":"3d","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\nVisual perspective taking (VPT), the ability to accurately perceive and reason about the perspectives of others, is an essential feature of human intelligence. \nDeep neural networks (DNNs) may be a good candidate for modeling VPT and its computational demands in light of a growing number of reports indicating that DNNs gain the ability to analyze 3D scenes after training on large static-image datasets.\nWe developed the 3D perception challenge (3D-PC) for comparing 3Dâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/3D-PC/3D-PC.","url":"https://huggingface.co/datasets/3D-PC/3D-PC","creator_name":"3D-PC","creator_url":"https://huggingface.co/3D-PC","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","cc-by-4.0","10K - 100K","parquet","3D"],"keywords_longer_than_N":true},
	{"name":"navier-stokes-dataset","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tNavier Stokes Dataset of Isotropic Turbulence in a periodic box\n\t\n\n\n\nThe dataset for tensor-to-tensor or trajectory-to-trajectory neural operators, generated from Navier-Stokes equations \nto model the isotropic turbulence [1] such that the spectra satisfy the inverse cascade discovered by A.N. Kolmogorov [2].\n[1]: McWilliams, J. C. (1984). The emergence of isolated coherent vortices in turbulent flow. Journal of Fluid Mechanics, 146, 21-43.\n[2]: Kolmogorov, A. N. (1941). The localâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/scaomath/navier-stokes-dataset.","url":"https://huggingface.co/datasets/scaomath/navier-stokes-dataset","creator_name":"Shuhao Cao","creator_url":"https://huggingface.co/scaomath","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-to-3d","mit","1K<n<10K","arxiv:2405.17211","doi:10.57967/hf/2470"],"keywords_longer_than_N":true},
	{"name":"RelitLRM_Web","keyword":"3d","description":"YunjinZhang/RelitLRM_Web dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/YunjinZhang/RelitLRM_Web","creator_name":"Tianyuan Zhang","creator_url":"https://huggingface.co/YunjinZhang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"MCTED","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tMCTED - Mars CTX Terrain-Elevation Dataset\n\t\n\nDataset repository (pending ESA license) | arXiv article\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nMCTED is a machine-learning-ready dataset of optical images of the surface of Mars, paired with their corresponding digital elevation models.\nIt was created using an extensive repository of orthoimage-DEM pairs with the NASA Ames Stereo Pipeline using the Mars Reconneissance Orbiter's CTX instrument imagery by\nDay et al. 2023. We process the samples from theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ESA-Datalabs/MCTED.","url":"https://huggingface.co/datasets/ESA-Datalabs/MCTED","creator_name":"ESA Datalabs","creator_url":"https://huggingface.co/ESA-Datalabs","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","image-to-image","English","cc0-1.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"MCTED","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tMCTED - Mars CTX Terrain-Elevation Dataset\n\t\n\nDataset repository (pending ESA license) | arXiv article\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nMCTED is a machine-learning-ready dataset of optical images of the surface of Mars, paired with their corresponding digital elevation models.\nIt was created using an extensive repository of orthoimage-DEM pairs with the NASA Ames Stereo Pipeline using the Mars Reconneissance Orbiter's CTX instrument imagery by\nDay et al. 2023. We process the samples from theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ESA-Datalabs/MCTED.","url":"https://huggingface.co/datasets/ESA-Datalabs/MCTED","creator_name":"ESA Datalabs","creator_url":"https://huggingface.co/ESA-Datalabs","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","image-to-image","English","cc0-1.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"squeeze3d_rf_nerfmae","keyword":"image-to-3d","description":"This dataset is for the paper Squeeze3D: Your 3D Generation Model is Secretly an Extreme Neural Compressor. It contains latent representations of 3D data used for training and evaluating the Squeeze3D model.\nProject page\nCode\n","url":"https://huggingface.co/datasets/rishitdagli/squeeze3d_rf_nerfmae","creator_name":"Rishit Dagli","creator_url":"https://huggingface.co/rishitdagli","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","mit","1K - 10K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"mujoco","keyword":"3d","description":"introvoyz041/mujoco dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/introvoyz041/mujoco","creator_name":"Bri Parales","creator_url":"https://huggingface.co/introvoyz041","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","3D","Image","Text"],"keywords_longer_than_N":true},
	{"name":"Prusaslicer","keyword":"3d","description":"introvoyz041/Prusaslicer dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/introvoyz041/Prusaslicer","creator_name":"Bri Parales","creator_url":"https://huggingface.co/introvoyz041","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","text","3D","Image"],"keywords_longer_than_N":true},
	{"name":"InstantSplat","keyword":"3d","description":"\n\t\n\t\t\n\t\tInstantSplat: Sparse-view SfM-free Gaussian Splatting in Seconds\n\t\n\n[Project Page]  |  [Arxiv]  |  [Video]  |  [Code]  |  [HF Demo]\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThis repository contains two large-scale datasets: Tanks and Temples and MVimgNet.\n\nTanks and Temples: This dataset includes five outdoor scenes and three indoor scenes, namely Barn, Family, Francis, Horse, Ignatius, Church, Ballroom, and Museum.MVimgNet: This dataset comprises seven outdoor scenes, covering a variety of scene typesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kairunwen/InstantSplat.","url":"https://huggingface.co/datasets/kairunwen/InstantSplat","creator_name":"Kairun Wen","creator_url":"https://huggingface.co/kairunwen","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","English","apache-2.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"InstantSplat","keyword":"3d","description":"\n\t\n\t\t\n\t\tInstantSplat: Sparse-view SfM-free Gaussian Splatting in Seconds\n\t\n\n[Project Page]  |  [Arxiv]  |  [Video]  |  [Code]  |  [HF Demo]\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThis repository contains two large-scale datasets: Tanks and Temples and MVimgNet.\n\nTanks and Temples: This dataset includes five outdoor scenes and three indoor scenes, namely Barn, Family, Francis, Horse, Ignatius, Church, Ballroom, and Museum.MVimgNet: This dataset comprises seven outdoor scenes, covering a variety of scene typesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kairunwen/InstantSplat.","url":"https://huggingface.co/datasets/kairunwen/InstantSplat","creator_name":"Kairun Wen","creator_url":"https://huggingface.co/kairunwen","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","English","apache-2.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"XLD-Baidu","keyword":"3d","description":"lifuguan/XLD-Baidu dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/lifuguan/XLD-Baidu","creator_name":"leoli","creator_url":"https://huggingface.co/lifuguan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"InstantSplat","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tInstantSplat: Sparse-view SfM-free Gaussian Splatting in Seconds\n\t\n\n[Project Page]  |  [Arxiv]  |  [Video]  |  [Code]  |  [HF Demo]\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThis repository contains two large-scale datasets: Tanks and Temples and MVimgNet.\n\nTanks and Temples: This dataset includes five outdoor scenes and three indoor scenes, namely Barn, Family, Francis, Horse, Ignatius, Church, Ballroom, and Museum.MVimgNet: This dataset comprises seven outdoor scenes, covering a variety of scene typesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kairunwen/InstantSplat.","url":"https://huggingface.co/datasets/kairunwen/InstantSplat","creator_name":"Kairun Wen","creator_url":"https://huggingface.co/kairunwen","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","English","apache-2.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"fMRI-Shape","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tfMRI-Shape Dataset: A Component of the fMRI-3D Dataset for MinD-3D++\n\t\n\nThis repository contains the fMRI-Shape dataset, a component of the comprehensive fMRI-3D dataset introduced and utilized in the paper MinD-3D++: Advancing fMRI-Based 3D Reconstruction with High-Quality Textured Mesh Generation and a Comprehensive Dataset. This work builds upon the initial \"MinD-3D\" research.\nThe fMRI-3D dataset consists of two components: fMRI-Shape (this dataset) and fMRI-Objaverse. Both datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fudan-fMRI/fMRI-Shape.","url":"https://huggingface.co/datasets/Fudan-fMRI/fMRI-Shape","creator_name":"Fudan-fMRI-yanwei","creator_url":"https://huggingface.co/Fudan-fMRI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","apache-2.0","1K - 10K","text","Text"],"keywords_longer_than_N":true},
	{"name":"PhysicalAI-SimReady-Warehouse-01","keyword":"3d","description":"\n\t\n\t\t\n\t\tNVIDIA Physical AI SimReady Warehouse OpenUSD Dataset\n\t\n\n\n\nDataset Version: 1.1.0\nDate: May 18, 2025\nAuthor: NVIDIA, Corporation\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\n\n\t\t\n\t\n\t\tContents\n\t\n\nThis dataset includes the following:\n\nThis README file\nA CSV catalog that enumerates all of the OpenUSD assets that are part of this dataset including a sub-folder of images that showcase each 3D asset (physical_ai_simready_warehouse_01.csv). The CSV file is organized inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/PhysicalAI-SimReady-Warehouse-01.","url":"https://huggingface.co/datasets/nvidia/PhysicalAI-SimReady-Warehouse-01","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","robotics","depth-estimation","object-detection","image-classification"],"keywords_longer_than_N":true},
	{"name":"PhysicalAI-SimReady-Warehouse-01","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tNVIDIA Physical AI SimReady Warehouse OpenUSD Dataset\n\t\n\n\n\nDataset Version: 1.1.0\nDate: May 18, 2025\nAuthor: NVIDIA, Corporation\nLicense: CC-BY-4.0 (Creative Commons Attribution 4.0 International)\n\n\t\t\n\t\n\t\tContents\n\t\n\nThis dataset includes the following:\n\nThis README file\nA CSV catalog that enumerates all of the OpenUSD assets that are part of this dataset including a sub-folder of images that showcase each 3D asset (physical_ai_simready_warehouse_01.csv). The CSV file is organized inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/PhysicalAI-SimReady-Warehouse-01.","url":"https://huggingface.co/datasets/nvidia/PhysicalAI-SimReady-Warehouse-01","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","robotics","depth-estimation","object-detection","image-classification"],"keywords_longer_than_N":true},
	{"name":"WorldScore","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tWorldScore: A Unified Evaluation Benchmark for World Generation\n\t\n\n\n    \n    \n    \n    \n\n\n\n\n\t\n\t\n\t\n\t\tWorldScore: A Unified Evaluation Benchmark for World Generation\n\t\n\n\t\n\t\t\n\t\tHaoyi Duan*, Hong-Xing \"Koven\" Yu*, Sirui Chen, Li Fei-Fei, Jiajun Wu (\"*\" denotes equal contribution)\n\t\n\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@article{duan2025worldscore,\n  title={WorldScore: A Unified Evaluation Benchmark for World Generation},\n  author={Duan, Haoyi and Yu, Hong-Xing and Chen, Sirui and Fei-Fei, Li and Wuâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Howieeeee/WorldScore.","url":"https://huggingface.co/datasets/Howieeeee/WorldScore","creator_name":"Haoyi Duan","creator_url":"https://huggingface.co/Howieeeee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-video","image-to-3d","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Hypo3D","keyword":"3d","description":"MatchLab/Hypo3D dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/MatchLab/Hypo3D","creator_name":"MatchLab","creator_url":"https://huggingface.co/MatchLab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","1K - 10K","imagefolder","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"Industrialrobotics","keyword":"3d","description":"introvoyz041/Industrialrobotics dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/introvoyz041/Industrialrobotics","creator_name":"Bri Parales","creator_url":"https://huggingface.co/introvoyz041","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","3D","Image","Text"],"keywords_longer_than_N":true},
	{"name":"iso3d","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tiso3d - Isolated Synthetic Objects 3D\n\t\n\nA dataset of isolated object images for evaluating image-to-3D models.\nPaper: 3D Arena: An Open Platform for Generative 3D Evaluation\n\n\t\n\t\t\n\t\tLeaderboard\n\t\n\nVote and view results at 3d-arena.\n\n\t\n\t\t\n\t\tCuration\n\t\n\nImages are created using dreamshaper-xl and white background lora on karlo-v1 prompts.\n\nEach karlo-v1 prompt is extended with {prompt}, isolated object render, with a white background and negative prompt text, watermark, shadowâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dylanebert/iso3d.","url":"https://huggingface.co/datasets/dylanebert/iso3d","creator_name":"Dylan Ebert","creator_url":"https://huggingface.co/dylanebert","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"DA-2","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tDA2: Depth Anything in Any Direction\n\t\n\n\n\n\n\nDA2 predicts dense, scale-invariant distance from a single 360Â° panorama in an end-to-end manner, with remarkable geometric fidelity and strong zero-shot generalization.\n\n\t\n\t\t\n\t\tðŸŽ“ Citation\n\t\n\nIf you find our dataset useful, please consider citing our paperðŸŒ¹:\n@article{li2025depth,\n  title={DA $\\^{} 2$: Depth Anything in Any Direction},\n  author={Li, Haodong and Zheng, Wangguangdong and He, Jing and Liu, Yuhao and Lin, Xin and Yang, Xin andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/haodongli/DA-2.","url":"https://huggingface.co/datasets/haodongli/DA-2","creator_name":"Haodong Li","creator_url":"https://huggingface.co/haodongli","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","apache-2.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"DA-2","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tDA2: Depth Anything in Any Direction\n\t\n\n\n\n\n\nDA2 predicts dense, scale-invariant distance from a single 360Â° panorama in an end-to-end manner, with remarkable geometric fidelity and strong zero-shot generalization.\n\n\t\n\t\t\n\t\tðŸŽ“ Citation\n\t\n\nIf you find our dataset useful, please consider citing our paperðŸŒ¹:\n@article{li2025depth,\n  title={DA $\\^{} 2$: Depth Anything in Any Direction},\n  author={Li, Haodong and Zheng, Wangguangdong and He, Jing and Liu, Yuhao and Lin, Xin and Yang, Xin andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/haodongli/DA-2.","url":"https://huggingface.co/datasets/haodongli/DA-2","creator_name":"Haodong Li","creator_url":"https://huggingface.co/haodongli","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","apache-2.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"TRELLIS-500K","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tTRELLIS-500K\n\t\n\nTRELLIS-500K is a dataset of 500K 3D assets curated from Objaverse(XL), ABO, 3D-FUTURE, HSSD, and Toys4k, filtered based on aesthetic scores.\nThis dataset serves for 3D generation tasks.\nIt was introduced in the paper Structured 3D Latents for Scalable and Versatile 3D Generation.\n\n\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\nThe following table summarizes the dataset's filtering and composition:\nNOTE: Some of the 3D assets lack text captions. Please filter out such assets if captionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JeffreyXiang/TRELLIS-500K.","url":"https://huggingface.co/datasets/JeffreyXiang/TRELLIS-500K","creator_name":"Jianfeng Xiang","creator_url":"https://huggingface.co/JeffreyXiang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","text-to-3d","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"TRELLIS-500K","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tTRELLIS-500K\n\t\n\nTRELLIS-500K is a dataset of 500K 3D assets curated from Objaverse(XL), ABO, 3D-FUTURE, HSSD, and Toys4k, filtered based on aesthetic scores.\nThis dataset serves for 3D generation tasks.\nIt was introduced in the paper Structured 3D Latents for Scalable and Versatile 3D Generation.\n\n\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\nThe following table summarizes the dataset's filtering and composition:\nNOTE: Some of the 3D assets lack text captions. Please filter out such assets if captionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JeffreyXiang/TRELLIS-500K.","url":"https://huggingface.co/datasets/JeffreyXiang/TRELLIS-500K","creator_name":"Jianfeng Xiang","creator_url":"https://huggingface.co/JeffreyXiang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","text-to-3d","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"realhouse","keyword":"3d","description":"FutureMa/realhouse dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/FutureMa/realhouse","creator_name":"MaShijian","creator_url":"https://huggingface.co/FutureMa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"PetraAI","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tPETRA\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nPETRA is a multilingual dataset for training and evaluating AI systems on a diverse range of tasks across multiple modalities. It contains data in Arabic and English for tasks including translation, summarization, question answering, and more.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nData is separated by language into /ar and /en directories\nWithin each language directory, data is separated by task into subdirectories  \nTasks include:\nTranslation\nSummarizationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PetraAI/PetraAI.","url":"https://huggingface.co/datasets/PetraAI/PetraAI","creator_name":"Shady BA","creator_url":"https://huggingface.co/PetraAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"UpGrow-Boost","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\t UpGrow Boostâ„¢\n\t\n\nWelcome to the UpGrow Boost Dataset repository on Hugging Face. This repository provides insights into our dataset used for powering our AI-driven Instagram growth services.\n\n\t\n\t\t\n\t\tðŸŒ About UpGrow\n\t\n\nUpGrow is a trailblazing platform offering Instagram growth services powered by artificial intelligence (AI) and advanced machine learning algorithms for rapid and efficient Instagram growth.\n\n\t\n\t\t\n\t\tðŸ“Š UpGrow-Boost Dataset\n\t\n\nThe UpGrow-Boost Dataset is a collection ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/UpGrowTeam/UpGrow-Boost.","url":"https://huggingface.co/datasets/UpGrowTeam/UpGrow-Boost","creator_name":"UpGrow","creator_url":"https://huggingface.co/UpGrowTeam","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["zero-shot-classification","depth-estimation","multiple-choice","summarization","English"],"keywords_longer_than_N":true},
	{"name":"nyu_depth_v2","keyword":"depth-estimation","description":"The NYU-Depth V2 data set is comprised of video sequences from a variety of indoor scenes as recorded by both the RGB and Depth cameras from the Microsoft Kinect.","url":"https://huggingface.co/datasets/sayakpaul/nyu_depth_v2","creator_name":"Sayak Paul","creator_url":"https://huggingface.co/sayakpaul","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","monolingual","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"nyu_depth_v2","keyword":"depth-estimation","description":"The NYU-Depth V2 data set is comprised of video sequences from a variety of indoor scenes as recorded by both the RGB and Depth cameras from the Microsoft Kinect.","url":"https://huggingface.co/datasets/sayakpaul/nyu_depth_v2","creator_name":"Sayak Paul","creator_url":"https://huggingface.co/sayakpaul","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","monolingual","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"idr0012-fuchs-cellmorph-S-BIAD845","keyword":"3d","description":"stefanches/idr0012-fuchs-cellmorph-S-BIAD845 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/stefanches/idr0012-fuchs-cellmorph-S-BIAD845","creator_name":"Stefan Dvoretskii","creator_url":"https://huggingface.co/stefanches","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["fill-mask","feature-extraction","cc0-1.0","n>1T","3D"],"keywords_longer_than_N":true},
	{"name":"idr0012-fuchs-cellmorph-S-BIAD845","keyword":"3d","description":"stefanches/idr0012-fuchs-cellmorph-S-BIAD845 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/stefanches/idr0012-fuchs-cellmorph-S-BIAD845","creator_name":"Stefan Dvoretskii","creator_url":"https://huggingface.co/stefanches","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["fill-mask","feature-extraction","cc0-1.0","n>1T","3D"],"keywords_longer_than_N":true},
	{"name":"mydata","keyword":"3d","description":"TheHenk/mydata dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/TheHenk/mydata","creator_name":"Henrik Ljungberg","creator_url":"https://huggingface.co/TheHenk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"DungeonAssistant","keyword":"3d","description":"Check https://github.com/JeffersonQin/DungeonAssistant for details.\n","url":"https://huggingface.co/datasets/gyrojeff/DungeonAssistant","creator_name":"Haoyun Qin","creator_url":"https://huggingface.co/gyrojeff","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","3D","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"gafoart","keyword":"3d","description":"gafoart/gafoart dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/gafoart/gafoart","creator_name":"Cesar Rodriguez","creator_url":"https://huggingface.co/gafoart","license_name":"PostgreSQL License","license_url":"https://choosealicense.com/licenses/postgresql/","language":"en","first_N":5,"first_N_keywords":["postgresql","< 1K","3D","Image","Video"],"keywords_longer_than_N":true},
	{"name":"Hi3DBench","keyword":"3d","description":"Hierarchical 3D Benmark\nThis is an annotation dataset for 3D quality evaluation, including Object-Level, Part-Level and Material-Subject annotations.\nWe also release 3D assets generated from new 3D generative models that are not included in 3DGen-Bench dataset.\n","url":"https://huggingface.co/datasets/3DTopia/Hi3DBench","creator_name":"3DTopia","creator_url":"https://huggingface.co/3DTopia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","image-to-3d","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Hi3DBench","keyword":"image-to-3d","description":"Hierarchical 3D Benmark\nThis is an annotation dataset for 3D quality evaluation, including Object-Level, Part-Level and Material-Subject annotations.\nWe also release 3D assets generated from new 3D generative models that are not included in 3DGen-Bench dataset.\n","url":"https://huggingface.co/datasets/3DTopia/Hi3DBench","creator_name":"3DTopia","creator_url":"https://huggingface.co/3DTopia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","image-to-3d","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Hi3DBench","keyword":"text-to-3d","description":"Hierarchical 3D Benmark\nThis is an annotation dataset for 3D quality evaluation, including Object-Level, Part-Level and Material-Subject annotations.\nWe also release 3D assets generated from new 3D generative models that are not included in 3DGen-Bench dataset.\n","url":"https://huggingface.co/datasets/3DTopia/Hi3DBench","creator_name":"3DTopia","creator_url":"https://huggingface.co/3DTopia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","image-to-3d","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"MESHY.AI_363_PLY_Creatures_Labelled","keyword":"3d","description":"\nmeshy_creatures.zip - 363 Samples PLY (Vertex Colored, Labelled).\n\nRefined from this dataset but with fixed spelling mistakes and slightly improved labelling this dataset of 363 creatures includes people, animals, monsters, and robots. Along with some mythical dragons, mushroom people, frogs, four legged animals with two legs, etc.\nThese models have been scaled to a unit sphere which is a normalised cubic scale multiplied by 0.55 which means they fit perfectly within a unit sphere.\nThisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tfnn/MESHY.AI_363_PLY_Creatures_Labelled.","url":"https://huggingface.co/datasets/tfnn/MESHY.AI_363_PLY_Creatures_Labelled","creator_name":"James William Fletcher","creator_url":"https://huggingface.co/tfnn","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["English","cc0-1.0","n<1K","3D","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"MESHY.AI_363_PLY_Creatures_Labelled","keyword":"3d","description":"\nmeshy_creatures.zip - 363 Samples PLY (Vertex Colored, Labelled).\n\nRefined from this dataset but with fixed spelling mistakes and slightly improved labelling this dataset of 363 creatures includes people, animals, monsters, and robots. Along with some mythical dragons, mushroom people, frogs, four legged animals with two legs, etc.\nThese models have been scaled to a unit sphere which is a normalised cubic scale multiplied by 0.55 which means they fit perfectly within a unit sphere.\nThisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tfnn/MESHY.AI_363_PLY_Creatures_Labelled.","url":"https://huggingface.co/datasets/tfnn/MESHY.AI_363_PLY_Creatures_Labelled","creator_name":"James William Fletcher","creator_url":"https://huggingface.co/tfnn","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["English","cc0-1.0","n<1K","3D","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Military-Aircraft-Detection","keyword":"depth-estimation","description":"Dataset for object detection of military aircraft\nbounding box in PASCAL VOC format (xmin, ymin, xmax, ymax)\n43 aircraft types\n(A-10, A-400M, AG-600, AV-8B, B-1, B-2, B-52 Be-200, C-130, C-17, C-2, C-5, E-2, E-7, EF-2000, F-117, F-14, F-15, F-16, F/A-18, F-22, F-35, F-4, J-20, JAS-39, MQ-9, Mig-31, Mirage2000, P-3(CP-140), RQ-4, Rafale, SR-71(may contain A-12), Su-34, Su-57, Tornado, Tu-160, Tu-95(Tu-142), U-2, US-2(US-1A Kai), V-22, Vulcan, XB-70, YF-23)\nPlease let me know if you find wrongâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Illia56/Military-Aircraft-Detection.","url":"https://huggingface.co/datasets/Illia56/Military-Aircraft-Detection","creator_name":"Illia Liudogovskyi","creator_url":"https://huggingface.co/Illia56","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["object-detection","zero-shot-classification","zero-shot-image-classification","depth-estimation","image-classification"],"keywords_longer_than_N":true},
	{"name":"pixie","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tPixie Dataset\n\t\n\nThis dataset contains data and pre-trained models for the paper Pixie: Fast and Generalizable Supervised Learning of 3D Physics from Pixels.\n\nProject Page: https://pixie-3d.github.io/\nCode: https://github.com/vlongle/pixie\n\n\n\t\n\t\t\n\t\n\t\n\t\tContents\n\t\n\n\ncheckpoints_continuous_mse/: Continuous material property prediction model checkpoints\ncheckpoints_discrete/: Discrete material classification model checkpoints\nreal_scene_data/: Real scene data for evaluationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vlongle/pixie.","url":"https://huggingface.co/datasets/vlongle/pixie","creator_name":"Long Le","creator_url":"https://huggingface.co/vlongle","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","mit","< 1K","json","Image"],"keywords_longer_than_N":true},
	{"name":"scene3d-bg","keyword":"3d","description":"xinjjj/scene3d-bg dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/xinjjj/scene3d-bg","creator_name":"xinjjj","creator_url":"https://huggingface.co/xinjjj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","text","3D","Image"],"keywords_longer_than_N":true},
	{"name":"HouseLayout3D","keyword":"3d","description":"\n\t\n\t\t\n\t\tHouseLayout3D: A Benchmark Dataset for 3D Layout Estimation in the Wild\n\t\n\nHouseLayout3D is a challenging benchmark dataset for 3D layout estimation in large-scale, multi-floor buildings. It is built upon real-world building scans from Matterport3D, and provides detailed annotations of structural elements across up to five floors and forty rooms per building. The dataset is designed to support research in scene understanding, indoor mapping, and robotics applications that requireâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/houselayout3d/HouseLayout3D.","url":"https://huggingface.co/datasets/houselayout3d/HouseLayout3D","creator_name":"HouseLayout3D","creator_url":"https://huggingface.co/houselayout3d","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","10K - 100K","3D","Text","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"vpocc-vanishing-points","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tCitation\n\t\n\n@article{kim2024vpocc,\n  title={VPOcc: Exploiting Vanishing Point for Monocular 3D Semantic Occupancy Prediction},\n  author={Kim, Junsu and Lee, Junhee and Shin, Ukcheol and Oh, Jean and Joo, Kyungdon},\n  journal={arXiv preprint arXiv:2408.03551},\n  year={2024}\n}\n\n","url":"https://huggingface.co/datasets/joonsu0109/vpocc-vanishing-points","creator_name":"Junsu Kim","creator_url":"https://huggingface.co/joonsu0109","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","mit","arxiv:2408.03551","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"omages_ABO","keyword":"text-to-3d","description":"This repo hosts the processed data of the ABO dataset for the paper An Object is Worth 64x64 Pixels: Generating 3D Object via Image Diffusion.\nPlease refer to the project homepage, arxiv page and github repo for more details.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset details\n\t\n\nWe first download the .glb ABO shapes, then we turn the .glb files into 1024x1024x12 object images using Blender 4.0. We set the maximum number of patches to 64 and set the margin to be 2%. The 1024 resolution data is in the data/ folderâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/3dlg-hcvc/omages_ABO.","url":"https://huggingface.co/datasets/3dlg-hcvc/omages_ABO","creator_name":"3D Language & Generation Research Group","creator_url":"https://huggingface.co/3dlg-hcvc","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","cc-by-4.0","Image","arxiv:2408.03178","arxiv:2110.06199"],"keywords_longer_than_N":true},
	{"name":"RoboTwin_asset","keyword":"3d","description":"ZanxinChen/RoboTwin_asset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ZanxinChen/RoboTwin_asset","creator_name":"ZanxinChen","creator_url":"https://huggingface.co/ZanxinChen","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"3DRewardDB","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\n\t\n\t\t3DRewardDB\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\n3DRewardDB is a diverse 3D dataset suitable for training and testing models aligned with human preferences. \nTo build the 3DRewardDB, We select 2530 prompts from cap3d, each corresponding to 4-10 3D assets generated using ashawkey/mvdream-sd2.1-diffusers.\nNotice: The complete dataset will be used for commercial purposes, so we have only open-sourced 1000 of the 2530 prompts.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n# 3DRewardDB\n./\nâ”œâ”€â”€ data\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yejunliang23/3DRewardDB.","url":"https://huggingface.co/datasets/yejunliang23/3DRewardDB","creator_name":"yejunliang","creator_url":"https://huggingface.co/yejunliang23","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","English","apache-2.0","Image","arxiv:2403.14613"],"keywords_longer_than_N":true},
	{"name":"MLDSUM_NEW","keyword":"depth-estimation","description":"sandylolpotty/MLDSUM_NEW dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sandylolpotty/MLDSUM_NEW","creator_name":"sandeep","creator_url":"https://huggingface.co/sandylolpotty","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"DyMesh_32f","keyword":"3d","description":"\n\t\n\t\t\n\t\tA Feed-Forward 4D Foundation Model for Text-Driven Universal Mesh Animation (ICCV 2025)\n\t\n\nZijie Wu1,2, Chaohui Yu2, Fan Wang2, Xiang Bai1 \n1Huazhong University of Science and Technology (HUST), 2DAMO Acadamy, Alibaba Group\n\n\n\nWe present AnimateAnyMesh: the first feed-forward universal mesh animation framework that enables efficient motion generation for arbitrary 3D meshes. Given a static mesh and prompt, our method generates high-quality animations in only a few seconds.\n\t\n\t\t\n\t\tâ­â€¦ See the full description on the dataset page: https://huggingface.co/datasets/JarrentWu/DyMesh_32f.","url":"https://huggingface.co/datasets/JarrentWu/DyMesh_32f","creator_name":"Zj Wu","creator_url":"https://huggingface.co/JarrentWu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["English","apache-2.0","arxiv:2506.09982","ðŸ‡ºðŸ‡¸ Region: US","3D"],"keywords_longer_than_N":true},
	{"name":"4dgs","keyword":"3d","description":"Langelaw/4dgs dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Langelaw/4dgs","creator_name":"ZHANG CHI","creator_url":"https://huggingface.co/Langelaw","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"3D-Scene-Segmentation-HQ","keyword":"3d","description":"3D Segmentation HQ Dataset\nThe 3D Segmentation HQ dataset is a curated collection of 5 real-world scenes with high-quality object segmentation masks designed for research in 3D scene understanding, editing, and rendering.\nThis dataset improves upon existing benchmarks by providing cleaner and more consistent object masks across multiple views, enabling reliable evaluation and training for tasks such as:\n\n3D semantic segmentation\nObject-level scene editing (e.g., removal, recolorization)\n3Dâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/joshir/3D-Scene-Segmentation-HQ.","url":"https://huggingface.co/datasets/joshir/3D-Scene-Segmentation-HQ","creator_name":"Raushan","creator_url":"https://huggingface.co/joshir","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","imagefolder","Image","Datasets"],"keywords_longer_than_N":true},
	{"name":"H3DBench","keyword":"3d","description":"Hierarchical 3D Benmark\nThis is an annotation dataset for 3D quality evaluation, including Object-Level, Part-Level and Material-Subject annotations.\nWe also release 3D assets generated from new 3D generative models that are not included in 3DGen-Bench dataset.\n","url":"https://huggingface.co/datasets/anonymous-mY2nG5/H3DBench","creator_name":"mY2nG5","creator_url":"https://huggingface.co/anonymous-mY2nG5","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","image-to-3d","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"H3DBench","keyword":"image-to-3d","description":"Hierarchical 3D Benmark\nThis is an annotation dataset for 3D quality evaluation, including Object-Level, Part-Level and Material-Subject annotations.\nWe also release 3D assets generated from new 3D generative models that are not included in 3DGen-Bench dataset.\n","url":"https://huggingface.co/datasets/anonymous-mY2nG5/H3DBench","creator_name":"mY2nG5","creator_url":"https://huggingface.co/anonymous-mY2nG5","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","image-to-3d","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"H3DBench","keyword":"text-to-3d","description":"Hierarchical 3D Benmark\nThis is an annotation dataset for 3D quality evaluation, including Object-Level, Part-Level and Material-Subject annotations.\nWe also release 3D assets generated from new 3D generative models that are not included in 3DGen-Bench dataset.\n","url":"https://huggingface.co/datasets/anonymous-mY2nG5/H3DBench","creator_name":"mY2nG5","creator_url":"https://huggingface.co/anonymous-mY2nG5","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","image-to-3d","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"EmbodiedEval","keyword":"3d","description":"This repository contains the dataset of the paper EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents.\nGithub repository: https://github.com/thunlp/EmbodiedEval\nProject Page: https://embodiedeval.github.io/\n","url":"https://huggingface.co/datasets/EmbodiedEval/EmbodiedEval","creator_name":"EmbodiedEval","creator_url":"https://huggingface.co/EmbodiedEval","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["robotics","video-text-to-text","English","cc0-1.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"HUVER","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Card for HUVER\n\t\n\n\n\nThe dataset is comprised of a 6,051 unique UAV configurations, where each configuration is described by multiple data for-\nmats, including a grammar string, an RGB image, and an GLB file.\nComplementing these representation modalities, we also provide a configuration-based description, i.e., a text descriptor describing the features of each UAV using natural language\n\nCurated by: Abhiram Karri, Gary Stump, Christopher McComb, Binyang Song\n\nLanguage(s) (NLP):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/raiselab/HUVER.","url":"https://huggingface.co/datasets/raiselab/HUVER","creator_name":"RAISE Lab","creator_url":"https://huggingface.co/raiselab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","image-to-3d","image-feature-extraction","text-to-3d","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"HUVER","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tDataset Card for HUVER\n\t\n\n\n\nThe dataset is comprised of a 6,051 unique UAV configurations, where each configuration is described by multiple data for-\nmats, including a grammar string, an RGB image, and an GLB file.\nComplementing these representation modalities, we also provide a configuration-based description, i.e., a text descriptor describing the features of each UAV using natural language\n\nCurated by: Abhiram Karri, Gary Stump, Christopher McComb, Binyang Song\n\nLanguage(s) (NLP):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/raiselab/HUVER.","url":"https://huggingface.co/datasets/raiselab/HUVER","creator_name":"RAISE Lab","creator_url":"https://huggingface.co/raiselab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","image-to-3d","image-feature-extraction","text-to-3d","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"HUVER","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tDataset Card for HUVER\n\t\n\n\n\nThe dataset is comprised of a 6,051 unique UAV configurations, where each configuration is described by multiple data for-\nmats, including a grammar string, an RGB image, and an GLB file.\nComplementing these representation modalities, we also provide a configuration-based description, i.e., a text descriptor describing the features of each UAV using natural language\n\nCurated by: Abhiram Karri, Gary Stump, Christopher McComb, Binyang Song\n\nLanguage(s) (NLP):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/raiselab/HUVER.","url":"https://huggingface.co/datasets/raiselab/HUVER","creator_name":"RAISE Lab","creator_url":"https://huggingface.co/raiselab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","image-to-3d","image-feature-extraction","text-to-3d","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"Diycncmachinemetaldrawing","keyword":"3d","description":"introvoyz041/Diycncmachinemetaldrawing dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/introvoyz041/Diycncmachinemetaldrawing","creator_name":"Bri Parales","creator_url":"https://huggingface.co/introvoyz041","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"StableText2Brick","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Card for StableText2Brick\n\t\n\nThis dataset contains over 47,000 toy brick structures of over 28,000 unique 3D objects accompanied by detailed captions.\nIt was used to train BrickGPT, the first approach for generating physically stable toy brick models from text prompts, as described in Generating Physically Stable and Buildable Brick Structures from Text.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nRepository: AvaLovelace1/BrickGPT\nPaper: Generating Physically Stableâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AvaLovelace/StableText2Brick.","url":"https://huggingface.co/datasets/AvaLovelace/StableText2Brick","creator_name":"Ava Pun","creator_url":"https://huggingface.co/AvaLovelace","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"StableText2Brick","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Card for StableText2Brick\n\t\n\nThis dataset contains over 47,000 toy brick structures of over 28,000 unique 3D objects accompanied by detailed captions.\nIt was used to train BrickGPT, the first approach for generating physically stable toy brick models from text prompts, as described in Generating Physically Stable and Buildable Brick Structures from Text.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nRepository: AvaLovelace1/BrickGPT\nPaper: Generating Physically Stableâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AvaLovelace/StableText2Brick.","url":"https://huggingface.co/datasets/AvaLovelace/StableText2Brick","creator_name":"Ava Pun","creator_url":"https://huggingface.co/AvaLovelace","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"StableText2Brick","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tDataset Card for StableText2Brick\n\t\n\nThis dataset contains over 47,000 toy brick structures of over 28,000 unique 3D objects accompanied by detailed captions.\nIt was used to train BrickGPT, the first approach for generating physically stable toy brick models from text prompts, as described in Generating Physically Stable and Buildable Brick Structures from Text.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nRepository: AvaLovelace1/BrickGPT\nPaper: Generating Physically Stableâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AvaLovelace/StableText2Brick.","url":"https://huggingface.co/datasets/AvaLovelace/StableText2Brick","creator_name":"Ava Pun","creator_url":"https://huggingface.co/AvaLovelace","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"SynthVPT","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tVPT-Synth-Objects: A Synthetic Dataset for Visual Perspective Taking\n\t\n\nThis is a proof-of-concept synthetic dataset designed for training socio-cognitive foundational models for robotics, specifically in Visual Perspective Taking (VPT). The core task is to enable a robot to infer an object's 6D pose (position and orientation) relative to another agent, given a single RGB image.\nThis dataset was generated using NVIDIA Isaac Sim and Omniverse Replicator. Each entry provides an imageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jwgcurrie/SynthVPT.","url":"https://huggingface.co/datasets/jwgcurrie/SynthVPT","creator_name":"Joel Currie","creator_url":"https://huggingface.co/jwgcurrie","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","robotics","image-feature-extraction","depth-estimation","image-to-text"],"keywords_longer_than_N":true},
	{"name":"SynthVPT","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tVPT-Synth-Objects: A Synthetic Dataset for Visual Perspective Taking\n\t\n\nThis is a proof-of-concept synthetic dataset designed for training socio-cognitive foundational models for robotics, specifically in Visual Perspective Taking (VPT). The core task is to enable a robot to infer an object's 6D pose (position and orientation) relative to another agent, given a single RGB image.\nThis dataset was generated using NVIDIA Isaac Sim and Omniverse Replicator. Each entry provides an imageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jwgcurrie/SynthVPT.","url":"https://huggingface.co/datasets/jwgcurrie/SynthVPT","creator_name":"Joel Currie","creator_url":"https://huggingface.co/jwgcurrie","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","robotics","image-feature-extraction","depth-estimation","image-to-text"],"keywords_longer_than_N":true},
	{"name":"us-in-the-wild","keyword":"image-to-3d","description":"We collect the data following a standardized protocol using a hand-held ultrasound device (Butterfly iQ+ by Butterfly Network Inc., Burlington, MA, USA). We capture video and mid-sagittal images, including the suprapatellar longitudinal view of the suprapatellar recess of the knee. Using this, we capture 10 unique casual sweeps at 30 FPS on multiple unique subjects around the human knee with at least 85 frames in each sweep. All sweeps in this dataset have been captured by the authors onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rishitdagli/us-in-the-wild.","url":"https://huggingface.co/datasets/rishitdagli/us-in-the-wild","creator_name":"Rishit Dagli","creator_url":"https://huggingface.co/rishitdagli","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","apache-2.0","1K<n<10K","Image","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Rockfall_Simulator","keyword":"3d","description":"\n\t\n\t\t\n\t\tRockfall Simulator dataset\n\t\n\nThis dataset contains simulated rockfall measurement dataset using a physical model. For detailed documentation, usage instructions, and data description, please refer to the GitHub repository:https://github.com/zhaoyiww/fusion4landslide. Relevant arXiv paper: arxiv.org/abs/2506.16265.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0).\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/zhaoyiww/Rockfall_Simulator.","url":"https://huggingface.co/datasets/zhaoyiww/Rockfall_Simulator","creator_name":"Zhaoyi Wang","creator_url":"https://huggingface.co/zhaoyiww","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["cc-by-4.0","10M - 100M","text","3D","Image"],"keywords_longer_than_N":true},
	{"name":"T23D-CompBench","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tText-to-3D Comprehensive Benchmark (T23D-CompBench) ðŸŽ¥ðŸ“Š\n\t\n\nCode Â· Project Page Â· Paper@ArXiv Â· Prompt list\nWelcome to the T23D-CompBench dataset! This repository contains around 3,600 textured meshes generated by various models using the Prompt list. These textured meshes have been annotated from twelve evaluation dimensions, including Object Alignment, Attribute Alignment, Interaction Alignment, Overall Alignment, Texture Clarity, Texture Aesthetics, Geometry Loss, Geometryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ccccby/T23D-CompBench.","url":"https://huggingface.co/datasets/ccccby/T23D-CompBench","creator_name":"Bingyang Cui","creator_url":"https://huggingface.co/ccccby","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-to-3d","English","cc-by-4.0","1K<n<10K","arxiv:2509.23841"],"keywords_longer_than_N":true},
	{"name":"T23D-CompBench","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tText-to-3D Comprehensive Benchmark (T23D-CompBench) ðŸŽ¥ðŸ“Š\n\t\n\nCode Â· Project Page Â· Paper@ArXiv Â· Prompt list\nWelcome to the T23D-CompBench dataset! This repository contains around 3,600 textured meshes generated by various models using the Prompt list. These textured meshes have been annotated from twelve evaluation dimensions, including Object Alignment, Attribute Alignment, Interaction Alignment, Overall Alignment, Texture Clarity, Texture Aesthetics, Geometry Loss, Geometryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ccccby/T23D-CompBench.","url":"https://huggingface.co/datasets/ccccby/T23D-CompBench","creator_name":"Bingyang Cui","creator_url":"https://huggingface.co/ccccby","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-to-3d","English","cc-by-4.0","1K<n<10K","arxiv:2509.23841"],"keywords_longer_than_N":true},
	{"name":"meshfleet_arena","keyword":"3d","description":"DamianBoborzi/meshfleet_arena dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/DamianBoborzi/meshfleet_arena","creator_name":"Damian Boborzi","creator_url":"https://huggingface.co/DamianBoborzi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","csv","3D","Image"],"keywords_longer_than_N":true},
	{"name":"1000_Robot_Manipulation_Tasks","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\t1000 Robot Manipulation Tasks\n\t\n\nThis dataset is currently undergoing a phased upload process. Due to its substantial size, the complete data is being incrementally published to ensure stability and integrity during transmission. We appreciate your patience as we finalize the full availability of the dataset.\nThis dataset is distributed under the MIT License. This permissive free software license grants users the freedom to use, copy, modify, merge, publish, distribute, sublicenseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PitVit/1000_Robot_Manipulation_Tasks.","url":"https://huggingface.co/datasets/PitVit/1000_Robot_Manipulation_Tasks","creator_name":"Pietro Vitiello","creator_url":"https://huggingface.co/PitVit","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["robotics","depth-estimation","image-segmentation","object-detection","English"],"keywords_longer_than_N":true},
	{"name":"ArchonView","keyword":"image-to-3d","description":"This is the anonymous version of the ArchonView dataset directory, for review of the paper \"Next-Scale Autoregressive Models are Zero-Shot Single-Image Object View Synthesizers\".\nThe folder checkpoints contains our pretrained checkpoints for each depth setting; eval contains evaluation datasets. training-data is the training dataset rendered from Objaverse, where the four training split shards have to be pieced together into a .tar.gz file first.\n","url":"https://huggingface.co/datasets/anon8567671/ArchonView","creator_name":"anonymous","creator_url":"https://huggingface.co/anon8567671","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"MVRLT","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tMVRLT\n\t\n\n","url":"https://huggingface.co/datasets/BartenderXD/MVRLT","creator_name":"Bartender","creator_url":"https://huggingface.co/BartenderXD","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","text-to-3d","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"MVRLT","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tMVRLT\n\t\n\n","url":"https://huggingface.co/datasets/BartenderXD/MVRLT","creator_name":"Bartender","creator_url":"https://huggingface.co/BartenderXD","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","text-to-3d","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"panorama_hdr_dataset","keyword":"image-to-3d","description":"Panorama HDR images from https://hdri-haven.com/\nCaptions are from Florence-2-large\n","url":"https://huggingface.co/datasets/gokaygokay/panorama_hdr_dataset","creator_name":"gokay aydogan","creator_url":"https://huggingface.co/gokaygokay","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"pbrpx","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Card for PBRPX Asset Library\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata for 710 physically-based rendering (PBR) assets from pbrpx.com, a CC0 asset library. The dataset includes comprehensive information about 3D models, textures, and materials with detailed file listings, download URLs, texture resolutions, and categorization data. Assets include nature elements (trees, rocks), architectural materials (brick, concrete), and various other 3D models withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/pbrpx.","url":"https://huggingface.co/datasets/nyuuzyou/pbrpx","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","image-to-image","found"],"keywords_longer_than_N":true},
	{"name":"pbrpx","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Card for PBRPX Asset Library\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata for 710 physically-based rendering (PBR) assets from pbrpx.com, a CC0 asset library. The dataset includes comprehensive information about 3D models, textures, and materials with detailed file listings, download URLs, texture resolutions, and categorization data. Assets include nature elements (trees, rocks), architectural materials (brick, concrete), and various other 3D models withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/pbrpx.","url":"https://huggingface.co/datasets/nyuuzyou/pbrpx","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","image-to-image","found"],"keywords_longer_than_N":true},
	{"name":"OpenSpaces","keyword":"depth-estimation","description":"\n\n\t\n\t\t\n\t\tOpenSpaces\n\t\n\nThe OpenSpaces dataset is created using VQASynth to synthesize spatialVQA data using images from the first 30K rows \nof the localized narratives split of the cauldron.\nCompared to the related dataset used to train SpaceLLaVA, \nthe OpenSpaces emphasizes greater diversity in the image distribution instead of focusing on warehouse scenes.\nThe following chart shows the distribution of images over tags labeled by CLIP embedding similarity:\nThe OpenSpaces dataset also includesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/remyxai/OpenSpaces.","url":"https://huggingface.co/datasets/remyxai/OpenSpaces","creator_name":"Remyx AI","creator_url":"https://huggingface.co/remyxai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","depth-estimation","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"3DFDReal","keyword":"3d","description":"\n\n\n\t\n\t\t\n\t\tðŸ§µ 3DFDReal: Real-World 3D Fashion Dataset\n\t\n\n\n\t\n\t\t\n\t\tEmpowering Virtual Try-On Applications with High-Quality 3D Fashion Data\n\t\n\n\n\n\nElectronics and Telecommunications Research Institute (ETRI)Media Intellectualization Research Section\n\n\n\n\n\t\n\t\n\t\n\t\tðŸŒŸ Highlights\n\t\n\n\n\n\n\n\n\n\n\t\n\t\t\n\t\tðŸ“Š 1,000+\n\t\n\n3D Point CloudsHigh-quality captures\n\n\n\n\n\t\n\t\t\n\t\tðŸŽ¥ 4K@60fps\n\t\n\nMulti-View VideosProfessional recording\n\n\n\n\n\t\n\t\t\n\t\tðŸ·ï¸ Rich Metadata\n\t\n\nDetailed AnnotationsSemantic labels & attributesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kusses/3DFDReal.","url":"https://huggingface.co/datasets/kusses/3DFDReal","creator_name":"Jiyoun Lim","creator_url":"https://huggingface.co/kusses","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K<n<10K","3D","Text"],"keywords_longer_than_N":true},
	{"name":"SoleilScan","keyword":"3d","description":"\n\nã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯ã€é«˜æ©Ÿèƒ½ãƒ•ã‚©ãƒˆã‚°ãƒ©ãƒ¡ãƒˆãƒªãƒ¼ã‚½ãƒ•ãƒˆã€ŒRealityCapture 1.4ã€ã‚’ä½¿ç”¨ã—ã¦ã€ã‚¯ãƒ©ã‚¤ãƒŸãƒ³ã‚°ã‚¸ãƒ ã®ã‚½ãƒ¬ã‚¤ãƒ¦ã®å£ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚\n\n\t\n\t\t\n\t\n\t\n\t\tãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç›®çš„\n\t\n\n\nã‚½ãƒ¬ã‚¤ãƒ¦ã®ã‚¯ãƒ©ã‚¤ãƒŸãƒ³ã‚°ã‚¦ã‚©ãƒ¼ãƒ«ã‚’é«˜ç²¾åº¦ã§3Dã‚¹ã‚­ãƒ£ãƒ³ã™ã‚‹\nRealityCapture 1.4ã®æ€§èƒ½ã‚’å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§æ¤œè¨¼ã™ã‚‹\nã‚¹ã‚­ãƒ£ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ã€ã‚¯ãƒ©ã‚¤ãƒŸãƒ³ã‚°ã‚¦ã‚©ãƒ¼ãƒ«ã®åˆ†æžã‚„å¯è¦–åŒ–ã‚’è¡Œã†\n\n\n\t\n\t\t\n\t\n\t\n\t\tä½¿ç”¨ã—ãŸã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢\n\t\n\n\nRealityCapture 1.4\niphone14 pro\n\n\n\t\n\t\t\n\t\n\t\n\t\tãƒ‡ãƒ¼ã‚¿\n\t\n\n\nã“ã®ãƒªãƒã‚¸ãƒˆãƒªã«ã¯ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼š\n\né«˜è§£åƒåº¦ã®å†™çœŸï¼ˆRAWå½¢å¼ã¨JPEGå½¢å¼ï¼‰\nRealityCapture 1.4ã§å‡¦ç†ã•ã‚ŒãŸ3Dãƒ¢ãƒ‡ãƒ«ï¼ˆOBJå½¢å¼ã¨FBXå½¢å¼ï¼‰\nãƒ†ã‚¯ã‚¹ãƒãƒ£ç”»åƒ\nãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚¡ã‚¤ãƒ«\n\n\n\t\t\n\t\n\tä»Šå¾Œã®å±•æœ›\n\t\n\n\n3Dãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸã‚¯ãƒ©ã‚¤ãƒŸãƒ³ã‚°ãƒ«ãƒ¼ãƒˆã®åˆ†æž\nVRã‚„ARã§ã®ã‚¯ãƒ©ã‚¤ãƒŸãƒ³ã‚°ã‚¦ã‚©ãƒ¼ãƒ«ã®å¯è¦–åŒ–\n3Dãƒ—ãƒªãƒ³ãƒˆã«ã‚ˆã‚‹æ¨¡åž‹ã®ä½œæˆâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MakiAi/SoleilScan.","url":"https://huggingface.co/datasets/MakiAi/SoleilScan","creator_name":"Sunwood.ai.labs","creator_url":"https://huggingface.co/MakiAi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"DurLAR_S","keyword":"depth-estimation","description":"\n\n\t\n\t\t\n\t\tDurLAR: A High-Fidelity 128-Channel LiDAR Dataset\n\t\n\n\n\t\n\t\t\n\t\tNews\n\t\n\n\n[2024/12/05] We provide the intrinsic parameters of our OS1-128 LiDAR [download].\n\n\n\t\n\t\t\n\t\tSensor placement\n\t\n\n\nLiDAR: Ouster OS1-128 LiDAR sensor with 128 channels vertical resolution\n\nStereo Camera: Carnegie Robotics MultiSense S21 stereo camera with grayscale, colour, and IR enhanced imagers, 2048x1088 @ 2MP resolution\n\nGNSS/INS: OxTS RT3000v3 global navigation satellite and inertial navigation system, supportingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/l1997i/DurLAR_S.","url":"https://huggingface.co/datasets/l1997i/DurLAR_S","creator_name":"Li Li","creator_url":"https://huggingface.co/l1997i","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","English","cc-by-4.0","10K - 100K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"EmbodiedGenRLv2-BG","keyword":"3d","description":"xinjjj/EmbodiedGenRLv2-BG dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/xinjjj/EmbodiedGenRLv2-BG","creator_name":"xinjjj","creator_url":"https://huggingface.co/xinjjj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","text","3D","Image"],"keywords_longer_than_N":true},
	{"name":"SynthHuman","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Card for SynthHuman\n\t\n\n\nThis is a FiftyOne dataset with 3000 samples.\n\n\t\n\t\t\n\t\tInstallation\n\t\n\nIf you haven't already, install FiftyOne:\npip install -U fiftyone\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nimport fiftyone as fo\nfrom fiftyone.utils.huggingface import load_from_hub\n\n# Load the dataset\n# Note: other available arguments include 'max_samples', etc\ndataset = load_from_hub(\"Voxel51/SynthHuman\")\n\n# Launch the App\nsession = fo.launch_app(dataset)\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Voxel51/SynthHuman.","url":"https://huggingface.co/datasets/Voxel51/SynthHuman","creator_name":"Voxel51","creator_url":"https://huggingface.co/Voxel51","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["English","cdla-permissive-2.0","10K - 100K","imagefolder","3D"],"keywords_longer_than_N":true},
	{"name":"M3VIR","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tMÂ³VIR\n\t\n\nIn the field of restoration and 3D reconstruction, particularly for rendered content such as gaming environments, the lack of sufficient ground-truth training data presents a significant challenge. While these techniques are extensively studied in real-world applications, their adaptation to virtual or synthetic environments remains relatively underexplored. This is largely due to the distinct characteristics of rendered content, which differ from natural scenes in terms ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/guluthemonster/M3VIR.","url":"https://huggingface.co/datasets/guluthemonster/M3VIR","creator_name":"Yuanzhi Li","creator_url":"https://huggingface.co/guluthemonster","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","English","mit","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"OmniPart-page-assets","keyword":"3d","description":"omnipart/OmniPart-page-assets dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/omnipart/OmniPart-page-assets","creator_name":"OmniPart","creator_url":"https://huggingface.co/omnipart","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","3D","Datasets","Croissant"],"keywords_longer_than_N":true},
	{"name":"Bottle","keyword":"3d","description":"Venkatakrishnan-Ramesh/Bottle dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Venkatakrishnan-Ramesh/Bottle","creator_name":"Venkatakrishnan R","creator_url":"https://huggingface.co/Venkatakrishnan-Ramesh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","1K - 10K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"Cars_I_like","keyword":"depth-estimation","description":"Basilisk181297/Cars_I_like dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Basilisk181297/Cars_I_like","creator_name":"Basil Minhaj","creator_url":"https://huggingface.co/Basilisk181297","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","depth-estimation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"diode-subset-train","keyword":"depth-estimation","description":"DIODE dataset: https://diode-dataset.org/\nCode to prepare the archive: TBA\n","url":"https://huggingface.co/datasets/sayakpaul/diode-subset-train","creator_name":"Sayak Paul","creator_url":"https://huggingface.co/sayakpaul","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","ðŸ‡ºðŸ‡¸ Region: US","depth-estimation"],"keywords_longer_than_N":false},
	{"name":"DART","keyword":"image-to-3d","description":"\n\n  DART: Articulated Hand Model with Diverse Accessories and Rich Textures\n  \n    Daiheng Gao*\n    Â·\n    Yuliang Xiu*\n    Â·\n    Kailin Li*\n    Â·\n    Lixin Yang*\n    \n    Feng Wang\n    Â·\n    Peng Zhang\n    Â·\n    Bang Zhang\n    Â·\n    Cewu Lu\n   Â·\n    Ping Tan\n  \n  NeurIPS 2022 (Datasets and Benchmarks Track)\n  \n  \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n    \n    \n    \n  \n    \n\n\n\n\n\n\t\n\t\t\n\t\tUpdate\n\t\n\n\n[2022.10.07] DART's raw textures+accessories are released at RAW\n[2022.09.29]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yuliang/DART.","url":"https://huggingface.co/datasets/Yuliang/DART","creator_name":"Yuliang Xiu","creator_url":"https://huggingface.co/Yuliang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","English","mit","100K<n<1M","Image"],"keywords_longer_than_N":true},
	{"name":"Military-Aircraft-Recognition-dataset","keyword":"depth-estimation","description":"This is a remote sensing image Military Aircraft Recognition dataset that include 3842 images, 20 types, and 22341 instances annotated with horizontal bounding boxes and oriented bounding boxes.\n","url":"https://huggingface.co/datasets/Alex5666/Military-Aircraft-Recognition-dataset","creator_name":"Gracio","creator_url":"https://huggingface.co/Alex5666","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-segmentation","image-to-text","image-to-image","object-detection"],"keywords_longer_than_N":true},
	{"name":"img_pointV1","keyword":"3d","description":"\n\n\t\n\t\t\n\t\timg_pointV1\n\t\n\nThis dataset is a collection of 3D point clouds generated from images in the ImageNet-1k VL Enriched dataset (visual-layer/imagenet-1k-vl-enriched).\nEach 2D image is converted into a point cloud where the (X, Y) coordinates correspond to pixel locations, and the Z coordinate (depth/elevation) is derived from the pixel's grayscale intensity. The original image colors are retained as the colors of the points. The point clouds are stored in the GLB format.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/RAY-AUTRA-TECHNOLOGY/img_pointV1.","url":"https://huggingface.co/datasets/RAY-AUTRA-TECHNOLOGY/img_pointV1","creator_name":"RAY AUTRA TECHNOLOGY","creator_url":"https://huggingface.co/RAY-AUTRA-TECHNOLOGY","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","3D","ðŸ‡ºðŸ‡¸ Region: US","vision"],"keywords_longer_than_N":true},
	{"name":"img_pointV1","keyword":"3d","description":"\n\n\t\n\t\t\n\t\timg_pointV1\n\t\n\nThis dataset is a collection of 3D point clouds generated from images in the ImageNet-1k VL Enriched dataset (visual-layer/imagenet-1k-vl-enriched).\nEach 2D image is converted into a point cloud where the (X, Y) coordinates correspond to pixel locations, and the Z coordinate (depth/elevation) is derived from the pixel's grayscale intensity. The original image colors are retained as the colors of the points. The point clouds are stored in the GLB format.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/RAY-AUTRA-TECHNOLOGY/img_pointV1.","url":"https://huggingface.co/datasets/RAY-AUTRA-TECHNOLOGY/img_pointV1","creator_name":"RAY AUTRA TECHNOLOGY","creator_url":"https://huggingface.co/RAY-AUTRA-TECHNOLOGY","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","3D","ðŸ‡ºðŸ‡¸ Region: US","vision"],"keywords_longer_than_N":true},
	{"name":"DSI-Bench","keyword":"3d","description":"\n\t\n\t\t\n\t\tDSI-Bench: A Benchmark for Dynamic Spatial Intelligence\n\t\n\nPaper | Project Page | Code\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nReasoning about dynamic spatial relationships is essential, as both observers and objects often move simultaneously. Although vision-language models (VLMs) and visual expertise models excel in 2D tasks and static scenarios, their ability to fully understand dynamic 3D scenarios remains limited. We introduce Dynamic Spatial Intelligence and propose DSI-Bench, a benchmark withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Viglong/DSI-Bench.","url":"https://huggingface.co/datasets/Viglong/DSI-Bench","creator_name":"ZiangZhang","creator_url":"https://huggingface.co/Viglong","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["video-text-to-text","cc-by-4.0","1K - 10K","Video","3D"],"keywords_longer_than_N":true},
	{"name":"DSI-Bench","keyword":"3d","description":"\n\t\n\t\t\n\t\tDSI-Bench: A Benchmark for Dynamic Spatial Intelligence\n\t\n\nPaper | Project Page | Code\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nReasoning about dynamic spatial relationships is essential, as both observers and objects often move simultaneously. Although vision-language models (VLMs) and visual expertise models excel in 2D tasks and static scenarios, their ability to fully understand dynamic 3D scenarios remains limited. We introduce Dynamic Spatial Intelligence and propose DSI-Bench, a benchmark withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Viglong/DSI-Bench.","url":"https://huggingface.co/datasets/Viglong/DSI-Bench","creator_name":"ZiangZhang","creator_url":"https://huggingface.co/Viglong","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["video-text-to-text","cc-by-4.0","1K - 10K","Video","3D"],"keywords_longer_than_N":true},
	{"name":"Forest_Depth_Estimation_by_Frost_Head","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tForest Depth Estimation by Frost Head\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Frost Head Forest Depth Estimation Dataset is a comprehensive collection of synthetic forest images generated using Unreal Engine 5. This dataset is specifically designed for advanced forest depth estimation research and related applications in the field of computer vision and environmental analysis.\n\n\t\n\t\t\n\t\tDataset Construction\n\t\n\nThe Frost Head Forest Depth Estimation Dataset is constructed using advanced renderingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/frosthead/Forest_Depth_Estimation_by_Frost_Head.","url":"https://huggingface.co/datasets/frosthead/Forest_Depth_Estimation_by_Frost_Head","creator_name":"Ayush Sharma","creator_url":"https://huggingface.co/frosthead","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-image","depth-estimation","apache-2.0","1K<n<10K","Image"],"keywords_longer_than_N":true},
	{"name":"BlendNet","keyword":"3d","description":"\n\t\n\t\t\n\t\tðŸ“š BlendNet\n\t\n\nThe dataset contains $12k$ samples. To balance cost savings with data quality and scale, we manually annotated $2k$ samples and used GPT-4o to annotate the remaining $10k$ samples.\nFor more details, please visit our GitHub repository or refer to our arXiv paper.\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“– Citation\n\t\n\n@misc{du2024blenderllmtraininglargelanguage,\n      title={BlenderLLM: Training Large Language Models for Computer-Aided Design with Self-improvement}, \n      author={Yuhao Du andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/BlendNet.","url":"https://huggingface.co/datasets/FreedomIntelligence/BlendNet","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"Coil100-Augmented","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset derives from Coil100. \nThere are more than 1,1M images of 100 objects. Each object was turned on a turnable through 360 degrees to vary object pose with respect to a fixed color camera. Images of the objects were taken at pose intervals of 5 degrees. This corresponds to 72 poses per object. \nIn addition to the original dataset, planar rotation (9 angles) and  18 scaling factors have been applied so that there are no dependencies between factors.\nObjectsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dappu97/Coil100-Augmented.","url":"https://huggingface.co/datasets/dappu97/Coil100-Augmented","creator_name":"Jacopo Dapueto","creator_url":"https://huggingface.co/dappu97","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-classification","image-to-3d","image-segmentation","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"MATE-3D","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tMulti-DimensionAl Text-to-3D Quality Evaluation Benchmark (MATE-3D) ðŸŽ¥ðŸ“Š\n\t\n\nCode Â· Project Page Â· Paper@ArXiv Â· Prompt list\nWelcome to the MATE-3D dataset! This repository contains around 1,280 textured meshes generated by various models using the Prompt list. These textured meshes have been annotated from four evaluation dimensions, including semantic alignment, geometry quality, texture quality, and overall quality.\n\n\t\n\t\n\t\n\t\tDataset Details ðŸ“š\n\t\n\n\nPaper: Read the PaperCode: Codeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ccccby/MATE-3D.","url":"https://huggingface.co/datasets/ccccby/MATE-3D","creator_name":"Bingyang Cui","creator_url":"https://huggingface.co/ccccby","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-to-3d","English","cc-by-4.0","1K<n<10K","arxiv:2412.11170"],"keywords_longer_than_N":true},
	{"name":"layout_diffusion_scannetpp_voxel0.2","keyword":"text-to-3d","description":"This dataset is used in the paper SceneCraft: Layout-Guided 3D Scene Generation.\n\n\t\n\t\t\n\t\tFile information\n\t\n\nThe repository contains the following file information:\n","url":"https://huggingface.co/datasets/gzzyyxy/layout_diffusion_scannetpp_voxel0.2","creator_name":"YangXiuyu","creator_url":"https://huggingface.co/gzzyyxy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","apache-2.0","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"RefRef","keyword":"image-to-3d","description":"RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects\n\n\n  Yue Yin Â· \n  Enze Tao Â· \n  Weijian Deng Â· \n  Dylan Campbell\n\n\n\n\n  \n    \n  \n  \n  \n  \n  \n  \n  Abstract\n   \n  Modern 3D reconstruction and novel view synthesis approaches have demonstrated strong performance on scenes with opaque Lambertian objects. However, most assume straight light paths and therefore cannot properly handle refractive and reflective materials. Moreover, datasets specialized forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yinyue27/RefRef.","url":"https://huggingface.co/datasets/yinyue27/RefRef","creator_name":"yue's organization","creator_url":"https://huggingface.co/yinyue27","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"GameIR","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tGameIR\n\t\n\nImage restoration techniques such as super-resolution and image synthesis are used in products like NVIDIA's DLSS but are less understood by the public when applied to gaming. This is due to a shortage of relevant ground-truth training data for gaming, which differs from typical content with its distinct, sharp low-resolution images.\nIn this case, we develop GameIR, a large-scale high-quality computer-synthesized ground-truth dataset to fill in the blanks, targeting at 2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLLebin/GameIR.","url":"https://huggingface.co/datasets/LLLebin/GameIR","creator_name":"Lebin Zhou","creator_url":"https://huggingface.co/LLLebin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-image","image-to-3d","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"uniocc","keyword":"3d","description":"\n\t\n\t\t\n\t\tUniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving\n\t\n\n\n\n\n\nPaper | Project Page | Code\n\n\n\nAutonomous Driving researchers, have you ever been bothered by the fact that popular datasets all have their different\nformats, and standardizing them is a pain? Have you ever been frustrated by the difficulty of just understanding\nthe file semantics? This challenge is even worse in the occupancy domain. But, UniOcc is here to help.\n\nUniOcc is a unifiedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tasl-lab/uniocc.","url":"https://huggingface.co/datasets/tasl-lab/uniocc","creator_name":"Trustworthy Autonomous Systems Laboratory","creator_url":"https://huggingface.co/tasl-lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-to-3d","mit","3D","arxiv:2503.24381","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"uniocc","keyword":"3d","description":"\n\t\n\t\t\n\t\tUniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving\n\t\n\n\n\n\n\nPaper | Project Page | Code\n\n\n\nAutonomous Driving researchers, have you ever been bothered by the fact that popular datasets all have their different\nformats, and standardizing them is a pain? Have you ever been frustrated by the difficulty of just understanding\nthe file semantics? This challenge is even worse in the occupancy domain. But, UniOcc is here to help.\n\nUniOcc is a unifiedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tasl-lab/uniocc.","url":"https://huggingface.co/datasets/tasl-lab/uniocc","creator_name":"Trustworthy Autonomous Systems Laboratory","creator_url":"https://huggingface.co/tasl-lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-to-3d","mit","3D","arxiv:2503.24381","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"uniocc","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tUniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving\n\t\n\n\n\n\n\nPaper | Project Page | Code\n\n\n\nAutonomous Driving researchers, have you ever been bothered by the fact that popular datasets all have their different\nformats, and standardizing them is a pain? Have you ever been frustrated by the difficulty of just understanding\nthe file semantics? This challenge is even worse in the occupancy domain. But, UniOcc is here to help.\n\nUniOcc is a unifiedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tasl-lab/uniocc.","url":"https://huggingface.co/datasets/tasl-lab/uniocc","creator_name":"Trustworthy Autonomous Systems Laboratory","creator_url":"https://huggingface.co/tasl-lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-to-3d","mit","3D","arxiv:2503.24381","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"menagerie_mujoco","keyword":"3d","description":"introvoyz041/menagerie_mujoco dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/introvoyz041/menagerie_mujoco","creator_name":"Bri Parales","creator_url":"https://huggingface.co/introvoyz041","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","text","3D","Text"],"keywords_longer_than_N":true},
	{"name":"QuantumAI","keyword":"depth-estimation","description":"Groovy-123/QuantumAI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Groovy-123/QuantumAI","creator_name":"KWAME MARFO","creator_url":"https://huggingface.co/Groovy-123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"QuantumAI","keyword":"text-to-3d","description":"Groovy-123/QuantumAI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Groovy-123/QuantumAI","creator_name":"KWAME MARFO","creator_url":"https://huggingface.co/Groovy-123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"fMRI-Objaverse","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tfMRI-Objaverse\n\t\n\nThis repository contains fMRI-Objaverse, a comprehensive dataset for fMRI-based 3D reconstruction, as presented in the paper MinD-3D++: Advancing fMRI-Based 3D Reconstruction with High-Quality Textured Mesh Generation and a Comprehensive Dataset.\n\nProject Page: https://jianxgao.github.io/MinD-3D\nCode: https://github.com/JianxGao/MinD-3D\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nfMRI-Objaverse is an extended dataset for fMRI-Shape. It is part of the larger fMRI-3D dataset, whichâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fudan-fMRI/fMRI-Objaverse.","url":"https://huggingface.co/datasets/Fudan-fMRI/fMRI-Objaverse","creator_name":"Fudan-fMRI-yanwei","creator_url":"https://huggingface.co/Fudan-fMRI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","apache-2.0","1K - 10K","text","Text"],"keywords_longer_than_N":true},
	{"name":"QuantumAI","keyword":"image-to-3d","description":"Groovy-123/QuantumAI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Groovy-123/QuantumAI","creator_name":"KWAME MARFO","creator_url":"https://huggingface.co/Groovy-123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"ObjaverseSyntheticEditable","keyword":"3d","description":"EmbodiedEval/ObjaverseSyntheticEditable dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/EmbodiedEval/ObjaverseSyntheticEditable","creator_name":"EmbodiedEval","creator_url":"https://huggingface.co/EmbodiedEval","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"wordnet-definitions","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tWordNet Multiple Definitions - Columnar Format\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is an optimized columnar version of WordNet multiple definitions, designed for high-performance queries and rapid extraction.\nEach definition was sourced by GPT-5 Nano. I may update this to include additional definitions in the future, but I will not break the format.\nThe original dataset has a more unabridged and noisy set of data; so I'm definitely going to leave it intact. Noisy training is importantâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AbstractPhil/wordnet-definitions.","url":"https://huggingface.co/datasets/AbstractPhil/wordnet-definitions","creator_name":"AbstractPhila","creator_url":"https://huggingface.co/AbstractPhil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","translation","text-classification","question-answering"],"keywords_longer_than_N":true},
	{"name":"ROBOMASTER-2025-LiDAR-ROSBAG","keyword":"depth-estimation","description":"\n    \n\n\nROBOMASTER-2025 Â· åŽåŒ—ç†å·¥å¤§å­¦HORIZONæˆ˜é˜Ÿ Â· LiDAR ROSBAG\n\n\n\n\t\n\t\t\n\t\tðŸ“– æ¦‚è¿°\n\t\n\n\n\næ•°æ®æ¥æºï¼š åŽåŒ—ç†å·¥å¤§å­¦ HORIZON æˆ˜é˜Ÿ â€” é›·è¾¾ç»„ä¾æ‰˜å¹³å°ï¼š åŽåŒ—ç†å·¥ RM åˆ›æ–°å®žéªŒå®¤å½•åˆ¶æ—¶é—´åœ°ç‚¹ï¼š ROBOMASTER 2025 è¶…çº§å¯¹æŠ—èµ›ï¼ŒåŒ—äº¬ç†å·¥å¤§å­¦ï¼ˆç æµ·ï¼‰å—éƒ¨èµ›åŒºçŽ°åœºå®žå½•æ•°æ®ç”¨é€”ï¼š ROBOMASTER åœºæ™¯ä¸‹çš„ç‚¹äº‘è¯†åˆ«ã€ç›®æ ‡æ£€æµ‹ã€ä¸‰ç»´å»ºå›¾ç­‰ä»»åŠ¡  \n\n\n\n\n\t\n\t\t\n\t\tðŸ—‚ï¸ æ•°æ®æ¦‚è§ˆ\n\t\n\n\n\t\n\t\t\næ–‡ä»¶å\næ—¶é•¿\nå¤§å°\næ¶ˆæ¯æ•°\nç‚¹äº‘è¯é¢˜\n\n\n\t\t\nRM-LiDAR-ROSBAG_01.bag\n13åˆ†22ç§’\n11.2â€¯GB\n8037\n/cloudpoints\n\n\nRM-LiDAR-ROSBAG_02.bag\n13åˆ†59ç§’\n12.9â€¯GB\n8399\n/cloudpoints\n\n\n\t\n\n\næ•°æ®æ ¼å¼ä¸ºæ ‡å‡† ROS 1 .bag æ–‡ä»¶ï¼ŒæœªåŽ‹ç¼©ï¼Œé‡‡æ ·é¢‘çŽ‡çº¦ä¸º 10 Hzã€‚\n\n\n  \n    \n      \n        \n      \n      \n        \n      \n    \n  â€‹\tðŸŽ¥â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BreCaspian/ROBOMASTER-2025-LiDAR-ROSBAG.","url":"https://huggingface.co/datasets/BreCaspian/ROBOMASTER-2025-LiDAR-ROSBAG","creator_name":"Yaosir","creator_url":"https://huggingface.co/BreCaspian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["robotics","object-detection","depth-estimation","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"INS","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dtc111/INS.","url":"https://huggingface.co/datasets/dtc111/INS","creator_name":"Tianchen Deng","creator_url":"https://huggingface.co/dtc111","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["apache-2.0","100M<n<1B","ðŸ‡ºðŸ‡¸ Region: US","3D","Reconstruction"],"keywords_longer_than_N":true},
	{"name":"savage-x3d-generation","keyword":"3d","description":"\n\t\n\t\t\n\t\tSavage X3D Model Generation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nThis dataset enables training of Large Language Models (LLMs) to generate structured 3D models in X3D format from natural language descriptions. It contains 19,712 instruction-following examples derived from the Savage 3D Model Repository maintained by the Naval Postgraduate School.\n\n\t\n\t\t\n\t\tKey Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal Training Examples\n19,712\n\n\nBase X3D Models\n1,232â€¦ See the full description on the dataset page: https://huggingface.co/datasets/stratplans/savage-x3d-generation.","url":"https://huggingface.co/datasets/stratplans/savage-x3d-generation","creator_name":"JosÃ© JimÃ©nez","creator_url":"https://huggingface.co/stratplans","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"VLABench_assets","keyword":"3d","description":"jirufengyu/VLABench_assets dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/jirufengyu/VLABench_assets","creator_name":"wenyoupeng","creator_url":"https://huggingface.co/jirufengyu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","3D","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"psegs-ios-lidar-ext","keyword":"3d","description":"\n\t\n\t\t\n\t\tPSegs iOS Lidar Extension\n\t\n\n\nThis project contains data captured using Lidar-equipped iPhone(s)\nfor use as an extension with the \nPSegs project.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\nthreeDScannerApp_data - This is test data captured\n  using the 3D Scanner App for iOS.\nps_external_test_fixtures - These are fixtures\n  created using the data in this repo and code in \n  PSegs.  They are hosted here and \n  provided to power PSegs unit tests.\n\n","url":"https://huggingface.co/datasets/PSegs/psegs-ios-lidar-ext","creator_name":"Perception Segments","creator_url":"https://huggingface.co/PSegs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"my_smolvla123456789","keyword":"depth-estimation","description":"Amanpatel81/my_smolvla123456789 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Amanpatel81/my_smolvla123456789","creator_name":"Amankumar Patel","creator_url":"https://huggingface.co/Amanpatel81","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","table-question-answering","question-answering","translation","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"MeshFleet","keyword":"3d","description":"This is a curated collection of 3D car models derived from Objaverse-XL described in MeshFleet: Filtered and Annotated 3D Vehicle Dataset for Domain Specific Generative Modeling. The MeshFleet dataset provides metadata for 3D car models, including their SHA256 from Objaverse-XL, vehicle category, and size. The core dataset is available as a CSV file: meshfleet_with_vehicle_categories_df.csv. You can easily load it using pandas:\nimport pandas as pd\n\nmeshfleet_df =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DamianBoborzi/MeshFleet.","url":"https://huggingface.co/datasets/DamianBoborzi/MeshFleet","creator_name":"Damian Boborzi","creator_url":"https://huggingface.co/DamianBoborzi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","apache-2.0","1K - 10K","parquet","3D"],"keywords_longer_than_N":true},
	{"name":"3d-prompt","keyword":"3d","description":"Miguelpef/3d-prompt dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Miguelpef/3d-prompt","creator_name":"Miguel","creator_url":"https://huggingface.co/Miguelpef","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Spanish","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"3d-prompt","keyword":"3d","description":"Miguelpef/3d-prompt dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Miguelpef/3d-prompt","creator_name":"Miguel","creator_url":"https://huggingface.co/Miguelpef","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Spanish","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"MeshFleet","keyword":"image-to-3d","description":"This is a curated collection of 3D car models derived from Objaverse-XL described in MeshFleet: Filtered and Annotated 3D Vehicle Dataset for Domain Specific Generative Modeling. The MeshFleet dataset provides metadata for 3D car models, including their SHA256 from Objaverse-XL, vehicle category, and size. The core dataset is available as a CSV file: meshfleet_with_vehicle_categories_df.csv. You can easily load it using pandas:\nimport pandas as pd\n\nmeshfleet_df =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DamianBoborzi/MeshFleet.","url":"https://huggingface.co/datasets/DamianBoborzi/MeshFleet","creator_name":"Damian Boborzi","creator_url":"https://huggingface.co/DamianBoborzi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","apache-2.0","1K - 10K","parquet","3D"],"keywords_longer_than_N":true},
	{"name":"PhysicalAI-SpatialIntelligence-Lyra-SDG","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tLyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation\n\t\n\nPaper, Project Page, Code\nSherwin Bahmani,\nTianchang Shen,\nJiawei Ren,\nJiahui Huang,\nYifeng Jiang,\nHaithem Turki,\nAndrea Tagliasacchi,\nDavid B. Lindell,\nZan Gojcic,\nSanja Fidler,\nHuan Ling,\nJun Gao,\nXuanchi Ren \n\n\t\n\t\t\n\t\tDataset Description:\n\t\n\nThe PhysicalAI-SpatialIntelligence-Lyra-SDG Dataset is a multi-view 3D and 4D dataset generated using GEN3C. \nThe 3D reconstruction setup uses 59,031 imagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/PhysicalAI-SpatialIntelligence-Lyra-SDG.","url":"https://huggingface.co/datasets/nvidia/PhysicalAI-SpatialIntelligence-Lyra-SDG","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","text-to-3d","cc-by-4.0","arxiv:2509.19296","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"PhysicalAI-SpatialIntelligence-Lyra-SDG","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tLyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation\n\t\n\nPaper, Project Page, Code\nSherwin Bahmani,\nTianchang Shen,\nJiawei Ren,\nJiahui Huang,\nYifeng Jiang,\nHaithem Turki,\nAndrea Tagliasacchi,\nDavid B. Lindell,\nZan Gojcic,\nSanja Fidler,\nHuan Ling,\nJun Gao,\nXuanchi Ren \n\n\t\n\t\t\n\t\tDataset Description:\n\t\n\nThe PhysicalAI-SpatialIntelligence-Lyra-SDG Dataset is a multi-view 3D and 4D dataset generated using GEN3C. \nThe 3D reconstruction setup uses 59,031 imagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/PhysicalAI-SpatialIntelligence-Lyra-SDG.","url":"https://huggingface.co/datasets/nvidia/PhysicalAI-SpatialIntelligence-Lyra-SDG","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","text-to-3d","cc-by-4.0","arxiv:2509.19296","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"gaussian_splatting","keyword":"3d","description":"\n\t\n\t\t\n\t\tGaussian Splats Dataset\n\t\n\n3D Gaussian Splatting for Real-Time Radiance Field Rendering  \nDataset Author: Paula RamosCreated Using: 3D Gaussian Splatting PaperCode Repository: GitHub - graphdeco-inria/gaussian-splatting \n\n\t\n\t\t\n\t\n\t\n\t\tDescription\n\t\n\nThis dataset consists of Gaussian Splats representations of different real-world scenes, created using the official 3D Gaussian Splatting method. Each scene folder contains:\nA reference image representing the scene.\nA PLY file stored in aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Voxel51/gaussian_splatting.","url":"https://huggingface.co/datasets/Voxel51/gaussian_splatting","creator_name":"Voxel51","creator_url":"https://huggingface.co/Voxel51","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","imagefolder","3D"],"keywords_longer_than_N":true},
	{"name":"DSRSTO-dataset","keyword":"3d","description":"the project's GitHub repository: https://github.com/WangYuLin-SEU/KASAL\n\n\n\t\n\t\t\n\t\tDSRSTO-dataset\n\t\n\n\n\t\n\t\t\n\t\t1. Dataset Description\n\t\n\nThe DSRSTO-dataset is a specialized dataset designed to support research on 3D object symmetry. It includes annotations for seven distinct types of symmetries and is composed of 3D models created using 3D CAD software, making it a valuable resource for tasks such as pose estimation, object recognition, and symmetry-based 3D model analysis.\n\n\t\n\t\t\n\t\tKey Features:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SEU-WYL/DSRSTO-dataset.","url":"https://huggingface.co/datasets/SEU-WYL/DSRSTO-dataset","creator_name":"yulin wang","creator_url":"https://huggingface.co/SEU-WYL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","json","3D","Text"],"keywords_longer_than_N":true},
	{"name":"CurveWireframe","keyword":"3d","description":"This repo hosts the processed data of the ABC dataset for the paper CLR-Wire: Towards Continuous Latent Representations for 3D Curve Wireframe Generation (ACM SIGGRAPH 2025).\nPlease refer to the project homepage, arxiv page and github repo for more details.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset details\n\t\n\nWe first download the .step, then we turn the .step files into .npz curve wireframe using pythonocc. We set the maximum number of curves to 128. Please refer to our GitHub repository for instructions onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qixuema/CurveWireframe.","url":"https://huggingface.co/datasets/qixuema/CurveWireframe","creator_name":"Xueqi 'Sebastian' Ma","creator_url":"https://huggingface.co/qixuema","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"CurveWireframe","keyword":"3d","description":"This repo hosts the processed data of the ABC dataset for the paper CLR-Wire: Towards Continuous Latent Representations for 3D Curve Wireframe Generation (ACM SIGGRAPH 2025).\nPlease refer to the project homepage, arxiv page and github repo for more details.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset details\n\t\n\nWe first download the .step, then we turn the .step files into .npz curve wireframe using pythonocc. We set the maximum number of curves to 128. Please refer to our GitHub repository for instructions onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qixuema/CurveWireframe.","url":"https://huggingface.co/datasets/qixuema/CurveWireframe","creator_name":"Xueqi 'Sebastian' Ma","creator_url":"https://huggingface.co/qixuema","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"Diffusion4RobustDepth","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tDiffusion4RobustDepth\n\t\n\nThis repository contains the generated dataset and trained network weights used in the paper \"Diffusion Models for Monocular Depth Estimation: Overcoming Challenging Conditions\" (ECCV 2024).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized into three main categories:\n\ndriving/: Contains autonomous driving datasets with challenging images.\nToM/: Contains the Transparent and Mirrored (ToM) objects dataset.\nweights/: Contains the weights of models trained inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fabiotosi92/Diffusion4RobustDepth.","url":"https://huggingface.co/datasets/fabiotosi92/Diffusion4RobustDepth","creator_name":"Fabio Tosi","creator_url":"https://huggingface.co/fabiotosi92","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","mit","100K - 1M","webdataset","Image"],"keywords_longer_than_N":true},
	{"name":"MeshFleet_TRELLIS","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tMeshFleet: Filtered and Annotated 3D Vehicle Dataset for Domain Specific Generative Modeling\n\t\n\nThis is a processed version of the MeshFleet Dataset using the dataset pipeline from TRELLIS. It contains all the 3D models from the original dataset, but is already preprocessed and ready to use with the TRELLIS training pipeline. For fast loading and processing the dataset is chunked and compressed to webdataset files. All files for each object are stored in a separate file. You can eitherâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DamianBoborzi/MeshFleet_TRELLIS.","url":"https://huggingface.co/datasets/DamianBoborzi/MeshFleet_TRELLIS","creator_name":"Damian Boborzi","creator_url":"https://huggingface.co/DamianBoborzi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","text-to-3d","apache-2.0","arxiv:2503.14002","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"MeshFleet_TRELLIS","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tMeshFleet: Filtered and Annotated 3D Vehicle Dataset for Domain Specific Generative Modeling\n\t\n\nThis is a processed version of the MeshFleet Dataset using the dataset pipeline from TRELLIS. It contains all the 3D models from the original dataset, but is already preprocessed and ready to use with the TRELLIS training pipeline. For fast loading and processing the dataset is chunked and compressed to webdataset files. All files for each object are stored in a separate file. You can eitherâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DamianBoborzi/MeshFleet_TRELLIS.","url":"https://huggingface.co/datasets/DamianBoborzi/MeshFleet_TRELLIS","creator_name":"Damian Boborzi","creator_url":"https://huggingface.co/DamianBoborzi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","text-to-3d","apache-2.0","arxiv:2503.14002","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"Hirthjoint","keyword":"3d","description":"introvoyz041/Hirthjoint dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/introvoyz041/Hirthjoint","creator_name":"Bri Parales","creator_url":"https://huggingface.co/introvoyz041","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"HSRD-100","keyword":"3d","description":"\n\t\n\t\t\n\t\tHSRD-100: 100 High-Quality 3D Human Scans Dataset from HumanScanRepository\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHSRD-100 is a comprehensive 3D human scan dataset featuring 100 high-quality poses from 10 diverse individuals. This dataset provides a balanced representation of human demographics and poses, making it ideal for computer vision, machine learning, and 3D modeling applications.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\nTotal Poses: 100\nUnique Individuals: 10â€¦ See the full description on the dataset page: https://huggingface.co/datasets/digitalrealitylab/HSRD-100.","url":"https://huggingface.co/datasets/digitalrealitylab/HSRD-100","creator_name":"Digital Reality Lab","creator_url":"https://huggingface.co/digitalrealitylab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["keypoint-detection","image-classification","text-to-3d","image-to-3d","other"],"keywords_longer_than_N":true},
	{"name":"HSRD-100","keyword":"3d","description":"\n\t\n\t\t\n\t\tHSRD-100: 100 High-Quality 3D Human Scans Dataset from HumanScanRepository\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHSRD-100 is a comprehensive 3D human scan dataset featuring 100 high-quality poses from 10 diverse individuals. This dataset provides a balanced representation of human demographics and poses, making it ideal for computer vision, machine learning, and 3D modeling applications.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\nTotal Poses: 100\nUnique Individuals: 10â€¦ See the full description on the dataset page: https://huggingface.co/datasets/digitalrealitylab/HSRD-100.","url":"https://huggingface.co/datasets/digitalrealitylab/HSRD-100","creator_name":"Digital Reality Lab","creator_url":"https://huggingface.co/digitalrealitylab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["keypoint-detection","image-classification","text-to-3d","image-to-3d","other"],"keywords_longer_than_N":true},
	{"name":"carla-autopilot-multimodal-dataset","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tCARLA Autopilot Multimodal Dataset\n\t\n\nThis dataset contains synchronized multimodal driving data collected in the CARLA simulator using the autopilot feature. It provides RGB images from multiple cameras, semantic segmentation, LiDAR point clouds, 2D bounding boxes, and ego-vehicle state/control signals across varied weather, maps, and traffic densities.\nThe dataset is designed for research in autonomous driving, sensor fusion, imitation learning, and self-driving evaluation.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/immanuelpeter/carla-autopilot-multimodal-dataset.","url":"https://huggingface.co/datasets/immanuelpeter/carla-autopilot-multimodal-dataset","creator_name":"Immanuel Peter","creator_url":"https://huggingface.co/immanuelpeter","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["object-detection","image-classification","image-segmentation","depth-estimation","video-classification"],"keywords_longer_than_N":true},
	{"name":"HSRD-100","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tHSRD-100: 100 High-Quality 3D Human Scans Dataset from HumanScanRepository\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHSRD-100 is a comprehensive 3D human scan dataset featuring 100 high-quality poses from 10 diverse individuals. This dataset provides a balanced representation of human demographics and poses, making it ideal for computer vision, machine learning, and 3D modeling applications.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\nTotal Poses: 100\nUnique Individuals: 10â€¦ See the full description on the dataset page: https://huggingface.co/datasets/digitalrealitylab/HSRD-100.","url":"https://huggingface.co/datasets/digitalrealitylab/HSRD-100","creator_name":"Digital Reality Lab","creator_url":"https://huggingface.co/digitalrealitylab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["keypoint-detection","image-classification","text-to-3d","image-to-3d","other"],"keywords_longer_than_N":true},
	{"name":"HSRD-100","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tHSRD-100: 100 High-Quality 3D Human Scans Dataset from HumanScanRepository\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHSRD-100 is a comprehensive 3D human scan dataset featuring 100 high-quality poses from 10 diverse individuals. This dataset provides a balanced representation of human demographics and poses, making it ideal for computer vision, machine learning, and 3D modeling applications.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\nTotal Poses: 100\nUnique Individuals: 10â€¦ See the full description on the dataset page: https://huggingface.co/datasets/digitalrealitylab/HSRD-100.","url":"https://huggingface.co/datasets/digitalrealitylab/HSRD-100","creator_name":"Digital Reality Lab","creator_url":"https://huggingface.co/digitalrealitylab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["keypoint-detection","image-classification","text-to-3d","image-to-3d","other"],"keywords_longer_than_N":true},
	{"name":"Advance","keyword":"depth-estimation","description":"Groovy-123/Advance dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Groovy-123/Advance","creator_name":"KWAME MARFO","creator_url":"https://huggingface.co/Groovy-123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Advance","keyword":"image-to-3d","description":"Groovy-123/Advance dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Groovy-123/Advance","creator_name":"KWAME MARFO","creator_url":"https://huggingface.co/Groovy-123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Advance","keyword":"text-to-3d","description":"Groovy-123/Advance dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Groovy-123/Advance","creator_name":"KWAME MARFO","creator_url":"https://huggingface.co/Groovy-123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Any6D","keyword":"3d","description":"taeyeop/Any6D dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/taeyeop/Any6D","creator_name":"Taeyeop Lee","creator_url":"https://huggingface.co/taeyeop","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"EmbodiedOcc-ScanNet","keyword":"image-to-3d","description":"This repository contains the EmbodiedOcc-ScanNet dataset, which is a reorganized benchmark based on local annotations, designed to facilitate the evaluation of the embodied 3D occupancy prediction task. It accompanies the paper EmbodiedOcc: Embodied 3D Occupancy Prediction for Vision-based Online Scene Understanding.\nProject page: https://ykiwu.github.io/EmbodiedOcc/\nCode: https://github.com/YkiWu/EmbodiedOcc\n\n\t\n\t\t\n\t\n\t\n\t\tPaper Abstract\n\t\n\n3D occupancy prediction provides a comprehensiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YkiWu/EmbodiedOcc-ScanNet.","url":"https://huggingface.co/datasets/YkiWu/EmbodiedOcc-ScanNet","creator_name":"YkiWu","creator_url":"https://huggingface.co/YkiWu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["image-to-3d","apache-2.0","arxiv:2412.04380","ðŸ‡ºðŸ‡¸ Region: US","3d-occupancy-prediction"],"keywords_longer_than_N":true},
	{"name":"PRISM","keyword":"3d","description":"\n\t\n\t\t\n\t\tPRISM\n\t\n\n[Paper] [arXiv] [Project Website]\nPurpose-driven Robotic Interaction in Scene Manipulation (PRISM) is a large-scale synthetic dataset for Task-Oriented Grasping featuring cluttered environments and diverse, realistic task descriptions. We use 2365 object instances from ShapeNet-Sem along with stable grasps from ACRONYM to compose 10,000 unique and diverse scenes. Within each scene we capture 10 views, within which there are multiple tasks to be performed. This results in 379kâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/PRISM.","url":"https://huggingface.co/datasets/allenai/PRISM","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["robotics","English","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"PRISM","keyword":"3d","description":"\n\t\n\t\t\n\t\tPRISM\n\t\n\n[Paper] [arXiv] [Project Website]\nPurpose-driven Robotic Interaction in Scene Manipulation (PRISM) is a large-scale synthetic dataset for Task-Oriented Grasping featuring cluttered environments and diverse, realistic task descriptions. We use 2365 object instances from ShapeNet-Sem along with stable grasps from ACRONYM to compose 10,000 unique and diverse scenes. Within each scene we capture 10 views, within which there are multiple tasks to be performed. This results in 379kâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/PRISM.","url":"https://huggingface.co/datasets/allenai/PRISM","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["robotics","English","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"DiffusionGS","keyword":"3d","description":"CaiYuanhao/DiffusionGS dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/CaiYuanhao/DiffusionGS","creator_name":"Yuanhao Cai","creator_url":"https://huggingface.co/CaiYuanhao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","3D","Image","Video"],"keywords_longer_than_N":true},
	{"name":"sweet-corals","keyword":"3d","description":"\n\t\n\t\t\n\t\tCoral reefs 3D photogrammetry\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nWe 3D mapped multiple coral reefs in Indonesia (following this protocol) and sharing all our data with you ðŸ¤—\n\nThis dataset currently contains 90,289 (352GB) of raw GoPro images and some colour-corrected images.\nAdditional data - including camera poses, reconstructed 3D point clouds, 3D polygonal meshes, orthomosaics, annotations, and 3D Gaussian Splatting models - will be added soon. We just decided share raw data right now, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wildflow/sweet-corals.","url":"https://huggingface.co/datasets/wildflow/sweet-corals","creator_name":"wildflow","creator_url":"https://huggingface.co/wildflow","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","imagefolder","Image","3D"],"keywords_longer_than_N":true},
	{"name":"sweet-corals","keyword":"3d","description":"\n\t\n\t\t\n\t\tCoral reefs 3D photogrammetry\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nWe 3D mapped multiple coral reefs in Indonesia (following this protocol) and sharing all our data with you ðŸ¤—\n\nThis dataset currently contains 90,289 (352GB) of raw GoPro images and some colour-corrected images.\nAdditional data - including camera poses, reconstructed 3D point clouds, 3D polygonal meshes, orthomosaics, annotations, and 3D Gaussian Splatting models - will be added soon. We just decided share raw data right now, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wildflow/sweet-corals.","url":"https://huggingface.co/datasets/wildflow/sweet-corals","creator_name":"wildflow","creator_url":"https://huggingface.co/wildflow","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","imagefolder","Image","3D"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-CC-BY-4.0","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-CC-BY-4.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the Creative Commons Attribution 4.0 International (CC-BY-4.0) license. The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:\n\nEnglishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-4.0.","url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-4.0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-CC-BY-4.0","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-CC-BY-4.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the Creative Commons Attribution 4.0 International (CC-BY-4.0) license. The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:\n\nEnglishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-4.0.","url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-4.0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"NeSpoF-segmentation","keyword":"3d","description":"\n\t\n\t\t\n\t\tExtended NeSpoF Dataset\n\t\n\n\n\n\nFabian PerezÂ¹Â² Â· Sara RojasÂ² Â· Carlos HinojosaÂ² Â· Hoover Rueda-ChacÃ³nÂ¹ Â· Bernard GhanemÂ²\nÂ¹Universidad Industrial de Santander Â· Â²King Abdullah University of Science and Technology (KAUST)\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nThis dataset is an extension of the NeSpoF dataset, enriched with ground-truth material labels for evaluating material segmentation in synthetic multi-view settings. The annotations provide consistent material labeling across differentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Factral/NeSpoF-segmentation.","url":"https://huggingface.co/datasets/Factral/NeSpoF-segmentation","creator_name":"Fabian Perez","creator_url":"https://huggingface.co/Factral","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","image-to-3d","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"NeSpoF-segmentation","keyword":"3d","description":"\n\t\n\t\t\n\t\tExtended NeSpoF Dataset\n\t\n\n\n\n\nFabian PerezÂ¹Â² Â· Sara RojasÂ² Â· Carlos HinojosaÂ² Â· Hoover Rueda-ChacÃ³nÂ¹ Â· Bernard GhanemÂ²\nÂ¹Universidad Industrial de Santander Â· Â²King Abdullah University of Science and Technology (KAUST)\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nThis dataset is an extension of the NeSpoF dataset, enriched with ground-truth material labels for evaluating material segmentation in synthetic multi-view settings. The annotations provide consistent material labeling across differentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Factral/NeSpoF-segmentation.","url":"https://huggingface.co/datasets/Factral/NeSpoF-segmentation","creator_name":"Fabian Perez","creator_url":"https://huggingface.co/Factral","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","image-to-3d","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"NeSpoF-segmentation","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tExtended NeSpoF Dataset\n\t\n\n\n\n\nFabian PerezÂ¹Â² Â· Sara RojasÂ² Â· Carlos HinojosaÂ² Â· Hoover Rueda-ChacÃ³nÂ¹ Â· Bernard GhanemÂ²\nÂ¹Universidad Industrial de Santander Â· Â²King Abdullah University of Science and Technology (KAUST)\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nThis dataset is an extension of the NeSpoF dataset, enriched with ground-truth material labels for evaluating material segmentation in synthetic multi-view settings. The annotations provide consistent material labeling across differentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Factral/NeSpoF-segmentation.","url":"https://huggingface.co/datasets/Factral/NeSpoF-segmentation","creator_name":"Fabian Perez","creator_url":"https://huggingface.co/Factral","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-segmentation","image-to-3d","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Turin3D","keyword":"3d","description":"\n\t\n\t\t\n\t\tTurin 3D Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe Turin 3D dataset is a collection of LiDAR point cloud data acquired within the city of Turin, Italy on January 2022 and collected in LAS 1.4 format. It's designed for use in 3D semantic segmentation tasks.\nThis dataset offers a detailed 3D representation of the urban environment, enabling the development and evaluation of semantic segmentation models for urban scenes.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nThis dataset is intended for researchers andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/links-ads/Turin3D.","url":"https://huggingface.co/datasets/links-ads/Turin3D","creator_name":"LINKS - AI, Data & Space","creator_url":"https://huggingface.co/links-ads","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10M<n<100M","3D","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Turin3D","keyword":"3d","description":"\n\t\n\t\t\n\t\tTurin 3D Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe Turin 3D dataset is a collection of LiDAR point cloud data acquired within the city of Turin, Italy on January 2022 and collected in LAS 1.4 format. It's designed for use in 3D semantic segmentation tasks.\nThis dataset offers a detailed 3D representation of the urban environment, enabling the development and evaluation of semantic segmentation models for urban scenes.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nThis dataset is intended for researchers andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/links-ads/Turin3D.","url":"https://huggingface.co/datasets/links-ads/Turin3D","creator_name":"LINKS - AI, Data & Space","creator_url":"https://huggingface.co/links-ads","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10M<n<100M","3D","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"kit-motion-language","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tðŸ•ºðŸ—£ï¸ KIT Motion-Language Dataset\n\t\n\nDisclaimer: ðŸ™ I am not the original author of this dataset. All rights and credit belong to the creators at KIT HÂ²T. This upload is for accessibility purposes only.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3,966 human motion sequences with natural language annotations, collected to enable machine learning research in motion-language understanding.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nðŸƒ Human motion data in C3D and MMM formats\nðŸ“ Natural languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vonexel/kit-motion-language.","url":"https://huggingface.co/datasets/vonexel/kit-motion-language","creator_name":"Nikolai Mozgovoi","creator_url":"https://huggingface.co/vonexel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","English","mit","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Varying_Altitude_Dataset","keyword":"image-to-3d","description":"Varying Altitude Dataset (*Under Review at NeurIPS 2025 data track)\nVarying Altitude Dataset is a multi-scale, multi-view image dataset collected using Google Earth Studio. It captures the same geographic locations from three distinct altitude tiers to support research in 3D reconstruction, camera localization, and novel view synthesis. The tiers include:\nSatellite View: Overhead ortho-images offering a broad, map-like geodetic context.\nAerial View: Captured using a scripted triple-helixâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/letsGoBlind/Varying_Altitude_Dataset.","url":"https://huggingface.co/datasets/letsGoBlind/Varying_Altitude_Dataset","creator_name":"lgb","creator_url":"https://huggingface.co/letsGoBlind","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","afl-3.0","10K<n<100K","Image","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"PrediTree","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tðŸŒ³ PrediTree: A Multi-Temporal Multi-Spectral Sub-Meter Canopy Height Maps Dataset\n\t\n\n\n\n\n\n\n\t\n\t\n\t\n\t\tðŸ“– Overview\n\t\n\nPrediTree is a large-scale multi-temporal, multi-spectral canopy height datasetdesigned for ðŸŒ remote sensing, forestry monitoring, and environmental analysis.All imagery and canopy height products are spatially aligned at 0.5 m resolution, enabling fine-grained tree growth prediction and ecological studies.\n\n\n\t\n\t\t\n\t\tâœ¨ Key Highlights\n\t\n\n\nðŸ“Š Multi-Temporal: 3 yearlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hiyam-d/PrediTree.","url":"https://huggingface.co/datasets/hiyam-d/PrediTree","creator_name":"Hiyam Debary","creator_url":"https://huggingface.co/hiyam-d","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","apache-2.0","100K - 1M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"TRELLIS-500K-fork","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tTRELLIS-500K\n\t\n\nTRELLIS-500K is a dataset of 500K 3D assets curated from Objaverse(XL), ABO, 3D-FUTURE, HSSD, and Toys4k, filtered based on aesthetic scores.\nThis dataset serves for 3D generation tasks.\nIt was introduced in the paper Structured 3D Latents for Scalable and Versatile 3D Generation.\n\n\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\nThe following table summarizes the dataset's filtering and composition:\nNOTE: Some of the 3D assets lack text captions. Please filter out such assets if captionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gqk/TRELLIS-500K-fork.","url":"https://huggingface.co/datasets/gqk/TRELLIS-500K-fork","creator_name":"Jorah Gao","creator_url":"https://huggingface.co/gqk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","text-to-3d","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"genie_data","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tGENIE Dataset\n\t\n\nThis repository contains the data and assets used in the paper GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing, which introduces a hybrid model for interactive editing of Neural Radiance Fields.\nProject page | Code\n\n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset content\n\t\n\nIn the following folders you can find:\n\nblender - our animations with scripts used to generate them\nconfigs - configuration files used during the experimetns shown in our paper\ndata - contains NeRFâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MikolajZ/genie_data.","url":"https://huggingface.co/datasets/MikolajZ/genie_data","creator_name":"MikoÅ‚aj ZieliÅ„ski","creator_url":"https://huggingface.co/MikolajZ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"TRELLIS-500K-fork","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tTRELLIS-500K\n\t\n\nTRELLIS-500K is a dataset of 500K 3D assets curated from Objaverse(XL), ABO, 3D-FUTURE, HSSD, and Toys4k, filtered based on aesthetic scores.\nThis dataset serves for 3D generation tasks.\nIt was introduced in the paper Structured 3D Latents for Scalable and Versatile 3D Generation.\n\n\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\nThe following table summarizes the dataset's filtering and composition:\nNOTE: Some of the 3D assets lack text captions. Please filter out such assets if captionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gqk/TRELLIS-500K-fork.","url":"https://huggingface.co/datasets/gqk/TRELLIS-500K-fork","creator_name":"Jorah Gao","creator_url":"https://huggingface.co/gqk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","text-to-3d","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"MBZUAI-Campus","keyword":"image-to-3d","description":"This dataset provides the necessary files and scripts to reconstruct the MBZUAI campus using COLMAP, GLOMAP, and NERFstudio. It contains preprocessed video sequences and metadata required for hierarchical 3D reconstruction.\n\nThe dataset includes:\n- Raw video sequences\n- Preprocessed frames\n- Calibration and metadata\n- Reconstruction scripts\n\nThe hierarchical reconstruction starts with a base structure, followed by incremental updates with additional sequences.\n","url":"https://huggingface.co/datasets/sebothetramp/MBZUAI-Campus","creator_name":"Sebastian Cavada","creator_url":"https://huggingface.co/sebothetramp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","robotics","other","English","mit"],"keywords_longer_than_N":true},
	{"name":"mujoko","keyword":"3d","description":"introvoyz041/mujoko dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/introvoyz041/mujoko","creator_name":"Bri Parales","creator_url":"https://huggingface.co/introvoyz041","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"Dora-bench-256","keyword":"3d","description":"aruichen/Dora-bench-256 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/aruichen/Dora-bench-256","creator_name":"aruichen","creator_url":"https://huggingface.co/aruichen","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["cc-by-4.0","3D","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"GSO-SAD","keyword":"3d","description":"the project's GitHub repository: https://github.com/WangYuLin-SEU/KASAL\n\n\n\t\n\t\t\n\t\tGoogle Scanned Objects (GSO) Symmetry Axis Dataset\n\t\n\n\n\t\n\t\t\n\t\t1. Dataset Description\n\t\n\nThis dataset is an extension of the Google Scanned Objects (GSO) dataset, enriched with symmetry axis annotations for each object. It is designed to assist in pose estimation tasks by providing explicit symmetry information for objects with both geometric and texture symmetries.\n\n\t\n\t\t\n\t\tKey Features:\n\t\n\nObjects: 3D scannedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SEU-WYL/GSO-SAD.","url":"https://huggingface.co/datasets/SEU-WYL/GSO-SAD","creator_name":"yulin wang","creator_url":"https://huggingface.co/SEU-WYL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","3D","Image","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"StreakNet-Dataset","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tStreakNet-Dataset\n\t\n\n\n\n\nStreakNet-Dataset is an underwater laser imaging dataset for UCLR systems, introduced in the paper StreakNet-Arch: An Anti-scattering Network-based Architecture for Underwater Carrier LiDAR-Radar Imaging. It comprises a collection of streak-tube images captured by a UCLR system at distances of 10m, 13m, 15m, and 20m, contributing 2,695,168 real-world underwater 3D point cloud data.\nFor the associated source code, models, and comprehensive usage instructionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Coder-AN/StreakNet-Dataset.","url":"https://huggingface.co/datasets/Coder-AN/StreakNet-Dataset","creator_name":"Hongjun An","creator_url":"https://huggingface.co/Coder-AN","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["image-to-3d","apache-2.0","arxiv:2404.09158","ðŸ‡ºðŸ‡¸ Region: US","underwater-laser-imaging"],"keywords_longer_than_N":true},
	{"name":"HiRISE-DTMs","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tHiRISE Digital Terrain Models\n\t\n\nHiRISE DTMs are digital terrain models created for the surface of Mars. These DTMs are generated using stereo-matching techniques on two satellite images taken from different angles as part of the High-Resolution Imaging Science Experiment (HiRISE) project.\nThis dataset consists of stereo pairs and their respective digital terrain models. More detailed descriptions about the generation of the digital terrain models are included in [1]. This dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Diffins/HiRISE-DTMs.","url":"https://huggingface.co/datasets/Diffins/HiRISE-DTMs","creator_name":"Diffins Solutions","creator_url":"https://huggingface.co/Diffins","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"robot_descriptions","keyword":"3d","description":"wty-yy/robot_descriptions dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/wty-yy/robot_descriptions","creator_name":"TianyangWu","creator_url":"https://huggingface.co/wty-yy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","3D","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"Dora-diffusion-results","keyword":"3d","description":"aruichen/Dora-diffusion-results dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/aruichen/Dora-diffusion-results","creator_name":"aruichen","creator_url":"https://huggingface.co/aruichen","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","3D","Image","Video"],"keywords_longer_than_N":true},
	{"name":"ycb-fixed-meshes","keyword":"3d","description":"This folder has updated versions of the YCB meshes. All updates are in google_16k folders for each object.\nThe following updated are available:\nnontextured_proc.stl: These are simplified meshes with the normals fixed recommended to be used as collision models. (Note: The normal fixes has to be done manually so not all meshes are verfied, feel free to update them using meshlab, blender, etc).\nnontextured_binvox.bt: These file are voxelised representation of the meshes (resolution up to 1mm).â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ll4ma-lab/ycb-fixed-meshes.","url":"https://huggingface.co/datasets/ll4ma-lab/ycb-fixed-meshes","creator_name":"Utah Learning Lab for Manipulation Autonomy","creator_url":"https://huggingface.co/ll4ma-lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"MESHY.AI_800_GLB_3D-Assets_Categorised_and_Labelled","keyword":"3d","description":"\nMESHY_GLB.zip - 809 Samples GLB/GLTF (Textured, Categorised).\nMESHY_PLY.zip - 788 Samples PLY (Vertex Colored, Uncategorised).\n\nThis dataset is also available in vertex color projected PLY files with an open source model browser that makes the task of creating hand-picked subsets of this dataset fast and easy, you can download it here at: https://archive.org/details/meshy-collection-1.7z\nI curated this selection from assets generated by members of the MESHY.AI Discord server.\nI mostlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tfnn/MESHY.AI_800_GLB_3D-Assets_Categorised_and_Labelled.","url":"https://huggingface.co/datasets/tfnn/MESHY.AI_800_GLB_3D-Assets_Categorised_and_Labelled","creator_name":"James William Fletcher","creator_url":"https://huggingface.co/tfnn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["English","mit","n<1K","3D","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"MESHY.AI_800_GLB_3D-Assets_Categorised_and_Labelled","keyword":"3d","description":"\nMESHY_GLB.zip - 809 Samples GLB/GLTF (Textured, Categorised).\nMESHY_PLY.zip - 788 Samples PLY (Vertex Colored, Uncategorised).\n\nThis dataset is also available in vertex color projected PLY files with an open source model browser that makes the task of creating hand-picked subsets of this dataset fast and easy, you can download it here at: https://archive.org/details/meshy-collection-1.7z\nI curated this selection from assets generated by members of the MESHY.AI Discord server.\nI mostlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tfnn/MESHY.AI_800_GLB_3D-Assets_Categorised_and_Labelled.","url":"https://huggingface.co/datasets/tfnn/MESHY.AI_800_GLB_3D-Assets_Categorised_and_Labelled","creator_name":"James William Fletcher","creator_url":"https://huggingface.co/tfnn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["English","mit","n<1K","3D","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Tel-Aviv-Pics","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tTel Aviv Urban Photography Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 53 high-quality photographs of Tel Aviv's urban environment, captured to serve as reference material for game development, 3D world creation, and digital environment design.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Images: 53 photographs\nLocation: Tel Aviv, Israel\nFormat: JPG\nAverage Size: ~1MB per image\nResolution: High-resolution photographs suitable for texture extraction and reference\nLicense:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/danielrosehill/Tel-Aviv-Pics.","url":"https://huggingface.co/datasets/danielrosehill/Tel-Aviv-Pics","creator_name":"Daniel Rosehill","creator_url":"https://huggingface.co/danielrosehill","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-image","image-to-3d","text-to-image","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"splats","keyword":"3d","description":"kedardes/splats dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kedardes/splats","creator_name":"Kedar Pizza","creator_url":"https://huggingface.co/kedardes","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"SIU3R","keyword":"image-to-3d","description":"This is the official Hugging Face repository for SIU3R: Simultaneous Scene Understanding and 3D Reconstruction Beyond Feature Alignment.\nProject Page: https://insomniaaac.github.io/siu3r/\nCode: https://github.com/WU-CVGL/SIU3R\n\n\t\n\t\t\n\t\tPretrained Models for SIU3R\n\t\n\nWe provide pretrained models for the Panoptic Segmentation task. We train MASt3R backbone with adapter on the COCO dataset for SIU3R initialization.\n\n\t\n\t\t\n\t\tPreprocessed Scannet Dataset for SIU3R Training\n\t\n\nThis dataset is aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/insomnia7/SIU3R.","url":"https://huggingface.co/datasets/insomnia7/SIU3R","creator_name":"XuQi","creator_url":"https://huggingface.co/insomnia7","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","image-segmentation","text-retrieval","mit","arxiv:2507.02705"],"keywords_longer_than_N":true},
	{"name":"gauss_gym_data","keyword":"3d","description":"escontra/gauss_gym_data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/escontra/gauss_gym_data","creator_name":"Alejandro Escontrela","creator_url":"https://huggingface.co/escontra","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","json","3D","Datasets"],"keywords_longer_than_N":true},
	{"name":"3D-NEXRAD","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Card for 3D-NEXRAD\n\t\n\n\n\n3D gridded radar reflectivity data collected from the U.S.NEXRAD WSR-88D radar network. \n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nThe 3D-NEXRDA dataset comprises 3D radar observations of severe storm events across the United States, with each event captured at different geographic locations. \nThe dataset provides high-resolution insights into storm dynamics with high temporal and spatial resolution.\n\nTemporal Coverage:\n\nTime Span: 2020.01.01 - 2022.12.31â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ziyeeee/3D-NEXRAD.","url":"https://huggingface.co/datasets/Ziyeeee/3D-NEXRAD","creator_name":"Ziye Wang","creator_url":"https://huggingface.co/Ziyeeee","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["cc-by-4.0","ðŸ‡ºðŸ‡¸ Region: US","3D","Radar","Prediction"],"keywords_longer_than_N":false},
	{"name":"Printer","keyword":"3d","description":"introvoyz041/Printer dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/introvoyz041/Printer","creator_name":"Bri Parales","creator_url":"https://huggingface.co/introvoyz041","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","text","3D","Text"],"keywords_longer_than_N":true},
	{"name":"atlas-large","keyword":"3d","description":"This is an extended version of the ATLAS dataset at https://huggingface.co/datasets/ggxxii/ATLAS. This dataset contains text prompts, uv textures and different views of the rendered RGB images using SMPL model and AMASS poses. The original ATLAS dataset was released with the paper TexDreamer. The details of the paper can be found at author's github page at https://ggxxii.github.io/texdreamer. This extended version of dataset is created to aid an easy implementation of the TexDreamer paper.\n","url":"https://huggingface.co/datasets/navintiwari/atlas-large","creator_name":"Navin Tiwari","creator_url":"https://huggingface.co/navintiwari","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"atlas-large","keyword":"3d","description":"This is an extended version of the ATLAS dataset at https://huggingface.co/datasets/ggxxii/ATLAS. This dataset contains text prompts, uv textures and different views of the rendered RGB images using SMPL model and AMASS poses. The original ATLAS dataset was released with the paper TexDreamer. The details of the paper can be found at author's github page at https://ggxxii.github.io/texdreamer. This extended version of dataset is created to aid an easy implementation of the TexDreamer paper.\n","url":"https://huggingface.co/datasets/navintiwari/atlas-large","creator_name":"Navin Tiwari","creator_url":"https://huggingface.co/navintiwari","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-image","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"nyuv2","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tNYUv2\n\t\n\nThis is an unofficial and preprocessed version of NYU Depth Dataset V2 made available for easier integration with modern ML workflows. The dataset was converted from the original .mat format into a split structure with embedded RGB images, depth maps, semantic masks, and instance masks in Hugging Face-compatible format.\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“¸ Sample Visualization\n\t\n\n\n  \n    \n      \n        \n        RGB\n      \n      \n        \n        Depth (Jet colormap)\n        \n        Semantic Maskâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jagennath-hari/nyuv2.","url":"https://huggingface.co/datasets/jagennath-hari/nyuv2","creator_name":"Jagennath Hari","creator_url":"https://huggingface.co/jagennath-hari","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","image-segmentation","image-feature-extraction","English","mit"],"keywords_longer_than_N":true},
	{"name":"3DComicScene","keyword":"3d","description":"\n\t\n\t\t\n\t\tæ¼«ç”» 3D åœºæ™¯æ•°æ®é›†\n\t\n\n\n\t\n\t\t\n\t\tæ•´ä½“ç»“æž„\n\t\n\n\nArchitecture: åŒ…å«å»ºç­‘ç›¸å…³çš„æ–‡ä»¶ï¼Œç»†åˆ†ä¸ºä¸åŒç±»åž‹çš„å»ºç­‘ï¼ˆå¦‚ä¸­å›½å¤ä»£å»ºç­‘ã€çŽ°ä»£å»ºç­‘ã€å¤–å›½å»ºç­‘ç­‰ï¼‰ï¼Œå¹¶ä¸”æ¯ç§å»ºç­‘ç±»åž‹ä¸‹åˆæœ‰å®¤å†…ã€å®¤å¤–ã€ææ–™ã€ç½‘æ ¼ç­‰å­ç›®å½•ã€‚\n\nCharacters: åŒ…å«å„ç§è§’è‰²çš„æ–‡ä»¶ï¼Œåˆ†ä¸ºåŠ¨ç‰©ï¼ˆå¦‚æ°´ç”ŸåŠ¨ç‰©ã€é¸Ÿç±»ã€å“ºä¹³åŠ¨ç‰©ã€çˆ¬è¡ŒåŠ¨ç‰©ï¼‰ã€å¹»æƒ³è§’è‰²å’Œäººç±»ï¼ˆç”·æ€§ã€å¥³æ€§ï¼‰ç­‰ã€‚\n\nMisc: åŒ…å«å„ç§æ‚é¡¹å†…å®¹ï¼Œåˆ†ä¸ºæŠ½è±¡ã€å¹»æƒ³ã€åŽ†å²å’Œç§‘å¹»ç­‰ç±»åˆ«ã€‚\n\nNature: åŒ…å«è‡ªç„¶ç›¸å…³çš„æ–‡ä»¶ï¼Œç»†åˆ†ä¸ºé£Žæ™¯ã€æ¤ç‰©ã€å²©çŸ³ã€æ ‘æœ¨å’Œæ°´ä½“ï¼ˆå¦‚æ¹–æ³Šã€æµ·æ´‹ã€æ²³æµï¼‰ç­‰ã€‚\n\nObjects: åŒ…å«å„ç§ç‰©ä½“çš„æ–‡ä»¶ï¼Œåˆ†ä¸ºè¡£ç‰©ã€ç”µå­äº§å“ã€å®¶å…·ã€åŽ¨æˆ¿ç”¨å…·ã€å·¥å…·å’Œæ­¦å™¨ï¼ˆå†·å…µå™¨å’Œç«å™¨ï¼‰ç­‰ã€‚\n\nTextures: åŒ…å«ä¸åŒæè´¨çš„çº¹ç†æ–‡ä»¶ï¼Œå¦‚é™¶ç“·ã€å¸ƒæ–™ã€çŽ»ç’ƒã€é‡‘å±žã€å¡‘æ–™ã€çŸ³æå’Œæœ¨æç­‰ã€‚\n\nVehicles: åŒ…å«å„ç§äº¤é€šå·¥å…·çš„æ–‡ä»¶ï¼Œåˆ†ä¸ºè‡ªè¡Œè½¦ã€æ±½è½¦ã€é£žæœºã€èˆ¹åªå’Œç«è½¦ç­‰ã€‚\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tæ•°æ®å­˜å‚¨æ ‡å‡†\n\t\n\næ¯ä¸€ä¸ªç±»åˆ«æ–‡ä»¶å¤¹éƒ½åŒ…å«è‹¥å¹²å­æ–‡ä»¶å¤¹ï¼Œæœ€åŽä¸€çº§å­æ–‡ä»¶å¤¹ä¸­æœ‰ä¸‰ä¸ªæ•°æ®æ–‡ä»¶å¤¹ï¼š\n\nimagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Asianfleet/3DComicScene.","url":"https://huggingface.co/datasets/Asianfleet/3DComicScene","creator_name":"WonderComicJourney","creator_url":"https://huggingface.co/Asianfleet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"360-USID","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nWe present the 360-USID dataset in AuraFusion360: Augmented Unseen Region Alignment for Reference-based 360Â° Unbounded Scene Inpainting.\nWe introduce first 360Â° Unbounded Scenes Inpaint-\ning Dataset (360-USID), consisting of seven scenes with\ntraining views (RGB images and object masks), novel test-\ning views (inpainting ground truth), camera poses, and a reference view\n(without objects) for evaluating with other reference-based\nmethods.\nWe further collect and processâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kkennethwu/360-USID.","url":"https://huggingface.co/datasets/kkennethwu/360-USID","creator_name":"Chung-Ho Wu","creator_url":"https://huggingface.co/kkennethwu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","apache-2.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"ambientcg","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Card for AmbientCG Textures and HDRIs\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 14,202 high-quality texture images and HDRI environments from ambientcg.com. It includes a comprehensive collection of materials such as fabric, metal, wood, stone, concrete, nature elements, and HDRI skyboxes for 3D rendering and computer graphics applications. The original archives were downloaded, unpacked, and images were compressed using PNG optimization and JPEG quality compressionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/ambientcg.","url":"https://huggingface.co/datasets/nyuuzyou/ambientcg","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","image-to-image","found"],"keywords_longer_than_N":true},
	{"name":"ambientcg","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Card for AmbientCG Textures and HDRIs\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 14,202 high-quality texture images and HDRI environments from ambientcg.com. It includes a comprehensive collection of materials such as fabric, metal, wood, stone, concrete, nature elements, and HDRI skyboxes for 3D rendering and computer graphics applications. The original archives were downloaded, unpacked, and images were compressed using PNG optimization and JPEG quality compressionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/ambientcg.","url":"https://huggingface.co/datasets/nyuuzyou/ambientcg","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-to-text","text-to-image","image-to-image","found"],"keywords_longer_than_N":true},
	{"name":"bilarf_data","keyword":"3d","description":"\n\t\n\t\t\n\t\tBilaRF Dataset\n\t\n\nProject Page | Arxiv | Code\nThis dataset contains our own captured nighttime scenes, synthetic data generated from RawNeRF dataset, and editing samples.\nTo use the data, please go to 'Files and versions' and download 'bilarf_data.zip'.\nThe source images with EXIF metadata are available for download at this Google Drive link.\nThe dataset follows the file structure of NeRF LLFF data (forward-facing scenes).\nIn addition, editing samples are stored in the 'edits/'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yuehao/bilarf_data.","url":"https://huggingface.co/datasets/Yuehao/bilarf_data","creator_name":"Yuehao Wang","creator_url":"https://huggingface.co/Yuehao","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","imagefolder","Image","3D"],"keywords_longer_than_N":true},
	{"name":"bilarf_data","keyword":"3d","description":"\n\t\n\t\t\n\t\tBilaRF Dataset\n\t\n\nProject Page | Arxiv | Code\nThis dataset contains our own captured nighttime scenes, synthetic data generated from RawNeRF dataset, and editing samples.\nTo use the data, please go to 'Files and versions' and download 'bilarf_data.zip'.\nThe source images with EXIF metadata are available for download at this Google Drive link.\nThe dataset follows the file structure of NeRF LLFF data (forward-facing scenes).\nIn addition, editing samples are stored in the 'edits/'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yuehao/bilarf_data.","url":"https://huggingface.co/datasets/Yuehao/bilarf_data","creator_name":"Yuehao Wang","creator_url":"https://huggingface.co/Yuehao","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","imagefolder","Image","3D"],"keywords_longer_than_N":true},
	{"name":"MOVIS","keyword":"image-to-3d","description":"This repository contains the dataset for the paper MOVIS: Enhancing Multi-Object Novel View Synthesis for Indoor Scenes.\nProject page: https://jason-aplp.github.io/MOVIS/\nCode: https://github.com/Jason-aplp/MOVIS-code\n","url":"https://huggingface.co/datasets/JasonAplp/MOVIS","creator_name":"Ruijie Lu","creator_url":"https://huggingface.co/JasonAplp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-to-3d","mit","arxiv:2412.11457","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"COIL-100","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tDataset Card for COIL-100\n\t\n\n\nThis is a FiftyOne dataset with 7200 samples.\n\n\t\n\t\t\n\t\tInstallation\n\t\n\nIf you haven't already, install FiftyOne:\npip install -U fiftyone\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nimport fiftyone as fo\nimport fiftyone.utils.huggingface as fouh\n\n# Load the dataset\n# Note: other available arguments include 'max_samples', etc\ndataset = fouh.load_from_hub(\"Voxel51/COIL-100\")\n\n# Launch the App\nsession = fo.launch_app(dataset)\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Voxel51/COIL-100.","url":"https://huggingface.co/datasets/Voxel51/COIL-100","creator_name":"Voxel51","creator_url":"https://huggingface.co/Voxel51","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","image-to-3d","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"DyMesh_16f","keyword":"3d","description":"\n\t\n\t\t\n\t\tA Feed-Forward 4D Foundation Model for Text-Driven Universal Mesh Animation (ICCV 2025)\n\t\n\nZijie Wu1,2, Chaohui Yu2, Fan Wang2, Xiang Bai1 \n1Huazhong University of Science and Technology (HUST), 2DAMO Acadamy, Alibaba Group\n\n\n\nWe present AnimateAnyMesh: the first feed-forward universal mesh animation framework that enables efficient motion generation for arbitrary 3D meshes. Given a static mesh and prompt, our method generates high-quality animations in only a few seconds.\n\t\n\t\t\n\t\tâ­â€¦ See the full description on the dataset page: https://huggingface.co/datasets/JarrentWu/DyMesh_16f.","url":"https://huggingface.co/datasets/JarrentWu/DyMesh_16f","creator_name":"Zj Wu","creator_url":"https://huggingface.co/JarrentWu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["English","apache-2.0","arxiv:2506.09982","ðŸ‡ºðŸ‡¸ Region: US","3D"],"keywords_longer_than_N":true},
	{"name":"3DCoMPaT200","keyword":"3d","description":"\n\t\n\t\t\n\t\t3DCoMPaT200 Dataset\n\t\n\nThe 3DCoMPaT200 dataset is a comprehensive collection of 3D objects with compositional part annotations. This repository contains various formats and versions of the dataset organized for different use cases.\n\n\t\n\t\t\n\t\tðŸ“ Directory Structure\n\t\n\n\n\t\n\t\t\n\t\t2D Folder\n\t\n\nContains train, validation, and test data in tar format for 10 compositions:\n\nTraining set\nValidation set\nTest set\n\nEach file contains 2D representations of the objects with their correspondingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CoMPaT/3DCoMPaT200.","url":"https://huggingface.co/datasets/CoMPaT/3DCoMPaT200","creator_name":"CoMPaT","creator_url":"https://huggingface.co/CoMPaT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["cc-by-4.0","1M - 10M","webdataset","3D","Image"],"keywords_longer_than_N":true},
	{"name":"ByteCameraDepth","keyword":"3d","description":"\n\t\n\t\t\n\t\tByteCameraDepth Dataset\n\t\n\nPaper | Project Page | Code\nByteCameraDepth is a multi-camera depth estimation dataset containing synchronized depth, color, and auxiliary data captured from various 3D cameras. The dataset provides comprehensive depth sensing from multiple cameras in various in-door scenarios, making it ideal for developing and evaluating depth estimation algorithms.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\n\nPurpose: Multi-camera depth estimation research and benchmarking\nTotalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ByteDance-Seed/ByteCameraDepth.","url":"https://huggingface.co/datasets/ByteDance-Seed/ByteCameraDepth","creator_name":"ByteDance Seed","creator_url":"https://huggingface.co/ByteDance-Seed","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","cc-by-4.0","100K - 1M","webdataset","Image"],"keywords_longer_than_N":true},
	{"name":"ByteCameraDepth","keyword":"3d","description":"\n\t\n\t\t\n\t\tByteCameraDepth Dataset\n\t\n\nPaper | Project Page | Code\nByteCameraDepth is a multi-camera depth estimation dataset containing synchronized depth, color, and auxiliary data captured from various 3D cameras. The dataset provides comprehensive depth sensing from multiple cameras in various in-door scenarios, making it ideal for developing and evaluating depth estimation algorithms.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\n\nPurpose: Multi-camera depth estimation research and benchmarking\nTotalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ByteDance-Seed/ByteCameraDepth.","url":"https://huggingface.co/datasets/ByteDance-Seed/ByteCameraDepth","creator_name":"ByteDance Seed","creator_url":"https://huggingface.co/ByteDance-Seed","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","cc-by-4.0","100K - 1M","webdataset","Image"],"keywords_longer_than_N":true},
	{"name":"Luminous","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kskip/Luminous.","url":"https://huggingface.co/datasets/Kskip/Luminous","creator_name":"William Kyle Skipper","creator_url":"https://huggingface.co/Kskip","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","summarization","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"ByteCameraDepth","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tByteCameraDepth Dataset\n\t\n\nPaper | Project Page | Code\nByteCameraDepth is a multi-camera depth estimation dataset containing synchronized depth, color, and auxiliary data captured from various 3D cameras. The dataset provides comprehensive depth sensing from multiple cameras in various in-door scenarios, making it ideal for developing and evaluating depth estimation algorithms.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\n\nPurpose: Multi-camera depth estimation research and benchmarking\nTotalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ByteDance-Seed/ByteCameraDepth.","url":"https://huggingface.co/datasets/ByteDance-Seed/ByteCameraDepth","creator_name":"ByteDance Seed","creator_url":"https://huggingface.co/ByteDance-Seed","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","cc-by-4.0","100K - 1M","webdataset","Image"],"keywords_longer_than_N":true},
	{"name":"Wild-SLAM","keyword":"image-to-3d","description":"This repository contains data for WildGS-SLAM: Monocular Gaussian Splatting SLAM in Dynamic Environments.\nPaper | Project Page | Code\nWildGS-SLAM accurately tracks the camera trajectory and reconstructs a 3D Gaussian map for static elements from a monocular video sequence, effectively removing dynamic components.\n\n\t\n\t\t\n\t\n\t\n\t\tDatasets Used\n\t\n\nWildGS-SLAM uses data from the following datasets:\n\nWild-SLAM Mocap Dataset: (Hugging Face)  Download instructions are available in the github repository.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gradient-spaces/Wild-SLAM.","url":"https://huggingface.co/datasets/gradient-spaces/Wild-SLAM","creator_name":"Gradient Spaces Research Group","creator_url":"https://huggingface.co/gradient-spaces","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","apache-2.0","Image","arxiv:2504.03886","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Totalsegmentor_Pelvis_Bone_Recon_Dataset","keyword":"3d","description":"HajihajihaJimmy/Totalsegmentor_Pelvis_Bone_Recon_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/HajihajihaJimmy/Totalsegmentor_Pelvis_Bone_Recon_Dataset","creator_name":"Jixiang Chen","creator_url":"https://huggingface.co/HajihajihaJimmy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","imagefolder","3D"],"keywords_longer_than_N":true},
	{"name":"helvipad","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tHELVIPAD: A Real-World Dataset for Omnidirectional Stereo Depth Estimation \n\t\n\nThe Helvipad dataset is a real-world stereo dataset designed for omnidirectional depth estimation. It comprises 39,553 paired equirectangular images captured using a top-bottom 360Â° camera setup and corresponding pixel-wise depth and disparity labels derived from LiDAR point clouds. The dataset spans diverse indoor and outdoor scenes under varying lighting conditions, including night-time environments.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/chcorbi/helvipad.","url":"https://huggingface.co/datasets/chcorbi/helvipad","creator_name":"Charles CorbiÃ¨re","creator_url":"https://huggingface.co/chcorbi","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","original","cc0-1.0","10K<n<100K","Image"],"keywords_longer_than_N":true},
	{"name":"helvipad","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tHELVIPAD: A Real-World Dataset for Omnidirectional Stereo Depth Estimation \n\t\n\nThe Helvipad dataset is a real-world stereo dataset designed for omnidirectional depth estimation. It comprises 39,553 paired equirectangular images captured using a top-bottom 360Â° camera setup and corresponding pixel-wise depth and disparity labels derived from LiDAR point clouds. The dataset spans diverse indoor and outdoor scenes under varying lighting conditions, including night-time environments.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/chcorbi/helvipad.","url":"https://huggingface.co/datasets/chcorbi/helvipad","creator_name":"Charles CorbiÃ¨re","creator_url":"https://huggingface.co/chcorbi","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","original","cc0-1.0","10K<n<100K","Image"],"keywords_longer_than_N":true},
	{"name":"PhysDreamer","keyword":"3d","description":"This dataset contains datas, and pretrained models in paper PhysDreamer: Physics-Based Interaction with 3D Objects via Video Generation. [website] \n\n\t\n\t\t\n\t\tUsage\n\t\n\nphysics_dreamer.zip contains images, camera poses and optimized 3D Gaussians for four scenes: alocasia, carnation, telephone and hat. \nmodels.zip contains optimized models (velocity fields and material fields) for four scenes: alocasia, carnation, telephone and hat. \n","url":"https://huggingface.co/datasets/YunjinZhang/PhysDreamer","creator_name":"Tianyuan Zhang","creator_url":"https://huggingface.co/YunjinZhang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"STEM2Mat","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tAutoMat Benchmark: STEM Image to Crystal Structure\n\t\n\nThe AutoMat Benchmark is a multimodal dataset designed to evaluate deepâ€‘learning systems for iDPC-STEMâ€‘based crystalâ€‘structure reconstruction and property prediction.\nCode: https://github.com/yyt-2378/AutoMat\n\n\n\t\n\t\t\n\t\tðŸ“ Dataset Structure\n\t\n\nThe dataset is organized into three tiers of increasing difficulty:\nbenchmark/\nâ”œâ”€â”€ tier1/\nâ”‚   â”œâ”€â”€ img/          # STEM images (e.g., PNG, TIFF)\nâ”‚   â”œâ”€â”€ label/        # Atomic position labelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yaotianvector/STEM2Mat.","url":"https://huggingface.co/datasets/yaotianvector/STEM2Mat","creator_name":"yang","creator_url":"https://huggingface.co/yaotianvector","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"TactileDreamFusion","keyword":"3d","description":"Ruihan28/TactileDreamFusion dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Ruihan28/TactileDreamFusion","creator_name":"Ruihan Gao","creator_url":"https://huggingface.co/Ruihan28","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"simple-chairs","keyword":"3d","description":"andyye/simple-chairs dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/andyye/simple-chairs","creator_name":"andyye","creator_url":"https://huggingface.co/andyye","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","3D","Text"],"keywords_longer_than_N":true},
	{"name":"HO-Tracker","keyword":"3d","description":"\n\t\n\t\t\n\t\tHO-Tracker Challenge â€” HANDS Workshop @ ICCV 2025\n\t\n\n\n\t\n\t\t\n\t\tDataset\n\t\n\nSample training data is provided in data/train_sample.\nTo browse the dataset locally:\n# Step 1: Install dependencies\npip install open3d==0.18.0\npip install git+https://github.com/lixiny/manotorch.git\n\n# Step 2: Download the MANO model from https://mano.is.tue.nl/downloads/\n#         Place the extracted MANO assets under the `data/` directory\n#         (e.g., `data/mano_v1_2`).\n\n# Step 3: Launch the viewer\npythonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LiKailin/HO-Tracker.","url":"https://huggingface.co/datasets/LiKailin/HO-Tracker","creator_name":"Kailin Li","creator_url":"https://huggingface.co/LiKailin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","English","mit","3D","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"HO-Tracker","keyword":"3d","description":"\n\t\n\t\t\n\t\tHO-Tracker Challenge â€” HANDS Workshop @ ICCV 2025\n\t\n\n\n\t\n\t\t\n\t\tDataset\n\t\n\nSample training data is provided in data/train_sample.\nTo browse the dataset locally:\n# Step 1: Install dependencies\npip install open3d==0.18.0\npip install git+https://github.com/lixiny/manotorch.git\n\n# Step 2: Download the MANO model from https://mano.is.tue.nl/downloads/\n#         Place the extracted MANO assets under the `data/` directory\n#         (e.g., `data/mano_v1_2`).\n\n# Step 3: Launch the viewer\npythonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LiKailin/HO-Tracker.","url":"https://huggingface.co/datasets/LiKailin/HO-Tracker","creator_name":"Kailin Li","creator_url":"https://huggingface.co/LiKailin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","English","mit","3D","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"mipnerf360","keyword":"image-to-3d","description":"nvs-bench/mipnerf360 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/nvs-bench/mipnerf360","creator_name":"nvs-bench","creator_url":"https://huggingface.co/nvs-bench","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"EmbodiedGenRLv2","keyword":"3d","description":"xinjjj/EmbodiedGenRLv2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/xinjjj/EmbodiedGenRLv2","creator_name":"xinjjj","creator_url":"https://huggingface.co/xinjjj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"SVAD","keyword":"3d","description":"gqy2468/SVAD dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/gqy2468/SVAD","creator_name":"guoqiya","creator_url":"https://huggingface.co/gqy2468","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","text","3D","Image"],"keywords_longer_than_N":true},
	{"name":"fida","keyword":"3d","description":"ttVeelo/fida dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ttVeelo/fida","creator_name":"Hossein Ghazanfari","creator_url":"https://huggingface.co/ttVeelo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"surprise-3d","keyword":"3d","description":"\n\t\n\t\t\n\t\tSURPRISE3D Dataset\n\t\n\nðŸ“„ Paper: SURPRISE3D: A Dataset for Spatial Understanding and Reasoning in Complex 3D Scenes\nðŸ”— arXiv: arxiv:2507.07781\nðŸ’» Code: GitHub Repository\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nSURPRISE3D is a novel dataset designed to evaluate language-guided spatial reasoning segmentation in complex 3D scenes. As detailed in our paper, this dataset addresses the critical gap in current 3D vision-language research where existing datasets often mix semantic cues with spatialâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hhllzz/surprise-3d.","url":"https://huggingface.co/datasets/hhllzz/surprise-3d","creator_name":"hanlue zhang","creator_url":"https://huggingface.co/hhllzz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","English","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"surprise-3d","keyword":"3d","description":"\n\t\n\t\t\n\t\tSURPRISE3D Dataset\n\t\n\nðŸ“„ Paper: SURPRISE3D: A Dataset for Spatial Understanding and Reasoning in Complex 3D Scenes\nðŸ”— arXiv: arxiv:2507.07781\nðŸ’» Code: GitHub Repository\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nSURPRISE3D is a novel dataset designed to evaluate language-guided spatial reasoning segmentation in complex 3D scenes. As detailed in our paper, this dataset addresses the critical gap in current 3D vision-language research where existing datasets often mix semantic cues with spatialâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hhllzz/surprise-3d.","url":"https://huggingface.co/datasets/hhllzz/surprise-3d","creator_name":"hanlue zhang","creator_url":"https://huggingface.co/hhllzz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","English","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-CC-BY-3.0","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-CC-BY-3.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the Creative Commons Attribution 3.0 (CC-BY-3.0) license. The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:\n\nEnglish (en): Allâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-3.0.","url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-3.0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"OpenGameArt-CC-BY-3.0","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Card for OpenGameArt-CC-BY-3.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains game artwork assets collected from OpenGameArt.org that are specifically released under the Creative Commons Attribution 3.0 (CC-BY-3.0) license. The dataset includes various types of game assets such as 2D art, 3D art, concept art, music, sound effects, textures, and documents along with their associated metadata.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily monolingual:\n\nEnglish (en): Allâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-3.0.","url":"https://huggingface.co/datasets/nyuuzyou/OpenGameArt-CC-BY-3.0","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["image-classification","text-classification","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"csvps","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tCityscapes VPS\n\t\n\nThis dataset is derived from the videos in the validation split of the Cityscapes[^1] dataset.\nIt aggregates the images and metadata from Cityscapes[^1], Cityscapes-VPS[^2] and Cityscapes-DVPS[^3] into a single structured format. \nThis comprehensive derivative was created out of the need for a batteries-included variant of the dataset for academic purposes.\nSpecifically, joining samples from the individual datasets in their original structure (each is organizedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/khwstolle/csvps.","url":"https://huggingface.co/datasets/khwstolle/csvps","creator_name":"Kurt H.W. Stolle","creator_url":"https://huggingface.co/khwstolle","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","image-segmentation","video-classification","object-detection","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"FreeSplatterStatic","keyword":"3d","description":"bluestyle97/FreeSplatterStatic dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/bluestyle97/FreeSplatterStatic","creator_name":"Jiale Xu","creator_url":"https://huggingface.co/bluestyle97","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"DTTD2-IPhone","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tDTTD-Mobile: Digital Twin Tracking Dataset Calibrated with a Optical MoCap System and a Mobile Device\n\t\n\nðŸ¤” Are current 3D object tracking methods truely robust enough for low-fidelity depth sensors like the iPhone LiDAR? We provide a new dataset on a mobile device: 18 objects observed in 100 videos with 47,668 sampled frames and 114,143 object annotations.\nðŸŒ¹ If our work is useful or relevant to your research, please kindly recognize our contributions by citing our papers:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZixunH/DTTD2-IPhone.","url":"https://huggingface.co/datasets/ZixunH/DTTD2-IPhone","creator_name":"Zixun Huang","creator_url":"https://huggingface.co/ZixunH","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["robotics","object-detection","depth-estimation","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"EuLearn","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3D objects representing a topologically diverse collection of surfaces, each generated from closed, parameterized curves with varying number of self-intersections (singular knots). \nThe surfaces are organized by topological genus, ranging from 0 to 10. \nFor each surface, we included the following four files:\n\nNon-Smoothed STL Mesh (*_ns.stl): A 3D mesh of the surface with sharp geometry and unmodified vertex positions. This version retainsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/appliedgeometry/EuLearn.","url":"https://huggingface.co/datasets/appliedgeometry/EuLearn","creator_name":"Applied Geometry Lab","creator_url":"https://huggingface.co/appliedgeometry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","graph-ml","text-to-3d","tabular-regression","other"],"keywords_longer_than_N":true},
	{"name":"dvrk_model","keyword":"3d","description":"introvoyz041/dvrk_model dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/introvoyz041/dvrk_model","creator_name":"Bri Parales","creator_url":"https://huggingface.co/introvoyz041","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"EuLearn","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3D objects representing a topologically diverse collection of surfaces, each generated from closed, parameterized curves with varying number of self-intersections (singular knots). \nThe surfaces are organized by topological genus, ranging from 0 to 10. \nFor each surface, we included the following four files:\n\nNon-Smoothed STL Mesh (*_ns.stl): A 3D mesh of the surface with sharp geometry and unmodified vertex positions. This version retainsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/appliedgeometry/EuLearn.","url":"https://huggingface.co/datasets/appliedgeometry/EuLearn","creator_name":"Applied Geometry Lab","creator_url":"https://huggingface.co/appliedgeometry","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","graph-ml","text-to-3d","tabular-regression","other"],"keywords_longer_than_N":true},
	{"name":"rnaglib","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset contains the tasks provided by rnaglib, a benchmarking suite for RNA structure-function modelling.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThis dataset is a Python package wrapping RNA benchmark datasets and tasks. Data access, preprocessing, and task-specific pipelines are implemented in code and not fully expressed through this metadata schema. See documentation at https://github.com/cgoliver/rnaglib.\n\nCurated by:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/luiswyss/rnaglib.","url":"https://huggingface.co/datasets/luiswyss/rnaglib","creator_name":"Luis Wyss","creator_url":"https://huggingface.co/luiswyss","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["graph-ml","mit","1K - 10K","text","Text"],"keywords_longer_than_N":true},
	{"name":"deepsearch-llama-finetune","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tDeepSearch Llama Finetune Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe DeepSearch Llama Finetune Dataset is a specialized collection of high-quality, real-world prompts and responses, meticulously crafted for fine-tuning Llama-based conversational AI models. This dataset is optimized for:\n\nCreativity: Responses are original, engaging, and leverage creative formats (Markdown, tables, outlines, etc.).\nEffectiveness: Answers are highly relevant, actionable, and tailored for real-world applications.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/enosislabs/deepsearch-llama-finetune.","url":"https://huggingface.co/datasets/enosislabs/deepsearch-llama-finetune","creator_name":"Enosis Labs, Inc.","creator_url":"https://huggingface.co/enosislabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","depth-estimation","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Recycling","keyword":"3d","description":"introvoyz041/Recycling dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/introvoyz041/Recycling","creator_name":"Bri Parales","creator_url":"https://huggingface.co/introvoyz041","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"3d-arena","keyword":"3d","description":"For more information, visit the 3D Arena Space.\nInputs are sourced from iso3D.\nTo assist with easily running inputs, are input image URLs are provided in inputs.txt.\n","url":"https://huggingface.co/datasets/dylanebert/3d-arena","creator_name":"Dylan Ebert","creator_url":"https://huggingface.co/dylanebert","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","1K - 10K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"3d-arena","keyword":"image-to-3d","description":"For more information, visit the 3D Arena Space.\nInputs are sourced from iso3D.\nTo assist with easily running inputs, are input image URLs are provided in inputs.txt.\n","url":"https://huggingface.co/datasets/dylanebert/3d-arena","creator_name":"Dylan Ebert","creator_url":"https://huggingface.co/dylanebert","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","1K - 10K","imagefolder","3D","Image"],"keywords_longer_than_N":true},
	{"name":"uco3d","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Card for UnCommon Objects in 3D\n\t\n\n\nThis is a FiftyOne dataset with 52 samples.\n\n\t\n\t\t\n\t\tInstallation\n\t\n\nIf you haven't already, install FiftyOne:\npip install -U fiftyone\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nimport fiftyone as fo\nfrom fiftyone.utils.huggingface import load_from_hub\n\n# Load the dataset\n# Note: other available arguments include 'max_samples', etc\ndataset = load_from_hub(\"Voxel51/uco3d\")\n\n# Launch the App\nsession = fo.launch_app(dataset)\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Voxel51/uco3d.","url":"https://huggingface.co/datasets/Voxel51/uco3d","creator_name":"Voxel51","creator_url":"https://huggingface.co/Voxel51","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","cc-by-4.0","< 1K","3D"],"keywords_longer_than_N":true},
	{"name":"uco3d","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Card for UnCommon Objects in 3D\n\t\n\n\nThis is a FiftyOne dataset with 52 samples.\n\n\t\n\t\t\n\t\tInstallation\n\t\n\nIf you haven't already, install FiftyOne:\npip install -U fiftyone\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nimport fiftyone as fo\nfrom fiftyone.utils.huggingface import load_from_hub\n\n# Load the dataset\n# Note: other available arguments include 'max_samples', etc\ndataset = load_from_hub(\"Voxel51/uco3d\")\n\n# Launch the App\nsession = fo.launch_app(dataset)\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Voxel51/uco3d.","url":"https://huggingface.co/datasets/Voxel51/uco3d","creator_name":"Voxel51","creator_url":"https://huggingface.co/Voxel51","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","cc-by-4.0","< 1K","3D"],"keywords_longer_than_N":true},
	{"name":"genie_demo_data","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tGENIE Demo Dataset\n\t\n\nThis is a small demo subset of the full GENIE dataset for interactive editing of Neural Radiance Fields.\nProject page | Paper | Code\n\n\t\n\t\t\n\t\n\t\n\t\tDownloading\n\t\n\nTo download please use commands:\ngit lfs install\ngit clone https://huggingface.co/datasets/MikolajZ/genie_demo_data\n\n\n\t\n\t\n\t\n\t\tðŸ“„ Citation\n\t\n\nIf you use this demo, please cite:\n@misc{zielinski2025genie,\n  title     = {GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing},\n  author    =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MikolajZ/genie_demo_data.","url":"https://huggingface.co/datasets/MikolajZ/genie_demo_data","creator_name":"MikoÅ‚aj ZieliÅ„ski","creator_url":"https://huggingface.co/MikolajZ","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"map-anything","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tMapAnything Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains pre-computed metadata and covisibility matrices for supporting the MapAnything codebase. This metadata enables easy reproducible training and benchmarking for feed-forward 3D reconstruction tasks.\nPlease see our Data Processing README for more details.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use this dataset in your research, please cite our paper:\n@inproceedings{keetha2025mapanything,\n  title={{MapAnything}: Universalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/map-anything.","url":"https://huggingface.co/datasets/facebook/map-anything","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["image-to-3d","depth-estimation","English","apache-2.0","100B<n<1T"],"keywords_longer_than_N":true},
	{"name":"map-anything","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tMapAnything Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains pre-computed metadata and covisibility matrices for supporting the MapAnything codebase. This metadata enables easy reproducible training and benchmarking for feed-forward 3D reconstruction tasks.\nPlease see our Data Processing README for more details.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use this dataset in your research, please cite our paper:\n@inproceedings{keetha2025mapanything,\n  title={{MapAnything}: Universalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/map-anything.","url":"https://huggingface.co/datasets/facebook/map-anything","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["image-to-3d","depth-estimation","English","apache-2.0","100B<n<1T"],"keywords_longer_than_N":true},
	{"name":"GTA5-MultiDomain","keyword":"image-to-3d","description":"zgh456/GTA5-MultiDomain dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zgh456/GTA5-MultiDomain","creator_name":"Gehao Zhang","creator_url":"https://huggingface.co/zgh456","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-to-3d","image-feature-extraction","English","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"map-anything","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tMapAnything Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains pre-computed metadata and covisibility matrices for supporting the MapAnything codebase. This metadata enables easy reproducible training and benchmarking for feed-forward 3D reconstruction tasks.\nPlease see our Data Processing README for more details.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use this dataset in your research, please cite our paper:\n@inproceedings{keetha2025mapanything,\n  title={{MapAnything}: Universalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/map-anything.","url":"https://huggingface.co/datasets/facebook/map-anything","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["image-to-3d","depth-estimation","English","apache-2.0","100B<n<1T"],"keywords_longer_than_N":true},
	{"name":"ML-Proto-Dataset","keyword":"3d","description":"gle3D/ML-Proto-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/gle3D/ML-Proto-Dataset","creator_name":"Glenn","creator_url":"https://huggingface.co/gle3D","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","csv","3D","Image"],"keywords_longer_than_N":true},
	{"name":"Edit3D-Bench","keyword":"image-to-3d","description":"\n\t\n\t\t\n\t\tEdit3D-Bench\n\t\n\nPaper | Project Page | Code\nEdit3D-Bench is a benchmark for 3D editing evaluation, introduced in the paper VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space.\nThis dataset comprises 100 high-quality 3D models, with 50 selected from Google Scanned Objects (GSO) and 50 from PartObjaverse-Tiny.\nFor each model, we provide 3 distinct editing prompts. Each prompt is accompanied by a complete set of annotated 3D assets, including\n\noriginal 3D assetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/huanngzh/Edit3D-Bench.","url":"https://huggingface.co/datasets/huanngzh/Edit3D-Bench","creator_name":"zehuan-huang","creator_url":"https://huggingface.co/huanngzh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","text-to-3d","English","mit","Image"],"keywords_longer_than_N":true},
	{"name":"Edit3D-Bench","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tEdit3D-Bench\n\t\n\nPaper | Project Page | Code\nEdit3D-Bench is a benchmark for 3D editing evaluation, introduced in the paper VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space.\nThis dataset comprises 100 high-quality 3D models, with 50 selected from Google Scanned Objects (GSO) and 50 from PartObjaverse-Tiny.\nFor each model, we provide 3 distinct editing prompts. Each prompt is accompanied by a complete set of annotated 3D assets, including\n\noriginal 3D assetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/huanngzh/Edit3D-Bench.","url":"https://huggingface.co/datasets/huanngzh/Edit3D-Bench","creator_name":"zehuan-huang","creator_url":"https://huggingface.co/huanngzh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-3d","text-to-3d","English","mit","Image"],"keywords_longer_than_N":true},
	{"name":"StereoFromCarla","keyword":"depth-estimation","description":"\n\t\n\t\t\n\t\tStereoFromCarla\n\t\n\n[ðŸ“‚ GitHub] \n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nWelcome to the StereoFromCarla Open Dataset! This dataset is designed to support research and development in the field of Stereo Depth Estimation. The dataset is composed of data collected from CARLA simulator.\nThe subset of finished Stereo Dataset, Normal Town01, is uploaded here. The whole dataset is uploaded through bypy.\n\n\t\n\t\t\n\t\tData List\n\t\n\n\n\t\n\t\t\n\t\tStereoFromCarla\n\t\n\nNormal Town01\n\n\t\n\t\t\n\t\tStereoFromCarlaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wrl2003/StereoFromCarla.","url":"https://huggingface.co/datasets/wrl2003/StereoFromCarla","creator_name":"Rangdy Wang","creator_url":"https://huggingface.co/wrl2003","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["depth-estimation","image-to-image","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"ShapeNet-C13","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\tShapeNet C13 Dataset\n\t\n\nThis repository contains the ShapeNet C13 dataset, introduced in TriCoLo: Trimodal Contrastive Loss for Text to Shape Retrieval.\n\n\t\n\t\t\n\t\tIntroducation\n\t\n\nShapeNet C13 dataset contains paired shapes and captions for 13 object categories from ShapeNet.\n\n\t\n\t\t\n\t\tDataset Attributes\n\t\n\nmodel_id: the model identifier as defined in ShapeNet. synset_id: the category (synset) identifier as defined in ShapeNet. description: the textual caption describing the 3D model.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/3dlg-hcvc/ShapeNet-C13.","url":"https://huggingface.co/datasets/3dlg-hcvc/ShapeNet-C13","creator_name":"3D Language & Generation Research Group","creator_url":"https://huggingface.co/3dlg-hcvc","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"404mini","keyword":"text-to-3d","description":"\n\t\n\t\t\n\t\t404-GEN Mini 3D\n\t\n\nThis dataset contains over 20,000 3D assets generated with text prompts using 3D Gaussian Splatting, designed for text-to-3D generation tasks. This is a sample of a much larger dataset comprised of 21.5M assets and 40TB in size, available by request at https://dataset.404.xyz\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n404-GEN Mini 3D is a collection of over 20,000 3D assets generated from text prompts on Bittensor Subnet 17, providing mid- andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/404-Gen/404mini.","url":"https://huggingface.co/datasets/404-Gen/404mini","creator_name":"404â€”GEN","creator_url":"https://huggingface.co/404-Gen","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-3d","English","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"pbflbm-part-orientation","keyword":"3d","description":"\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe following directory structure is consistent across all datasets. Each geometry is assigned an unique identifier: {dataset_name}_00000000 where {dataset_name} is the name of the dataset and 00000000 is an 8-digit number starting from zero.\nEach dataset has two main folders: info and stl. The info folder contains metadata about each geometry in JSON format, including geometric parameters, random rotation applied to the geometry, reverse transformation (label) inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sebius/pbflbm-part-orientation.","url":"https://huggingface.co/datasets/sebius/pbflbm-part-orientation","creator_name":"Sebastian Wenger","creator_url":"https://huggingface.co/sebius","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","3D","doi:10.57967/hf/4458","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"GridNet-HD","keyword":"3d","description":"\n\t\n\t\t\n\t\tðŸ—‚ GridNet-HD dataset\n\t\n\n\n\t\n\t\t\n\t\t1. Introduction\n\t\n\nThis dataset was developed for 3D semantic segmentation task using both images and 3D point clouds specialized on electrical infrastructure.\nGrid (electrical) Network at High Density and High Resolution represents the first Image+LiDAR dataset accurately co-referenced in the electrical infrastructure domain.\nThis dataset is associated with a public leaderboard hosted on Hugging Face Spaces, available at: leaderboard.\nThe dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/heig-vd-geo/GridNet-HD.","url":"https://huggingface.co/datasets/heig-vd-geo/GridNet-HD","creator_name":"HEIG-Vd Geomatic","creator_url":"https://huggingface.co/heig-vd-geo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"GridNet-HD","keyword":"3d","description":"\n\t\n\t\t\n\t\tðŸ—‚ GridNet-HD dataset\n\t\n\n\n\t\n\t\t\n\t\t1. Introduction\n\t\n\nThis dataset was developed for 3D semantic segmentation task using both images and 3D point clouds specialized on electrical infrastructure.\nGrid (electrical) Network at High Density and High Resolution represents the first Image+LiDAR dataset accurately co-referenced in the electrical infrastructure domain.\nThis dataset is associated with a public leaderboard hosted on Hugging Face Spaces, available at: leaderboard.\nThe dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/heig-vd-geo/GridNet-HD.","url":"https://huggingface.co/datasets/heig-vd-geo/GridNet-HD","creator_name":"HEIG-Vd Geomatic","creator_url":"https://huggingface.co/heig-vd-geo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Microsoft_Learn","keyword":"depth-estimation","description":"PetraAI/Microsoft_Learn dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/PetraAI/Microsoft_Learn","creator_name":"Shady BA","creator_url":"https://huggingface.co/PetraAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","fill-mask","sentence-similarity","summarization"],"keywords_longer_than_N":true}
]
;
